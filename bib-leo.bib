
@article{zhu_federated_2021,
	title = {Federated learning on non-{IID} data: {A} survey},
	volume = {465},
	issn = {0925-2312},
	shorttitle = {Federated learning on non-{IID} data},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231221013254},
	doi = {10.1016/j.neucom.2021.07.098},
	abstract = {Federated learning is an emerging distributed machine learning framework for privacy preservation. However, models trained in federated learning usually have worse performance than those trained in the standard centralized learning mode, especially when the training data are not independent and identically distributed (Non-IID) on the local devices. In this survey, we provide a detailed analysis of the influence of Non-IID data on both parametric and non-parametric machine learning models in both horizontal and vertical federated learning. In addition, current research work on handling challenges of Non-IID data in federated learning are reviewed, and both advantages and disadvantages of these approaches are discussed. Finally, we suggest several future research directions before concluding the paper.},
	urldate = {2024-05-16},
	journal = {Neurocomputing},
	author = {Zhu, Hangyu and Xu, Jinjin and Liu, Shiqing and Jin, Yaochu},
	month = nov,
	year = {2021},
	keywords = {Federated learning, Machine learning, Non-IID data, Privacy preservation},
	pages = {371--390},
}

@inproceedings{aouedi_intrusion_2022,
	title = {Intrusion detection for {Softwarized} {Networks} with {Semi}-supervised {Federated} {Learning}},
	url = {https://ieeexplore.ieee.org/document/9839042},
	doi = {10.1109/ICC45855.2022.9839042},
	abstract = {With the increasing development of 5G/Beyond 5G and network softwarization techniques, we have more flexibility and agility in the network. This can be exploited by Machine Learning (ML) to integrate intelligence in the network and improve network as well as service management in edge-cloud environment. Intrusion detection systems (IDS) is one of the challenging issues for managing network. However, traditional approaches in this domain require all data (and their associated labels) to be centralized at the same location. In this context, such approaches lead to: (i) a large bandwidth overhead, as raw data needs to be transmitted to the server, (ii) low incentives for devices to send their private data, and (iii) large computing and storage resources needed on the server side to label and treat all this data. In this paper, to cope with the above limitations, we propose a semi-supervised federated learning model for IDS. Moreover, we use network softwarisation for automation and deployment. Our model combines Federated Learning and Semi-Supervised Learning where the clients train unsupervised models (using unlabeled data) to learn the representative and low-dimensional features and the server conducts a supervised model (using labeled data). We evaluate this approach on the well-known UNSW-NB15 dataset and the experimental results demonstrate that our approach can achieve accuracy and detection rates up to 84.32\% and 83.10\%, respectively while keeping the data private with limited overhead.},
	urldate = {2024-04-25},
	booktitle = {{ICC} 2022 - {IEEE} {International} {Conference} on {Communications}},
	author = {Aouedi, Ons and Piamrat, Kandaraj and Muller, Guillaume and Singh, Kamal},
	month = may,
	year = {2022},
	note = {ISSN: 1938-1883},
	keywords = {Automation, Bandwidth, Computational modeling, Deep Learning, Federated Learning, Image edge detection, Internet of Things, Intrusion Detection, Intrusion detection, Machine Learning, Machine learning, Semi-supervised learning, Semisupervised learning, \_read, ⛔ No DOI found},
	pages = {5244--5249},
}

@article{campos_evaluating_2022,
	title = {Evaluating {Federated} {Learning} for intrusion detection in {Internet} of {Things}: {Review} and challenges},
	volume = {203},
	issn = {1389-1286},
	shorttitle = {Evaluating {Federated} {Learning} for intrusion detection in {Internet} of {Things}},
	url = {https://www.sciencedirect.com/science/article/pii/S1389128621005405},
	doi = {10.1016/j.comnet.2021.108661},
	abstract = {The application of Machine Learning (ML) techniques to the well-known intrusion detection systems (IDS) is key to cope with increasingly sophisticated cybersecurity attacks through an effective and efficient detection process. In the context of the Internet of Things (IoT), most ML-enabled IDS approaches use centralized approaches where IoT devices share their data with data centers for further analysis. To mitigate privacy concerns associated with centralized approaches, in recent years the use of Federated Learning (FL) has attracted a significant interest in different sectors, including healthcare and transport systems. However, the development of FL-enabled IDS for IoT is in its infancy, and still requires research efforts from various areas, in order to identify the main challenges for the deployment in real-world scenarios. In this direction, our work evaluates a FL-enabled IDS approach based on a multiclass classifier considering different data distributions for the detection of different attacks in an IoT scenario. In particular, we use three different settings that are obtained by partitioning the recent ToN\_IoT dataset according to IoT devices’ IP address and types of attack. Furthermore, we evaluate the impact of different aggregation functions according to such setting by using the recent IBMFL framework as FL implementation. Additionally, we identify a set of challenges and future directions based on the existing literature and the analysis of our evaluation results.},
	urldate = {2024-04-25},
	journal = {Computer Networks},
	author = {Campos, Enrique Mármol and Saura, Pablo Fernández and González-Vidal, Aurora and Hernández-Ramos, José L. and Bernabé, Jorge Bernal and Baldini, Gianmarco and Skarmeta, Antonio},
	month = feb,
	year = {2022},
	keywords = {+survey, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Networking and Internet Architecture, Federated Learning, Internet of Things, Intrusion detection systems, \_processed, ⛔ No DOI found},
	pages = {108661},
}

@article{wagner_cyber_2019,
	title = {Cyber threat intelligence sharing: {Survey} and research directions},
	volume = {87},
	issn = {01674048},
	doi = {10.1016/j.cose.2019.101589},
	abstract = {Cyber Threat Intelligence (CTI) sharing has become a novel weapon in the arsenal of cyber defenders to proactively mitigate increasing cyber attacks. Automating the process of CTI sharing, and even the basic consumption, has raised new challenges for researchers and practitioners. This extensive literature survey explores the current state-of-the-art and approaches different problem areas of interest pertaining to the larger field of sharing cyber threat intelligence. The motivation for this research stems from the recent emergence of sharing cyber threat intelligence and the involved challenges of automating its processes. This work comprises a considerable amount of articles from academic and gray literature, and focuses on technical and non-technical challenges. Moreover, the findings reveal which topics were widely discussed, and hence considered relevant by the authors and cyber threat intelligence sharing communities.},
	journal = {Computers \& Security},
	author = {Wagner, Thomas D. and Mahbub, Khaled and Palomar, Esther and Abdallah, Ali E.},
	year = {2019},
	pages = {101589},
}

@article{rashid_federated_2023,
	title = {A {Federated} {Learning}-{Based} {Approach} for {Improving} {Intrusion} {Detection} in {Industrial} {Internet} of {Things} {Networks}},
	volume = {3},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2673-8732},
	url = {https://www.mdpi.com/2673-8732/3/1/8},
	doi = {10.3390/network3010008},
	abstract = {The Internet of Things (IoT) is a network of electrical devices that are connected to the Internet wirelessly. This group of devices generates a large amount of data with information about users, which makes the whole system sensitive and prone to malicious attacks eventually. The rapidly growing IoT-connected devices under a centralized ML system could threaten data privacy. The popular centralized machine learning (ML)-assisted approaches are difficult to apply due to their requirement of enormous amounts of data in a central entity. Owing to the growing distribution of data over numerous networks of connected devices, decentralized ML solutions are needed. In this paper, we propose a Federated Learning (FL) method for detecting unwanted intrusions to guarantee the protection of IoT networks. This method ensures privacy and security by federated training of local IoT device data. Local IoT clients share only parameter updates with a central global server, which aggregates them and distributes an improved detection algorithm. After each round of FL training, each of the IoT clients receives an updated model from the global server and trains their local dataset, where IoT devices can keep their own privacy intact while optimizing the overall model. To evaluate the efficiency of the proposed method, we conducted exhaustive experiments on a new dataset named Edge-IIoTset. The performance evaluation demonstrates the reliability and effectiveness of the proposed intrusion detection model by achieving an accuracy (92.49\%) close to that offered by the conventional centralized ML models’ accuracy (93.92\%) using the FL method.},
	language = {en},
	number = {1},
	urldate = {2024-04-12},
	journal = {Network},
	author = {Rashid, Md Mamunur and Khan, Shahriar Usman and Eusufzai, Fariha and Redwan, Md Azharuddin and Sabuj, Saifur Rahman and Elsharief, Mahmoud},
	month = mar,
	year = {2023},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Internet of Things, federated learning, intrusion detection, machine learning, neural networks, privacy, security},
	pages = {158--179},
}

@article{fedorchenko_comparative_2022,
	title = {Comparative {Review} of the {Intrusion} {Detection} {Systems} {Based} on {Federated} {Learning}: {Advantages} and {Open} {Challenges}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1999-4893},
	shorttitle = {Comparative {Review} of the {Intrusion} {Detection} {Systems} {Based} on {Federated} {Learning}},
	url = {https://www.mdpi.com/1999-4893/15/7/247},
	doi = {10.3390/a15070247},
	abstract = {In order to provide an accurate and timely response to different types of the attacks, intrusion and anomaly detection systems collect and analyze a lot of data that may include personal and other sensitive data. These systems could be considered a source of privacy-aware risks. Application of the federated learning paradigm for training attack and anomaly detection models may significantly decrease such risks as the data generated locally are not transferred to any party, and training is performed mainly locally on data sources. Another benefit of the usage of federated learning for intrusion detection is its ability to support collaboration between entities that could not share their dataset for confidential or other reasons. While this approach is able to overcome the aforementioned challenges it is rather new and not well-researched. The challenges and research questions appear while using it to implement analytical systems. In this paper, the authors review existing solutions for intrusion and anomaly detection based on the federated learning, and study their advantages as well as open challenges still facing them. The paper analyzes the architecture of the proposed intrusion detection systems and the approaches used to model data partition across the clients. The paper ends with discussion and formulation of the open challenges.},
	language = {en},
	number = {7},
	urldate = {2024-04-24},
	journal = {Algorithms},
	author = {Fedorchenko, Elena and Novikova, Evgenia and Shulepov, Anton},
	month = jul,
	year = {2022},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {+survey, Internet of Things, artificial intelligence, data partition, federated learning, intrusion detection, machine learning, system architecture},
	pages = {247},
}

@article{ruzafa-alcazar_intrusion_2023,
	title = {Intrusion {Detection} {Based} on {Privacy}-{Preserving} {Federated} {Learning} for the {Industrial} {IoT}},
	volume = {19},
	issn = {1941-0050},
	url = {https://ieeexplore.ieee.org/document/9609643},
	doi = {10.1109/TII.2021.3126728},
	abstract = {Federated learning (FL) has attracted significant interest given its prominent advantages and applicability in many scenarios. However, it has been demonstrated that sharing updated gradients/weights during the training process can lead to privacy concerns. In the context of the Internet of Things (IoT), this can be exacerbated due to intrusion detection systems (IDSs), which are intended to detect security attacks by analyzing the devices’ network traffic. Our work provides a comprehensive evaluation of differential privacy techniques, which are applied during the training of an FL-enabled IDS for industrial IoT. Unlike previous approaches, we deal with nonindependent and identically distributed data over the recent ToN\_IoT dataset, and compare the accuracy obtained considering different privacy requirements and aggregation functions, namely FedAvg and the recently proposed Fed+. According to our evaluation, the use of Fed+ in our setting provides similar results even when noise is included in the federated training process.},
	number = {2},
	urldate = {2024-04-24},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Ruzafa-Alcázar, Pedro and Fernández-Saura, Pablo and Mármol-Campos, Enrique and González-Vidal, Aurora and Hernández-Ramos, José L. and Bernal-Bernabe, Jorge and Skarmeta, Antonio F.},
	month = feb,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Industrial Informatics},
	keywords = {Collaborative work, Data models, Differential privacy, Differential privacy (DP), Informatics, Internet of Things (IoT), Intrusion detection, Privacy, Training, federated learning (FL), intrusion detection systems (IDSs), machine learning},
	pages = {1145--1154},
}

@article{ismaila_review_2024,
	title = {Review on {Approaches} of {Federated} {Modeling} in {Anomaly}-{Based} {Intrusion} {Detection} for {IoT} {Devices}},
	volume = {12},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10445150},
	doi = {10.1109/ACCESS.2024.3369915},
	abstract = {The novelty of Federated Learning (FL) has emerged as a promising alternative to centralized machine learning systems in the context of anomaly-based intrusion detection systems (AIDS) deployed on Internet of Things (IoT) devices. Unlike traditional centralized models, FL allows on-device model training and updates, reducing privacy concerns and issues such as single points of failure and high false alarm rates (FAR). This approach, termed ‘Fed-AIDS,’ offers a more secure and efficient solution. However, the development of Fed-AIDS models faces challenges related to limited training data and the diverse nature of IoT datasets. Additionally, FL’s decentralized nature introduces weight divergence issues arising from non-Independently and Identically Distributed (non-IID) clients. To address these challenges and optimize Fed-AIDS modeling, interdisciplinary research efforts are vital. The primary objective of this study is to conduct an up-to-date review by adopting a Systematic Literature Review (SLR) approach to analyze existing studies of Fed-AIDS modeling procedures for IoT devices. Data from the published studies were retrieved from Scopus database, which covered major publishers such as IEEE, Elsevier and others. Specifically, our review conducted from the following Fed-AIDS perspectives: workflow and tools, training dataset, complexities of non-IID data in Fed-AIDS models, classification tasks, aggregation tasks, and model validation metrics. Based on the research findings, the study highlights a series of challenges and proposes potential solutions to stand in future research in Fed-AIDS modeling, aiming to advance the field of IoT device security.},
	urldate = {2024-04-24},
	journal = {IEEE Access},
	author = {Isma’ila, Umar Audi and Danyaro, Kamaluddeen Usman and Muazu, Aminu Aminu and Maiwada, Umar Danjuma},
	year = {2024},
	note = {Conference Name: IEEE Access},
	keywords = {Anomaly detection, Data models, Federated learning, Federated learning modeling, Internet of Things, Intrusion detection, IoT devices, Machine learning, Performance evaluation, Reviews, Security, Systematics, Training, aggregation function, anomaly-based intrusion detection, non-IDD data},
	pages = {30941--30961},
}

@article{sarhan_towards_2022,
	title = {Towards a {Standard} {Feature} {Set} for {Network} {Intrusion} {Detection} {System} {Datasets}},
	volume = {27},
	issn = {1572-8153},
	url = {https://doi.org/10.1007/s11036-021-01843-0},
	doi = {10.1007/s11036-021-01843-0},
	abstract = {Network Intrusion Detection Systems (NIDSs) are important tools for the protection of computer networks against increasingly frequent and sophisticated cyber attacks. Recently, a lot of research effort has been dedicated to the development of Machine Learning (ML) based NIDSs. As in any ML-based application, the availability of high-quality datasets is critical for the training and evaluation of ML-based NIDS. One of the key problems with the currently available NIDS datasets is the lack of a standard feature set. The use of a unique and proprietary set of features for each of the publicly available datasets makes it virtually impossible to compare the performance of ML-based traffic classifiers on different datasets, and hence to evaluate the ability of these systems to generalise across different network scenarios. To address that limitation, this paper proposes and evaluates standard NIDS feature sets based on the NetFlow network meta-data collection protocol and system. We evaluate and compare two NetFlow-based feature set variants, a version with 12 features, and another one with 43 features. For our evaluation, we converted four widely used NIDS datasets (UNSW-NB15, BoT-IoT, ToN-IoT, CSE-CIC-IDS2018) into new variants with our proposed NetFlow based feature sets. Based on an Extra Tree classifier, we compared the classification performance of the NetFlow-based feature sets with the proprietary feature sets provided with the original datasets. While the smaller feature set cannot match the classification performance of the proprietary feature sets, the larger set with 43 NetFlow features, surprisingly achieves a consistently higher classification performance compared to the original feature set, which was tailored to each of the considered NIDS datasets. The proposed NetFlow-based NIDS feature set, together with four benchmark datasets, made available to the research community, allow a fair comparison of ML-based network traffic classifiers across different NIDS datasets. We believe that having a standard feature set is critical for allowing a more rigorous and thorough evaluation of ML-based NIDSs and that it can help bridge the gap between academic research and the practical deployment of such systems.},
	language = {en},
	number = {1},
	urldate = {2024-04-23},
	journal = {Mobile Networks and Applications},
	author = {Sarhan, Mohanad and Layeghy, Siamak and Portmann, Marius},
	month = feb,
	year = {2022},
	keywords = {Machine learning, NetFlow, Network intrusion detection system},
	pages = {357--370},
}

@article{gu_badnets_2019,
	title = {{BadNets}: {Evaluating} {Backdooring} {Attacks} on {Deep} {Neural} {Networks}},
	volume = {7},
	issn = {2169-3536},
	shorttitle = {{BadNets}},
	url = {https://ieeexplore.ieee.org/document/8685687},
	doi = {10.1109/ACCESS.2019.2909068},
	abstract = {Deep learning-based techniques have achieved state-of-the-art performance on a wide variety of recognition and classification tasks. However, these networks are typically computationally expensive to train, requiring weeks of computation on many GPUs; as a result, many users outsource the training procedure to the cloud or rely on pre-trained models that are then fine-tuned for a specific task. In this paper, we show that the outsourced training introduces new security risks: an adversary can create a maliciously trained network (a backdoored neural network, or a BadNet) that has the state-of-the-art performance on the user's training and validation samples but behaves badly on specific attacker-chosen inputs. We first explore the properties of BadNets in a toy example, by creating a backdoored handwritten digit classifier. Next, we demonstrate backdoors in a more realistic scenario by creating a U.S. street sign classifier that identifies stop signs as speed limits when a special sticker is added to the stop sign; we then show in addition that the backdoor in our U.S. street sign detector can persist even if the network is later retrained for another task and cause a drop in an accuracy of 25\% on average when the backdoor trigger is present. These results demonstrate that backdoors in neural networks are both powerful and-because the behavior of neural networks is difficult to explicate-stealthy. This paper provides motivation for further research into techniques for verifying and inspecting neural networks, just as we have developed tools for verifying and debugging software.},
	urldate = {2024-04-22},
	journal = {IEEE Access},
	author = {Gu, Tianyu and Liu, Kang and Dolan-Gavitt, Brendan and Garg, Siddharth},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {Biological neural networks, Computational modeling, Computer security, Machine learning, Perturbation methods, Security, Training, machine learning, neural networks},
	pages = {47230--47244},
}

@inproceedings{lavaur_federated_2022,
	title = {Federated learning as enabler for collaborative security between not fully-trusting distributed parties},
	copyright = {All rights reserved},
	url = {http://ceur-ws.org/Vol-3329/paper-04.pdf},
	booktitle = {Proceedings of the 29th computer \& electronics security application rendezvous ({C}\&{ESAR}): {Ensuring} trust in a decentralized world},
	author = {Lavaur, Leo and Coste, Benjamin and Pahl, Marc-Oliver and Busnel, Yann and Autrel, Fabien},
	year = {2022},
	note = {tex.crossref: CESAR2022},
	keywords = {⛔ No DOI found},
	pages = {65--80},
}

@article{zhu_attention-based_2022,
	title = {Attention-based federated incremental learning for traffic classification in the {Internet} of {Things}},
	volume = {185},
	issn = {01403664},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0140366422000123},
	doi = {10.1016/j.comcom.2022.01.006},
	abstract = {The Internet of Things (IoT) traffic follows non-independent and identical distribution (non-IID). Traditional machine learning classification methods will cause low classification accuracy, high communication costs, and privacy leakage issues. Federated Learning enables several clients to train a deep learning model collaboratively without requiring any of the clients to share their local data with a centralized server. In this paper, we propose a novel attention-based federated incremental learning algorithm: Fed-SOINN. We introduce the attention mechanism to improve the weight of parameters uploaded by clients which are beneficial to the global model, where instead of the full gradient, only a small subset of important gradients is communicated. Meanwhile, we improve the sparsity of the model by upgrading the online optimization function in Fed-SOINN, it also brings faster convergence speed and higher accuracy in the changeable network environment. Results reveal that Fed-SOINN has improved detection accuracy by 3.1\% compared with benchmark methods and can reduce the number of communications rounds up to 73\%. When facing new traffic categories, the incremental learning mechanism in Fed-SOINN also effectively identify unknown traffic categories.},
	language = {en},
	urldate = {2022-01-31},
	journal = {Computer Communications},
	author = {Zhu, Meng-yuan and Chen, Zhuo and Chen, Ke-fan and Lv, Na and Zhong, Yun},
	month = mar,
	year = {2022},
	keywords = {\_read},
	pages = {168--175},
}

@inproceedings{zhang_iot_2023,
	title = {{IoT} {Intrusion} {Detection} {Based} on {Personalized} {Federated} {Learning}},
	isbn = {978-89-950043-9-5},
	url = {https://ieeexplore.ieee.org/abstract/document/10258223},
	abstract = {The failure of edge devices in the IoT will affect the use of IoT applications. The introduction of the federated learning can train efficient models for devices under the premise of protecting privacy. However, current solutions rarely focus on the problem of data heterogeneity on IoT devices. In this paper, we introduce two personalized federated learning algorithms to implement intrusion detection models, which aim to solve data heterogeneity. We perform diverse partitions on the IoT dataset to simulate data heterogeneity on devices. Our experiments show that the proposed models have high performance in detecting attacks under various data distributions. Under the Non-IID setting, the test accuracies of our models are 95.5\% and 93.4\%, which are 8.4\% and 6.3\% higher than the model using traditional federated learning (FedAvg), respectively.},
	urldate = {2024-04-12},
	booktitle = {2023 24st {Asia}-{Pacific} {Network} {Operations} and {Management} {Symposium} ({APNOMS})},
	author = {Zhang, Qianqian and Wang, Ying and Wei, Tongyan and Wen, Jiachen and Chen, Jingjing and Qiu, Xuesong},
	month = sep,
	year = {2023},
	note = {ISSN: 2576-8565},
	keywords = {Data models, Federated learning, Internet of Things, Intrusion Detection, Intrusion detection, IoT, Partitioning algorithms, Performance evaluation, Personalized Federated Learning, Privacy},
	pages = {326--329},
}

@inproceedings{yadav_unsupervised_2021,
	address = {Kyoto, Japan},
	title = {Unsupervised {Federated} {Learning} based {IoT} {Intrusion} {Detection}},
	isbn = {978-1-66543-676-2},
	url = {https://ieeexplore.ieee.org/document/9621784/},
	doi = {10.1109/GCCE53005.2021.9621784},
	abstract = {Machine learning has been widely used these days to detect novel intrusions across IoT devices. Supervised-based machine learning techniques need labelled datasets to train a model. Due to privacy reasons, these days, people don’t share the dataset generated across their devices with external authority. When datasets are not aggregated centrally, it becomes very difﬁcult to process the unlabelled data and train a model across edge devices. Considering these drawbacks, we have brought an unsupervised deep learning approach that uses autoencoders to learn from unlabeled data. Our approach uses federated machine learning and can be trained across the unlabeled dataset of edge devices without compromising people’s privacy. We have tested our approach against CICIDS 2017 dataset in a federated environment and have got an accuracy of 97.75\% in detecting intrusions.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2021 {IEEE} 10th {Global} {Conference} on {Consumer} {Electronics} ({GCCE})},
	publisher = {IEEE},
	author = {Yadav, Krishna and Gupta, B.B and Hsu, Ching-Hsein and Chui, Kwok Tai},
	month = oct,
	year = {2021},
	keywords = {\_read},
	pages = {298--301},
}

@article{rahman_internet_2020,
	title = {Internet of {Things} {Intrusion} {Detection}: {Centralized}, {On}-{Device}, or {Federated} {Learning}?},
	volume = {34},
	issn = {0890-8044, 1558-156X},
	shorttitle = {Internet of {Things} {Intrusion} {Detection}},
	url = {https://ieeexplore.ieee.org/document/9183799/},
	doi = {10.1109/MNET.011.2000286},
	abstract = {With the ever increasing number of cyber-attacks, Internet of Things (IoT) devices are being exposed to serious malware, attacks, and malicious activities alongside their development. While past research has been focused on centralized intrusion detection assuming the existence of a central entity to store and perform analysis on data from all participant devices, these approaches cannot scale well with the fast growth of IoT connected devices and introduce a single-point failure risk that may compromise data privacy. Moreover, with data being widely spread across large networks of connected devices, decentralized computations are very much in need. In this context, we propose in this article a Federated Learning based scheme for IoT intrusion detection that maintains data privacy by performing local training and inference of detection models. In this scheme, not only privacy can be assured, but also devices can benefit from their peers’ knowledge by communicating only their updates with a remote server that aggregates the latter and shares an improved detection model with participating devices. We perform thorough experiments on an NSL-KDD dataset to evaluate the efficiency of the proposed approach. Experimental results and empirical analysis explore the robustness and advantages of the proposed Federated Learning detection model by reaching an accuracy close to that of the centralized approach and outperforming the distributed unaggregated on-device trained models.},
	language = {en},
	number = {6},
	urldate = {2021-06-01},
	journal = {IEEE Network},
	author = {Rahman, Sawsan Abdul and Tout, Hanine and Talhi, Chamseddine and Mourad, Azzam},
	month = nov,
	year = {2020},
	note = {CorpusID:226401673},
	keywords = {survey-fids},
	pages = {310--317},
}

@inproceedings{qin_line-speed_2020,
	title = {Line-{Speed} and {Scalable} {Intrusion} {Detection} at the {Network} {Edge} via {Federated} {Learning}},
	url = {https://ieeexplore.ieee.org/document/9142704},
	abstract = {Intrusion detection through classifying incoming packets is a crucial functionality at the network edge, requiring accuracy, efficiency and scalability at the same time, introducing a great challenge. On the one hand, traditional table-based switch functions have limited capacity to identify complicated network attack behaviors. On the other hand, machine learning based methods providing high accuracy are widely used for packet classification, but they typically require packets to be forwarded to an extra host and therefore increase the network latency. To overcome these limitations, in this paper we propose an architecture with programmable data plane switches. We show that Binarized Neural Networks (BNNs) can be implemented as switch functions at the network edge classifying incoming packets at the line speed of the switches. To train BNNs in a scalable manner, we adopt a federated learning approach that keeps the communication overheads of training small even for scenarios involving many edge network domains. We next develop a prototype using the P4 language and perform evaluations. The results demonstrate that a multi-fold improvement in latency and communication overheads can be achieved compared to state-of the-art learning architectures.},
	urldate = {2024-04-12},
	booktitle = {2020 {IFIP} {Networking} {Conference} ({Networking})},
	author = {Qin, Qiaofeng and Poularakis, Konstantinos and Leung, Kin K. and Tassiulas, Leandros},
	month = jun,
	year = {2020},
	keywords = {Logic gates, Neural networks, Security, Servers, Switches, Training, survey-fids},
	pages = {352--360},
}

@inproceedings{pahl_all_2018,
	title = {All {Eyes} on {You}: {Distributed} {Multi}-{Dimensional} {IoT} {Microservice} {Anomaly} {Detection}},
	shorttitle = {All {Eyes} on {You}},
	url = {https://ieeexplore.ieee.org/abstract/document/8584985},
	abstract = {The Internet of Things (IoT) is a Distributed System of cooperating Microservices (μSs). IoT services manage devices that monitor and control their environments. The interaction of the IoT with the physical environment creates strong security, privacy, and safety implications. It makes providing adequate security for IoT μSs essential. However, the complexity of IoT services makes detecting anomalous behavior difficult. We present a machine-learning based approach for modeling IoT service behavior by only observing inter-service communication. Our algorithm continuously learns μS models on distributed IoT nodes within an IoT site. Combining the learned models within and in-between IoT sites converges our μS models within short time. Sharing the resulting stable models among compute nodes enables good anomaly detection. As one application, firewalling IoT μSs becomes possible. Combining our autonomous μS modeling with firewalling enables retrofitting security to existing IoT installations. We enable retrofitting access control to existing non-secure IoT installations. Our proposed approach is resource efficient, matching the requirements of the IoT. To evaluate the quality of our proposed algorithm, we show its behavior for a set of common IoT attacks. We evaluate how domain knowledge enables us to decorrelate events on a node, and how adding context features improves the detection rate.},
	urldate = {2024-04-12},
	booktitle = {2018 14th {International} {Conference} on {Network} and {Service} {Management} ({CNSM})},
	author = {Pahl, Marc-Oliver and Aubet, François-Xavier},
	month = nov,
	year = {2018},
	note = {ISSN: 2165-963X
ISBN: 9783903176140},
	keywords = {Adaptation models, Biological system modeling, Computational modeling, Internet of Things, IoT, Middleware, Monitoring, Security, anomaly detection, machine learning, modeling, security, survey-fids},
	pages = {72--80},
}

@inproceedings{neto_fedsa_2022,
	title = {{FedSA}: {Accelerating} {Intrusion} {Detection} in {Collaborative} {Environments} with {Federated} {Simulated} {Annealing}},
	shorttitle = {{FedSA}},
	url = {https://ieeexplore.ieee.org/document/9844024},
	doi = {10.1109/NetSoft54395.2022.9844024},
	abstract = {Fast identification of new network attack patterns is crucial for improving network security. Nevertheless, identifying an ongoing attack in a heterogeneous network is a non-trivial task. Federated learning emerges as a solution to collaborative training for an Intrusion Detection System (IDS). The federated learning-based IDS trains a global model using local machine learning models provided by federated participants without sharing local data. However, optimization challenges are intrinsic to federated learning. This paper proposes the Federated Simulated Annealing (FedSA) metaheuristic to select the hyperparameters and a subset of participants for each aggregation round in federated learning. FedSA optimizes hyperparameters linked to the global model convergence. The proposal reduces aggregation rounds and speeds up convergence. Thus, FedSA accelerates learning extraction from local models, requiring fewer IDS updates. The proposal assessment shows that the FedSA global model converges in less than ten communication rounds. The proposal requires up to 50\% fewer aggregation rounds to achieve approximately 97\% accuracy in attack detection than the conventional aggregation approach.},
	urldate = {2024-04-12},
	booktitle = {2022 {IEEE} 8th {International} {Conference} on {Network} {Softwarization} ({NetSoft})},
	author = {Neto, Helio N. Cunha and Dusparic, Ivana and Mattos, Diogo M. F. and Fernande, Natalia C.},
	month = jun,
	year = {2022},
	note = {ISSN: 2693-9789},
	keywords = {Collaboration, Collaborative work, Data models, Intrusion detection, Simulated annealing, Training, Training data},
	pages = {420--428},
}

@inproceedings{mokry_efficient_2021,
	address = {Orlando, FL, USA},
	title = {Efficient and {Privacy}-{Preserving} {Collaborative} {Intrusion} {Detection} {Using} {Additive} {Secret} {Sharing} and {Differential} {Privacy}},
	isbn = {978-1-66543-902-2},
	url = {https://ieeexplore.ieee.org/document/9671428/},
	doi = {10.1109/BigData52589.2021.9671428},
	abstract = {Intrusion Detection Systems are commonly used by organizations to monitor network trafﬁc and detect attacks or suspicious behaviours. However, many attacks occur across organizations and are often difﬁcult to detect using any single IDS. Collaborative Intrusion Detection Systems could lead to more accurate prediction and detection of cyber threats as well as a reduction of security administrators’ workload as similar threats from different places can be merged. However, most organizations are unwilling to disclose sensitive information about their internal network topology and trafﬁc, lending these systems unusable. Existing solutions using homomorphic encryption and secure multi-party computation are often expensive. In this paper, we propose efﬁcient and privacy preserving techniques to correlate alerts generated at different organizations. We propose skP rototypes, a distributed clustering algorithm for horizontally partitioned mixed data using additive secret sharing. This algorithm can be used to create a privacy preserving, collaborative intrusion detection system. We also propose dpkP rototypes which uses differential privacy on categorical attributes and is more efﬁcient than skP rototypes for categorical attributes with many distinct values. Theoretical and experimental results validate the effectiveness of our algorithms.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2021 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	publisher = {IEEE},
	author = {Mokry, Laylon and Slife, Paul and Bishop, Patrick and Quiroz, Jose and Guzzi, Cooper and Chen, Zhiyuan and Crainiceanu, Adina and Needham, Don},
	month = dec,
	year = {2021},
	keywords = {\_read},
	pages = {3324--3333},
}

@inproceedings{chen_network_2020,
	address = {Cham},
	title = {Network {Anomaly} {Detection} {Using} {Federated} {Deep} {Autoencoding} {Gaussian} {Mixture} {Model}},
	isbn = {978-3-030-45778-5},
	doi = {10.1007/978-3-030-45778-5_1},
	abstract = {Deep autoencoding Gaussian mixture model (DAGMM) employs dimensionality reduction and density estimation and jointly optimizes them for unsupervised anomaly detection tasks. However, the absence of large amount of training data greatly compromises DAGMM’s performance. Due to rising concerns for privacy, a worse situation can be expected. By aggregating only parameters from local training on clients for obtaining knowledge from more private data, federated learning is proposed to enhance model performance. Meanwhile, privacy is properly protected. Inspired by the aforementioned, this paper presents a federated deep autoencoding Gaussian mixture model (FDAGMM) to improve the disappointing performance of DAGMM caused by limited data amount. The superiority of our proposed FDAGMM is empirically demonstrated with extensive experiments.},
	language = {en},
	booktitle = {Machine {Learning} for {Networking}},
	publisher = {Springer International Publishing},
	author = {Chen, Yang and Zhang, Junzhe and Yeo, Chai Kiat},
	editor = {Boumerdassi, Selma and Renault, Éric and Mühlethaler, Paul},
	year = {2020},
	keywords = {survey-fids},
	pages = {1--14},
}

@misc{noauthor_network_nodate,
	title = {Network {Anomaly} {Detection} {Using} {Federated} {Deep} {Autoencoding} {Gaussian} {Mixture} {Model} {\textbar} {Machine} {Learning} for {Networking}},
	url = {https://dlnext.acm.org/doi/10.1007/978-3-030-45778-5_1},
	language = {en},
	urldate = {2024-04-12},
	journal = {Guide Proceedings},
}

@inproceedings{al-athba_al-marri_federated_2020,
	title = {Federated {Mimic} {Learning} for {Privacy} {Preserving} {Intrusion} {Detection}},
	url = {https://ieeexplore.ieee.org/document/9234959},
	doi = {10.1109/BlackSeaCom48709.2020.9234959},
	abstract = {Internet of things (IoT) devices are prone to attacks due to the limitation of their privacy and security components. These attacks vary from exploiting backdoors to disrupting the communication network of the devices. Intrusion Detection Systems (IDS) play an essential role in ensuring information privacy and security of IoT devices against these attacks. Recently, deep learning-based IDS techniques are becoming more prominent due to their high classification accuracy. However, conventional deep learning techniques jeopardize user privacy due to the transfer of user data to a centralized server. Federated learning (FL) is a popular privacy-preserving decentralized learning method. FL enables training models locally at the edge devices and transferring local models to a centralized server instead of transferring sensitive data. Nevertheless, FL can suffer from reverse engineering ML attacks that can learn information about the user's data from model. To overcome the problem of reverse engineering, mimic learning is another way to preserve the privacy of ML-based IDS. In mimic learning, a student model is trained with the public dataset, which is labeled with the teacher model that is trained by sensitive user data. In this work, we propose a novel approach that combines the advantages of FL and mimic learning, namely federated mimic learning to create a distributed IDS while minimizing the risk of jeopardizing users' privacy, and benchmark its performance compared to other ML-based IDS techniques using NSL-KDD dataset. Our results show that we can achieve 98.11\% detection accuracy with federated mimic learning.},
	urldate = {2024-04-12},
	booktitle = {2020 {IEEE} {International} {Black} {Sea} {Conference} on {Communications} and {Networking} ({BlackSeaCom})},
	author = {Al-Athba Al-Marri, Noor Ali and Ciftler, Bekir S. and Abdallah, Mohamed M.},
	month = may,
	year = {2020},
	keywords = {Benchmark testing, Data models, Data privacy, Feature extraction, Federated Learning, Internet of Things, Intrusion Detection Systems, Intrusion detection, Mimic Learning, Privacy-Preserving, Servers, Training, survey-fids},
	pages = {1--6},
}

@misc{sun_can_2019,
	title = {Can {You} {Really} {Backdoor} {Federated} {Learning}?},
	url = {http://arxiv.org/abs/1911.07963},
	abstract = {The decentralized nature of federated learning makes detecting and defending against adversarial attacks a challenging task. This paper focuses on backdoor attacks in the federated learning setting, where the goal of the adversary is to reduce the performance of the model on targeted tasks while maintaining a good performance on the main task. Unlike existing works, we allow non-malicious clients to have correctly labeled samples from the targeted tasks. We conduct a comprehensive study of backdoor attacks and defenses for the EMNIST dataset, a real-life, user-partitioned, and non-iid dataset. We observe that in the absence of defenses, the performance of the attack largely depends on the fraction of adversaries present and the “complexity” of the targeted task. Moreover, we show that norm clipping and “weak” differential privacy mitigate the attacks without hurting the overall performance. We have implemented the attacks and defenses in TensorFlow Federated (TFF), a TensorFlow framework for federated learning. In open sourcing our code, our goal is to encourage researchers to contribute new attacks and defenses and evaluate them on standard federated datasets.},
	language = {en},
	urldate = {2023-11-02},
	publisher = {arXiv},
	author = {Sun, Ziteng and Kairouz, Peter and Suresh, Ananda Theertha and McMahan, H. Brendan},
	month = dec,
	year = {2019},
	note = {arXiv:1911.07963 [cs, stat]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{qin_line-speed_2020-1,
	title = {Line-{Speed} and {Scalable} {Intrusion} {Detection} at the {Network} {Edge} via {Federated} {Learning}},
	abstract = {Intrusion detection through classifying incoming packets is a crucial functionality at the network edge, requiring accuracy, efﬁciency and scalability at the same time, introducing a great challenge. On the one hand, traditional table-based switch functions have limited capacity to identify complicated network attack behaviors. On the other hand, machine learning based methods providing high accuracy are widely used for packet classiﬁcation, but they typically require packets to be forwarded to an extra host and therefore increase the network latency. To overcome these limitations, in this paper we propose an architecture with programmable data plane switches. We show that Binarized Neural Networks (BNNs) can be implemented as switch functions at the network edge classifying incoming packets at the line speed of the switches. To train BNNs in a scalable manner, we adopt a federated learning approach that keeps the communication overheads of training small even for scenarios involving many edge network domains. We next develop a prototype using the P4 language and perform evaluations. The results demonstrate that a multi-fold improvement in latency and communication overheads can be achieved compared to state-ofthe-art learning architectures.},
	language = {en},
	author = {Qin, Qiaofeng and Poularakis, Konstantinos and Leung, Kin K and Tassiulas, Leandros},
	month = jun,
	year = {2020},
	keywords = {survey-fids, ⛔ No DOI found},
	pages = {9},
}

@article{pahl_all_2018-1,
	title = {All {Eyes} on {You}: {Distributed} {Multi}-{Dimensional} {IoT} {Microservice} {Anomaly} {Detection}},
	abstract = {The Internet of Things (IoT) is a Distributed System of cooperating Microservices (μ Ss). IoT services manage devices that monitor and control their environments. The interaction of the IoT with the physical environment creates strong security, privacy, and safety implications. It makes providing adequate security for IoT μ Ss essential. However, the complexity of IoT services makes detecting anomalous behavior difficult.We present a machine-learning based approach for modeling IoT service behavior by only observing inter-service communication. Our algorithm continuously learns μS models on distributed IoT nodes within an IoT site. Combining the learned models within and in-between IoT sites converges our μS models within short time. Sharing the resulting stable models among compute nodes enables good anomaly detection.As one application, firewalling IoT μ Ss becomes possible. Combining our autonomous μS modeling with firewalling enables retrofitting security to existing IoT installations. We enable retrofitting access control to existing non-secure IoT installations.Our proposed approach is resource efficient, matching the requirements of the IoT. To evaluate the quality of our proposed algorithm, we show its behavior for a set of common IoT attacks. We evaluate how domain knowledge enables us to decorrelate events on a node, and how adding context features improves the detection rate.},
	journal = {14th International Conference on Network and Service Management, CNSM 2018, 1st Workshop on Segment Routing and Service Function Chaining},
	author = {Pahl, Marc-Oliver and Aubet, Francois Xavier},
	year = {2018},
	note = {ISBN: 9783903176140},
	keywords = {survey-fids, ⛔ No DOI found},
	pages = {72--80},
}

@inproceedings{chen_network_2020-1,
	address = {Cham},
	title = {Network anomaly detection using federated deep autoencoding gaussian mixture model},
	isbn = {978-3-030-45778-5},
	abstract = {Deep autoencoding Gaussian mixture model (DAGMM) employs dimensionality reduction and density estimation and jointly optimizes them for unsupervised anomaly detection tasks. However, the absence of large amount of training data greatly compromises DAGMM's performance. Due to rising concerns for privacy, a worse situation can be expected. By aggregating only parameters from local training on clients for obtaining knowledge from more private data, federated learning is proposed to enhance model performance. Meanwhile, privacy is properly protected. Inspired by the aforementioned, this paper presents a federated deep autoencoding Gaussian mixture model (FDAGMM) to improve the disappointing performance of DAGMM caused by limited data amount. The superiority of our proposed FDAGMM is empirically demonstrated with extensive experiments.},
	booktitle = {Machine learning for networking},
	publisher = {Springer International Publishing},
	author = {Chen, Yang and Zhang, Junzhe and Yeo, Chai Kiat},
	editor = {Boumerdassi, Selma and Renault, Éric and Mühlethaler, Paul},
	year = {2020},
	keywords = {survey-fids},
	pages = {1--14},
}

@article{li_distributed_2020,
	title = {Distributed {Network} {Intrusion} {Detection} {System} in {Satellite}-{Terrestrial} {Integrated} {Networks} {Using} {Federated} {Learning}},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9274426/},
	doi = {10.1109/ACCESS.2020.3041641},
	abstract = {The existing satellite-terrestrial integrated networks (STINs) suffer from security and privacy concerns due to the limited resources, poor attack resistance and high privacy requirements of satellite networks. Network Intrusion Detection System (NIDS) is intended to provide a high level of protection for modern network environments, but how to implement distributed NIDS on STINs has not been widely discussed. At the same time, satellite networks have always lacked real and effective security data sets as references. To solve these problems, we propose a distributed NIDS using Federal Learning (FL) in STIN to properly allocate resources in each domain to analyze and block malicious trafﬁc, especially distributed denial-of-service (DDoS) attacks. Speciﬁcally, we ﬁrst design a typical STIN topology, on the basis of which we collect and design security data sets adapted to satellite and terrestrial networks in STIN, respectively. To address the problem of poor attack resistance of satellite networks, we propose a satellite network topology optimization algorithm to reduce the difﬁculty in tracing malicious packets due to frequent link switching. In order to solve the problem of limited resources and high privacy requirements of satellite networks, we propose an algorithm for FL adaptation to STIN, and build a distributed NIDS using FL in STIN. Finally, we deploy the designed distributed NIDS in a prototype system and evaluate our proposed distributed NIDS with a large number of simulations of randomly generated malicious trafﬁc. Related results demonstrate that the performance of our approach is better than traditional deep learning and intrusion detection methods in terms of malicious trafﬁc recognition rate, packet loss rate, and CPU utilization.},
	language = {en},
	urldate = {2021-10-25},
	journal = {IEEE Access},
	author = {Li, Kun and Zhou, Huachun and Tu, Zhe and Wang, Weilin and Zhang, Hongke},
	year = {2020},
	keywords = {survey-fids},
	pages = {214852--214865},
}

@inproceedings{cetin_federated_2019,
	address = {Los Angeles, CA, USA},
	title = {Federated {Wireless} {Network} {Intrusion} {Detection}},
	isbn = {978-1-72810-858-2},
	url = {https://ieeexplore.ieee.org/document/9005507/},
	doi = {10.1109/BigData47090.2019.9005507},
	abstract = {Wi-Fi has become the wireless networking standard that allows short- to medium-range device to connect without wires. For the last 20 year, the Wi-Fi technology has so pervasive that most devices in use today are mobile and connect to the internet through Wi-Fi. Unlike wired network, a wireless network lacks a clear boundary, which leads to signiﬁcant Wi-Fi network security concerns, especially because the current security measures are prone to several types of intrusion. To address this problem, machine learning and deep learning methods have been successfully developed to identify network attacks. However, collecting data to develop models is expensive and raises privacy concerns. The goal of this paper is to evaluate a federated learning approach that would alleviate such privacy concerns. This initial work on intrusion detection is performed in a simulated environment. Once proven feasible, this process would allow edge devices to collaboratively update global anomaly detection models, without sharing sensitive training data. On a set of tests with the AWID intrusion detection data set, we show that our federated approach is effective in terms of classiﬁcation accuracy, computation cost, as well as communication cost.},
	language = {en},
	urldate = {2021-10-25},
	booktitle = {2019 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	publisher = {IEEE},
	author = {Cetin, Burak and Lazar, Alina and Kim, Jinoh and Sim, Alex and Wu, Kesheng},
	month = dec,
	year = {2019},
	keywords = {survey-fids},
	pages = {6004--6006},
}

@article{hei_trusted_2020,
	title = {A trusted feature aggregator federated learning for distributed malicious attack detection},
	volume = {99},
	issn = {01674048},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167404820303060},
	doi = {10.1016/j.cose.2020.102033},
	language = {en},
	urldate = {2021-10-25},
	journal = {Computers \& Security},
	author = {Hei, Xinhong and Yin, Xinyue and Wang, Yichuan and Ren, Ju and Zhu, Lei},
	month = dec,
	year = {2020},
	keywords = {survey-fids},
	pages = {102033},
}

@article{chen_intrusion_2020,
	title = {Intrusion {Detection} for {Wireless} {Edge} {Networks} {Based} on {Federated} {Learning}},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9274294/},
	doi = {10.1109/ACCESS.2020.3041793},
	abstract = {Edge computing provides off-load computing and application services close to end-users, greatly reducing cloud pressure and communication overhead. However, wireless edge networks still face the risk of network attacks. To ensure the security of wireless edge networks, we present Federated Learning-based Attention Gated Recurrent Unit (FedAGRU), an intrusion detection algorithm for wireless edge networks. FedAGRU differs from current centralized learning methods by updating universal learning models rather than directly sharing raw data among edge devices and a central server. We also apply the attention mechanism to increase the weight of important devices, by avoiding the upload of unimportant updates to the server, FedAGRU can greatly reduce communication overhead while ensuring learning convergence. Our experimental results show that, compared with other centralized learning algorithms, FedAGRU improves detection accuracy by approximately 8\%. In addition, FedAGRU’s communication cost is 70\% less than other federated learning algorithms, and it exhibits strong robustness against poisoning attacks.},
	language = {en},
	urldate = {2021-10-25},
	journal = {IEEE Access},
	author = {Chen, Zhuo and Lv, Na and Liu, Pengfei and Fang, Yu and Chen, Kun and Pan, Wu},
	year = {2020},
	keywords = {survey-fids},
	pages = {217463--217472},
}

@inproceedings{kim_collaborative_2020,
	address = {Chongqing, China},
	title = {Collaborative {Anomaly} {Detection} for {Internet} of {Things} based on {Federated} {Learning}},
	isbn = {978-1-72817-327-6},
	url = {https://ieeexplore.ieee.org/document/9238913/},
	doi = {10.1109/ICCC49849.2020.9238913},
	abstract = {In this paper, we propose a federated learning(FL)-based collaborative anomaly detection system. This system consists of multiple edge nodes and a server node. The edge nodes are in charge of not only monitoring and collecting data, but also to train an anomaly detection neural network classification model based on the local data. On the other hand, the server aggregates the parameters from the edges and generates a new model for the next round. This system structure achieves light weight transmission between the server and the edge nodes, and user privacy can be well protected since raw data are not communicated directly. We implement the proposed scheme in the practical system and present experimental results that demonstrate results competitive with those of state-ofthe-art models.},
	language = {en},
	urldate = {2021-10-25},
	booktitle = {2020 {IEEE}/{CIC} {International} {Conference} on {Communications} in {China} ({ICCC})},
	publisher = {IEEE},
	author = {Kim, Seongwoo and Cai, He and Hua, Cunqing and Gu, Pengwenlong and Xu, Wenchao and Park, Jeonghyeok},
	month = aug,
	year = {2020},
	keywords = {survey-fids},
	pages = {623--628},
}

@article{sun_adaptive_2021,
	title = {Adaptive {Intrusion} {Detection} in the {Networking} of {Large}-{Scale} {LANs} {With} {Segmented} {Federated} {Learning}},
	volume = {2},
	issn = {2644-125X},
	url = {https://ieeexplore.ieee.org/document/9296578/},
	doi = {10.1109/OJCOMS.2020.3044323},
	abstract = {Predominant network intrusion detection systems (NIDS) aim to identify malicious traffic patterns based on a handcrafted dataset of rules. Recently, the application of machine learning in NIDS helps alleviate the enormous effort of human observation. Federated learning (FL) is a collaborative learning scheme concerning distributed data. Instead of sharing raw data, it allows a participant to share only a trained local model. Despite the success of existing FL solutions, in NIDS, a network’s traffic data distribution does not always fit into the single global model of FL; some networks have similarities with each other but other networks do not. We propose Segmented-Federated Learning (Segmented-FL), where by employing periodic local model evaluation and network segmentation, we aim to bring similar network environments to the same group. A comparison between FL and our method was conducted against a range of metrics including the weighted precision, recall, and F1 score, using a collected dataset from 20 massively distributed networks within 60 days. By studying the optimized hyperparameters of Segmented-FL and employing three evaluation methods, it shows that Segmented-FL has better performance in all three types of intrusion detection tasks, achieving validation weighted F1 scores of 0.964, 0.803, and 0.912 with Method A, Method B, and Method C respectively. For each method, this scheme shows a gain of 0.1\%, 4.0\% and 1.1\% in performance compared with FL.},
	language = {en},
	urldate = {2021-10-04},
	journal = {IEEE Open Journal of the Communications Society},
	author = {Sun, Yuwei and Esaki, Hiroshi and Ochiai, Hideya},
	year = {2021},
	keywords = {survey-fids},
	pages = {102--112},
}

@inproceedings{fan_iotdefender_2020,
	address = {Guangzhou, China},
	title = {{IoTDefender}: {A} {Federated} {Transfer} {Learning} {Intrusion} {Detection} {Framework} for {5G} {IoT}},
	isbn = {978-1-66540-396-2},
	shorttitle = {{IoTDefender}},
	url = {https://ieeexplore.ieee.org/document/9343358/},
	doi = {10.1109/BigDataSE50710.2020.00020},
	language = {en},
	urldate = {2021-10-04},
	booktitle = {2020 {IEEE} 14th {International} {Conference} on {Big} {Data} {Science} and {Engineering} ({BigDataSE})},
	publisher = {IEEE},
	author = {Fan, Yulin and Li, Yang and Zhan, Mengqi and Cui, Huajun and Zhang, Yan},
	month = dec,
	year = {2020},
	keywords = {survey-fids},
	pages = {88--95},
}

@article{liu_blockchain_2021,
	title = {Blockchain and {Federated} {Learning} for {Collaborative} {Intrusion} {Detection} in {Vehicular} {Edge} {Computing}},
	volume = {70},
	issn = {0018-9545, 1939-9359},
	url = {https://ieeexplore.ieee.org/document/9420262/},
	doi = {10.1109/TVT.2021.3076780},
	abstract = {The vehicular networks constructed by interconnected vehicles and transportation infrastructure are vulnerable to cyber-intrusions due to the expanded use of software and the introduction of wireless interfaces. Intrusion detection systems (IDSs) can be customized efﬁciently in response to this increased attack surface. There has been signiﬁcant progress in detecting malicious attack trafﬁc using machine learning approaches. However, existing IDSs require network devices with powerful computing capabilities to continuously train and update complex network models, which reduces the efﬁciency and defense capability of intrusion detection systems due to limited resources and untimely model updates. This work proposes a cooperative intrusion detection mechanism that ofﬂoads the training model to distributed edge devices (e.g., connected vehicles and roadside units (RSUs). Distributed federated-based approach reduces resource utilization of the central server while assuring security and privacy. To ensure the security of the aggregation model, blockchain is used for the storage and sharing of the training models. This work analyzes common attacks and shows that the proposed scheme achieves cooperative privacy-preservation for vehicles while reducing communication overhead and computation cost.},
	language = {en},
	number = {6},
	urldate = {2021-10-04},
	journal = {IEEE Transactions on Vehicular Technology},
	author = {Liu, Hong and Zhang, Shuaipeng and Zhang, Pengfei and Zhou, Xinqiang and Shao, Xuebin and Pu, Geguang and Zhang, Yan},
	month = jun,
	year = {2021},
	keywords = {survey-fids},
	pages = {6073--6084},
}

@inproceedings{qin_federated_2021,
	address = {Kuala Lumpur, Malaysia},
	title = {Federated {Learning}-{Based} {Network} {Intrusion} {Detection} with a {Feature} {Selection} {Approach}},
	isbn = {978-1-66543-897-1},
	url = {https://ieeexplore.ieee.org/document/9514222/},
	doi = {10.1109/ICECCE52056.2021.9514222},
	abstract = {With the increase and diversity of network attacks, machine learning has shown its efﬁciency in realizing intrusion detection. Federated Learning (FL) has been proposed as a new distributed machine learning approach, which collaboratively trains a prediction model by aggregating local models of users without sharing their privacy-sensitive data. Recently, the approach is applied to optimize intrusion detection for resourced-constrained environments. However, since the attacks are becoming more sophisticated and targeted, there is also a growing need to enhance detection models according to the characteristics of attack type; meanwhile, choosing effective feature sets from the network trafﬁc characteristics is considered one of the most important technologies in data analysis. In this paper, we ﬁrst proposed a federated learning-based intrusion detection system with feature selection technology. Firstly, a greedy algorithm is suggested to select features that achieve better intrusion detection accuracy regarding different attack categories. Afterward, multiple global models are generated by the server in federated learning, according to the decided features of edge devices. For evaluating the effectiveness of the proposed approach, simulation experiments based on the latest on-device neural network for anomaly detection are conducted over the NSL-KDD dataset. Experimental results demonstrate greatly improved accuracy of our method.},
	language = {en},
	urldate = {2021-10-04},
	booktitle = {2021 {International} {Conference} on {Electrical}, {Communication}, and {Computer} {Engineering} ({ICECCE})},
	publisher = {IEEE},
	author = {Qin, Yang and Kondo, Masaaki},
	month = jun,
	year = {2021},
	keywords = {survey-fids},
	pages = {1--6},
}

@article{popoola_federated_2021,
	title = {Federated {Deep} {Learning} for {Zero}-{Day} {Botnet} {Attack} {Detection} in {IoT} {Edge} {Devices}},
	issn = {2327-4662, 2372-2541},
	url = {https://ieeexplore.ieee.org/document/9499122/},
	doi = {10.1109/JIOT.2021.3100755},
	abstract = {Deep Learning (DL) has been widely proposed for botnet attack detection in Internet of Things (IoT) networks. However, the traditional Centralized DL (CDL) method cannot be used to detect previously unknown (zero-day) botnet attack without breaching the data privacy rights of the users. In this paper, we propose Federated Deep Learning (FDL) method for zero-day botnet attack detection to avoid data privacy leakage in IoT edge devices. In this method, an optimal Deep Neural Network (DNN) architecture is employed for network trafﬁc classiﬁcation. A model parameter server remotely coordinates the independent training of the DNN models in multiple IoT edge devices, while Federated Averaging (FedAvg) algorithm is used to aggregate local model updates. A global DNN model is produced after a number of communication rounds between the model parameter server and the IoT edge devices. Zero-day botnet attack scenarios in IoT edge devices is simulated with the BotIoT and N-BaIoT data sets. Experiment results show that FDL model: (a) detects zero-day botnet attacks with high classiﬁcation performance; (b) guarantees data privacy and security; (c) has low communication overhead (d) requires low memory space for the storage of training data; and (e) has low network latency. Therefore, FDL method outperformed CDL, Localized DL, and Distributed DL methods in this application scenario.},
	language = {en},
	urldate = {2021-10-01},
	journal = {IEEE Internet of Things Journal},
	author = {Popoola, Segun I. and Ande, Ruth and Adebisi, Bamidele and Gui, Guan and Hammoudeh, Mohammad and Jogunola, Olamide},
	year = {2021},
	keywords = {survey-fids},
	pages = {1--1},
}

@inproceedings{sun_intrusion_2020,
	address = {Glasgow, United Kingdom},
	title = {Intrusion {Detection} with {Segmented} {Federated} {Learning} for {Large}-{Scale} {Multiple} {LANs}},
	isbn = {978-1-72816-926-2},
	url = {https://ieeexplore.ieee.org/document/9207094/},
	doi = {10.1109/IJCNN48605.2020.9207094},
	abstract = {Traditional approaches to cybersecurity issues usually protect users from attacks after the occurrence of specific types of attacks. Besides, patterns of recent cyberattacks tend to be changeable, which add up to unpredictability of them. On the other hand, machine learning, as a new method used to detect intrusion, is attracting more and more attention. Moreover, through the sharing of local training data, the centralized learning approach has proven to improve a model’s performance. In this research, a segmented federated learning is proposed, different from a collaborative learning based on single global model in a traditional federated learning model, it keeps multiple global models which allow each segment of participants to conduct collaborative learning separately and rearranges the segmentation of participants dynamically as well. Furthermore, these multiple global models interact with each other for updating parameters, thus being adaptable to various participants’ LANs. A dataset covering two months’ traffic data from 20 participants’ LANs in the LAN-Security Monitoring Project is used. We adopt three types of knowledgebased methods for labeling network events and train a CNN model based on the dataset. At last, we achieve validation accuracies of 0.923, 0.813 and 0.877 individually with these labeling methods.},
	language = {en},
	urldate = {2021-10-01},
	booktitle = {2020 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	publisher = {IEEE},
	author = {Sun, Yuwei and Ochiai, Hideya and Esaki, Hiroshi},
	month = jul,
	year = {2020},
	keywords = {survey-fids},
	pages = {1--8},
}

@inproceedings{schneble_attack_2019,
	title = {Attack detection using federated learning in medical cyber-physical systems},
	shorttitle = {{ICCCN}},
	abstract = {Medical Cyber-Physical Systems (MCPS) are networked systems of medical devices that provide seamless integration of physical and computation components in healthcare environments to deliver high quality care by enabling continuous monitoring and treatment. As MCPS store sensitive medical data and personal health data, security breaches and unauthorized access to this information can lead to severe repercussions for both the patient and hospital in the form of loss of privacy, abuse, physical harm and liability. The heterogeneity of devices involved in these systems (such as body sensor nodes and mobile devices) introduce large attack surfaces and hence necessitate the design of effective security solutions for these environments. In this paper, we design and implement a massively distributed, machine-learning-based intrusion detection solution for MCPS. Speciﬁcally, we explore the concept of Federated Learning to minimize the communication and computation costs involved in traditional machine learning based solutions. We evaluate our design with real patient data and against security attacks such as Denial of Service, data modiﬁcation, and data injection. Experimental results illustrate that our system achieves high detection accuracy of 99.0\% and a False Positive Rate of 1.0\% along with a reduced network communication overhead. Lastly, we show that the system can cope with unevenly distributed data and is a scalable solution that leverages the computing resources of many mobile devices.},
	language = {en},
	booktitle = {2019 28th {International} {Conference} on {Computer} {Communication} and {Networks} ({ICCCN})},
	author = {Schneble, William and Thamilarasu, Geethapriya},
	month = aug,
	year = {2019},
	keywords = {survey-fids},
}

@inproceedings{nguyen_diot_2019,
	title = {D{ÏoT}: {A} {Federated} {Self}-learning {Anomaly} {Detection} {System} for {IoT}},
	volume = {2019-July},
	isbn = {978-1-72812-519-0},
	url = {https://ieeexplore.ieee.org/document/8884802/},
	doi = {10.1109/ICDCS.2019.00080},
	abstract = {IoT devices are increasingly deployed in daily life. Many of these devices are, however, vulnerable due to insecure design, implementation, and configuration. As a result, many networks already have vulnerable IoT devices that are easy to compromise. This has led to a new category of malware specifically targeting IoT devices. However, existing intrusion detection techniques are not effective in detecting compromised IoT devices given the massive scale of the problem in terms of the number of different types of devices and manufacturers involved. In this paper, we present DÏoT, an autonomous self-learning distributed system for detecting compromised IoT devices. DÏoT builds effectively on device-type-specific communication profiles without human intervention nor labeled data that are subsequently used to detect anomalous deviations in devices' communication behavior, potentially caused by malicious adversaries. DÏoT utilizes a federated learning approach for aggregating behavior profiles efficiently. To the best of our knowledge, it is the first system to employ a federated learning approach to anomaly-detection-based intrusion detection. Consequently, DÏoT can cope with emerging new and unknown attacks. We systematically and extensively evaluated more than 30 off-the-shelf IoT devices over a long term and show that DÏoT is highly effective (95.6\% detection rate) and fast (257 ms) at detecting devices compromised by, for instance, the infamous Mirai malware. DÏoT reported no false alarms when evaluated in a real-world smart home deployment setting.},
	booktitle = {2019 {IEEE} 39th {International} {Conference} on {Distributed} {Computing} {Systems} ({ICDCS})},
	publisher = {IEEE},
	author = {Nguyen, Thien Duc and Marchal, Samuel and Miettinen, Markus and Fereidooni, Hossein and Asokan, N. and Sadeghi, Ahmad-Reza},
	month = jul,
	year = {2019},
	keywords = {survey-fids},
	pages = {756--767},
}

@article{li_deepfed_2020,
	title = {{DeepFed}: {Federated} {Deep} {Learning} for {Intrusion} {Detection} in {Industrial} {Cyber}-{Physical} {Systems}},
	volume = {3203},
	issn = {1551-3203},
	url = {https://ieeexplore.ieee.org/document/9195012/},
	doi = {10.1109/TII.2020.3023430},
	abstract = {The rapid convergence of legacy industrial infrastructures with intelligent networking and computing technologies (e.g., 5G, software defined networking, and artificial intelligence), have dramatically increased the attack surface of industrial cyber-physical systems (CPSs). However, withstanding cyber threats to such large-scale, complex, and heterogeneous industrial CPSs has been extremely challenging, due to the insufficiency of high-quality attack examples. In this paper, we propose a novel federated deep learning scheme, named DeepFed, to detect cyber threats against softwarized industrial CPSs. Specifically, we first design a new deep learning based intrusion detection model for industrial CPSs, by making use of a convolutional neur},
	number = {c},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Li, Beibei and Wu, Yuhao and Song, Jiarui and Lu, Rongxing and Li, Tao and Zhao, Liang},
	year = {2020},
	note = {ISBN: 2013018112007},
	keywords = {survey-fids},
	pages = {1--1},
}

@article{rathore_blockseciotnet_2019,
	title = {{BlockSecIoTNet}: {Blockchain}-based decentralized security architecture for {IoT} network},
	volume = {143},
	issn = {10848045},
	url = {https://doi.org/10.1016/j.jnca.2019.06.019},
	doi = {10.1016/j.jnca.2019.06.019},
	abstract = {The exponential growth of the use of insecure stationary and portable devices in the Internet of Things (IoT) network of the smart city has made the security of the smart city against cyber-attacks a vital issue. Various mechanisms for detecting security attacks that rely on centralized and distributed architectures have already been proposed, but they tend to be inefficient due to such problems as storage constraints, the high cost of computation, high latency, and a single point of failure. Moreover, existing security mechanisms are faced with the issue of monitoring and collecting historic data throughout the entire IoT network of the smart city in order to deliver optimal security and defense against cyberattacks. To address the current challenges, this paper proposes a decentralized security architecture based on Software Defined Networking (SDN) coupled with a blockchain technology for IoT network in the smart city that relies on the three core technologies of SDN, Blockchain, and Fog and mobile edge computing in order to detect attacks in the IoT network more effectively. Thus, in the proposed architecture, SDN is liable to continuous monitoring and analysis of traffic data in the entire IoT network in order to provide an optimal attack detection model; Blockchain delivers decentralized attack detection to mitigate the “single point of failure” problem inherent to the existing architecture; and Fog and mobile edge computing supports attack detection at the fog node and, subsequently, attack mitigation at the edge node, thus enabling early detection and mitigation with lesser storage constraints, cheaper computation, and low latency. To validate the performance of the proposed architecture, it was subjected to an experimental evaluation, the results of which show that it outperforms both centralized and distributed architectures in terms of accuracy and detection time.},
	number = {December 2018},
	journal = {Journal of Network and Computer Applications},
	author = {Rathore, Shailendra and Wook Kwon, Byung and Park, Jong Hyuk},
	month = oct,
	year = {2019},
	note = {Publisher: Elsevier Ltd},
	keywords = {survey-fids},
	pages = {167--177},
}

@inproceedings{zhao_multi-task_2019,
	address = {Hanoi, Ha Long Bay, Viet Nam},
	title = {Multi-{Task} {Network} {Anomaly} {Detection} using {Federated} {Learning}},
	isbn = {978-1-4503-7245-9},
	url = {http://dl.acm.org/citation.cfm?doid=3368926.3369705},
	doi = {10.1145/3368926.3369705},
	abstract = {Because of the complexity of network traffic, there are various significant challenges in the network anomaly detection fields. One of the major challenges is the lack of labeled training data. In this paper, we use federated learning to tackle data scarcity problem and to preserve data privacy, where multiple participants collaboratively train a global model. Unlike the centralized training architecture, participants do not need to share their training to the server in federated learning, which can prevent the training data from being exploited by attackers. Moreover, most of the previous works focus on one specific task of anomaly detection, which restricts the application areas and can not provide more valuable information to network administrators. Therefore, we propose a multi-task deep neural network in federated learning (MT-DNN-FL) to perform network anomaly detection task, VPN (Tor) traffic recognition task, and traffic classification task, simultaneously. Compared with multiple single-task models, the multi-task method can reduce training time overhead. Experiments conducted on well-known CICIDS2017, ISCXVPN2016, and ISCXTor2016 datasets, show that the detection and classification performance achieved by the proposed method is better than the baseline methods in centralized training architecture.},
	language = {en},
	urldate = {2021-06-07},
	booktitle = {Proceedings of the {Tenth} {International} {Symposium} on {Information} and {Communication} {Technology}  - {SoICT} 2019},
	publisher = {ACM Press},
	author = {Zhao, Ying and Chen, Junjun and Wu, Di and Teng, Jian and Yu, Shui},
	year = {2019},
	keywords = {survey-fids},
	pages = {273--279},
}

@article{zhang_blockchain-based_2020,
	title = {Blockchain-based {Federated} {Learning} for {Device} {Failure} {Detection} in {Industrial} {IoT}},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/document/9233457/},
	doi = {10.1109/JIOT.2020.3032544},
	abstract = {Device failure detection is one of most essential problems in industrial internet of things (IIoT). However, in conventional IIoT device failure detection, client devices need to upload raw data to the central server for model training, which might lead to disclosure of sensitive business data. Therefore, in this paper, to ensure client data privacy, we propose a blockchain-based federated learning approach for device failure detection in IIoT. First, we present a platform architecture of blockchain-based federated learning systems for failure detection in IIoT, which enables verifiable integrity of client data. In the architecture, each client periodically creates a Merkle tree in which each leaf node represents a client data record, and stores the tree root on a blockchain. Further, to address the data heterogeneity issue in IIoT failure detection, we propose a novel centroid distance weighted federated averaging (CDW{\textbackslash}\_FedAvg) algorithm taking into account the distance between positive class and negative class of each client dataset. In addition, to motivate clients to participate in federated learning, a smart contact based incentive mechanism is designed depending on the size and the centroid distance of client data used in local model training. A prototype of the proposed architecture is implemented with our industry partner, and evaluated in terms of feasibility, accuracy and performance. The results show that the approach is feasible, and has satisfactory accuracy and performance.},
	journal = {IEEE Internet of Things Journal},
	author = {Zhang, Weishan and Lu, Qinghua and Yu, Qiuyu and Li, Zhaotong and Liu, Yue and Lo, Sin Kit and Chen, Shiping and Xu, Xiwei and Zhu, Liming},
	month = sep,
	year = {2020},
	keywords = {survey-fids},
	pages = {1--1},
}

@inproceedings{al-naday_service-based_2023,
	title = {Service-based {Federated} {Deep} {Reinforcement} {Learning} for {Anomaly} {Detection} in {Fog} {Ecosystems}},
	url = {https://ieeexplore.ieee.org/document/10073495},
	doi = {10.1109/ICIN56760.2023.10073495},
	abstract = {With Digital transformation, the diversity of services and infrastructure in backhaul fog network(s) is rising to unprecedented levels. This is causing a rising threat of a wider range of cyber attacks coupled with a growing integration of constrained range of infrastructure, particularly seen at the network edge. Deep reinforcement-based learning is an attractive approach to detecting attacks, as it allows less dependency on labeled data with better ability to classify different attacks. However, current approaches to learning are known to be computationally expensive (cost) and the learning experience can be negatively impacted by the presence of outliers and noise (quality). This work tackles both the cost and quality challenges with a novel service-based federated deep reinforcement learning solution, enabling anomaly detection and attack classification at a reduced data cost and with better quality. The federated settings in the proposed approach enable multiple edge units to create clusters that follow a bottom-up learning approach. The proposed solution adapts deep Q-learning Network (DQN) for service-tunable flow classification, and introduces a novel federated DQN (FDQN) for federated learning. Through such targeted training and validation, variation in data patterns and noise is reduced. This leads to improved performance per service with lower training cost. Performance and cost of the solution, along with sensitivity to exploration parameters are evaluated using an example publicly available dataset (UNSW-NB15). Evaluation results show the proposed solution to maintain detection accuracy with lower data supply, while improving the classification rate by a factor of ≈ 2.},
	urldate = {2024-04-12},
	booktitle = {2023 26th {Conference} on {Innovation} in {Clouds}, {Internet} and {Networks} and {Workshops} ({ICIN})},
	author = {Al-Naday, Mays and Reed, Martin and Dobre, Vlad and Toor, Salman and Volckaert, Bruno and De Turck, Filip},
	month = mar,
	year = {2023},
	note = {ISSN: 2472-8144},
	keywords = {Cloud computing, Costs, Deep Q-Learning, Deep learning, Q-learning, Sensitivity, Technological innovation, Training, anomaly detection, cloud-to-edge continuum, cyber security, federated deep reinforcement learning, fog computing},
	pages = {121--128},
}

@inproceedings{attanayaka_peer--peer_2023,
	title = {Peer-to-{Peer} {Federated} {Learning} {Based} {Anomaly} {Detection} for {Open} {Radio} {Access} {Networks}},
	url = {https://ieeexplore.ieee.org/document/10278993},
	doi = {10.1109/ICC45041.2023.10278993},
	abstract = {Open radio access network (O-RAN) has been recognized as a revolutionized architecture to support the multi-class wireless services required in fifth-generation (5G) and beyond 5G networks. The openness and the distributed nature of the O-RAN architecture have created new forms of threat surfaces than the conventional RAN architecture and require complex anomaly detection mechanisms. Moreover, with the introduction of RAN intelligent controllers (RICs), it is possible to utilize advanced Artificial Intelligence (AI)/ Machine Learning (ML) algorithms based on closed control loops to detect anomalies in a data-driven manner. In this paper, we particularly investigate the use of Federated Learning (FL) for anomaly detection in the O-RAN architecture, which can further preserve data privacy. We propose a peer-to-peer (P2P) FL-based anomaly detection mechanism for the O-RAN architecture and provide a comprehensive analysis of four variants of P2P FL techniques. Moreover, we simulate the proposed models using the UNSW-NB15 dataset.},
	urldate = {2024-04-12},
	booktitle = {{ICC} 2023 - {IEEE} {International} {Conference} on {Communications}},
	author = {Attanayaka, Dinaj and Porambage, Pawani and Liyanage, Madhusanka and Ylianttila, Mika},
	month = may,
	year = {2023},
	note = {ISSN: 1938-1883},
	keywords = {5G, 5G mobile communication, 6G, Anomaly detection, Data privacy, Federated learning, Machine learning algorithms, Network automation, O-RAN, Peer-to-peer computing, Privacy, RAN Intelligent controllers, Security, Wireless communication},
	pages = {5464--5470},
}

@inproceedings{rumesh_comprehensive_2023,
	title = {Comprehensive {Analysis} {Over} {Centralized} and {Federated} {Learning}-{Based} {Anomaly} {Detection} in {Networks} with {Explainable} {AI} ({XAI})},
	url = {https://ieeexplore.ieee.org/document/10278845},
	doi = {10.1109/ICC45041.2023.10278845},
	abstract = {Many forms of machine learning (ML) and artificial intelligence (AI) techniques are adopted in communication networks to perform all optimizations, security management, and decision-making tasks. Instead of using conventional blackbox models, the tendency is to use explainable ML models that provide transparency and accountability. Moreover, Federate Learning (FL) type ML models are becoming more popular than the typical Centralized Learning (CL) models due to the distributed nature of the networks and security privacy concerns. Therefore, it is very timely to research how to find the explainability using Explainable AI (XAI) in different ML models. This paper comprehensively analyzes using XAI in CL and FL-based anomaly detection in networks. We use a deep neural network as the black-box model with two data sets, UNSW-NB15 and NSLKDD, and SHapley Additive exPlanations (SHAP) as the XAI model. We demonstrate that the FL explanation differs from CL with the client anomaly percentage.},
	urldate = {2024-04-12},
	booktitle = {{ICC} 2023 - {IEEE} {International} {Conference} on {Communications}},
	author = {Rumesh, Yasintha and Senevirathna, Thulitha Theekshana and Porambage, Pawani and Liyanage, Madhusanka and Ylianttila, Mika},
	month = may,
	year = {2023},
	note = {ISSN: 1938-1883},
	keywords = {6G, Autonomous aerial vehicles, Centralized Learning, Closed box, Data models, Decision making, Explainable AI, Federated Learning, Federated learning, Privacy, Security, Security management},
	pages = {4853--4859},
}

@article{babbar_frhids_2023,
	title = {{FRHIDS}: {Federated} {Learning} {Recommender} {Hydrid} {Intrusion} {Detection} {System} {Model} in {Software} {Defined} {Networking} for {Consumer} {Devices}},
	issn = {1558-4127},
	shorttitle = {{FRHIDS}},
	url = {https://ieeexplore.ieee.org/abstract/document/10304342},
	doi = {10.1109/TCE.2023.3329151},
	abstract = {In the past few years, numerous methods of attack against recommendation systems have been developed. Cellphones, smart devices, and self-driving cars are instances of distributed IoT consumer devices that generate massive amounts of data on a daily basis and pose security threats to the cloud server. Due to the higher exchange of data, the challenges in this domain lead to increased security issues. Therefore, intrusion detection systems are important for the security and privacy of IoT consumer devices and hence to the cloud server. Due to the prediction, classification of attacks and recommendation of malware devices, the accuracy of machine learning and deep learning approaches for research in security for IoT consumer devices has gained tremendous popularity. Federated learning (FL), is a privacy-preserving decentralized learning technique that does not transport data but instead trains the model locally before sending the parameters to a cloud server, which helps in ensuring the security of data. However, communication channels can still be attacked by hackers, so blocking malicious data is a major requirement for the cloud server. In this paper, a federated learning recommender hybrid intrusion detection system (FRHIDS) model has been proposed that detects the attacks on the SDN network incoming from the IoT consumer devices and recommends that the safety devices transmit the decrypted data to the federated cloud server. In this model, the preservation of the security and privacy model parameters by utilizing the process of testing and training has been implemented. Simulation shows that the proposed approach’s well-designed recommender system has outperformed state-of-the-art models. The performance of the proposed technique is evaluated based on its computational complexity and validation, which have shown 12\% improvement over the already existing techniques.},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Consumer Electronics},
	author = {Babbar, Himanshi and Rani, Shalli},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Consumer Electronics},
	keywords = {Cloud computing, Computational modeling, Consumer Devices, Data models, Deep learning, Federated Learning, Hybrid Deep Learning Model, Intrusion Detection System, Intrusion detection, Recommender System, Security, Servers},
	pages = {1--1},
}

@article{liu_asynchronous_2023,
	title = {An {Asynchronous} {Federated} {Learning} {Arbitration} {Model} for {Low}-{Rate} {DDoS} {Attack} {Detection}},
	volume = {11},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10049569},
	doi = {10.1109/ACCESS.2023.3247512},
	abstract = {Low-rate Distributed Denial of Service (LDDoS) attacks have been one of the most notorious network security threats, which use periodic slight multi-variate time series pulse flows to degrade network quality. Limited by the poor data in a single client, a powerful and satisfactory LDDoS attack detection model is hard to be trained. Federated Learning (FL) is a promising paradigm offering joint learning through multiple clients. We propose an asynchronous federated learning arbitration framework based on bidirectional LSTM (bi-LSTM) and attention mechanism (AsyncFL-bLAM). In the AsyncFL-bLAM, the leader node election algorithm is proposed for constructing the framework of asynchronous federated learning. The proposed bLAM model composed of feature extracter and arbitrator takes on the responsibility of LDDoS detection locally. Furthermore, the novel AsyncFL framework helps to upload and aggregate the bLAM models’ parameters asynchronously between leader node and client nodes. Experimental results show that the AsyncFL-bLAM outperforms the state-of-the-art models in accuracy, and reduces the overall communication rounds.},
	urldate = {2024-04-12},
	journal = {IEEE Access},
	author = {Liu, Zengguang and Guo, Cuiyun and Liu, Deyong and Yin, Xiaochun},
	year = {2023},
	note = {Conference Name: IEEE Access},
	keywords = {Arbitration mechanism, Data models, Electronic mail, Feature extraction, Federated learning, IP networks, Internet of Things, Training, asynchronous federated learning, deep learning, low-rate distributed denial-of-service},
	pages = {18448--18460},
}

@article{fang_comprehensive_2023,
	title = {Comprehensive {Android} {Malware} {Detection} {Based} on {Federated} {Learning} {Architecture}},
	volume = {18},
	issn = {1556-6021},
	url = {https://ieeexplore.ieee.org/abstract/document/10155173},
	doi = {10.1109/TIFS.2023.3287395},
	abstract = {Android malware and its variants are a major challenge for mobile platforms. However, there are two main problems in the existing detection methods: a ) The detection method lacks the evolution ability for Android malware, which leads to the low detection rate of the detection model for malware and its variants. b ) Traditional detection methods require centralized data for model training, however, the aggregation of training samples is limited due to the infectivity of malware and growing data privacy concerns, centralized detection methods are difficult to be applied in actual detection scenarios. In this paper, we propose FEDriod, a comprehensive Android malware detection method based on federated learning architecture that protects against growing Android malware or emerging Android malware variants. Specifically, we employ genetic evolution strategy to simulate the evolution of Android malware and develop potential malware variants from typical Android malware. Then, we customize the Android malware detection model based on residual neural network to achieve high detection accuracy. Finally, to achieve the protection sensitive data, we develope a federated learning framework to allows multiple Android malware detection agencies to jointly build a comprehensive Android malware detection model. We comprehensively evaluate the performance of FEDriod on the CIC, Drebin, and Contagio authoritative datasets. Experimental results show that our local model outperforms all baseline classifiers. In the federal scenario, our proposed method is superior to the state-of-the-art detection methods, especially in the cross-dataset evaluation, the F1 of FEDriod is 98.53\%. More important, we performed genetic evolution experiments on the Drebin dataset, and the results showed that our proposed method has the ability to detect Android malware variants.},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Fang, Wenbo and He, Junjiang and Li, Wenshan and Lan, Xiaolong and Chen, Yang and Li, Tao and Huang, Jiwu and Zhang, Linlin},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Deep learning, Evolution (biology), Genetic evolution, Genetics, Malware, Operating systems, Smart phones, Training, android malware detection, federated learning, residual networks},
	pages = {3977--3990},
}

@article{sharma_edge-assisted_2024,
	title = {Edge-assisted federated learning for anomaly detection in diverse {IoT} network},
	issn = {2511-2112},
	url = {https://doi.org/10.1007/s41870-024-01728-x},
	doi = {10.1007/s41870-024-01728-x},
	abstract = {The rapid expansion and increasing complexity of Internet of Things (IoT) networks have led to a heightened need for effective and adaptable anomaly detection techniques. The vast variety of devices, communication protocols over 5G and other networks, and data types present in diverse IoT environments poses significant challenges for traditional centralized methods. With the rapid increase of users in 5G networks will require drastic security measures in IoT. This paper proposes an edge-assisted federated learning approach for detecting anomalies in heterogeneous IoT networks, enabling robust and efficient performance across a wide range of devices and scenarios. Our proposed method combines the advantages of federated learning and edge computing, allowing IoT devices to collaboratively train a shared machine learning model while keeping their data local. This approach not only preserves privacy but also reduces communication overhead and latency, providing a scalable solution for large-scale IoT deployments. By incorporating edge computing, our method ensures that data processing occurs closer to the source, further improving efficiency and reducing the reliance on centralized cloud resources. We present a thorough evaluation of our edge-assisted federated learning approach, comparing it to traditional centralized techniques as well as other distributed learning methods. The results demonstrate that our approach achieves superior performance in detecting anomalies in diverse IoT environments while maintaining low latency, communication overhead over network, and energy consumption. Additionally, we showcase the adaptability of our method to various IoT network configurations and device capabilities, highlighting its potential as a versatile solution for real-world IoT anomaly detection challenges.},
	language = {en},
	urldate = {2024-04-12},
	journal = {International Journal of Information Technology},
	author = {Sharma, Priya and Sharma, Sanjay Kumar and Dani, Diksha},
	month = feb,
	year = {2024},
	keywords = {5G, Anomaly detection, Distributed machine learning, Edge computing, Federated learning, Heterogeneous networks, Internet of things (IoT) network, Privacy preservation, Scalability},
}

@article{marmol_campos_misbehavior_2024,
	title = {Misbehavior detection in intelligent transportation systems based on federated learning},
	volume = {25},
	issn = {2542-6605},
	url = {https://www.sciencedirect.com/science/article/pii/S2542660524000696},
	doi = {10.1016/j.iot.2024.101127},
	abstract = {Misbehavior detection represents a key security approach in vehicular scenarios to identify attacks that cannot be detected by traditional cryptographic mechanisms. In this context, the application of Machine Learning (ML) techniques has been widely considered to identify increasingly sophisticated misbehavior attacks. However, most of the proposed approaches are based on centralized settings, which could pose privacy issues, as well as an increased latency leading to severe consequences in the vehicular environment where real-time and scalability requirements are challenging. To address this issue, we propose a collaborative learning approach based on Federated Learning (FL) for vehicles’ misbehavior detection. We use the reference misbehavior dataset VeReMi, which is re-balanced by applying the SMOTE-Tomek technique. We carry out a thorough evaluation considering different balancing settings and number of nodes. The evaluation results overcome recent state-of-the-art approaches, with an overall accuracy of 93\% using an optimized multilayer perceptron (MLP) for multiclass classification.},
	urldate = {2024-04-12},
	journal = {Internet of Things},
	author = {Mármol Campos, Enrique and Hernandez-Ramos, José L. and González Vidal, Aurora and Baldini, Gianmarco and Skarmeta, Antonio},
	month = apr,
	year = {2024},
	keywords = {Federated learning, Intelligent transportation systems, Misbehavior detection},
	pages = {101127},
}

@article{he_federated_2023,
	title = {Federated {Continuous} {Learning} {Based} on {Stacked} {Broad} {Learning} {System} {Assisted} by {Digital} {Twin} {Networks}: {An} {Incremental} {Learning} {Approach} for {Intrusion} {Detection} in {UAV} {Networks}},
	volume = {10},
	issn = {2327-4662},
	shorttitle = {Federated {Continuous} {Learning} {Based} on {Stacked} {Broad} {Learning} {System} {Assisted} by {Digital} {Twin} {Networks}},
	url = {https://ieeexplore.ieee.org/abstract/document/10143925},
	doi = {10.1109/JIOT.2023.3282648},
	abstract = {The edge of the Internet of Things (IoT), which consists of unmanned aerial vehicles (UAVs), is vulnerable to network intrusion because software and wireless connections are used extensively in the IoT. Designing an efficient intrusion detection system (IDS) model is imperative. However, when creating IDS models with distributed data collected by UAVs, it is necessary to take precautions to protect the data’s security and privacy. Furthermore, most of the IDS models are focused on one-time learning but not on continuous learning. To this end, we propose a federated continuous learning framework with a stacked broad learning system (FCL-SBLS) based on the digital twin network (DTN), which can learn and train the IDS model on new data quickly and continuously. In order to improve the efficiency and quality of the IDS model when training and aggregation, we employ an asynchronous federated learning (FL) architecture, and a deep deterministic policy gradient (DDPG)-based UAV selection scheme assisted by DTN is proposed to help the global IDS model aggregation. The presented algorithm is validated using the CIC-IDS2017 data set, and the simulation results reveal that our algorithm achieves higher efficiency and accuracy than the existing FL scheme.},
	number = {22},
	urldate = {2024-04-12},
	journal = {IEEE Internet of Things Journal},
	author = {He, Xiaoqiang and Chen, Qianbin and Tang, Lun and Wang, Weili and Liu, Tong and Li, Li and Liu, Qinghai and Luo, Jia},
	month = nov,
	year = {2023},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Computational modeling, Data models, Data privacy, Digital twin network (DTN), Internet of Things, Intrusion detection, Learning systems, Training, federated continuous learning (FCL), intrusion detection system (IDS), stacked broad learning system (SBLS), unmanned aerial vehicle (UAV) network},
	pages = {19825--19838},
}

@article{fan_lightweight_2023,
	title = {Lightweight {Privacy} and {Security} {Computing} for {Blockchained} {Federated} {Learning} in {IoT}},
	volume = {10},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/abstract/document/10102683},
	doi = {10.1109/JIOT.2023.3267112},
	abstract = {The development of Internet of Things (IoT) makes human life more intelligent, and the interconnection of all things has become a reality. However, the surge in the number of devices and centralized management brings severe challenges to IoT, such as single point of failure, poor security, privacy leakage, and low reliability. Due to the decentralization, verifiability, and privacy protection of blockchain federated learning (BFL), some BFL schemes have been proposed to solve these problems, but bring new challenges, such as device privacy leakage and heavy security computing load. In this article, we propose a new decentralized, secure and verifiable consortium BFL privacy protection scheme, named LPBFL, which realizes lightweight computing while ensuring the privacy of the local model and data set of the device. To achieve lightweight privacy protection, LPBFL adopts the Paillier encryption and the newly designed lightweight digital signature and batch verification algorithm. Additionally, considering that devices upload invalid or even toxic local models intentionally or unintentionally, we design a device reputation selection mechanism to make BFL more efficient. Finally, the theoretical analysis proves the security of LPBFL and verifies the unforgeability of the proposed digital signature. Comprehensive comparisons and extensive experiments demonstrate that our LPBFL has significant advantages in multiple aspects.},
	number = {18},
	urldate = {2024-04-12},
	journal = {IEEE Internet of Things Journal},
	author = {Fan, Mochan and Ji, Kailai and Zhang, Zhaofeng and Yu, Hongfang and Sun, Gang},
	month = sep,
	year = {2023},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Blockchain, Blockchains, Computational modeling, Differential privacy, Internet of Things, Internet of Things (IoT), Privacy, Security, Training, federated learning, privacy protection},
	pages = {16048--16060},
}

@article{thein_personalized_2024,
	title = {Personalized federated learning-based intrusion detection system: {Poisoning} attack and defense},
	volume = {153},
	issn = {0167-739X},
	shorttitle = {Personalized federated learning-based intrusion detection system},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X23003783},
	doi = {10.1016/j.future.2023.10.005},
	abstract = {To deal with the increasing number of cyber-attacks, intrusion detection system (IDS) plays an important role in monitoring and ensuring the security of the computer network. With the power of machine learning and deep learning, intelligent IDS systems have gained increasing attention due to their efficiency and high classification accuracy. However, the premise of machine learning/deep learning is that the data must be in one central entity (e.g., server) to train the model. This causes additional concerns, such as data transmission costs and privacy leakage. Federated learning complements this shortcoming with a privacy-preserving decentralized learning technique. In federated learning, the data are not shared with the server, local model training is performed where the data reside and only the model parameters are exchanged with the server. This work investigates the federated learning-based IDS approach in the context of IoT data to study the main challenges imposed by federated learning. Two main issues, such as data heterogeneity and poisoning attacks launched by malicious clients, are the main focus of this study. As real-world IoT datasets are heterogeneous, we propose a personalized federated learning-based IDS approach to handle imbalanced data distributions. Moreover, a curious yet malicious client can poison the local data or model to corrupt the global intrusion detection model due to the distributed nature of federated learning, where the central server has no control over the client’s local training process. This study demonstrates that the existence of a malicious client can degrade the performance of the federated learning-based IDS model. Accordingly, we propose a robust approach called pFL-IDS to combat poisoning attacks against the federated learning-enabled IDS on heterogeneous IoT data. Our approach introduces mini-batch logit adjustment loss to local model training to obtain a personalized model tailored to each local data distribution. Moreover, we design a detection mechanism at the server to identify malicious agents by considering the cosine similarity of local models from the non-poisoned client’s centroid. The non-poisoned centroid is determined from the similarity between the pre-computed global model and the local models. If the poisoning attack is successful, poisoned clients will be closer to the pre-computed global model; any models further from the pre-computed model are taken as the non-poisoned clients. With this two-phase client similarity alignment, we identify poisoned clients and restrict their aggregation on the global intrusion detection model. In comparison with the baseline methods, we demonstrate that our pFL-IDS can detect poisoning attacks without compromising performance.},
	urldate = {2024-04-12},
	journal = {Future Generation Computer Systems},
	author = {Thein, Thin Tharaphe and Shiraishi, Yoshiaki and Morii, Masakatu},
	month = apr,
	year = {2024},
	keywords = {Intrusion detection system, Personalized federated learning, Poisoning attacks, Poisoning defense},
	pages = {182--192},
}

@article{cunha_neto_fedsbs_2024,
	title = {{FedSBS}: {Federated}-{Learning} participant-selection method for {Intrusion} {Detection} {Systems}},
	volume = {244},
	issn = {1389-1286},
	shorttitle = {{FedSBS}},
	url = {https://www.sciencedirect.com/science/article/pii/S138912862400183X},
	doi = {10.1016/j.comnet.2024.110351},
	abstract = {Federated Learning (FL) is a decentralized machine learning approach in which multiple participants collaboratively train a model. Participants keep data locally, train their local models, and aggregate them in a single global model in a federated server. Collaborative FL-based Intrusion Detection Systems face challenges on an uneven statistical distribution of data and malicious participants trying to subvert the learning process. The statistical hurdles associated with imbalanced data and malicious participants pose a risk of skewing the training with biased or random data. The inability to effectively manage these statistical inconsistencies may degrade system performance, leading to false intrusion detection or opening avenues for cybersecurity breaches. To overcome these challenges, we propose a training method that employs score-based participant selection and utilizes global momentum for model aggregation. Our method improves the global model performance while mitigating the risks posed by malicious participants. The proposal incorporates a scoring system based on an information gain variant to evaluate each participant’s contribution. The scoring system and an epsilon greedy selection method ensure robust participant selection in each aggregation round. Furthermore, incorporating a global momentum term helps preserve previous knowledge at each aggregation round, contributing to model stability and overall learning. The proposed solution has demonstrated superior performance, delivering 80\% F1-Score and 90\% accuracy on experiments even in the presence of malicious participants, revealing the robustness and effectiveness of the proposal in mitigating statistical challenges. Consequently, the proposed method significantly enhances the performance of federated learning models, leading to more secure and efficient collaborative intrusion detection systems.},
	urldate = {2024-04-12},
	journal = {Computer Networks},
	author = {Cunha Neto, Helio N. and Hribar, Jernej and Dusparic, Ivana and Fernandes, Natalia C. and Mattos, Diogo M. F.},
	month = may,
	year = {2024},
	keywords = {Collaborative learning, Federated Learning, Intrusion Detection System, Machine learning},
	pages = {110351},
}

@article{lazzarini_federated_2023,
	title = {Federated {Learning} for {IoT} {Intrusion} {Detection}},
	volume = {4},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2673-2688},
	url = {https://www.mdpi.com/2673-2688/4/3/28},
	doi = {10.3390/ai4030028},
	abstract = {The number of Internet of Things (IoT) devices has increased considerably in the past few years, resulting in a large growth of cyber attacks on IoT infrastructure. As part of a defense in depth approach to cybersecurity, intrusion detection systems (IDSs) have acquired a key role in attempting to detect malicious activities efficiently. Most modern approaches to IDS in IoT are based on machine learning (ML) techniques. The majority of these are centralized, which implies the sharing of data from source devices to a central server for classification. This presents potentially crucial issues related to privacy of user data as well as challenges in data transfers due to their volumes. In this article, we evaluate the use of federated learning (FL) as a method to implement intrusion detection in IoT environments. FL is an alternative, distributed method to centralized ML models, which has seen a surge of interest in IoT intrusion detection recently. In our implementation, we evaluate FL using a shallow artificial neural network (ANN) as the shared model and federated averaging (FedAvg) as the aggregation algorithm. The experiments are completed on the ToN\_IoT and CICIDS2017 datasets in binary and multiclass classification. Classification is performed by the distributed devices using their own data. No sharing of data occurs among participants, maintaining data privacy. When compared against a centralized approach, results have shown that a collaborative FL IDS can be an efficient alternative, in terms of accuracy, precision, recall and F1-score, making it a viable option as an IoT IDS. Additionally, with these results as baseline, we have evaluated alternative aggregation algorithms, namely FedAvgM, FedAdam and FedAdagrad, in the same setting by using the Flower FL framework. The results from the evaluation show that, in our scenario, FedAvg and FedAvgM tend to perform better compared to the two adaptive algorithms, FedAdam and FedAdagrad.},
	language = {en},
	number = {3},
	urldate = {2024-04-12},
	journal = {AI},
	author = {Lazzarini, Riccardo and Tianfield, Huaglory and Charissis, Vassilis},
	month = sep,
	year = {2023},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Internet of Things, deep learning, federated learning, intrusion detection systems},
	pages = {509--530},
}

@article{idrissi_fed-anids_2023,
	title = {Fed-{ANIDS}: {Federated} learning for anomaly-based network intrusion detection systems},
	volume = {234},
	issn = {0957-4174},
	shorttitle = {Fed-{ANIDS}},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417423015026},
	doi = {10.1016/j.eswa.2023.121000},
	abstract = {As computer networks and interconnected systems continue to gain widespread adoption, ensuring cybersecurity has become a prominent concern for organizations, regardless of their scale or size. Meanwhile, centralized machine learning-based Anomaly Detection (AD) methods have shown promising results in improving the accuracy and efficiency of Network Intrusion Detection Systems (NIDS). However, new challenges arise such as privacy concerns and regulatory restrictions that must be tackled. Federated Learning (FL) has emerged as a solution that allows distributed clients to collaboratively train a shared model while preserving the privacy of their local data. In this paper, we propose Fed-ANIDS, a NIDS that leverages AD and FL to address the privacy concerns associated with centralized models. To detect intrusions, we compute an intrusion score based on the reconstruction error of normal traffic using various AD models, including simple autoencoders, variational autoencoders, and adversarial autoencoders. We thoroughly evaluate Fed-ANIDS using various settings and popular datasets, including USTC-TFC2016, CIC-IDS2017, and CSE-CIC-IDS2018. The proposed method demonstrates its effectiveness by achieving high performance in terms of different metrics while preserving the data privacy of distributed clients. Our findings highlight that autoencoder-based models outperform other generative adversarial network-based models, achieving high detection accuracy coupled with fewer false alarms. In addition, the FL framework (FedProx), which is a generalization and re-parametrization of the standard method for FL (FedAvg), achieves better results. The code is available at https://github.com/meryemJanatiIdrissi/Fed-ANIDS.},
	urldate = {2024-04-12},
	journal = {Expert Systems with Applications},
	author = {Idrissi, Meryem Janati and Alami, Hamza and El Mahdaouy, Abdelkader and El Mekki, Abdellah and Oualil, Soufiane and Yartaoui, Zakaria and Berrada, Ismail},
	month = dec,
	year = {2023},
	keywords = {Anomaly detection, Autoencoders, Federated learning, Network intrusion detection, Network security and privacy},
	pages = {121000},
}

@article{yang_dependable_2023,
	title = {Dependable federated learning for {IoT} intrusion detection against poisoning attacks},
	volume = {132},
	issn = {0167-4048},
	url = {https://www.sciencedirect.com/science/article/pii/S0167404823002912},
	doi = {10.1016/j.cose.2023.103381},
	abstract = {Network intrusion detection methods based on federated learning (FL) and edge computing have great potential for protecting the cybersecurity of the Internet of Things. It overcomes the disadvantages of the traditional centralized method, such as high latency, overloaded network, and privacy leakage. At the same time, it can combine private data from multiple participants to train models, and the rich data can train more effective models. However, the inherent security vulnerabilities of the FL framework do not ensure the robustness of the global models trained collaboratively. Towards FL, each participant has access to model parameters and training data, and malicious participants can affect the global model by tampering with data or weights. This paper studies label-flipping attacks in FL-based IoT intrusion detection. We propose a lightweight detection mechanism to mitigate the impact of poisoning attacks on FL-based intrusion detection methods in IoT networks. The detection mechanism on a central server filters anomalous participants and excludes their uploaded models from the global model aggregation. Specifically, we propose a scoring mechanism for evaluating participants based on the loss of the local model and the training dataset size. Afterwards, the Manhattan similarity between each participant will be calculated according to the scores. Finally, the anomalous participants will be found by clustering algorithm for similarity cluster analysis. The experimental results show that our proposed detection method can defend against label-flipping attacks in FL. On the CIC-IDS-2017 dataset, our method can improve the accuracy of the intrusion detection model trained based on FL from 84.3\% to 97.1\%, while enhancing the protection of IoT network security.},
	urldate = {2024-04-12},
	journal = {Computers \& Security},
	author = {Yang, Run and He, Hui and Wang, Yulong and Qu, Yue and Zhang, Weizhe},
	month = sep,
	year = {2023},
	keywords = {Cyber-physical systems, Federated learning, Internet of thing, Label-flipping attacks, Network intrusion detection},
	pages = {103381},
}

@article{liu_delay_2024,
	title = {Delay and {Energy}-{Efficient} {Asynchronous} {Federated} {Learning} for {Intrusion} {Detection} in {Heterogeneous} {Industrial} {Internet} of {Things}},
	volume = {11},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/abstract/document/10365696},
	doi = {10.1109/JIOT.2023.3344457},
	abstract = {Federated learning (FL) is a promising solution to overcome data island and privacy issues in intrusion detection systems (IDSs) for the Industrial Internet of Things (IIoT). However, the heterogeneity of various IIoT devices poses formidable challenges to FL-based intrusion detection, especially the training cost relating to delay and energy consumption. In this article, we propose a delay and energy-efficient asynchronous FL (AFL) framework for intrusion detection (DEAFL-ID) in heterogeneous IIoT. Specifically, we address the shortcomings of low efficiency and high energy consumption in existing FL-based solutions involving all idle IIoT devices. To do so, we formulate an AFL-based optimal device selection problem which aims to select high-quality training devices in advance by exploring the device advantages in detection accuracy, delay reduction, and energy saving. Subsequently, a deep Q-network (DQN)-based learning algorithm is developed to quickly solve the above high-dimensional problem. In addition, to further improve the detection performance, we build a hybrid sampling-assisted convolutional neural network (CNN)-based IDS model, which can eliminate the imbalance of IIoT data and enable the selected devices to fully extract data features. Through simulations, we demonstrate that DEAFL-ID achieves a significant improvement in training cost and detection performance compared with existing IDS schemes.},
	number = {8},
	urldate = {2024-04-12},
	journal = {IEEE Internet of Things Journal},
	author = {Liu, Shumei and Yu, Yao and Zong, Yue and Yeoh, Phee Lep and Guo, Lei and Vucetic, Branka and Duong, Trung Q. and Li, Yonghui},
	month = apr,
	year = {2024},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Asynchronous federated learning (AFL), Data models, Delays, IIoT, Industrial Internet of Things, Intrusion detection, Performance evaluation, Servers, Training, delay and energy consumption, heterogeneous Industrial Internet of Things (IIoT) devices, intrusion detection},
	pages = {14739--14754},
}

@article{djaidja_federated_2024,
	title = {Federated learning for {5G} and beyond, a blessing and a curse- an experimental study on intrusion detection systems},
	volume = {139},
	issn = {0167-4048},
	url = {https://www.sciencedirect.com/science/article/pii/S0167404824000087},
	doi = {10.1016/j.cose.2024.103707},
	abstract = {5G's service providers now leverage Deep Learning (DL) to automate their network slice management, provisioning, and security. To this end, each slice owner contributes data to feed a common dataset used to train centralized learning models. However, this method raises privacy considerations that prevent its usage. Therefore, Federated learning (FL), a collaborative approach that ensures data privacy, is being investigated while striving toward the same performance as centralized learning. As 5G and beyond services are so diverse, the local slice's data is not intended to reflect the entire data distribution. Thus, local data of slices are Non-Independently and non-Identically distributed (Non-IID), posing a challenge for FL-based models. In this paper, we investigate the use of FL to secure network slices and detect potential attacks. For that purpose, we first propose an architecture for deploying intrusion detection systems (IDSs) in 5G and beyond networks. Next, we thoroughly evaluate the latest state-of-art FL algorithms, including FedAvg, FedProx, FedPer, and SCAFFOLD, in the context of Independently and Identically Distributed (IID) and Non-IID data distributions. We compare these FL models to centralized and local DL models. We find that SCAFFOLD outperforms all the other FL algorithms and ensures a stable learning loss convergence, a promising finding that strengthens the case for leveraging FL in IDS development. Nevertheless, none of the FL models could achieve the centralized model's performance in Non-IID scenarios.},
	urldate = {2024-04-12},
	journal = {Computers \& Security},
	author = {Djaidja, Taki Eddine Toufik and Brik, Bouziane and Boualouache, Abdelwahab and Senouci, Sidi Mohammed and Ghamri-Doudane, Yacine},
	month = apr,
	year = {2024},
	keywords = {5G and beyond, Deep learning, Federated learning, IDS, NON-IID},
	pages = {103707},
}

@article{cholakoska_federated_2023,
	title = {Federated {Learning} for {Network} {Intrusion} {Detection} in {Ambient} {Assisted} {Living} {Environments}},
	volume = {PP},
	doi = {10.1109/MIC.2023.3264700},
	abstract = {Given the Internet of Things rapid expansion and widespread adoption, it is of great concern to establish secure interaction between devices without worsening the quality of their performance. Using machine learning techniques has been shown to improve detecting anomalous behavior in these types of networks, but their implementation leads to poor performance and compromised privacy. To better address these shortcomings, federated learning is being introduced. It enables devices to collaboratively train and evaluate a shared model while keeping personal data on-site (e.g., smart homes, intensive care units, hospitals, etc.), thus minimizing the possibility of an attack and fostering real-time distribution of models and learning. The paper investigates the performance of federated learning in comparison to deep learning, with respect to network intrusion detection in ambient assisted living environments. The results demonstrate comparable performances of federated learning with deep learning, while achieving improved data privacy and security.},
	journal = {IEEE Internet Computing},
	author = {Cholakoska, Ana and Gjoreski, Hristijan and Rakovic, Valentin and Denkovski, Daniel and Kalendar, Marija and Pfitzner, Bjarne and Arnrich, Bert},
	month = jul,
	year = {2023},
	pages = {1--9},
}

@article{kollu_cloud-based_2023,
	title = {Cloud-{Based} {Smart} {Contract} {Analysis} in {FinTech} {Using} {IoT}-{Integrated} {Federated} {Learning} in {Intrusion} {Detection}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2306-5729},
	url = {https://www.mdpi.com/2306-5729/8/5/83},
	doi = {10.3390/data8050083},
	abstract = {Data sharing is proposed because the issue of data islands hinders advancement of artificial intelligence technology in the 5G era. Sharing high-quality data has a direct impact on how well machine-learning models work, but there will always be misuse and leakage of data. The field of financial technology, or FinTech, has received a lot of attention and is growing quickly. This field has seen the introduction of new terms as a result of its ongoing expansion. One example of such terminology is “FinTech”. This term is used to describe a variety of procedures utilized frequently in the financial technology industry. This study aims to create a cloud-based intrusion detection system based on IoT federated learning architecture as well as smart contract analysis. This study proposes a novel method for detecting intrusions using a cyber-threat federated graphical authentication system and cloud-based smart contracts in FinTech data. Users are required to create a route on a world map as their credentials under this scheme. We had 120 people participate in the evaluation, 60 of whom had a background in finance or FinTech. The simulation was then carried out in Python using a variety of FinTech cyber-attack datasets for accuracy, precision, recall, F-measure, AUC (Area under the ROC Curve), trust value, scalability, and integrity. The proposed technique attained accuracy of 95\%, precision of 85\%, RMSE of 59\%, recall of 68\%, F-measure of 83\%, AUC of 79\%, trust value of 65\%, scalability of 91\%, and integrity of 83\%.},
	language = {en},
	number = {5},
	urldate = {2024-04-12},
	journal = {Data},
	author = {Kollu, Venkatagurunatham Naidu and Janarthanan, Vijayaraj and Karupusamy, Muthulakshmi and Ramachandran, Manikandan},
	month = may,
	year = {2023},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {FinTech, IoT federated learning architecture, cloud computing, intrusion detection system, smart contract analysis},
	pages = {83},
}

@article{jin_federated_2023,
	title = {Federated {Incremental} {Learning} based {Evolvable} {Intrusion} {Detection} {System} for {Zero}-{Day} {Attacks}},
	volume = {37},
	issn = {1558-156X},
	url = {https://ieeexplore.ieee.org/abstract/document/10110017},
	doi = {10.1109/MNET.018.2200349},
	abstract = {Smart community networks bring great comfort and convenience for people, but also increase security risks of exposing system vulnerabilities and private data to network intruders. This problem has become more prominent as the ever-increasing zero-day attacks which may escape the existing intrusion detection system (IDS) through unknown vulnerabilities. In this article, to keep up with the continuous change of attacks, we conceive an evolvable IDS (EIDS), where the detection model is incrementally updated to turn newfound “unknown” attacks into “known” attacks. In order to discover zero-day attacks, we develop an open-set intrusion detection model based on discriminative auto-encoder. Since the geographically dispersed detectors may suffer from different attack variants, we propose a federated incremental learning based model update method to aggregate the knowledge from different detectors and update the detection model incrementally, which avoids the cumbersome model retraining. To the best of our knowledge, there are rarely few studies considering the federated incremental update of the distributed intrusion detection models. In this way, the “detecting-learning-updating” process forms an evolution cycle, which enables the EIDS to evolve in an autonomous manner. Finally, the experiments conducted on three public datasets demonstrate that EIDS can conduct open-set intrusion detection with an accuracy over 0.86 and significantly reduce over 90 percent of the model update time compared to the centralized model retraining.},
	number = {1},
	urldate = {2024-04-12},
	journal = {IEEE Network},
	author = {Jin, Dong and Chen, Shuangwu and He, Huasen and Jiang, Xiaofeng and Cheng, Siyu and Yang, Jian},
	month = jan,
	year = {2023},
	note = {Conference Name: IEEE Network},
	keywords = {Detectors, Intrusion detection, Security, Smart cities},
	pages = {125--132},
}

@article{popoola_federated_2023,
	title = {Federated {Deep} {Learning} for {Intrusion} {Detection} in {Consumer}-{Centric} {Internet} of {Things}},
	issn = {1558-4127},
	url = {https://ieeexplore.ieee.org/abstract/document/10373897},
	doi = {10.1109/TCE.2023.3347170},
	abstract = {Consumer-centric Internet of Things (CIoT) will play a pivotal role in the fifth industrial revolution (Industry 5.0) but it exhibits vulnerabilities that can render it susceptible to various cyberattacks. Recent studies have explored the potential of Federated Learning (FL) for privacy-preserving intrusion detection in IoT. However, the development of the FL models relied on unrealistic and irrelevant network traffic data, while also exhibiting limitations in terms of covered attack types and classification scenarios. In this paper, we develop Federated Deep Learning (FDL) models using three recent and highly relevant datasets, covering a wide range of attack types as well as binary and multi-class classification scenarios. Our findings demonstrate that the FDL models not only achieve high classification performance, comparable to traditional Centralized Deep Learning (CDL) models, in terms of accuracy (99.60±0.46\%), precision (92.50±8.40\%), recall (95.42±6.24\%), and F1 score (93.51±7.76\%) but also exhibit superior computational efficiency compared to their CDL counterparts. The FDL approach reduces the training time by 30.52-75.87\%. These classification performance and computational efficiency were achieved through multiple rounds of distributed local training in FDL. Therefore, the proposed FDL framework presents a robust security solution for designing and deploying a resilient CIoT.},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Consumer Electronics},
	author = {Popoola, Segun I. and Imoize, Agbotiname L. and Hammoudeh, Mohammad and Adebisi, Bamidele and Jogunola, Olamide and Aibinu, Abiodun M.},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Consumer Electronics},
	keywords = {Computational modeling, Deep learning, Federated learning, Industrial Internet of Things, Industries, Intrusion detection, Protocols, Training, cyber security, deep learning, industrial internet of things, intrusion detection},
	pages = {1--1},
}

@article{amiri-zarandi_sids_2023,
	title = {{SIDS}: {A} federated learning approach for intrusion detection in {IoT} using {Social} {Internet} of {Things}},
	volume = {236},
	issn = {1389-1286},
	shorttitle = {{SIDS}},
	url = {https://www.sciencedirect.com/science/article/pii/S1389128623004504},
	doi = {10.1016/j.comnet.2023.110005},
	abstract = {The Internet of Things (IoT) ecosystem needs Intrusion Detection Systems (IDS) to mitigate cyberattacks and exploit security vulnerabilities. Over the past years, utilizing machine learning in IDSs has gained a lot of attention. However, in many current works, the training data from different locations should be collected in a central server to be used in the learning process. This data-sharing procedure increases concerns regarding data privacy and decreases the data holders’ motivation to participate in the learning process. The use of distributed learning models has been considered a solution to overcome concerns related to privacy. However, these distributed learning models are vulnerable in the presence of untrusted nodes that can participate in the learning process and deteriorate performance. In this paper, we propose SIDS (Social Intrusion Detection System), a trust-oriented federated learning approach for intrusion detection in IoT that utilizes the Social Internet of Things (SIoT). The proposed approach leverages the social relationships among the objects in a system to provide a privacy-preserving collaborative mechanism for detecting intrusions in IoT environments. The experimental results show the proposed solution outperforms the learning models on individual servers while providing a privacy-preserving and trustable environment for collaboration.},
	urldate = {2024-04-12},
	journal = {Computer Networks},
	author = {Amiri-Zarandi, Mohammad and Dara, Rozita A. and Lin, Xiaodong},
	month = nov,
	year = {2023},
	keywords = {Federated learning, Generative Adversarial Networks, IoT, Privacy, SIoT, Security},
	pages = {110005},
}

@article{he_6g-enabled_2023,
	title = {{6G}-enabled {Consumer} {Electronics} {Device} {Intrusion} {Detection} with {Federated} {Meta}-{Learning} and {Digital} {Twins} in a {Meta}-{Verse} {Environment}},
	issn = {1558-4127},
	url = {https://ieeexplore.ieee.org/abstract/document/10271257},
	doi = {10.1109/TCE.2023.3321846},
	abstract = {The widespread adoption of consumer electronics devices coupled with the emergence of 6G technology has led to the establishment of an extensive network of interconnected devices, forming the underlying infrastructure of the Internet of Things (IoT). Nevertheless, this interconnectivity introduces a myriad of security concerns, given that these devices become susceptible to malicious activities and unauthorized breaches. Moreover, conventional intrusion detection systems encounter difficulties in managing imbalanced data scenarios, wherein the count of normal instances vastly exceeds that of intrusion instances. To address this issue, we propose a novel framework for 6G-enabled consumer electronics device intrusion detection, leveraging the power of federated meta-learning and digital twins within a Meta-Verse environment. By leveraging the distributed intelligence of meta-learning across a network of devices, our framework enables efficient and accurate detection of intrusions while mitigating the impact of imbalanced data. Furthermore, by utilizing digital twins within a Meta-Verse environment, we create a scalable and controlled setting for experimentation, enabling the development and evaluation of intrusion detection algorithms in a realistic yet controlled manner. Our experimental results demonstrate the effectiveness of the proposed framework in detecting intrusions on 6G-enabled consumer electronics devices. The federated meta-learning approach achieves superior performance compared to traditional intrusion detection methods, especially in imbalanced data scenarios.},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Consumer Electronics},
	author = {He, Suli and Du, Chengwen and Hossain, M. Shamim},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Consumer Electronics},
	keywords = {6G mobile communication, Consumer Electronics, Data models, Data privacy, Digital Twin, Federated Meta Learning, Intrusion Detection, Intrusion detection, Meta Learning, Metaverse, Security, Training},
	pages = {1--1},
}

@article{alsamiri_federated_2023,
	title = {Federated {Learning} for {Intrusion} {Detection} {Systems} in {Internet} of {Vehicles}: {A} {General} {Taxonomy}, {Applications}, and {Future} {Directions}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1999-5903},
	shorttitle = {Federated {Learning} for {Intrusion} {Detection} {Systems} in {Internet} of {Vehicles}},
	url = {https://www.mdpi.com/1999-5903/15/12/403},
	doi = {10.3390/fi15120403},
	abstract = {In recent years, the Internet of Vehicles (IoV) has garnered significant attention from researchers and automotive industry professionals due to its expanding range of applications and services aimed at enhancing road safety and driver/passenger comfort. However, the massive amount of data spread across this network makes securing it challenging. The IoV network generates, collects, and processes vast amounts of valuable and sensitive data that intruders can manipulate. An intrusion detection system (IDS) is the most typical method to protect such networks. An IDS monitors activity on the road to detect any sign of a security threat and generates an alert if a security anomaly is detected. Applying machine learning methods to large datasets helps detect anomalies, which can be utilized to discover potential intrusions. However, traditional centralized learning algorithms require gathering data from end devices and centralizing it for training on a single device. Vehicle makers and owners may not readily share the sensitive data necessary for training the models. Granting a single device access to enormous volumes of personal information raises significant privacy concerns, as any system-related problems could result in massive data leaks. To alleviate these problems, more secure options, such as Federated Learning (FL), must be explored. A decentralized machine learning technique, FL allows model training on client devices while maintaining user data privacy. Although FL for IDS has made significant progress, to our knowledge, there has been no comprehensive survey specifically dedicated to exploring the applications of FL for IDS in the IoV environment, similar to successful systems research in deep learning. To address this gap, we undertake a well-organized literature review on IDSs based on FL in an IoV environment. We introduce a general taxonomy to describe the FL systems to ensure a coherent structure and guide future research. Additionally, we identify the relevant state of the art in FL-based intrusion detection within the IoV domain, covering the years from FL’s inception in 2016 through 2023. Finally, we identify challenges and future research directions based on the existing literature.},
	language = {en},
	number = {12},
	urldate = {2024-04-12},
	journal = {Future Internet},
	author = {Alsamiri, Jadil and Alsubhi, Khalid},
	month = dec,
	year = {2023},
	note = {Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Federated Learning (FL), Internet of Vehicles (IoV), deep learning, intrusion detection systems (IDS), machine learning},
	pages = {403},
}

@inproceedings{islam_disparity-aware_2023,
	address = {New York, NY, USA},
	series = {{NSysS} '23},
	title = {Disparity-{Aware} {Federated} {Learning} for {Intrusion} {Detection} {Systems} in {Imbalanced} {Non}-{IID} {Settings}},
	isbn = {9798400708787},
	url = {https://dl.acm.org/doi/10.1145/3629188.3629197},
	doi = {10.1145/3629188.3629197},
	abstract = {Many variants of Federated Learning have been proposed to settle different challenges that come with numerous practical applications, one of which is dealing with non-IID data sources. As decentralized data sources in real life are bound to be non-IID, this is one of the hardest challenges, and yet the earliest federated algorithms struggle to resolve this issue, resulting in worse non-IID performance. Also, applications that require capturing really intricate insights from data while upholding the latest data privacy standards, such as Intrusion Detection Systems (IDS) have enabled the use of FL in those domains. In this article, we propose a novel Disparity-Aware federated learning approach that tackles non-IID and data imbalance from both global and local learning steps of FL. Our method capitalizes on state-of-the-art loss functions to tackle data imbalance at the client level and a class distribution-dependent clustering algorithm at the server to tackle class distribution skew. The nature of the process renders it applicable even in asynchronous federated learning schemes. Experiments with multiple benchmark intrusion detection datasets reveal improved performance over traditional deep learning approaches as well as earlier federated learning techniques.},
	urldate = {2024-04-12},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Networking}, {Systems} and {Security}},
	publisher = {Association for Computing Machinery},
	author = {Islam, Md Mohaiminul and Islam, A. B. M. Alim Al},
	year = {2023},
	keywords = {Disparity-awareness, Federated Learning, Imbalanced Learning, Intrusion Detection, NSL-KDD, Non-IID, UNSW-NB15},
	pages = {42--50},
}

@article{han_heterogeneous_2024,
	title = {Heterogeneous {Data}-{Aware} {Federated} {Learning} for {Intrusion} {Detection} {Systems} via {Meta}-{Sampling} in {Artificial} {Intelligence} of {Things}},
	volume = {11},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/abstract/document/10334467},
	doi = {10.1109/JIOT.2023.3337755},
	abstract = {Intrusion detection systems (IDSs) integrated with machine learning (ML) techniques have proven to be effective defenses against the increasing cybersecurity attacks in the Artificial Intelligence of Things (AIoT) domain. Privacy concerns have prompted the emergence of federated learning (FL) as a promising solution for AIoT intrusion detection. Despite their potential, FL-based IDSs still face challenges related to class-imbalanced data and Non-Independent and Identically Distributed (non-IID) data among AIoT devices. These challenges hinder FL from learning meaningful features from the data, thus impeding the convergence of the learning process. To tackle these issues, this article proposes a clustering-enabled federated meta-training (CFMT) framework for AIoT intrusion detection. The proposed CFMT framework effectively addresses the negative impact of imbalanced and non-IID data. Specifically, we design a data- and model-agnostic meta-sampler that adaptively balances local data sets, thereby mitigating the data imbalance problem. Additionally, we propose a dynamic clustering algorithm that selectively eliminates the local models affected by the training state bias caused by non-IID data, thereby addressing the non-IID data issue. Extensive case studies on two real-world data sets demonstrate the superior performance of the proposed CFMT framework compared to existing solutions, including federated non-IID algorithms and federated imbalanced learning algorithms, in terms of IDS performance. Our code and data are available at https://gitee.com/mindspore/models/tree/master/research/cv/HDFL-IDS-Meta.},
	number = {8},
	urldate = {2024-04-12},
	journal = {IEEE Internet of Things Journal},
	author = {Han, Weixiang and Peng, Jialiang and Yu, Jiahua and Kang, Jiawen and Lu, Jiaxun and Niyato, Dusit},
	month = apr,
	year = {2024},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Artificial Intelligence of Things (AIoT), Behavioral sciences, Data models, Data privacy, Federated learning, Intrusion detection, Security, Training, class imbalance, federated learning (FL), intrusion detection, non-IID},
	pages = {13340--13354},
}

@article{shan_cfl-ids_2024,
	title = {{CFL}-{IDS}: {An} {Effective} {Clustered} {Federated} {Learning} {Framework} for {Industrial} {Internet} of {Things} {Intrusion} {Detection}},
	volume = {11},
	issn = {2327-4662},
	shorttitle = {{CFL}-{IDS}},
	url = {https://ieeexplore.ieee.org/abstract/document/10285326},
	doi = {10.1109/JIOT.2023.3324302},
	abstract = {The Industrial Internet of Things (IIoT) offers the manufacturing sector opportunities for transformation and upgrade but also carries significant security risks. Traditional federated learning (FL) as a potential security solution is challenging in complicated application environments with heterogeneous data, imbalanced data, and poisoning attacks. To address these challenges, we construct a clustered FL Framework for IIoT intrusion detection (CFL-IDS) based on local models’ evaluation metrics (EMs). First, we designed an intrusion detection model with a dynamic focal loss (DFL) for all edge nodes (ENs). This model’s performance is enhanced under various imbalanced data partitions by dynamically altering the focus on samples during the loss minimization training process. Second, the time series of EMs of local models to reflect the data distribution of ENs implicitly, and use clustering algorithms to facilitate knowledge sharing among those ENs with similar data distribution to co-optimize a common model for them. Finally, an intelligent cooperative model aggregation mechanism (ICMAM) adaptively adjusts each local model’s weight distribution, which substantially improves the benefits of FL and alleviates subpar models’ alleviates interference from subpar models to FL. Experiments demonstrate that CFL-IDS has stronger robustness and displays superior performance under data imbalance and non-independent and identically distributed (non-IID) situations while being effective against poisoning attacks.},
	number = {6},
	urldate = {2024-04-12},
	journal = {IEEE Internet of Things Journal},
	author = {Shan, Yao and Yao, Yu and Zhou, Xiaoming and Zhao, Tong and Hu, Bo and Wang, Lei},
	month = mar,
	year = {2024},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Adaptation models, Clustered federated learning (FL), Computational modeling, Data models, Industrial Internet of Things, Industrial Internet of Things (IIoT) Intrusion detection, Intrusion detection, Robustness, Training, data imbalanced, evaluation metrics (EMs), non-independent and identically distributed (non-IID), poisoning attack},
	pages = {10007--10019},
}

@article{vadigi_federated_2023,
	title = {Federated reinforcement learning based intrusion detection system using dynamic attention mechanism},
	volume = {78},
	issn = {2214-2126},
	url = {https://www.sciencedirect.com/science/article/pii/S2214212623001928},
	doi = {10.1016/j.jisa.2023.103608},
	abstract = {Due to the recent advancements in the Internet of Things (IoT) and cloud computing technologies, the detection and prevention of intrusions in enterprise networks have become a crucial and challenging task. Real-time monitoring of network traffic and resources is required to protect those networks from intrusions. An Intrusion Detection System (IDS) analyses the data packets from the network and the system-level applications to detect any malicious activity. However, existing IDSs require all the data, collected at different network nodes, to be collated at one central location to perform the analysis for any model development. This approach hampers the data privacy at the network nodes as the data needs to be shared with other nodes. Furthermore, many of the existing IDSs are unable to adapt to evolving attack patterns, which may result in poor network vulnerability detection and significant degradation in the performance of the systems. To address these limitations, we present a Federated Deep Reinforcement Learning-based IDS in which multiple agents are deployed on the network in a distributed fashion, and each of these agents runs a Deep Q-Network logic. We considered the data privacy concerns of each agent while designing the system. In our system, the data at each agent node is not shared with any other nodes. At the same time, however, all the agents in the system benefit, via the attention weighted model aggregation process, from the distribution and pattern of the data available at all the other agents. We have also developed an attention mechanism that dynamically determines attention value of an agent, which is used in the model aggregation process. Our model can be scaled to large networks and is resistant to hardware or network failures at any agent node. We have tested and evaluated our proposed system on the cloud-based ISOT-CID dataset and the standard benchmark NSL-KDD dataset. The experimental findings demonstrate the performance and robustness of our proposed model in terms of metrics like accuracy, precision, false-positive rate, and area under the ROC curve.},
	urldate = {2024-04-12},
	journal = {Journal of Information Security and Applications},
	author = {Vadigi, Sreekanth and Sethi, Kamalakanta and Mohanty, Dinesh and Das, Shom Prasad and Bera, Padmalochan},
	month = nov,
	year = {2023},
	keywords = {Deep Q-networks, Dynamic attention mechanism, Federated learning, Intrusion detection systems (IDS), Reinforcement learning},
	pages = {103608},
}

@article{dong_fadngs_2024,
	title = {{FADngs}: {Federated} {Learning} for {Anomaly} {Detection}},
	issn = {2162-2388},
	shorttitle = {{FADngs}},
	url = {https://ieeexplore.ieee.org/abstract/document/10409269},
	doi = {10.1109/TNNLS.2024.3350660},
	abstract = {With the increasing demand for data privacy, federated learning (FL) has gained popularity for various applications. Most existing FL works focus on the classification task, overlooking those scenarios where anomaly detection may also require privacy-preserving. Traditional anomaly detection algorithms cannot be directly applied to the FL setting due to false and missing detection issues. Moreover, with common aggregation methods used in FL (e.g., averaging model parameters), the global model cannot keep the capacities of local models in discriminating anomalies deviating from local distributions, which further degrades the performance. For the aforementioned challenges, we propose Federated Anomaly Detection with Noisy Global Density Estimation, and Self-supervised Ensemble Distillation (FADngs). Specifically, FADngs aligns the knowledge of data distributions from each client by sharing processed density functions. Besides, FADngs trains local models in an improved contrastive learning way that learns more discriminative representations specific for anomaly detection based on the shared density functions. Furthermore, FADngs aggregates capacities by ensemble distillation, which distills the knowledge learned from different distributions to the global model. Our experiments demonstrate that the proposed method significantly outperforms state-of-the-art federated anomaly detection methods. We also empirically show that the shared density function is privacy-preserving. The code for the proposed method is provided for research purposes https://github.com/kanade00/Federated\_Anomaly\_detection.},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Dong, Boyu and Chen, Dong and Wu, Yu and Tang, Siliang and Zhuang, Yueting},
	year = {2024},
	note = {Conference Name: IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {Adaptation models, Anomaly detection, Data models, Density functional theory, Noise measurement, Self-supervised learning, Training, distributed learning, federated learning (FL), unsupervised learning},
	pages = {1--15},
}

@article{xing_fl-maae_2023,
	title = {{FL}-{MAAE}: {An} {Intrusion} {Detection} {Method} for the {Internet} of {Vehicles} {Based} on {Federated} {Learning} and {Memory}-{Augmented} {Autoencoder}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	shorttitle = {{FL}-{MAAE}},
	url = {https://www.mdpi.com/2079-9292/12/10/2284},
	doi = {10.3390/electronics12102284},
	abstract = {The Internet of Vehicles (IoV) is a network system that enables wireless communication and information exchange between vehicles and other traffic participants. Intrusion detection plays a very important role in the IoV. However, with the development of the IoV, unknown attack behaviors may appear. The lack of analysis and collection of these attack behavior has led to an imbalance in the sample data categories of the IoV intrusion detection, which causes the problem of low detection accuracy. At the same time, the intrusion detection model usually needs to upload data to the cloud for training, which will introduce the privacy risk due to of the leakage of vehicle users’ information. In this paper, we propose an intrusion detection method for the IoV based on federated learning and memory-augmented autoencoder (FL-MAAE). We add a memory module to the autoencoder model to enhance its ability to store the behavior feature patterns of the IoV, make it robust to imbalanced samples, and use the reconstruction error as the evaluation index, so as to detect unknown attacks in the IoV. We propose a federated learning based training method for the IoV intrusion detection model. Local training of intrusion detection models in roadside units can effectively protect the privacy of data resources. We also designed an aggregation method based on the performance contribution of participants to improve the reliability of model aggregation. We conducted experiments on the NSL-KDD intrusion detection dataset to evaluate the performance of the proposed method. Experimental results show that our method has the best intrusion detection performance. In the case of contaminated samples, the accuracy and F1 score of the proposed method are 9.6\% and 7.39\% higher than those of the comparison methods on average.},
	language = {en},
	number = {10},
	urldate = {2024-04-12},
	journal = {Electronics},
	author = {Xing, Ling and Wang, Kun and Wu, Honghai and Ma, Huahong and Zhang, Xiaohui},
	month = jan,
	year = {2023},
	note = {Number: 10
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Internet of Vehicles, autoencoder, federated learning, intrusion detection, network security},
	pages = {2284},
}

@article{ioannou_gemlids-miot_2024,
	title = {{GEMLIDS}-{MIOT}: {A} {Green} {Effective} {Machine} {Learning} {Intrusion} {Detection} {System} based on {Federated} {Learning} for {Medical} {IoT} network security hardening},
	volume = {218},
	issn = {01403664},
	shorttitle = {{GEMLIDS}-{MIOT}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0140366424000793},
	doi = {10.1016/j.comcom.2024.02.023},
	abstract = {The increasing use of Internet of Things (IoT) gadgets in a daily rate has heightened security apprehension, particularly within the healthcare sector. To prevent the unauthorized disclosure of sensitive data, it is imperative for Internet of Things (IoT) systems to promptly and effectively respond to harmful activities. Nevertheless, the act of transferring data to distant cloud servers for analysis gives rise to both temporal delays and apprehensions regarding privacy. To ensure the security of medical Internet of Things (MIoT) networks, a power-efficient Intrusion Detection System (IDS) is employed for three primary objectives that it will result in three stages of execution: i) The objective is to categorize different types of attacks, such as Man-in-the-Middle (MitM) and Distributed Denial of Service (DDoS), by utilizing well-established machine learning (ML) techniques. This classification stage will serve to enhance the Intrusion Detection System (IDS) and the reporting system. ii) Anomaly detection (unknown attack identification), or detection of unknown attacks, will be employed to identify previously unknown attacks. This identification stage involves retraining the ML model to enable future recognition and classification of these unknown attacks when the anomaly attack detector identifies that an unknown attack is recognized. Then, a retraining of the first stage classification model is executed due to the anomaly detection. iii) To ensure that a remote cloud server remains current with the latest classification model changes, Federated Learning (FL) will be utilized. FL allows for collaborative model training while preserving data privacy and security. The experimental findings indicate that the Enhanced Random Forest (also called ensemble random forest) algorithm achieves a remarkable accuracy rate of 99.98\% in classifying attacks. Thus, it will be our first stage classifier. Continuing, the One-Class Support Vector Machine (SVM) algorithm demonstrates a high level of accuracy, reaching 99.7\% in detecting anomalies and, hence, it will be our second stage identifier. Finally, the third-stage approach, which has as a target the overall system model updater, will be our introduced Federated Learning approach that works with the Enhanced Random Forests and identifies the ERF differences from the old model in an optimal way. The efficacy of our technique is confirmed through the implementation of experiments involving an Internet of Things (IoT) system and a Raspberry Pi MIoT gateway and with simulations that simulate the FL updating process. These experiments successfully identify known and unknown attacks with a high-reliability level while limiting resource utilization and energy consumption. Future studies of this work will focus on enhancing the scalability and efficiency of our Intrusion Detection System in MIoT networks.},
	language = {en},
	urldate = {2024-04-12},
	journal = {Computer Communications},
	author = {Ioannou, Iacovos and Nagaradjane, Prabagarane and Angin, Pelin and Balasubramanian, Palaniappan and Kavitha, Karthick Jeyagopal and Murugan, Palani and Vassiliou, Vasos},
	month = mar,
	year = {2024},
	pages = {209--239},
}

@article{yang_blockchain-based_2024,
	title = {Blockchain-{Based} {Federated} {Learning} {With} {Enhanced} {Privacy} and {Security} {Using} {Homomorphic} {Encryption} and {Reputation}},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/abstract/document/10475694},
	doi = {10.1109/JIOT.2024.3379395},
	abstract = {Federated learning, leveraging distributed data from multiple nodes to train a common model, allows for the use of more data to improve the model while also protecting the privacy of original data. However, challenges still exist in ensuring privacy and security within the interactions. To address these issues, this paper proposes a federated learning approach that incorporates blockchain, homomorphic encryption, and reputation. Using homomorphic encryption, edge nodes possessing local data can complete the training of ciphertext models, with their contributions to the aggregation being evaluated by a reputation mechanism. Both models and reputations are documented and verified on the blockchain through consensus process, which then determines the rewards based on the incentive mechanism. This approach not only incentivizes participation in training, but also ensures the privacy of data and models through encryption. Additionally, it addresses security risks associated with both data and network attacks, ultimately leading to a highly accurate trained model. To enhance the efficiency of learning and the performance of the model, a joint adaptive aggregation and resource optimization algorithm is introduced. Finally, simulations and analyses demonstrate that the proposed scheme enhances learning accuracy while maintaining privacy and security.},
	urldate = {2024-04-12},
	journal = {IEEE Internet of Things Journal},
	author = {Yang, Ruizhe and Zhao, Tonghui and Yu, F. Richard and Li, Meng and Zhang, Dajun and Zhao, Xuehui},
	year = {2024},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Data models, Data privacy, Federated learning, Industrial Internet of Things, Industrial Internet of Things (IIoT), Privacy, Security, Training, blockchain, privacy, security},
	pages = {1--1},
}

@article{al-hawawreh_federated_2023,
	title = {Federated {Learning}-assisted {Distributed} {Intrusion} {Detection} {Using} {Mesh} {Satellite} {Nets} for {Autonomous} {Vehicle} {Protection}},
	issn = {1558-4127},
	url = {https://ieeexplore.ieee.org/abstract/document/10261489},
	doi = {10.1109/TCE.2023.3318727},
	abstract = {The widespread use of intelligent consumer electronics, specifically autonomous vehicles, has exponentially increased. The key enablers of this pervasive are the Internet of Things (IoT), Artificial Intelligence (AI), and Satellite communications, which provide consumers with highly precise and reliable self-driving vehicles. However, autonomous vehicles come also with significant cybersecurity concerns. Attackers can easily use satellite links to launch cyberattacks against autonomous vehicles. An Intrusion Detection System (IDS) is one of the most effective mechanisms for providing secure autonomous vehicles. However, existing IDSs based on machine and deep learning train their models in a centralized server, which uploads data or parameters to the central server for training. This structure of IDS has challenges with vehicle mobility, brings processing delays, and increases privacy and security risks, affecting vehicles’ performance. Therefore, for the first time, this paper proposes a new federated learning-assisted distributed IDS using a mesh satellite net to protect autonomous vehicles. We construct a local model using a deep neural network. Then, we provide a mesh federated learning approach that keeps model training local and lets satellites exchange their parameters in a privacy-preserving way. The simulation results show that our proposed model works well while keeping the computation cost reasonable.},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Consumer Electronics},
	author = {Al-Hawawreh, Muna and Hossain, M. Shamim},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Consumer Electronics},
	keywords = {Autonomous vehicles, Consumer electronics, Intrusion detection, LEO satellite, Low earth orbit satellites, Peer-to-peer computing, Satellites, Servers, Training, federated learning, intrusion detection},
	pages = {1--1},
}

@article{ali_systematic_2023,
	title = {A systematic review of federated learning incentive mechanisms and associated security challenges},
	volume = {50},
	issn = {1574-0137},
	url = {https://www.sciencedirect.com/science/article/pii/S1574013723000606},
	doi = {10.1016/j.cosrev.2023.100593},
	abstract = {In response to various privacy risks, researchers and practitioners have been exploring different paradigms that can leverage the increased computational capabilities of consumer devices to train machine learning (ML) models in a distributed fashion without requiring the uploading of the training data from individual devices to central facilities. For this purpose, federated learning (FL) was proposed as a technique that can learn a global machine model at a central master node by the aggregation of models trained locally using private data. However, organizations may be reluctant to train models locally and to share these local ML models due to the required computational resources for model training at their end and due to privacy risks that may result from adversaries inverting these models to infer information about the private training data. Incentive mechanisms have been proposed to motivate end users to participate in collaborative training of ML models (using their local data) in return for certain rewards. However, the design of an optimal incentive mechanism for FL is challenging due to its distributed nature and the fact that the central server has no access to clients’ hyperparameters information and the amount/quality data used for training, which makes the task of determining the reward based on the contribution of individual clients in FL environment difficult. Even though several incentive mechanisms have been proposed for FL, a thorough up-to-date systematic review is missing and this paper fills this gap. To the best of our knowledge, this paper is the first systematic review that comprehensively enlists the design principles required for implementing these incentive mechanisms and then categorizes various incentive mechanisms according to their design principles. In addition, we also provide a comprehensive overview of security challenges associated with incentive-driven FL. Finally, we highlight the limitations and pitfalls of these incentive schemes and elaborate upon open-research issues that require further research attention.},
	urldate = {2024-04-12},
	journal = {Computer Science Review},
	author = {Ali, Asad and Ilahi, Inaam and Qayyum, Adnan and Mohammed, Ihab and Al-Fuqaha, Ala and Qadir, Junaid},
	month = nov,
	year = {2023},
	keywords = {Blockchain, Federated learning, Game theory, Incentive schemes, Mechanism design},
	pages = {100593},
}

@article{ali_blockchain_2023,
	title = {Blockchain and {Federated} {Learning}-based {Intrusion} {Detection} {Approaches} for {Edge}-enabled {Industrial} {IoT} {Networks}: {A} {Survey}},
	shorttitle = {Blockchain and {Federated} {Learning}-based {Intrusion} {Detection} {Approaches} for {Edge}-enabled {Industrial} {IoT} {Networks}},
	doi = {10.1016/j.adhoc.2023.103320},
	abstract = {The Industrial Internet of Things (IIoT) is an evolutionary extension of the traditional Internet of Things (IoT) into processes and machines for applications in the industrial sector. The IIoT systems generate a large amount of private and sensitive data i.e., stored and processed somewhere on the cloud-edge continuum. The IIoT devices, and the IIoT networks are subject to security mechanisms such as intelligent Intrusion Detection and Prevention Systems (IDS/IPS) systems, that can detect and respond unseen malicious network attacks. The adoption of centralized machine learning methods for IDS has become impractical due to the high computational cost and privacy concerns associated with storing large amounts of data on a single server along the cloud-edge continuum. The combination of federated learning and Blockchain has emerged as a promising advancement in addressing the challenge. Federated learning distributes learning to individual IIoT devices without compromising data privacy, while Blockchain enhances privacy and security. Many academic and industrial efforts outline IDS mechanisms using machine learning, deep learning, federated learning, and Blockchain technologies. The utilization of federated learning-based IDS has become increasingly popular and is now being applied to various tasks including IDS/IPS systems. However, existing intrusion detection systems (IDSs) survey are limited to the scope of classical machine learning and deep learning. To address this limitation, we analyze the IIoT literature that integrates Blockchain and federated learning to enhance IDSs and improve its threat detection capabilities. This survey explores the role of Blockchain and federated learning in addressing security and privacy issues, particularly those associated with IDS/IPS in IIoT networks. Insights on the possibilities of machine learning, federated learning, and Blockchain in supporting IDS to monitor IIoT network traffic for anomaly detection are discussed in detail through state of the art. Furthermore, we provide a set of recommendation based on our literature for the effective implementation of a Blockchain and federated learning-based network intrusion detection system. Finally, we summarize the study and highlight challenges as future research directions for Blockchain and Federated Learning-based technologies for cybersecurity and intrusion detection in IIoT.},
	journal = {Ad Hoc Networks},
	author = {Ali, Saqib and Li, Qianmu and Yousafzai, Abdullah},
	month = oct,
	year = {2023},
}

@article{al-naday_federated_2023,
	title = {Federated deep {Q}-learning networks for service-based anomaly detection and classification in edge-to-cloud ecosystems},
	issn = {1958-9395},
	url = {https://doi.org/10.1007/s12243-023-00977-4},
	doi = {10.1007/s12243-023-00977-4},
	abstract = {The diversity of services and infrastructure in metropolitan edge-to-cloud network(s) is rising to unprecedented levels. This is causing a rising threat of a wider range of cyber attacks coupled with a growing integration of a constrained range of infrastructure, particularly seen at the network edge. Deep reinforcement-based learning is an attractive approach to detecting attacks, as it allows less dependency on labeled data with better ability to classify different attacks. However, current approaches to learning are known to be computationally expensive (cost), and the learning experience can be negatively impacted by the presence of outliers and noise (quality). This work tackles both the cost and quality challenges with a novel service-based federated deep reinforcement learning solution, enabling anomaly detection and attack classification at a reduced data cost and with better quality. The federated settings in the proposed approach enable multiple edge units to create clusters that follow a bottom-up learning approach. The proposed solution adapts a deep Q-learning network (DQN) for service-tunable flow classification and introduces a novel federated DQN (FDQN) for federated learning. Through such targeted training and validation, variation in data patterns and noise is reduced. This leads to improved performance per service with lower training cost. Performance and cost of the solution, along with sensitivity to exploration parameters, are evaluated using examples of publicly available datasets (UNSW-NB15 and CIC-IDS2018). Evaluation results show the proposed solution to maintain detection accuracy in the range of ≈75–85\% with lower data supply while improving the classification rate by a factor of ≈2.},
	language = {en},
	urldate = {2024-04-12},
	journal = {Annals of Telecommunications},
	author = {AL-Naday, Mays and Dobre, Vlad and Reed, Martin and Toor, Salman and Volckaert, Bruno and De Turck, Filip},
	month = aug,
	year = {2023},
	keywords = {Anomaly detection, Cloud-to-edge continuum, Cyber security, Deep Q-learning, Federated deep reinforcement learning, Fog computing},
}

@article{hamdi_federated_2023,
	title = {Federated learning-based intrusion detection system for {Internet} of {Things}},
	volume = {22},
	issn = {1615-5270},
	url = {https://doi.org/10.1007/s10207-023-00727-6},
	doi = {10.1007/s10207-023-00727-6},
	abstract = {Intrusion detection in the Internet of Things is becoming increasingly important as the number of connected devices grows. Machine learning algorithms can be applied to detect anomalies in large data sets, making them useful for identifying potential intrusions. However, traditional centralized learning techniques entail collecting data from end devices in one central device for training. Allowing a single entity to have access to vast amounts of personal data raises many security concerns as any issue experienced with the system can lead to widespread data leakage. To prevent these issues, it is critical to seek more secure alternatives such as federated learning. It enables multiple parties to collaborate on the same model without having to share the data between them. This process not only helps protect data privacy, but also reduces the risk of data leakage and improves training efficiency. In this paper, we propose a federated-based intrusion detection system. To better investigate the performance of the proposed model, we considered client-side evaluation whereby in the same round, the clients transfer the local models to the server which aggregates them in an updated global model. Then, the server transfers the updated global model to the clients for evaluation. The clients evaluate the global model locally and send back the results to the server to be aggregated using metric aggregation function. The experimental results show that the proposed federated-IDS achieves a high detection rate.},
	language = {en},
	number = {6},
	urldate = {2024-04-12},
	journal = {International Journal of Information Security},
	author = {Hamdi, Najet},
	month = dec,
	year = {2023},
	keywords = {Centralized learning, Communication overhead, Cyberattacks, Federated learning, Internet of Things},
	pages = {1937--1948},
}

@article{jin_fl-iids_2024,
	title = {{FL}-{IIDS}: {A} novel federated learning-based incremental intrusion detection system},
	volume = {151},
	issn = {0167-739X},
	shorttitle = {{FL}-{IIDS}},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X23003503},
	doi = {10.1016/j.future.2023.09.019},
	abstract = {With the advantage of analyzing data of multiple work sites comprehensively while ensuring data privacy, federated learning-based intrusion detection systems (IDS) are emerging as a distributed intrusion detection paradigm. Most of these IDS are assumed to work on static data. However, in the actual network environment, the practice of setting data as static will lead to the phenomenon known as catastrophic forgetting, where old classes that have already appeared would be forgotten. In this paper, we propose a novel IDS framework called FL-IIDS to effectively address the catastrophic forgetting problem. Firstly, a new loss function is synthetically designed for local model training. With the new function, the class gradient balance loss function assigns different learning weights to data of the new and old classes so that the learning rate of the new classes would decrease and the memory of the overall old classes would be deepened. Moreover, the sample label smoothing loss function leverages the knowledge distillation method to enhance the local model memory for every specific class of old classes. Secondly, the relay client fusing sample reconstruction is employed to mitigate the spread of catastrophic forgetting globally without compromising data privacy. Extensive experimental results on the UNSW-NB15 dataset and the CICIDS2018 dataset show that our proposed framework improves the memory capability for old classes substantially without affecting the detection effectiveness of the IDS for new classes.},
	urldate = {2024-04-12},
	journal = {Future Generation Computer Systems},
	author = {Jin, Zhigang and Zhou, Junyi and Li, Bing and Wu, Xiaodong and Duan, Chenxu},
	month = feb,
	year = {2024},
	keywords = {Catastrophic forgetting, Continual learning, Distributed computation, Federated learning, Incremental learning, Intrusion detection system},
	pages = {57--70},
}

@article{jahromi_ensemble_2023,
	title = {An ensemble deep federated learning cyber-threat hunting model for {Industrial} {Internet} of {Things}},
	volume = {198},
	issn = {0140-3664},
	url = {https://www.sciencedirect.com/science/article/pii/S0140366422004327},
	doi = {10.1016/j.comcom.2022.11.009},
	abstract = {Industrial Internet of Things (IIoT) is an emerging technology with prompt evolution in diverse applications, including critical infrastructure. While the increasing number of IIoT devices in today’s critical infrastructure enhances their efficiency and reliability, it also increases their vulnerability towards cyber-attacks. Ambient Intelligence (AmI), including machine learning techniques, is a way to handle such challenges with minimizing the human role. Although using machine learning-based techniques is increased in some applications these days, they are not widely used in IIoT environments due to the privacy issues of transferring all the data into a single machine to train the models. This paper proposes an ensemble-based deep federated learning cyber-threat hunting model to hunt the attack samples without data sharing. The proposed hunting model consists of two parallel federated-based components, one analyzes the IIoT status based on the normal situation of the network, and the other analyzes it with considering the threat situation. This model used an ensemble of classifiers to make the final decision. The proposed cyber-threat hunting model is evaluated using two test cases and compared with some works in the literature and outperformed them in the f1-score metric. Moreover, evaluations show that the proposed model acts stable in facing different numbers of clients, and its training time is faster than the centralized models with the same computational complexity.},
	urldate = {2024-04-12},
	journal = {Computer Communications},
	author = {Jahromi, Amir Namavar and Karimipour, Hadis and Dehghantanha, Ali},
	month = jan,
	year = {2023},
	keywords = {Aambient Intelligence (AmI), Critical infrastructure, Cyber-threat hunting, Deep learning, Ensemble model, Federated learning, Industrial Internet of Things (IIoT), Industrial control systems, Industry4.0, Representation learning},
	pages = {108--116},
}

@inproceedings{quyen_federated_2022,
	address = {Cham},
	title = {Federated {Intrusion} {Detection} on {Non}-{IID} {Data} for {IIoT} {Networks} {Using} {Generative} {Adversarial} {Networks} and {Reinforcement} {Learning}},
	isbn = {978-3-031-21280-2},
	doi = {10.1007/978-3-031-21280-2_20},
	abstract = {Federated learning (FL) has become the promising approach for building collaborative intrusion detection systems (IDS) as providing privacy guaranteeing among data holders. Nevertheless, the non-independent and identically distributed (Non-IID) data in real-world scenarios negatively impacts the performance of aggregated models from training client updates. To this end, in this paper, we introduce Generative Adversarial Networks (GANs) and Reinforcement Learning (RL) approach for federated IDS that can deal with Non-IID data among organizational networks. More specifically, the imbalanced state between data classes is tackled by GAN-based data augmentation, while RL provides better performance in the client choosing process for federated IDS model training. Finally, the experimental results on Kitsune dataset indicate that our work can help to set up the collaboration between data holders for building more effective IDS to deploy in practice with distinguished data distribution.},
	language = {en},
	booktitle = {Information {Security} {Practice} and {Experience}},
	publisher = {Springer International Publishing},
	author = {Quyen, Nguyen Huu and Duy, Phan The and Vy, Nguyen Chi and Hien, Do Thi Thu and Pham, Van-Hau},
	editor = {Su, Chunhua and Gritzalis, Dimitris and Piuri, Vincenzo},
	year = {2022},
	pages = {364--381},
}

@article{fan_taking_2024,
	title = {Taking {Advantage} of the {Mistakes}: {Rethinking} {Clustered} {Federated} {Learning} for {IoT} {Anomaly} {Detection}},
	volume = {35},
	issn = {1558-2183},
	shorttitle = {Taking {Advantage} of the {Mistakes}},
	url = {https://ieeexplore.ieee.org/abstract/document/10476751},
	doi = {10.1109/TPDS.2024.3379905},
	abstract = {Clustered federated learning (CFL) is a promising solution to address the non-IID problem in the spatial domain for federated learning (FL). However, existing CFL solutions overlook the non-IID issue in the temporal domain and lack consideration of time efficiency. In this work, we propose a novel approach, called ClusterFLADS, which takes advantage of the false predictions of the inappropriate global models, together with knowledge of temperature scaling and catastrophic forgetting to reveal distributional similarities between the training data (of different clusters) and the test data. Additionally, we design an efficient feature extraction scheme by exploiting the role of each layer in a neural network's learning process. By strategically selecting model parameters and using PCA for dimensionality reduction, ClusterFLADS effectively improves clustering speed. We evaluate ClusterFLADS using real-world IoT trace data in various scenarios. Our results show that ClusterFLADS accurately and efficiently clusters clients, achieving a 100\% true positive rate and low false positives across various data distributions in both the spatial and temporal domains.},
	number = {6},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Fan, Jiamin and Wu, Kui and Tang, Guoming and Zhou, Yang and Huang, Shengqiang},
	month = jun,
	year = {2024},
	note = {Conference Name: IEEE Transactions on Parallel and Distributed Systems},
	keywords = {Adaptation models, Anomaly detection, Cluster federated learning, Data models, Feature extraction, Federated learning, Internet of Things, IoT traffic anomaly detection, Training, spatial-temporal non-IID problem},
	pages = {707--721},
}

@article{neto_survey_2023,
	title = {A {Survey} on {Securing} {Federated} {Learning}: {Analysis} of {Applications}, {Attacks}, {Challenges}, and {Trends}},
	volume = {11},
	issn = {2169-3536},
	shorttitle = {A {Survey} on {Securing} {Federated} {Learning}},
	url = {https://ieeexplore.ieee.org/document/10107622},
	doi = {10.1109/ACCESS.2023.3269980},
	abstract = {The growth of data generation capabilities, facilitated by advancements in communication and computation technologies, as well as the rise of the Internet of Things (IoT), results in vast amounts of data that significantly enhance the performance of machine learning models. However, collecting all necessary data to train accurate models is often unfeasible due to privacy laws. Federated Learning (FL) evolved as a collaborative machine learning approach for training models without sharing private data. Unfortunately, several in-design vulnerabilities have been exposed, allowing attackers to infer private data of participants and negatively impacting the performance of the federated model. In light of these challenges and to encourage the development of FL solutions, this paper provides a comprehensive analysis of secure FL proposals that both protect user privacy and enhance the performance of the model. We performed a systematic review using predefined criteria to screen and extract data from multiple electronic databases, resulting in a final set of studies for analysis. Through the systematic review methodology, the paper groups the security vulnerabilities of FL into model performance and data privacy attacks. It also presents an analysis and comparison of potential mitigation strategies against these attacks. Additionally, the paper conducts a security analysis of state-of-the-art FL applications and proposals based on the vulnerabilities addressed. Finally, the paper outlines the main applications of secure FL and lists future research challenges. The survey highlights the crucial role of security strategies in ensuring the protection of user privacy and model performance in the context of future FL applications.},
	urldate = {2024-04-12},
	journal = {IEEE Access},
	author = {Neto, Helio N. Cunha and Hribar, Jernej and Dusparic, Ivana and Mattos, Diogo Menezes Ferrazani and Fernandes, Natalia C.},
	year = {2023},
	note = {Conference Name: IEEE Access},
	keywords = {Cloud computing, Collaboration, Computational modeling, Data models, Edge computing, Federated learning, Information security, Machine learning, Security, collaborative learning, information security, machine learning, multiaccess edge computing},
	pages = {41928--41953},
}

@article{hajj_cross-layer_2023,
	title = {Cross-{Layer} {Federated} {Learning} for {Lightweight} {IoT} {Intrusion} {Detection} {Systems}},
	volume = {23},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/23/16/7038},
	doi = {10.3390/s23167038},
	abstract = {With the proliferation of IoT devices, ensuring the security and privacy of these devices and their associated data has become a critical challenge. In this paper, we propose a federated sampling and lightweight intrusion-detection system for IoT networks that use K-meansfor sampling network traffic and identifying anomalies in a semi-supervised way. The system is designed to preserve data privacy by performing local clustering on each device and sharing only summary statistics with a central aggregator. The proposed system is particularly suitable for resource-constrained IoT devices such as sensors with limited computational and storage capabilities. We evaluate the system’s performance using the publicly available NSL-KDD dataset. Our experiments and simulations demonstrate the effectiveness and efficiency of the proposed intrusion-detection system, highlighting the trade-offs between precision and recall when sharing statistics between workers and the coordinator. Notably, our experiments show that the proposed federated IDS can increase the true-positive rate up to 10\% when the workers and the coordinator collaborate.},
	language = {en},
	number = {16},
	urldate = {2024-04-12},
	journal = {Sensors},
	author = {Hajj, Suzan and Azar, Joseph and Bou Abdo, Jacques and Demerjian, Jacques and Guyeux, Christophe and Makhoul, Abdallah and Ginhac, Dominique},
	month = jan,
	year = {2023},
	note = {Number: 16
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {federated learning, internet of things, lightweight intrusion detection, lightweight sampling, semi-supervised learning},
	pages = {7038},
}

@article{alazab_enhancing_2023,
	title = {Enhancing {Privacy}-{Preserving} {Intrusion} {Detection} through {Federated} {Learning}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/12/16/3382},
	doi = {10.3390/electronics12163382},
	abstract = {Detecting anomalies, intrusions, and security threats in the network (including Internet of Things) traffic necessitates the processing of large volumes of sensitive data, which raises concerns about privacy and security. Federated learning, a distributed machine learning approach, enables multiple parties to collaboratively train a shared model while preserving data decentralization and privacy. In a federated learning environment, instead of training and evaluating the model on a single machine, each client learns a local model with the same structure but is trained on different local datasets. These local models are then communicated to an aggregation server that employs federated averaging to aggregate them and produce an optimized global model. This approach offers significant benefits for developing efficient and effective intrusion detection system (IDS) solutions. In this research, we investigated the effectiveness of federated learning for IDSs and compared it with that of traditional deep learning models. Our findings demonstrate that federated learning, by utilizing random client selection, achieved higher accuracy and lower loss compared to deep learning, particularly in scenarios emphasizing data privacy and security. Our experiments highlight the capability of federated learning to create global models without sharing sensitive data, thereby mitigating the risks associated with data breaches or leakage. The results suggest that federated averaging in federated learning has the potential to revolutionize the development of IDS solutions, thus making them more secure, efficient, and effective.},
	language = {en},
	number = {16},
	urldate = {2024-04-12},
	journal = {Electronics},
	author = {Alazab, Ammar and Khraisat, Ansam and Singh, Sarabjot and Jan, Tony},
	month = jan,
	year = {2023},
	note = {Number: 16
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {anomaly detection, communication network security, data privacy, federated learning, intrusion detection system},
	pages = {3382},
}

@inproceedings{rieger_crowdguard_2024,
	address = {San Diego, CA, USA},
	title = {{CrowdGuard}: {Federated} {Backdoor} {Detection} in {Federated} {Learning}},
	isbn = {978-1-891562-93-8},
	shorttitle = {{CrowdGuard}},
	url = {https://www.ndss-symposium.org/wp-content/uploads/2024-233-paper.pdf},
	doi = {10.14722/ndss.2024.23233},
	abstract = {Federated Learning (FL) is a promising approach enabling multiple clients to train Deep Neural Networks (DNNs) collaboratively without sharing their local training data. However, FL is susceptible to backdoor (or targeted poisoning) attacks. These attacks are initiated by malicious clients who seek to compromise the learning process by introducing specific behaviors into the learned model that can be triggered by carefully crafted inputs. Existing FL safeguards have various limitations: They are restricted to specific data distributions or reduce the global model accuracy due to excluding benign models or adding noise, are vulnerable to adaptive defense-aware adversaries, or require the server to access local models, allowing data inference attacks.},
	language = {en},
	urldate = {2024-04-12},
	booktitle = {Proceedings 2024 {Network} and {Distributed} {System} {Security} {Symposium}},
	publisher = {Internet Society},
	author = {Rieger, Phillip and Krauß, Torsten and Miettinen, Markus and Dmitrienko, Alexandra and Sadeghi, Ahmad-Reza},
	year = {2024},
}

@inproceedings{boudko_federated_2023,
	address = {Cham},
	title = {Federated {Learning} for {Collaborative} {Cybersecurity} of {Distributed} {Healthcare}},
	isbn = {978-3-031-48348-6},
	doi = {10.1007/978-3-031-48348-6_5},
	abstract = {Healthcare 4.0 is a new paradigm for providing healthcare services in highly distributed and complex settings. The distributed and heterogeneous nature of home-based medical devices, and their need to exchange data with external sources make Healthcare 4.0 solutions susceptible to cyberattacks and require decentralized solutions to protect sensitive local data. This work presents a collaborative approach to security incident detection for distributed healthcare utilizing federated learning. At this stage, the federated learning process has been facilitated and evaluated using simulation, training, and testing.},
	language = {en},
	booktitle = {Advances in {Mobile} {Computing} and {Multimedia} {Intelligence}},
	publisher = {Springer Nature Switzerland},
	author = {Boudko, Svetlana},
	editor = {Delir Haghighi, Pari and Khalil, Ismail and Kotsis, Gabriele and ER, Ngurah Agus Sanjaya},
	year = {2023},
	pages = {57--62},
}

@article{lin_fedevcp_2023,
	title = {{FedEVCP}: {Federated} {Learning}-{Based} {Anomalies} {Detection} for {Electric} {Vehicle} {Charging} {Pile}},
	issn = {0010-4620},
	shorttitle = {{FedEVCP}},
	url = {https://doi.org/10.1093/comjnl/bxad078},
	doi = {10.1093/comjnl/bxad078},
	abstract = {Vehicle-to-Grid (V2G) is a technology that enables electric vehicles to use smart charging methods to harness low-cost and renewable energy when it is available, and obtain income by feeding energy back into the grid. With the rise of V2G technology, the use of electric vehicles has begun to increase dramatically, which relies on the reliable Electric Vehicle Charging Pile (EVCP). However, most EVCPs are online and networked, introducing many potential network threats, such as Electricity Theft, Identity Theft and False Data Injection etc. Prior work has mostly focused on machine learning, which is not able to effectively capture the relationships and structures in network traffic, making it difficult to deal with the propagation and infection of the novel network attacks. Moreover, most neural network models collect and transfer data from EVCPs to the central server for training, which makes the central server attractive to attackers. It poses a serious threat to user privacy. To address these issues, propose an anomaly detection model that incorporates Federated Learning and Deep Autoencoder, which can increase the amount and diversity of data used to train deep learning models without compromising privacy. The proposed model forms a layer-by-layer unsupervised representation learning algorithm by autoencoder stacking, while batch normalization of hidden layers accelerates the convergence of the model to avoid overfitting and local optima, and introduces an attention mechanism to enhance key features of sequences composed of data vectors to improve the accuracy rate. To prevent the risk of user privacy leakage on the central server, EVCP is allowed to retain local data for model training and send model parameters to the central server for constructing new global models. Experimental results show that the proposed scheme achieves improved detection accuracy with superior performance than other similar models.},
	urldate = {2024-04-12},
	journal = {The Computer Journal},
	author = {Lin, Zhaoliang and Li, Jinguo},
	month = aug,
	year = {2023},
	pages = {bxad078},
}

@article{kristianto_misbehavior_2023,
	title = {Misbehavior detection system with semi-supervised federated learning},
	volume = {41},
	issn = {2214-2096},
	url = {https://www.sciencedirect.com/science/article/pii/S221420962300027X},
	doi = {10.1016/j.vehcom.2023.100597},
	abstract = {V2X communications can enhance transportation safety by exchanging safety information between vehicles, road infrastructures, networks, and pedestrians. However, the safety messages are vulnerable to disruption from faulty components or an attack that can cause misinformation. Recently, a machine learning-based misbehavior detection system (MDS) has been widely investigated to detect the misbehaving vehicles to secure the V2X communications. Nonetheless, machine learning models need sufficient labeled data for learning purposes. However, the volume of unlabeled data is usually larger than that of labeled data in practice. Moreover, transferring the large dataset to a centralized learning model will consume much bandwidth. Thus, we propose a semi-supervised federated learning MDS to overcome the limitations of unlabeled data and bring the training close to the data sources to reduce the bandwidth to the core network. Overall, our model with only limited labeled data training (5\%–30\%) can achieve the F1-score up to 0.96 and the recall up to 0.95. The F1-score is up to 0.26 higher and the recall is up to 0.29 higher than the performance of centralized supervised learning. The federated learning model can reduce the core network bandwidth utilization by up to 95\%.},
	urldate = {2024-04-12},
	journal = {Vehicular Communications},
	author = {Kristianto, Edy and Lin, Po-Ching and Hwang, Ren-Hung},
	month = jun,
	year = {2023},
	keywords = {Federated learning, Misbehavior detection system, Semi-supervised learning, V2X communications},
	pages = {100597},
}

@article{naeem_federated-learning-empowered_2023,
	title = {Federated-{Learning}-{Empowered} {Semi}-{Supervised} {Active} {Learning} {Framework} for {Intrusion} {Detection} in {ZSM}},
	volume = {61},
	issn = {1558-1896},
	url = {https://ieeexplore.ieee.org/abstract/document/10047851},
	doi = {10.1109/MCOM.001.2200533},
	abstract = {Exponential growth of novel radical applications and services in sixth-generation (6G) networks is expected to increase the complexity of managing existing network infrastructures. In this context, the zero touch network and service management (ZSM) paradigm, which leverages AI, SDN, and NFV techniques, is seen as a promising solution to automatically manage and orchestrate network resources. However, due to the closed-loop operation and automated end-to-end framework in a distributed 6G network, the ZSM architecture, along with its potential benefits, is exposed to various security threats. A recently proposed solution to address privacy concerns is federated learning (FL), whereby distributed training is performed, and the aggregated model parameters, instead of clients' raw data, are forwarded to the global server. However, most of the existing FL and semi-supervised learning (SSL) models for intrusion detection are based on the assumption that fully labeled data are always available at the server and client sides, which is not practical due to the high labeling costs and privacy constraints in the 6G network. In this article, we propose a novel FL-empowered semi-supervised active learning (FL-SSAL) security orchestration framework for the Label-at-Client scenario where, along with unlabeled samples, clients have a small portion of labeled data. The entropy-based active learning selects the most informative samples for data annotation and leverages the unlabeled data using a semi-supervised approach. The results of our experimental evaluations performed on the private, not independent and identically distributed (non-IID) dataset demonstrate that FL-SSAL achieves higher intrusion detection accuracy and has less communication overhead than baseline schemes with less labeled data.},
	number = {2},
	urldate = {2024-04-12},
	journal = {IEEE Communications Magazine},
	author = {Naeem, Faisal and Ali, Mansoor and Kaddoum, Georges},
	month = feb,
	year = {2023},
	note = {Conference Name: IEEE Communications Magazine},
	keywords = {6G mobile communication, Annotations, Costs, Data privacy, Distributed databases, Intrusion detection, Training},
	pages = {88--94},
}

@article{dos_santos_federated_2023,
	title = {Federated learning for reliable model updates in network-based intrusion detection},
	volume = {133},
	issn = {0167-4048},
	url = {https://www.sciencedirect.com/science/article/pii/S0167404823003231},
	doi = {10.1016/j.cose.2023.103413},
	abstract = {Machine Learning techniques for network-based intrusion detection are widely adopted in the scientific literature. Besides being highly variable, network traffic behavior changes over time, demanding proposed schemes to be periodically updated to ensure their reliability. Unfortunately, their efficiency is significantly limited in production environments. This paper proposes a new Federated Learning model for reliable network-based intrusion detection with highly confident model updates over time. Our proposed scheme assesses the classification reliability in an unsupervised fashion and rejects potential misclassifications even when outdated. In addition, it significantly eases the model update cost by conducting it in a Federated Learning rationale. To evaluate the effectiveness of our solution, we conduct an experimental campaign with a new dataset, MAWIFlow, with over 7 TB of real network traffic spanning a year. The achieved results of our proposed model are striking. It respectively improves the average false-positive and false-negative rates by up to 12\% and 9.6\% when no model updates are conducted. If done so, it can further improve the false-positive rate by up to 13\% while rejecting only 3.6\% of events and demanding only 0.3\% of events for model updates. Further, the comparison against the traditional Federated Learning approach confirms our model's remarkable performance in several scenarios. Finally, the quality and viability of our solution do prove that our approach can be successfully adopted for improving the accuracy and efficiency of classification systems in real-world scenarios where outdated models are prevalent and pave the way for future research in the area.},
	urldate = {2024-04-12},
	journal = {Computers \& Security},
	author = {dos Santos, Roger R. and Viegas, Eduardo K. and Santin, Altair O. and Tedeschi, Pietro},
	month = oct,
	year = {2023},
	keywords = {Federated learning, Intrusion detection, Network attacks, Reject option, Reliability},
	pages = {103413},
}

@article{singh_fair_2023,
	title = {Fair detection of poisoning attacks in federated learning on non-i.i.d. data},
	volume = {37},
	issn = {1573-756X},
	url = {https://doi.org/10.1007/s10618-022-00912-6},
	doi = {10.1007/s10618-022-00912-6},
	abstract = {Reconciling machine learning with individual privacy is one of the main motivations behind federated learning (FL), a decentralized machine learning technique that aggregates partial models trained by clients on their own private data to obtain a global deep learning model. Even if FL provides stronger privacy guarantees to the participating clients than centralized learning collecting the clients’ data in a central server, FL is vulnerable to some attacks whereby malicious clients submit bad updates in order to prevent the model from converging or, more subtly, to introduce artificial bias in the classification (poisoning). Poisoning detection techniques compute statistics on the updates to identify malicious clients. A downside of anti-poisoning techniques is that they might lead to discriminate minority groups whose data are significantly and legitimately different from those of the majority of clients. This would not only be unfair, but would yield poorer models that would fail to capture the knowledge in the training data, especially when data are not independent and identically distributed (non-i.i.d.). In this work, we strive to strike a balance between fighting poisoning and accommodating diversity to help learning fairer and less discriminatory federated learning models. In this way, we forestall the exclusion of diverse clients while still ensuring detection of poisoning attacks. Empirical work on three data sets shows that employing our approach to tell legitimate from malicious updates produces models that are more accurate than those obtained with state-of-the-art poisoning detection techniques. Additionally, we explore the impact of our proposal on the performance of models on non-i.i.d local training data.},
	language = {en},
	number = {5},
	urldate = {2024-04-12},
	journal = {Data Mining and Knowledge Discovery},
	author = {Singh, Ashneet Khandpur and Blanco-Justicia, Alberto and Domingo-Ferrer, Josep},
	month = sep,
	year = {2023},
	keywords = {Fairness, Federated learning, Minorities., Privacy, Security},
	pages = {1998--2023},
}

@article{badr_privacy-preserving_2023,
	title = {Privacy-{Preserving} and {Communication}-{Efficient} {Energy} {Prediction} {Scheme} {Based} on {Federated} {Learning} for {Smart} {Grids}},
	volume = {10},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/abstract/document/10005179},
	doi = {10.1109/JIOT.2022.3230586},
	abstract = {Energy forecasting is important because it enables infrastructure planning and power dispatching while reducing power outages and equipment failures. It is well-known that federated learning (FL) can be used to build a global energy predictor for smart grids without revealing the customers’ raw data to preserve privacy. However, it still reveals local models’ parameters during the training process, which may still leak customers’ data privacy. In addition, for the global model to converge, it requires multiple training rounds, which must be done in a communication-efficient way. Moreover, most existing works only focus on load forecasting while neglecting energy forecasting in net-metering systems. To address these limitations, in this article, we propose a privacy-preserving and communication-efficient FL-based energy predictor for net-metering systems. Based on a data set for real power consumption/generation readings, we first propose a multidata-source hybrid deep learning (DL)-based predictor to accurately predict future readings. Then, we repurpose an efficient inner-product functional encryption (IPFE) scheme for implementing secure data aggregation to preserve the customers’ privacy by encrypting their models’ parameters during the FL training. To address communication efficiency, we use a change and transmit (CAT) approach to update local model’s parameters, where only the parameters with sufficient changes are updated. Our extensive studies demonstrate that our approach accurately predicts future readings while providing privacy protection and high communication efficiency.},
	number = {9},
	urldate = {2024-04-12},
	journal = {IEEE Internet of Things Journal},
	author = {Badr, Mahmoud M. and Mahmoud, Mohamed M. E. A. and Fang, Yuguang and Abdulaal, Mohammed and Aljohani, Abdulah Jeza and Alasmary, Waleed and Ibrahem, Mohamed I.},
	month = may,
	year = {2023},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Communication efficiency, Data models, Forecasting, Predictive models, Privacy, Servers, Smart grids, Training, energy prediction, federated learning (FL), privacy preservation, smart grids},
	pages = {7719--7736},
}

@article{chandraumakantham_enhancing_2024,
	title = {Enhancing {Intrusion} {Detection} {Through} {Federated} {Learning} {With} {Enhanced} {Ghost}\_BiNet and {Homomorphic} {Encryption}},
	volume = {12},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10422789},
	doi = {10.1109/ACCESS.2024.3362347},
	abstract = {Intrusion detection is essential for safeguarding computer systems and networks against unauthorized access, malicious activities, and security breaches. Its application domains include network security, information security, and cybersecurity across various sectors such as finance, healthcare, government, and industry. Federated learning-based intrusion detection offers improved performance compared to conventional mechanisms by leveraging decentralized data sources, preserving data privacy, and enhancing model generalization through collaboration among multiple organizations. However, challenges faced by existing federated learning-based intrusion detection mechanisms include ensuring data privacy and security, mitigating communication overhead, and enhancing detection accuracy. In order to overcome these issues, this research article proposes a federated learning-based intrusion detection methodology that leverages Enhanced Ghost\_BiNet, a novel deep learning model, to enhance the security of information sharing and detection accuracy. Federated learning, a privacy-preserving machine learning technique, is utilized to enable multiple entities to collaboratively train a global intrusion detection model without sharing sensitive data. The proposed system first trains local models using Enhanced Ghost\_BiNet, which integrates GhostNet and Bidirectional Gated Recurrent Unit (BiGRU). To optimize the model’s performance, the Chaotic Chebyshev Artificial Humming Bird (CAh) algorithm is employed. Homomorphic encryption is applied to encrypt the local model updates, enhancing data privacy and security. Server-side aggregation of updates and collaborative optimization are introduced to minimize communication rounds during data aggregation. The results demonstrate that the Enhanced Ghost\_BiNet outperforms traditional models like GhostNet, BiGRU, RNN, Auto Encoder, and CNN in terms of accuracy, precision, recall, F-Score, and mean square error (MSE). For instance, the Enhanced Ghost\_BiNet achieves an accuracy of 99.24\% on the KDD CUP 99 dataset, surpassing the other models by a significant margin. The proposed methodology provides a robust and secure approach to intrusion detection, ensuring the confidentiality of sensitive data while improving detection accuracy.},
	urldate = {2024-04-12},
	journal = {IEEE Access},
	author = {ChandraUmakantham, Om Kumar and Gajendran, Sudhakaran and Marappan, Suguna},
	year = {2024},
	note = {Conference Name: IEEE Access},
	keywords = {Data models, Data privacy, Deep learning, Federated learning, Homomorphic encryption, Intrusion detection, Machine learning, Security, Training, enhanced Ghost\_BiNet, homomorphic encryption, hybrid deep learning, intrusion detection, privacy},
	pages = {24879--24893},
}

@article{hu_privacy-preserving_2023,
	title = {Privacy-preserving {Few}-shot {Traffic} {Detection} against {Advanced} {Persistent} {Threats} via {Federated} {Meta} {Learning}},
	issn = {2327-4697},
	url = {https://ieeexplore.ieee.org/abstract/document/10214668},
	doi = {10.1109/TNSE.2023.3304556},
	abstract = {Advanced Persistent Threats (APT) utilizes multiple zero-day vulnerabilities to threaten critical industrial infrastructure, having the characteristics of burst, unknown and cross-domain. To resist APT attacks, existing wisdom usually establish a security monitoring platform that remotely links to the cloud-based threat intelligence center. However, the real scenario where few victim users are willing to share raw attack samples considering privacy-preservation, such mentality is hysteretic and cannot identify APT attacks quickly without sacrificing additional incentives. To address this issue, a novel privacy-preserving few-shot traffic detection (PFTD) method based on federated meta learning (FML) is proposed. The PFTD treats the APT detection task as a model generalization optimization process, that transfers the learned knowledge to identify local unknown samples. Client-side models in FML achieve knowledge transferring by two-phase updating over both support dataset and query dataset, while the server-side model obtains global knowledge with model aggregation. These processes compile useful knowledge against APT attacks. With a novel wisdom, we obtained three advantages: 1) High accuracy with a few attack samples; 2) Low latency detection for removing rules matching process; 3) High personalizing to cross-domain APT attacks. Extensive experiments based on multiple benchmark datasets like CICIDS2017 and DAPT 2020 prove the superiority of proposed PFTD.},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Network Science and Engineering},
	author = {Hu, Yilun and Wu, Jun and Li, Gaolei and Li, Jianhua and Cheng, Jinke},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Network Science and Engineering},
	keywords = {Advanced Persistent Threats, Behavioral sciences, Data models, Federated Meta Learning, Few-shot Traffic Detection, Image edge detection, Intrusion detection, Metalearning, Privacy-preserving, Telecommunication traffic, Training},
	pages = {1--11},
}

@article{tran_efficient_2023,
	title = {An {Efficient} {Privacy}-{Enhancing} {Cross}-{Silo} {Federated} {Learning} and {Applications} for {False} {Data} {Injection} {Attack} {Detection} in {Smart} {Grids}},
	volume = {18},
	issn = {1556-6021},
	url = {https://ieeexplore.ieee.org/document/10103703},
	doi = {10.1109/TIFS.2023.3267892},
	abstract = {Federated Learning is a prominent machine learning paradigm which helps tackle data privacy issues by allowing clients to store their raw data locally and transfer only their local model parameters to an aggregator server to collaboratively train a shared global model. However, federated learning is vulnerable to inference attacks from dishonest aggregators who can infer information about clients’ training data from their model parameters. To deal with this issue, most of the proposed schemes in literature either require a non-colluded server setting, a trusted third-party to compute master secret keys or a secure multiparty computation protocol which is still inefficient over multiple iterations of computing an aggregation model. In this work, we propose an efficient cross-silo federated learning scheme with strong privacy preservation. By designing a double-layer encryption scheme which has no requirement to compute discrete logarithm, utilizing secret sharing only at the establishment phase and in the iterations when parties rejoin, and accelerating the computation performance via parallel computing, we achieve an efficient privacy-preserving federated learning protocol, which also allows clients to dropout and rejoin during the training process. The proposed scheme is demonstrated theoretically and empirically to provide provable privacy against an honest-but-curious aggregator server and simultaneously achieve desirable model utilities. The scheme is applied to false data injection attack detection (FDIA) in smart grids. This is a more secure cross-silo FDIA federated learning resilient to the local private data inference attacks than the existing works.},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Tran, Hong-Yen and Hu, Jiankun and Yin, Xuefei and Pota, Hemanshu R.},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Computational modeling, Cryptography, Data models, Federated learning, Privacy, Privacy-preserving, Servers, Training, encryption, false data injection attack detection, federated learning, secret sharing},
	pages = {2538--2552},
}

@article{houda_blockchain-enabled_2024,
	title = {Blockchain-{Enabled} {Federated} {Learning} for {Enhanced} {Collaborative} {Intrusion} {Detection} in {Vehicular} {Edge} {Computing}},
	issn = {1558-0016},
	url = {https://ieeexplore.ieee.org/abstract/document/10414404},
	doi = {10.1109/TITS.2024.3351699},
	abstract = {Intelligent Transportation Systems (ITSs) are transforming the global monitoring of road safety. These systems, including vehicular networks and transportation infrastructure, are vulnerable to several security issues, which could disrupt services and potentially cause harm to the users. It is crucial to establish robust security measures to protect against evolving attacks and ensure the safe and reliable operation of ITS. Artificial Intelligence (AI)-based Intrusion Detection Systems (IDS) are mainly used to enhance the security of ITS. The adoption of AI-based techniques to secure ITS against new emerging threats has been limited due to a lack of realistic and recent data on these types of attacks ( i.e., zero-day attacks). In this context, we introduce a novel Edge-based Framework that uses Federated Learning (FL) and blockchain to secure ITS against new emerging threats. In particular, our proposed framework consists of (1) a novel distributed Edge-based architecture that allows multiple Edge nodes to securely collaborate while preserving their privacy; and (2) a decentralized and secure reputation system based on blockchain technology to maintain the reliability and trustworthiness of the FL process within the ITS; This system manages reputation data for individual nodes (such as vehicles), guaranteeing the integrity of the FL training process. Experiment results using the UNSW-NB15 dataset show that our proposed framework achieves high accuracy and F1 score (99\%) in detecting new threats while ensuring the privacy and reliability of the whole ITS. These results demonstrate the effectiveness of our proposed framework in securing ITS.},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Houda, Zakaria Abou El and Moudoud, Hajar and Brik, Bouziane and Khoukhi, Lyes},
	year = {2024},
	note = {Conference Name: IEEE Transactions on Intelligent Transportation Systems},
	keywords = {Blockchains, Data privacy, Federated learning, Intrusion detection, Privacy, Reliability, Security, Sustainable intelligent transportation systems, blockchain, edge computing, federated learning(FL), green vehicular networks, intrusion detection systems},
	pages = {1--0},
}

@article{su_apfed_2024,
	title = {{APFed}: {Adaptive} personalized federated learning for intrusion detection in maritime meteorological sensor networks},
	issn = {2352-8648},
	shorttitle = {{APFed}},
	url = {https://www.sciencedirect.com/science/article/pii/S2352864824000191},
	doi = {10.1016/j.dcan.2024.02.001},
	abstract = {With the rapid development of advanced networking and computing technologies such as the Internet of Things, network function virtualization, and 5G infrastructure, new development opportunities are emerging for Maritime Meteorological Sensor Networks (MMSNs). However, the increasing number of intelligent devices joining the MMSN poses a growing threat to network security. Current Artificial Intelligence (AI) intrusion detection techniques turn intrusion detection into a classification problem, where AI excels. These techniques assume sufficient high-quality instances for model construction, which is often unsatisfactory for real-world operation with limited attack instances and constantly evolving characteristics. This paper proposes an Adaptive Personalized Federated learning (APFed) framework that allows multiple MMSN owners to engage in collaborative training. By employing an adaptive personalized update and a shared global classifier, the adverse effects of imbalanced, Non-Independent and Identically Distributed (Non-IID) data are mitigated, enabling the intrusion detection model to possess personalized capabilities and good global generalization. In addition, a lightweight intrusion detection model is proposed to detect various attacks with an effective adaptation to the MMSN environment. Finally, extensive experiments on a classical network dataset show that the attack classification accuracy is improved by about 5\% compared to most baselines in the global scenarios.},
	urldate = {2024-04-12},
	journal = {Digital Communications and Networks},
	author = {Su, Xin and Zhang, Guifu},
	month = feb,
	year = {2024},
	keywords = {Deep learning, Federated learning, Intrusion detection, Maritime meteorological sensor network, Personalized model},
}

@article{mahmoodi_autonomous_2023,
	title = {Autonomous {Federated} {Learning} for {Distributed} {Intrusion} {Detection} {Systems} in {Public} {Networks}},
	volume = {11},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10296918},
	doi = {10.1109/ACCESS.2023.3327922},
	abstract = {The rapid integration of IoT, cloud, and edge computing has resulted in highly interconnected networks, emphasizing the need for advanced Intrusion Detection Systems (IDS) to maintain security. Successful AI-based IDS relies on high-quality data for model training. Even though a vast array of datasets from controlled settings are accessible, many fall short as they are outdated and lack the representative data of network traffic dynamics typically seen in public networks. This paper aims to advance understanding in designing testbed architectures for defense mechanisms within public networks. At its core, this research introduces a unique testbed utilizing the connectivity of panOULU Municipal public network in the city of Oulu, Finland. This experimental setup examines AI-driven security across the public network. It utilizes edge-to-cloud infrastructures, incorporating Software-Defined Networking (SDN) and Network Function Virtualization (NFV) via the VMware vSphere platform. During the training phase, a script distinguishes incoming packets as either benign or malicious based on well-defined local parameters and simulated attack scenarios. This labeled data is then utilized for training machine learning models within the Federated Learning framework, FED-ML. Subsequently, these models are evaluated on previously unseen data. The entire procedure, from traffic gathering to model training, operates without human involvement. The evaluation dataset and testbed configuration we have made publicly available through this research can deepen our understanding of the challenges in safeguarding public networks, especially those that blend various technologies in diverse environments.},
	urldate = {2024-04-12},
	journal = {IEEE Access},
	author = {Mahmoodi, Alireza Bakhshi Zadi and Sheikhi, Saeid and Peltonen, Ella and Kostakos, Panos},
	year = {2023},
	note = {Conference Name: IEEE Access},
	keywords = {Data models, Internet of Things, Intrusion detection, Network security, Protocols, Security, Telecommunication traffic, Training, cybersecurity, data engineering, distributed computing, federated learning, stream processing},
	pages = {121325--121339},
}

@article{he_game_2023,
	title = {A {Game} {Theory}-{Based} {Incentive} {Mechanism} for {Collaborative} {Security} of {Federated} {Learning} in {Energy} {Blockchain} {Environment}},
	volume = {10},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/abstract/document/10143974},
	doi = {10.1109/JIOT.2023.3282732},
	abstract = {With the digital transformation of the energy industry, energy blockchain is playing an important role in application areas, such as energy data sharing and distributed power trading. In this process, the use of energy data is a top priority. Federated learning (FL) can enable the analysis and computation of energy data while protecting their privacy. However, traditional FL relies on a central server and parties involved are not fully trusted. In energy blockchain environment, FL also faces data poisoning attacks launched by energy departments, besides, the supervisory committee carrying out checking models can launch deception attacks. Therefore, we propose a game theory-based incentive mechanism for collaborative security of FL in energy blockchain environment, which can discourage nodes from taking malicious behaviors in iterative training of FL. First, we propose an FL model in energy blockchain environment, which can protect privacy and achieve collaborative security. Considering that game theory can be used to analyze the strategies of participants, we build a game model with energy departments and supervisory committee as players and design our incentive mechanism based on game theory, which is implemented by smart contracts. Even if the accuracy of model checking algorithm is low, malicious behaviors in FL can be reduced by using our incentive mechanism. In particular, we prove that our mechanism can lead game model to a Nash equilibrium (NE) that achieve collaborative security. Security analysis and experimental evaluation show that our incentive mechanism is feasible in energy blockchain with robustness, reliability, and low complexity.},
	number = {24},
	urldate = {2024-04-12},
	journal = {IEEE Internet of Things Journal},
	author = {He, Yunhua and Luo, Mingshun and Wu, Bin and Sun, Limin and Wu, Yongdong and Liu, Zhiquan and Xiao, Ke},
	month = dec,
	year = {2023},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Behavioral sciences, Blockchains, Collaboration, Computational modeling, Data models, Energy blockchain, Energy management, Federated learning, Game theory, Security, federated learning (FL), game theory, incentive mechanism, poisoning attacks},
	pages = {21294--21308},
}

@article{al-wesabi_pelican_2023,
	title = {Pelican {Optimization} {Algorithm} with {Federated} {Learning} {Driven} {Attack} {Detection} model in {Internet} of {Things} environment},
	volume = {148},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X23002121},
	doi = {10.1016/j.future.2023.05.029},
	abstract = {The Internet of Things (IoT) is comprised of millions of physical devices interconnected with the Internet through network that performs a task independently with less human interference. Despite the benefits of IoT, it is vulnerable to malicious attacks. Therefore, machine learning (ML) inspired decision-making is hardly preferred due to drawbacks (the requirement that every training dataset is stored on the central database), computation cost related to the training of massive amounts of information on the unified server, and security issues related to transferring attained statistics from IoT sensor to the server. The Federated Learning (FL) algorithm is the adaptable and most prominent way to resolve the shortcoming of ML-based techniques. The study proposes a Pelican Optimization Algorithm with Federated Learning Driven Attack Detection and classification (POAFL-DDC) technique in the IoT. The POAFL-DDC technique operates on decentralized on-device data for attack detection in the IoT. By substituting update weight with the central FL server, the data is placed on the local IoT device whereas federating training cycles on the DL model. For attack detection process, deep belief network (DBN) model is used in this work. In this study, the POA is utilized to optimize the DBN hyperparameters. The experimental validation of the POAFL-DDC algorithm is tested on TON\_IOT dataset and the results are examined in terms of different measures. The experimental outcomes demonstrated that the POAFL-DDC technique reaches superior results over other models.},
	urldate = {2024-04-12},
	journal = {Future Generation Computer Systems},
	author = {Al-Wesabi, Fahd N. and Mengash, Hanan Abdullah and Marzouk, Radwa and Alruwais, Nuha and Allafi, Randa and Alabdan, Rana and Alharbi, Meshal and Gupta, Deepak},
	month = nov,
	year = {2023},
	keywords = {Attack detection, Deep learning, Federated Learning, Internet of Things, Pelican Optimization Algorithm},
	pages = {118--127},
}

@inproceedings{merzouk_parameterizing_2023,
	address = {New York, NY, USA},
	series = {{ARES} '23},
	title = {Parameterizing poisoning attacks in federated learning-based intrusion detection},
	isbn = {9798400707728},
	url = {https://dl.acm.org/doi/10.1145/3600160.3605090},
	doi = {10.1145/3600160.3605090},
	abstract = {Federated learning is a promising research direction in network intrusion detection. It enables collaborative training of machine learning models without revealing sensitive data. However, the lack of transparency in federated learning creates a security threat. Since the server cannot ensure the clients’ reliability by analyzing their data, malicious clients have the opportunity to insert a backdoor in the model and activate it to evade detection. To maximize their chances of success, adversaries must fine-tune the attack parameters. Here we evaluate the impact of four attack parameters on the effectiveness, stealthiness, consistency, and timing of data poisoning attacks. Our results show that each parameter is decisive for the success of poisoning attacks, provided they are carefully adjusted to avoid damaging the model’s accuracy or the data’s consistency. Our findings serve as guidelines for the security evaluation of federated learning systems and insights for defense strategies. Our experiments are carried out on the UNSW-NB15 dataset, and their implementation is available in a public code repository.},
	urldate = {2024-04-12},
	booktitle = {Proceedings of the 18th {International} {Conference} on {Availability}, {Reliability} and {Security}},
	publisher = {Association for Computing Machinery},
	author = {Merzouk, Mohamed Amine and Cuppens, Frédéric and Boulahia-Cuppens, Nora and Yaich, Reda},
	year = {2023},
	keywords = {adversarial attack, backdoor, data poisoning, federated learning, intrusion detection},
	pages = {1--8},
}

@article{de_caldas_filho_botnet_2023,
	title = {Botnet {Detection} and {Mitigation} {Model} for {IoT} {Networks} {Using} {Federated} {Learning}},
	volume = {23},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/23/14/6305},
	doi = {10.3390/s23146305},
	abstract = {The Internet of Things (IoT) introduces significant security vulnerabilities, raising concerns about cyber-attacks. Attackers exploit these vulnerabilities to launch distributed denial-of-service (DDoS) attacks, compromising availability and causing financial damage to digital infrastructure. This study focuses on mitigating DDoS attacks in corporate local networks by developing a model that operates closer to the attack source. The model utilizes Host Intrusion Detection Systems (HIDS) to identify anomalous behaviors in IoT devices and employs network-based intrusion detection approaches through a Network Intrusion Detection System (NIDS) for comprehensive attack identification. Additionally, a Host Intrusion Detection and Prevention System (HIDPS) is implemented in a fog computing infrastructure for real-time and precise attack detection. The proposed model integrates NIDS with federated learning, allowing devices to locally analyze their data and contribute to the detection of anomalous traffic. The distributed architecture enhances security by preventing volumetric attack traffic from reaching internet service providers and destination servers. This research contributes to the advancement of cybersecurity in local network environments and strengthens the protection of IoT networks against malicious traffic. This work highlights the efficiency of using a federated training and detection procedure through deep learning to minimize the impact of a single point of failure (SPOF) and reduce the workload of each device, thus achieving accuracy of 89.753\% during detection and increasing privacy issues in a decentralized IoT infrastructure with a near-real-time detection and mitigation system.},
	language = {en},
	number = {14},
	urldate = {2024-04-12},
	journal = {Sensors},
	author = {de Caldas Filho, Francisco Lopes and Soares, Samuel Carlos Meneses and Oroski, Elder and de Oliveira Albuquerque, Robson and da Mata, Rafael Zerbini Alves and de Mendonça, Fábio Lúcio Lopes and de Sousa Júnior, Rafael Timóteo},
	month = jan,
	year = {2023},
	note = {Number: 14
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {DDoS, HIDPS, NIDS, deep learning, federated learning, fog computing},
	pages = {6305},
}

@article{cui_collaborative_2023,
	title = {Collaborative {Intrusion} {Detection} {System} for {SDVN}: {A} {Fairness} {Federated} {Deep} {Learning} {Approach}},
	volume = {34},
	issn = {1558-2183},
	shorttitle = {Collaborative {Intrusion} {Detection} {System} for {SDVN}},
	url = {https://ieeexplore.ieee.org/abstract/document/10177377},
	doi = {10.1109/TPDS.2023.3290650},
	abstract = {With the continuous innovations and development in communication technology and intelligent transportation systems, a new generation of vehicular ad hoc networks (VANETs) has become increasingly popular, making VANET communication security increasingly important. An intrusion detection system (IDS) is an important tool for detecting network attacks and is an effective means of improving network security. However, existing IDSs encounter several problems involving inaccurate detections, low detection efficiencies, and incomplete detections owing to extensive changes in vehicle locations in VANETs. This study explores federated learning in software-defined VANETs and designs an efficient and accurate collaborative intrusion detection system (CIDS) model. The model utilizes the collaboration among local software-defined networks (SDNs) to jointly train the CIDS model without directly exchanging local network data flows to improve the expansibility and globality of IDSs. To reduce the model difference between different SDN clients and improve the detection accuracy, this study regards the prediction loss for each SDN client as an objective from the perspective of constrained multi-objective optimization. By optimizing a surrogate maximum function containing all the objectives, the method adopts two-stage gradient optimization to achieve Pareto optimality for SDN clients with the worst fairness constraint maximization performance. In addition, this study evaluates the training model using two open-source datasets and compares it with the latest methods. Experimental results reveal that the proposed model ensures local data privacy and demonstrates high accuracy and efficiency in detecting attacks and is thus superior to the current schemes.},
	number = {9},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Cui, Jie and Sun, Hu and Zhong, Hong and Zhang, Jing and Wei, Lu and Bolodurina, Irina and He, Debiao},
	month = sep,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Parallel and Distributed Systems},
	keywords = {Collaboration, Computational modeling, Data models, Federated deep learning, Intrusion detection, Security, Training, Vehicular ad hoc networks, collaborative intrusion detection system, convolutional neural network, gradient optimization, intelligent transportation system},
	pages = {2512--2528},
}

@article{friha_felids_2022,
	title = {{FELIDS}: {Federated} learning-based intrusion detection system for agricultural {Internet} of {Things}},
	volume = {165},
	issn = {0743-7315},
	shorttitle = {{FELIDS}},
	url = {https://www.sciencedirect.com/science/article/pii/S0743731522000570},
	doi = {10.1016/j.jpdc.2022.03.003},
	abstract = {In this paper, we propose a federated learning-based intrusion detection system, named FELIDS, for securing agricultural-IoT infrastructures. Specifically, the FELIDS system protects data privacy through local learning, where devices benefit from the knowledge of their peers by sharing only updates from their model with an aggregation server that produces an improved detection model. In order to prevent Agricultural IoTs attacks, the FELIDS system employs three deep learning classifiers, namely, deep neural networks, convolutional neural networks, and recurrent neural networks. We study the performance of the proposed IDS on three different sources, including, CSE-CIC-IDS2018, MQTTset, and InSDN. The results demonstrate that the FELIDS system outperforms the classic/centralized versions of machine learning (non-federated learning) in protecting the privacy of IoT devices data and achieves the highest accuracy in detecting attacks.},
	urldate = {2024-04-12},
	journal = {Journal of Parallel and Distributed Computing},
	author = {Friha, Othmane and Ferrag, Mohamed Amine and Shu, Lei and Maglaras, Leandros and Choo, Kim-Kwang Raymond and Nafaa, Mehdi},
	month = jul,
	year = {2022},
	keywords = {Deep learning, Federated learning, Internet of Things, Privacy, Security},
	pages = {17--31},
}

@inproceedings{singh_android_2022,
	title = {Android {Web} {Security} {Solution} using {Cross}-device {Federated} {Learning}},
	url = {https://ieeexplore.ieee.org/abstract/document/9668449},
	doi = {10.1109/COMSNETS53615.2022.9668449},
	abstract = {Over the last one decade or so, Machine Learning has changed the global technology landscape with applications in almost all disciplines and verticals. Mobile and Web Security is an important research area in which researchers have been trying to apply Machine Learning, but data privacy concerns and high data communication costs to a central Machine Learning server have limited its use. Federated Learning is emerging as a promising solution which addresses privacy concerns and drastically reduces communication costs. In Federated Learning, data from individual devices is not communicated to a central server and model learning happens in a distributed manner. In this paper, we propose a Federated Learning solution for security of Android based devices. Mobile and Web Security solutions have evolved from signature-based detections to building Machine Learning models which are trained over large centralized malware repositories. We have used Federated Learning to learn security patterns from users' browsing data, which resides on individual devices and will never leave the devices. Federated Learning preserves users' privacy as it shares with the central server only the model that it learns from users' browsing data, and not the data itself. This way each mobile platform trains its own web security model from its data, and shares it to the centralized server. The centralized server aggregates these trained models received from numerous mobile devices and compiles an aggregated global model, which in turn is sent to mobile devices for inference. Mobile security solutions based on this concept create a sustained self-evolving security ecosystem, in which millions of mobile platforms share their learned models to form a robust distributed security paradigm. The results obtained using Federated Learning are found to be comparable with the results of centralized Machine Learning.},
	urldate = {2024-04-12},
	booktitle = {2022 14th {International} {Conference} on {COMmunication} {Systems} \& {NETworkS} ({COMSNETS})},
	author = {Singh, A K and Goyal, Navneet},
	month = jan,
	year = {2022},
	note = {ISSN: 2155-2509},
	keywords = {Android Security, Collaborative work, Costs, Data models, Data privacy, Federated Learning, Machine Learning, Machine learning, Mobile handsets, Privacy, Web Security},
	pages = {473--481},
}

@inproceedings{ayed_federated_2021,
	title = {Federated {Learning} for {Anomaly}-{Based} {Intrusion} {Detection}},
	url = {https://ieeexplore.ieee.org/abstract/document/9615816},
	doi = {10.1109/ISNCC52172.2021.9615816},
	abstract = {We are attending a severe zero-day cyber attacks. Machine learning based anomaly detection is definitely the most efficient defence in depth approach. It consists to analyzing the network traffic in order to distinguish the normal behaviour from the abnormal one. This approach is usually implemented in a central server where all the network traffic is analyzed which can rise privacy issues. In fact, with the increasing adoption of Cloud infrastructures, it is important to reduce as much as possible the outsourcing of such sensitive information to the several network nodes. A better approach is to ask each node to analyze its own data and then to exchange its learning finding (model) with a coordinator. In this paper, we investigate the application of federated learning for network-based intrusion detection. Our experiment was conducted based on the C ICIDS2017 dataset. We present a f ederated learning on a deep learning algorithm C NN based on model averaging. It is a self-learning system for detecting anomalies caused by malicious adversaries without human intervention and can cope with new and unknown attacks without decreasing performance. These experimentation demonstrate that this approach is effective in detecting intrusion.},
	urldate = {2024-04-12},
	booktitle = {2021 {International} {Symposium} on {Networks}, {Computers} and {Communications} ({ISNCC})},
	author = {Ayed, Mohamed Ali and Talhi, Chamseddine},
	month = oct,
	year = {2021},
	keywords = {Collaborative work, Data models, Data privacy, Deep learning, Network intrusion detection, Privacy, Telecommunication traffic},
	pages = {1--8},
}

@article{li_efficient_2023,
	title = {An {Efficient} {Federated} {Learning} {System} for {Network} {Intrusion} {Detection}},
	volume = {17},
	issn = {1937-9234},
	url = {https://ieeexplore.ieee.org/abstract/document/10032055},
	doi = {10.1109/JSYST.2023.3236995},
	abstract = {Network intrusion detection is used to detect unauthorized activities on a digital network, with which the cybersecurity teams of organizations can then kick-start prevention protocols to protect the security of their networks and data. In real-life scenarios, due to the lack of high-quality attack instance data, building an in-depth network intrusion detection system (NIDS) is always challenging for a single enterprise, in terms of handling complex network security threats. To remedy the problem, this article proposes an efficient intrusion detection system called dynamic weighted aggregation federated learning (DAFL) based on federated learning. Specifically, DAFL has used the full advantages of federated learning for data privacy preservation. Moreover, compared to a conventional federated-learning based intrusion detection system, our scheme has implemented dynamic filtering and weighting strategies for local models. In this way, DAFL can perform better in detecting network intrusions with less communication overhead. We give the detailed designs of DAFL, and our experimental results demonstrate that DAFL can achieve excellent detection performance with a low network communication overhead, with data privacy preserved.},
	number = {2},
	urldate = {2024-04-12},
	journal = {IEEE Systems Journal},
	author = {Li, Jianbin and Tong, Xin and Liu, Jinwei and Cheng, Long},
	month = jun,
	year = {2023},
	note = {Conference Name: IEEE Systems Journal},
	keywords = {Computational modeling, Data models, Data privacy, Federated learning, Network intrusion detection, Servers, Training, deep learning, dynamic weighted aggregation, federated learning, network intrusion detection},
	pages = {2455--2464},
}

@article{li_efficient_2023-1,
	title = {An {Efficient} {Federated} {Learning} {System} for {Network} {Intrusion} {Detection}},
	volume = {17},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1932-8184, 1937-9234, 2373-7816},
	url = {https://ieeexplore.ieee.org/document/10032055/},
	doi = {10.1109/JSYST.2023.3236995},
	number = {2},
	urldate = {2024-04-12},
	journal = {IEEE Systems Journal},
	author = {Li, Jianbin and Tong, Xin and Liu, Jinwei and Cheng, Long},
	month = jun,
	year = {2023},
	pages = {2455--2464},
}

@article{jiang_bfls_2023,
	title = {{BFLS}: {Blockchain} and {Federated} {Learning} for sharing threat detection models as {Cyber} {Threat} {Intelligence}},
	volume = {224},
	issn = {1389-1286},
	shorttitle = {{BFLS}},
	url = {https://www.sciencedirect.com/science/article/pii/S138912862300049X},
	doi = {10.1016/j.comnet.2023.109604},
	abstract = {Recently, Cyber Threat Intelligence (CTI) sharing has become an important weapon for cyber defenders to mitigate the increasing number of cyber attacks in a proactive and collaborative manner. However, with the dramatic increase in the deployment of shared communications between organizations, data has been a major priority to detect threats in the CTI sharing platform. In the modern environment, a valuable asset is the user’s threat data. Privacy policies are necessary to ensure the security of user data in the threat intelligence sharing community. Federated learning acts as a special machine learning technique for privacy preservation and offers to contextualize data in a CTI sharing platform. Therefore, this article proposes a new approach to threat intelligence sharing called BFLS (Blockchain and Federated Learning for sharing threat detection models as Cyber Threat Intelligence), where blockchain-based CTI sharing platforms are used for security and privacy. Federated learning technology is adopted for scalable machine learning applications, such as threat detection. Furthermore, users can obtain a well-trained threat detection model without sending personal data to the central server. Experimental results on the ISCX-IDS-2012 and CIC-DDoS-2019 datasets showed that BFLS can securely share CTI and has high accuracy in threat detection. The accuracies of BFLS are 98.92\% and 98.56\% on the two datasets, respectively.},
	urldate = {2024-04-12},
	journal = {Computer Networks},
	author = {Jiang, Tongtong and Shen, Guowei and Guo, Chun and Cui, Yunhe and Xie, Bo},
	month = apr,
	year = {2023},
	keywords = {Blockchain, Cyber Threat Intelligence, Federated learning, Threat detection},
	pages = {109604},
}

@article{jiang_deepfedwt_2022,
	title = {{DeepFedWT}: {A} federated deep learning framework for fault detection of wind turbines},
	volume = {199},
	issn = {0263-2241},
	shorttitle = {{DeepFedWT}},
	url = {https://www.sciencedirect.com/science/article/pii/S0263224122007497},
	doi = {10.1016/j.measurement.2022.111529},
	abstract = {Data-driven fault detection of wind turbines has gained increasingly attention. Currently, most existing methods require sufficient labeled data to train a reliable model in a centralized way. However, it is difficult to collect enough labeled data due to data privacy and strict confidentiality of wind farm owners. To this end, we propose a federated deep learning framework (DeepFedWT), which allows multiple decentralized WTs to collaboratively build a fault detection model using their local private data. Specifically, we designed a multi-scale residual attention network (MSRAN) model to extract informative features from raw multivariate sensor data, which first integrates a multiscale residual learning block to extract spatial features among different sensor variables at multiple scales and adopts a feature attention block to highlight important features highly associated with faults, and finally enables an enhanced fault detection. Experimental results on two real WT datasets demonstrate the effectiveness of our proposed DeepFedWT framework.},
	urldate = {2024-04-12},
	journal = {Measurement},
	author = {Jiang, Guoqian and Fan, WeiPeng and Li, Wenyue and Wang, Lijin and He, Qun and Xie, Ping and Li, Xiaoli},
	month = aug,
	year = {2022},
	keywords = {Deep learning, Fault detection, Feature attention, Federated learning, Multi-scale spatial feature extraction, Wind turbines (WTs)},
	pages = {111529},
}

@article{lv_misbehavior_2022,
	title = {Misbehavior {Detection} in {Vehicular} {Ad} {Hoc} {Networks} {Based} on {Privacy}-{Preserving} {Federated} {Learning} and {Blockchain}},
	volume = {19},
	issn = {1932-4537},
	url = {https://ieeexplore.ieee.org/abstract/document/9944011},
	doi = {10.1109/TNSM.2022.3220779},
	abstract = {As an irreversible trend, connected vehicles have become increasingly more popular. They depend on the generation and sharing of data between vehicles to improve safety and efficiency of the transportation system. Due to the open feature of the vehicular ad hoc network (VANET), it is possible for dishonest and misbehaving vehicles to disrupt traffic by transmitting false information. In recent years, misbehavior detection systems have been developed to detect the malicious behaviour, and machine learning methods have been employed to make the detection more accurately. However, existing misbehavior detection systems typically require a single entity (e.g., a central server) for centralized data collection and training. Model updates are restricted due to data privacy and high overhead of data communication, which reduces the defensive capability of misbehavior detection systems. In this paper, we propose a blockchain-based federated learning scheme to detect misbehavior, which is trained collaboratively by coordinating multiple distributed edge devices while ensuring data security and privacy. In addition, to further protect the privacy of the model on the blockchain, differential privacy with the Gaussian mechanism is leveraged to provide strict privacy protection. Common data falsification attacks are studied in this paper. The experimental results show that our proposed scheme is feasible and effective, and demonstrate that our scheme achieves satisfied accuracy and efficiency.},
	number = {4},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Lv, Pin and Xie, Linyan and Xu, Jia and Wu, Xu and Li, Taoshen},
	month = dec,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Network and Service Management},
	keywords = {Blockchains, Data models, Federated learning, Security, Servers, Training, Vehicular ad hoc networks, Vehicular network, blockchain, differential privacy, federated learning, misbehavior detection},
	pages = {3936--3948},
}

@article{otoum_federated_2022,
	title = {Federated and {Transfer} {Learning}-{Empowered} {Intrusion} {Detection} for {IoT} {Applications}},
	volume = {5},
	issn = {2576-3199},
	url = {https://ieeexplore.ieee.org/abstract/document/9945849},
	doi = {10.1109/IOTM.001.2200048},
	abstract = {The Internet of Things (IoT) can be described as a considerable number of sensors and physical devices connected to different applications, supported with networking technologies to communicate with other devices and the Internet. With the growing number of IoT users, emerging services, and the need for high availability and data exchange, cyberattacks on those applications have increased in recent years. Therefore, securing IoT applications has allured particular consideration from the industry and research fields. This article illustrates and comprehensively analyzes the effectiveness of using FL/TL trending techniques used with different Machine Learning (ML) and Deep Learning (DL) algorithms to drive the Intrusion Detection Systems (IDS) to secure the IoT applications. The Internet of Medical Things (IoMT) is considered in this article as a use case in which we have demonstrated that using federated and transfer learning can improve model performance, increase learning process speed, reduce the amount of data needed to be trained, and preserve the user's data privacy compared with the traditional learning approaches.},
	number = {3},
	urldate = {2024-04-12},
	journal = {IEEE Internet of Things Magazine},
	author = {Otoum, Yazan and Chamola, Vinay and Nayak, Amiya},
	month = sep,
	year = {2022},
	note = {Conference Name: IEEE Internet of Things Magazine},
	keywords = {Federated learning, Internet of Things, Intrusion detection, Learning systems, Machine learning algorithms, Transfer learning},
	pages = {50--54},
}

@article{yang_review_2023,
	title = {Review on application progress of federated learning model and security hazard protection},
	volume = {9},
	issn = {2352-8648},
	url = {https://www.sciencedirect.com/science/article/pii/S2352864822002474},
	doi = {10.1016/j.dcan.2022.11.006},
	abstract = {Federated learning is a new type of distributed learning framework that allows multiple participants to share training results without revealing their data privacy. As data privacy becomes more important, it becomes difficult to collect data from multiple data owners to make machine learning predictions due to the lack of data security. Data is forced to be stored independently between companies, creating “data silos”. With the goal of safeguarding data privacy and security, the federated learning framework greatly expands the amount of training data, effectively improving the shortcomings of traditional machine learning and deep learning, and bringing AI algorithms closer to our reality. In the context of the current international data security issues, federated learning is developing rapidly and has gradually moved from the theoretical to the applied level. The paper first introduces the federated learning framework, analyzes its advantages, reviews the results of federated learning applications in industries such as communication and healthcare, then analyzes the pitfalls of federated learning and discusses the security issues that should be considered in applications, and finally looks into the future of federated learning and the application layer.},
	number = {1},
	urldate = {2024-04-12},
	journal = {Digital Communications and Networks},
	author = {Yang, Aimin and Ma, Zezhong and Zhang, Chunying and Han, Yang and Hu, Zhibin and Zhang, Wei and Huang, Xiangdong and Wu, Yafeng},
	month = feb,
	year = {2023},
	keywords = {Data silos, Federated learning, Learning framework, Machine learning, Privacy protection},
	pages = {146--158},
}

@article{cheng_federated_2022,
	title = {Federated {Transfer} {Learning} {With} {Client} {Selection} for {Intrusion} {Detection} in {Mobile} {Edge} {Computing}},
	volume = {26},
	issn = {1558-2558},
	url = {https://ieeexplore.ieee.org/abstract/document/9668958},
	doi = {10.1109/LCOMM.2022.3140273},
	abstract = {In this letter, we propose an efficient federated transfer learning (FTL) framework with client selection for intrusion detection (ID) in mobile edge computing (MEC). Specifically, we leverage federated learning (FL) to preserve privacy by training model locally, and utilize transfer learning (TL) to improve training efficiency by knowledge transfer. For FL, unreliable and low-quality clients should not be selected to participate in the training. Therefore, we integrate FTL with a reinforcement learning (RL)-based client selection scheme to achieve the highest ID accuracy within a budget limit on the number of participating clients. Experimental results show that the FTL significantly improves ID accuracy and communication efficiency as compared with the FL. Furthermore, the FTL framework with RL-based client selection can achieve the highest accuracy within budget, which improves performance while saving cost.},
	number = {3},
	urldate = {2024-04-12},
	journal = {IEEE Communications Letters},
	author = {Cheng, Yanyu and Lu, Jianyuan and Niyato, Dusit and Lyu, Biao and Kang, Jiawen and Zhu, Shunmin},
	month = mar,
	year = {2022},
	note = {Conference Name: IEEE Communications Letters},
	keywords = {Client selection, Computational modeling, Data models, Multi-access edge computing, Servers, Training, Training data, Transfer learning, federated transfer learning, intrusion detection, mobile edge computing, reinforcement learning},
	pages = {552--556},
}

@article{novikova_federated_2022,
	title = {Federated {Learning} for {Intrusion} {Detection} in the {Critical} {Infrastructures}: {Vertically} {Partitioned} {Data} {Use} {Case}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1999-4893},
	shorttitle = {Federated {Learning} for {Intrusion} {Detection} in the {Critical} {Infrastructures}},
	url = {https://www.mdpi.com/1999-4893/15/4/104},
	doi = {10.3390/a15040104},
	abstract = {One of the challenges in the Internet of Things systems is the security of the critical data, for example, data used for intrusion detection. The paper research construction of an intrusion detection system that ensures the confidentiality of critical data at a given level of intrusion detection accuracy. For this goal, federated learning is used to train an intrusion detection model. Federated learning is a computational model for distributed machine learning that allows different collaborating entities to train one global model without sharing data. This paper considers the case when entities have data that are different in attributes. Authors believe that it is a common situation for the critical systems constructed using Internet of Things (IoT) technology, when industrial objects are monitored by different sets of sensors. To evaluate the applicability of the federated learning for this case, the authors developed an approach and an architecture of the intrusion detection system for vertically partitioned data that consider the principles of federated learning and conducted the series of experiments. To model vertically partitioned data, the authors used the Secure Water Treatment (SWaT) data set that describes the functioning of the water treatment facility. The conducted experiments demonstrate that the accuracy of the intrusion detection model trained using federated learning is compared with the accuracy of the intrusion detection model trained using the centralized machine learning model. However, the computational efficiency of the learning and inference process is currently extremely low. It is explained by the application of homomorphic encryption for input data protection from different data owners or data sources. This defines the necessity to elaborate techniques for generating attributes that could model horizontally partitioned data even for the cases when the collaborating entities share datasets that differ in their attributes.},
	language = {en},
	number = {4},
	urldate = {2024-04-12},
	journal = {Algorithms},
	author = {Novikova, Evgenia and Doynikova, Elena and Golubev, Sergey},
	month = apr,
	year = {2022},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {confidential data, critical infrastructures, federated learning, gradient boosting decision trees, homomorphic encryption, intrusion detection, vertically partitioned data},
	pages = {104},
}

@inproceedings{liu_three-layer_2022,
	title = {A {Three}-layer {Security} {Assurance} {Model} for a {Decentralized} {Federated} {Learning} {System}},
	url = {https://ieeexplore.ieee.org/abstract/document/9880591},
	doi = {10.1109/WOCC55104.2022.9880591},
	abstract = {We focus on the security issues of decentralized federated learning systems for the core requirements of secure environments and trusted computing for applications such as medical big data, distributed cognitive learning, and autonomous driving. We propose a three-layer security assurance model that aims to ensure secure trusted computing in decentralized networks. Therein, the first-layer security model realizes the authentication of trusted users through blockchain technology to ensure the safe access of legitimate users to the greatest extent; the second-layer security model utilizes the trusted execution environment (TEE) technology to realize the privacy protection and trusted computing of each local user; the last layer of security model adopts a set of detection and location algorithms for defending the internal attackers, in case the first two layers of models fail. Our experimental results show that the proposed three-layer security model can effectively defend against external and internal attacks in the network, thereby promoting secure and trusted computing in distributed federated learning networks.},
	urldate = {2024-04-12},
	booktitle = {2022 31st {Wireless} and {Optical} {Communications} {Conference} ({WOCC})},
	author = {Liu, Jinyu and Wang, Ziyang and Yang, Qing and Wu, Sissi Xiaoxiao},
	month = aug,
	year = {2022},
	note = {ISSN: 2379-1276},
	keywords = {Collaborative work, Computational modeling, Decentralized federated learning, Privacy, Resists, Simulation, Trusted Execution Environment (TEE), Trusted computing, Wireless communication, blockchain, insider attacker, security assurance},
	pages = {85--90},
}

@inproceedings{panagoda_application_2022,
	title = {Application of {Federated} {Learning} in {Health} {Care} {Sector} for {Malware} {Detection} and {Mitigation} {Using} {Software} {Defined} {Networking} {Approach}},
	url = {https://ieeexplore.ieee.org/abstract/document/9909488},
	doi = {10.1109/ASIANCON55314.2022.9909488},
	abstract = {This research takes us forward with the concepts of Federated Learning and SDN to introduce an efficient malware detection technique and provide a mitigation mechanism to give birth to a resilient and automated healthcare sector network system by also adding the feature of extended privacy preservation. Due to the daily transformation of new malware attacks on hospital ICEs, the healthcare industry is at an undefinable peak of never knowing its continuity direction. The state of blindness by the array of indispensable opportunities that new medical device inventions and their connected coordination offer daily, a factor that should be focused driven is not yet entirely understood by most healthcare operators and patients. This solution has the involvement of four clients in the form of hospital networks to build up the federated learning experimentation architectural structure with different geographical participation to reach the most reasonable accuracy rate with privacy preservation. While the logistic regression with cross-entropy conveys the detection, SDN comes in handy in the second half of the research to stack up the initial development phases of the system with malware mitigation based on policy implementation. The overall evaluation sums up with a system that proves the accuracy with the added privacy. It is no longer needed to continue with traditional centralized systems that offer almost everything but not privacy.},
	urldate = {2024-04-12},
	booktitle = {2022 2nd {Asian} {Conference} on {Innovation} in {Technology} ({ASIANCON})},
	author = {Panagoda, Dinelka and Malinda, Chathura and Wijetunga, Chamod and Rupasinghe, Lakmal and Bandara, Bathiya and Liyanapathirana, Chethana},
	month = aug,
	year = {2022},
	keywords = {Collaboration, Feature extraction, Federated Learning, Federated learning, Hospitals, Integrated Clinical Environment, Malware, Privacy, Software Defined Network, Technological innovation, decentralized learning, malware detection, malware mitigation, privacy},
	pages = {1--6},
}

@inproceedings{xia_abnormal_2022,
	title = {An {Abnormal} {Traffic} {Detection} {Method} for {IoT} {Devices} {Based} on {Federated} {Learning} and {Depthwise} {Separable} {Convolutional} {Neural} {Networks}},
	url = {https://ieeexplore.ieee.org/abstract/document/9894354},
	doi = {10.1109/IPCCC55026.2022.9894354},
	abstract = {As a bridge for information interaction between people and things, and things and things, IoT devices bring security issues and data privacy protection issues that have always been the main challenges in the IoT environment. In terms of abnormal traffic detection of IoT devices, data sharing between device data is usually not possible. This makes the deep learning method for model training based on a large amount of data unable to fully exert its strength due to the lack of IoT device attack instances, resulting in the problem of low detection accuracy. To this end, we propose an abnormal traffic detection model for IoT devices, FL-DSCNN (Federated Learning and Depthwise separable convolutional neural networks). First, the mayfly optimization algorithm is used to select the traffic features, and the model training time is reduced by reducing the feature dimension. Then, by introducing the FL framework, the depthwise separable convolutional neural network is used as a local model for collaborative training without sharing private data, avoiding the problem of lack of labeled data due to the “data silos” phenomenon while protecting data privacy. In addition, we experimentally verify the proposed method on the existing public dataset Aposemat IoT-23 dataset and compare and evaluate it with existing methods. The experimental results show that the method can achieve two-class and multi-class detection respectively. The detection accuracy rates of 98.52\% and 97.73\% prove the progress and superiority of the proposed FL-DSCNN model in the detection of abnormal traffic of IoT devices.},
	urldate = {2024-04-12},
	booktitle = {2022 {IEEE} {International} {Performance}, {Computing}, and {Communications} {Conference} ({IPCCC})},
	author = {Xia, Qinyu and Dong, Shi and Peng, Tao},
	month = nov,
	year = {2022},
	note = {ISSN: 2374-9628},
	keywords = {Data models, Data privacy, Deep learning, Depthwise separable convolutional neural networks, Feature selection, Federated learning, Internet of Things, IoT device attack detection, Performance evaluation, Training},
	pages = {352--359},
}

@article{wang_ai-empowered_2023,
	title = {{AI}-{Empowered} {Trajectory} {Anomaly} {Detection} for {Intelligent} {Transportation} {Systems}: {A} {Hierarchical} {Federated} {Learning} {Approach}},
	volume = {24},
	issn = {1558-0016},
	shorttitle = {{AI}-{Empowered} {Trajectory} {Anomaly} {Detection} for {Intelligent} {Transportation} {Systems}},
	url = {https://ieeexplore.ieee.org/abstract/document/9929438},
	doi = {10.1109/TITS.2022.3209903},
	abstract = {The vigorous development of positioning technology and ubiquitous computing has spawned trajectory big data. By analyzing and processing the trajectory big data in the form of data streams in a timely and effective manner, anomalies hidden in the trajectory data can be found, thus serving urban planning, traffic management, safety control and other applications. Limited by the inherent uncertainty, infinity, time-varying evolution, sparsity and skewed distribution of trajectory big data, traditional anomaly detection techniques cannot be directly applied to anomaly detection in trajectory big data. To solve this problem, we propose a hierarchical trajectory anomaly detection scheme for Intelligent Transportation Systems (ITS) using both machine learning and blockchain technologies. To be specific, a hierarchical federated learning strategy is proposed to improve the generalization ability of the global trajectory anomaly detection model by secondary fusion of the multi-area trajectory anomaly detection model. Then, by integrating blockchain and federated learning, the iterative exchange and fusion of the global trajectory anomaly detection model can be realized by means of on-chain and off-chain coordinated data access. Experiments show that the proposed scheme can improve the generalization ability of the trajectory anomaly detection model in different areas, while ensuring its reliability.},
	number = {4},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Wang, Xiaoding and Liu, Wenxin and Lin, Hui and Hu, Jia and Kaur, Kuljeet and Hossain, M. Shamim},
	month = apr,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Intelligent Transportation Systems},
	keywords = {Anomaly detection, Big Data, Data models, Machine learning algorithms, Roads, Trajectory, Uncertainty, blockchain, federated learning, intelligent transportation systems},
	pages = {4631--4640},
}

@inproceedings{jahromi_deep_2021,
	title = {Deep {Federated} {Learning}-{Based} {Cyber}-{Attack} {Detection} in {Industrial} {Control} {Systems}},
	url = {https://ieeexplore.ieee.org/abstract/document/9647838},
	doi = {10.1109/PST52912.2021.9647838},
	abstract = {Due to the differences between Information Technology (IT) and Industrial Control System (ICS) networks, current IT security solutions are not working effectively on ICS networks. Moreover, due to security and privacy issues, ICS owners usually do not share their network data with third parties to train specific machine learning-based ICS security solutions. To rectify the mentioned issues, a scalable deep federated learning-based method is presented in this paper. In the proposed method, each client trains an unsupervised deep neural network model using local data and shares its parameters with a server. The server aggregates the clients’ parameters, makes a generalized public model, and shares it with all clients. The proposed model is evaluated using a real-world ICS dataset in a water treatment system and compared with two non-federated learning-based methods. Findings show that the proposed method outperformed the other two methods with the same computational complexity as other deep neural network-based methods in the literature.},
	urldate = {2024-04-12},
	booktitle = {2021 18th {International} {Conference} on {Privacy}, {Security} and {Trust} ({PST})},
	author = {Jahromi, Amir Namavar and Karimipour, Hadis and Dehghantanha, Ali},
	month = dec,
	year = {2021},
	keywords = {Computational modeling, Cyber-attack detection, Cyber-physical systems, Data models, Data privacy, Deep neural networks, Federated learning, Industrial Control System (ICS), Industrial Internet of Things (IIoT), Industrial control, Integrated circuits, Learning systems, Training},
	pages = {1--6},
}

@article{ghimire_recent_2022,
	title = {Recent {Advances} on {Federated} {Learning} for {Cybersecurity} and {Cybersecurity} for {Federated} {Learning} for {Internet} of {Things}},
	volume = {9},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/abstract/document/9709603},
	doi = {10.1109/JIOT.2022.3150363},
	abstract = {Decentralized paradigm in the field of cybersecurity and machine learning (ML) for the emerging Internet of Things (IoT) has gained a lot of attention from the government, academia, and industries in recent years. Federated cybersecurity (FC) is regarded as a revolutionary concept to make the IoT safer and more efficient in the future. This emerging concept has the potential of detecting security threats, taking countermeasures, and limiting the spreading of threats over the IoT network system efficiently. An objective of cybersecurity is achieved by forming the federation of the learned and shared model on top of various participants. Federated learning (FL), which is regarded as a privacy-aware ML model, is particularly useful to secure the vulnerable IoT environment. In this article, we start with background and comparison of centralized learning, distributed on-site learning, and FL, which is then followed by a survey of the application of FL to cybersecurity for IoT. This survey primarily focuses on the security aspect but it also discusses several approaches that address the performance issues (e.g., accuracy, latency, resource constraint, and others) associated with FL, which may impact the security and overall performance of the IoT. To anticipate the future evolution of this new paradigm, we discuss the main ongoing research efforts, challenges, and research trends in this area. With this article, readers can have a more thorough understanding of FL for cybersecurity as well as cybersecurity for FL, different security attacks, and countermeasures.},
	number = {11},
	urldate = {2024-04-12},
	journal = {IEEE Internet of Things Journal},
	author = {Ghimire, Bimal and Rawat, Danda B.},
	month = jun,
	year = {2022},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Cloud computing, Collaborative work, Computational modeling, Computer security, Cybersecurity, Data models, Machine learning, Sensors, data offloading, federated cybersecurity (FC), federated learning (FL), machine learning (ML)},
	pages = {8229--8249},
}

@article{li_fsl_2023,
	title = {{FSL}: federated sequential learning-based cyberattack detection for {Industrial} {Internet} of {Things}},
	volume = {1},
	issn = {2731-667X},
	shorttitle = {{FSL}},
	url = {https://doi.org/10.1007/s44244-023-00006-2},
	doi = {10.1007/s44244-023-00006-2},
	abstract = {Industrial Internet of Things (IIoT) brings revolutionary technical supports to modern industries. However, today’s IIoT still faces the challenges of modeling varying time-series in common data isolation while considering data security. To accurately characterize industrial dynamics, we propose a possible solution based on federated sequence learning (FSL) with cyber attack detection capabilities. Under a federated framework, FSL constructs a collaborative global model without violating local data integrity. Taking advantages of the locally sequential modeling, FSL captures the intrinsic industrial time-series responses. Furthermore, data heterogeneity among distributed clients is also considered, which is important to maintenance a robust but sensitive attack detection. Experiments on classic distributed datasets demonstrate that FSL is capable to accurately model data heterogeneity caused by data isolation and dynamics of time-series. Real IIoT attack detection experiments using a distributed testbed show that our FSL provides better detection performances for industrial time-series sensory data compared to existing methods. Therefore, the proposed attack detection approach FSL is promising in real IIoT scenarios in terms of feasibility, robustness and accuracy.},
	language = {en},
	number = {1},
	urldate = {2024-04-12},
	journal = {Industrial Artificial Intelligence},
	author = {Li, Fangyu and Lin, Junnuo and Han, Honggui},
	month = mar,
	year = {2023},
	keywords = {Cyberattack detection, Federated learning, IIoT, Sequential modeling},
	pages = {4},
}

@article{hu_distributed_2023,
	title = {Distributed {Fire} {Detection} and {Localization} {Model} {Using} {Federated} {Learning}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2227-7390},
	url = {https://www.mdpi.com/2227-7390/11/7/1647},
	doi = {10.3390/math11071647},
	abstract = {Fire detection and monitoring systems based on machine vision have been gradually developed in recent years. Traditional centralized deep learning model training methods transfer large amounts of video image data to the cloud, making image data privacy and confidentiality difficult. In order to protect the data privacy in the fire detection system with heterogeneous data and to enhance its efficiency, this paper proposes an improved federated learning algorithm incorporating computer vision: FedVIS, which uses a federated dropout and gradient selection algorithm to reduce communication overhead, and uses a transformer to replace a traditional neural network to improve the robustness of federated learning in the context of heterogeneous data. FedVIS can reduce the communication overhead in addition to reducing the catastrophic forgetting of previous devices, improving convergence, and producing superior global models. In this paper’s experimental results, FedVIS outperforms the common federated learning methods FedSGD, FedAVG, FedAWS, and CMFL, and improves the detection effect by reducing communication costs. As the amount of clients increases, the accuracy of other algorithmic models decreases by 2–5\%, and the number of communication rounds required increases significantly; meanwhile, our method maintains a superior detection performance while requiring roughly the same number of communication rounds.},
	language = {en},
	number = {7},
	urldate = {2024-04-12},
	journal = {Mathematics},
	author = {Hu, Yue and Fu, Xinghao and Zeng, Wei},
	month = jan,
	year = {2023},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {deep learning, federated learning, fire detection system, privacy preservation},
	pages = {1647},
}

@article{ferrag_edge-iiotset_2022,
	title = {Edge-{IIoTset}: {A} {New} {Comprehensive} {Realistic} {Cyber} {Security} {Dataset} of {IoT} and {IIoT} {Applications} for {Centralized} and {Federated} {Learning}},
	volume = {10},
	issn = {2169-3536},
	shorttitle = {Edge-{IIoTset}},
	url = {https://ieeexplore.ieee.org/document/9751703},
	doi = {10.1109/ACCESS.2022.3165809},
	abstract = {In this paper, we propose a new comprehensive realistic cyber security dataset of IoT and IIoT applications, called Edge-IIoTset, which can be used by machine learning-based intrusion detection systems in two different modes, namely, centralized and federated learning. Specifically, the dataset has been generated using a purpose-built IoT/IIoT testbed with a large representative set of devices, sensors, protocols and cloud/edge configurations. The IoT data are generated from various IoT devices (more than 10 types) such as Low-cost digital sensors for sensing temperature and humidity, Ultrasonic sensor, Water level detection sensor, pH Sensor Meter, Soil Moisture sensor, Heart Rate Sensor, Flame Sensor, etc.). Furthermore, we identify and analyze fourteen attacks related to IoT and IIoT connectivity protocols, which are categorized into five threats, including, DoS/DDoS attacks, Information gathering, Man in the middle attacks, Injection attacks, and Malware attacks. In addition, we extract features obtained from different sources, including alerts, system resources, logs, network traffic, and propose new 61 features with high correlations from 1176 found features. After processing and analyzing the proposed realistic cyber security dataset, we provide a primary exploratory data analysis and evaluate the performance of machine learning approaches (i.e., traditional machine learning as well as deep learning) in both centralized and federated learning modes. The Edge-IIoTset dataset can be publicly accessed from http://ieee-dataport.org/8939.},
	urldate = {2024-04-12},
	journal = {IEEE Access},
	author = {Ferrag, Mohamed Amine and Friha, Othmane and Hamouda, Djallel and Maglaras, Leandros and Janicke, Helge},
	year = {2022},
	note = {Conference Name: IEEE Access},
	keywords = {Computer crime, Computer security, Cybersecurity applications, Industrial Internet of Things, IoT datasets, Protocols, Security, Sensors, Temperature sensors, deep learning, edge computing, federated learning},
	pages = {40281--40306},
}

@article{hou_federated_2022,
	title = {A {Federated} {Learning}-{Based} {Fault} {Detection} {Algorithm} for {Power} {Terminals}},
	volume = {2022},
	issn = {1024-123X},
	url = {https://www.hindawi.com/journals/mpe/2022/9031701/},
	doi = {10.1155/2022/9031701},
	abstract = {Power terminal is an important part of the power grid, and fault detection of power terminals is essential for the safety of the power grid. Existing fault detection of power terminals is usually based on artificial intelligent or deep learning models in the cloud or edge servers to achieve high accuracy and low latency. However, these methods cannot protect the privacy of the terminals and update the detection model incrementally. A terminal-edge-server collaborative fault detection model based on federated learning is proposed in this study to improve the accuracy of fault detection, reduce the data transmission and protect the privacy of the terminals. The fault detection model is initially trained in the server using historical data and updated using the parameters of local models from edge servers according to different updating strategies, then the parameters will be sent to each edge server and further to all terminals. Each edge server updates the local model via the compressed system log from terminals in its coverage region, and each terminal uses the model to detect fault according to the system behavior in the log. Experiment results show that this fault detection algorithm has high accuracy and low latency, and the accuracy increases with more model updating.},
	language = {en},
	urldate = {2024-04-12},
	journal = {Mathematical Problems in Engineering},
	author = {Hou, Shuai and Lu, Jizhe and Zhu, Enguo and Zhang, Hailong and Ye, Aliaosha},
	month = jul,
	year = {2022},
	note = {Publisher: Hindawi},
	pages = {e9031701},
}

@inproceedings{su_detection_2022,
	address = {Cham},
	title = {Detection {DDoS} of {Attacks} {Based} on {Federated} {Learning} with {Digital} {Twin} {Network}},
	isbn = {978-3-031-10989-8},
	doi = {10.1007/978-3-031-10989-8_13},
	abstract = {With Intrusion detection algorithms based on deep learning becoming a hot research topic, most studies pay attention to improving detection accuracy but ignore the problem that can not train a high-precision model due to the limited data of each client. This paper proposes an intrusion detection method based on federated learning and the LSTM model to protect the privacy and improve the classification effect in limited data. As a result of the experiments carried out on the KDD CUP 1999 dataset containing the current DDoS attack types, it was observed that the attacks on network traffic were detected with up to 99.17\% success. Furthermore, the federated learning model was constructed in the Digital Twin Network (DTN), an emerging network that utilizes digital twin (DT) technology to create the virtual twins of physical objects. It can real-time monitor the status of physical entities and feedback information to entities in time. Meanwhile, we propose a new optimization framework based on FedProx to tackle the system and statistical heterogeneity inherent in federated networks. This framework shows significantly more stable and accurate convergence behaviour and higher detection accuracy than FedProx and FedAvg.},
	language = {en},
	booktitle = {Knowledge {Science}, {Engineering} and {Management}},
	publisher = {Springer International Publishing},
	author = {Su, Dingling and Qu, Zehui},
	editor = {Memmi, Gerard and Yang, Baijian and Kong, Linghe and Zhang, Tianwei and Qiu, Meikang},
	year = {2022},
	pages = {153--164},
}

@inproceedings{kye_partial_2022,
	address = {New York, NY, USA},
	series = {{MobiHoc} '22},
	title = {Partial federated learning based network intrusion system for mobile devices: poster},
	isbn = {978-1-4503-9165-8},
	shorttitle = {Partial federated learning based network intrusion system for mobile devices},
	url = {https://dl.acm.org/doi/10.1145/3492866.3561257},
	doi = {10.1145/3492866.3561257},
	abstract = {We propose a partial federated learning based network intrusion system to utilize the limited communication resources of mobile devices. The key to our algorithm is that we share only part of the model to enable efficient communication and strengthen data privacy. The proposed method is evaluated using two network traffic datasets and three performance measures. Our simulation results confirm that the model can reach the performance of centralized learning, although the ratio of a shared layer is reduced up to 25\%.},
	urldate = {2024-04-12},
	booktitle = {Proceedings of the {Twenty}-{Third} {International} {Symposium} on {Theory}, {Algorithmic} {Foundations}, and {Protocol} {Design} for {Mobile} {Networks} and {Mobile} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Kye, Hyoseon and Kwon, Minhae},
	month = oct,
	year = {2022},
	keywords = {anomaly detection, autoencoder, federated learning, network intrusion system},
	pages = {283--284},
}

@inproceedings{zakariyya_resource_2022,
	address = {Cham},
	title = {Resource {Efficient} {Federated} {Deep} {Learning} for {IoT} {Security} {Monitoring}},
	isbn = {978-3-031-21311-3},
	doi = {10.1007/978-3-031-21311-3_6},
	abstract = {Federated Learning (FL) uses a distributed Machine Learning (ML) concept to build a global model using multiple local models trained on distributed edge devices. A disadvantage of the FL paradigm is the requirement of many communication rounds before model convergence. As a result, there is a challenge for running on-device FL with resource-hungry algorithms such as Deep Neural Network (DNN), especially in the resource-constrained Internet of Things (IoT) environments for security monitoring. To address this issue, this paper proposes Resource Efficient Federated Deep Learning (REFDL) method. Our method exploits and optimizes Federated Averaging (Fed-Avg) DNN based technique to reduce computational resources consumption for IoT security monitoring. It utilizes pruning and simulated micro-batching in optimizing the Fed-Avg DNN for effective and efficient IoT attacks detection at distributed edge nodes. The performance was evaluated using various realistic IoT and non-IoT benchmark datasets on virtual and testbed environments build with GB-BXBT-2807 edge-computing-like devices. The experimental results show that the proposed method can reduce memory usage by 81\% in the simulated environment of virtual workers compared to its benchmark counterpart. In the realistic testbed scenario, it saves 6\% memory while reducing execution time by 15\% without degrading accuracy.},
	language = {en},
	booktitle = {Attacks and {Defenses} for the {Internet}-of-{Things}},
	publisher = {Springer Nature Switzerland},
	author = {Zakariyya, Idris and Kalutarage, Harsha and Al-Kadri, M. Omar},
	editor = {Li, Wenjuan and Furnell, Steven and Meng, Weizhi},
	year = {2022},
	pages = {122--142},
}

@article{wang_federated_2023,
	title = {Federated deep learning for anomaly detection in the internet of things},
	volume = {108},
	issn = {0045-7906},
	url = {https://www.sciencedirect.com/science/article/pii/S0045790623000769},
	doi = {10.1016/j.compeleceng.2023.108651},
	abstract = {Privacy has emerged as a top worry as a result of the development of zero-day hacks because IoT devices produce and transmit sensitive information through the regular internet. This study suggests a deep neural network (DNN) and federated learning (FL) for an IoT network as well as mutual information (MI) for an effective anomaly detection method. The suggested method is different from the conventional model by use of decentralized on-device data to spot IoT network incursions. The information is kept on localized IoT devices for model training and only modified weights are shared in the centralized FL server is an advantage of integrating FL with Deep learning (DL). It uses the IoT-Botnet 2020 dataset for evaluation. Results demonstrate the efficiency of the DNN-based network intrusion detection system (NIDS) in comparison to the deep learning models with improvement in the accuracy of the model and a reduction in the False Alarm rate (FAR).},
	urldate = {2024-04-12},
	journal = {Computers and Electrical Engineering},
	author = {Wang, Xiaofeng and Wang, Yonghong and Javaheri, Zahra and Almutairi, Laila and Moghadamnejad, Navid and Younes, Osama S.},
	month = may,
	year = {2023},
	keywords = {Anomaly detection, Cyber-physical system, DNN, Deep learning, Federated learning, IoT environment, Network-based intrusion detection system, Security},
	pages = {108651},
}

@inproceedings{caglayan_clustering-based_2022,
	address = {Maspalomas, Spain},
	title = {A {Clustering}-{Based} {Scoring} {Mechanism} for {Malicious} {Model} {Detection} in {Federated} {Learning}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66547-404-7},
	url = {https://ieeexplore.ieee.org/document/9996731/},
	doi = {10.1109/DSD57027.2022.00038},
	abstract = {Federated learning is a distributed machine learning technique that aggregates every client model on a server to obtain a global model. However, some clients may harm the system by poisoning their model or data to make the global model irrelevant to its objective. This paper introduces an approach for the server to detect adversarial models by coordinate-based statistical comparison and eliminate them from the system when their participation rate is at most 40\%. Realistic experiments that use non-independent and identically distributed (non-iid) datasets with different batch sizes have been carried out to show that the proposed method can still identify the malicious nodes successfully even if some of the clients learn slower than others or send quantized model weights due to energy limitations.},
	language = {en},
	urldate = {2024-04-12},
	booktitle = {2022 25th {Euromicro} {Conference} on {Digital} {System} {Design} ({DSD})},
	publisher = {IEEE},
	author = {Caglayan, Cem and Yurdakul, Arda},
	month = aug,
	year = {2022},
	pages = {224--231},
}

@article{vaiyapuri_metaheuristics_2023,
	title = {Metaheuristics with federated learning enabled intrusion detection system in {Internet} of {Things} environment},
	volume = {40},
	copyright = {© 2022 John Wiley \& Sons Ltd.},
	issn = {1468-0394},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13138},
	doi = {10.1111/exsy.13138},
	abstract = {Because of increased applications of Internet of Things (IoT) environment in real-time environment, confidential data gathered by the IoT devices are being communicated to the cloud environment to train the machine learning (ML) models in understanding the patterns that exist in the data. At the same time, the sensitive nature of the IoT data attracts malicious users into hacking efforts. An intrusion detection system (IDS) can be applied to ensure security in the IoT environment. In order to improve security, the ML models can be executed at the data source instead of centralized cloud server. Federated learning (FL) is a recent progression of ML model which enables the ML models to move into the data source rather than moving the data to centralized cloud and thereby resolves cybersecurity problems in the IoT environment. In this view, this study introduces an FL based IDS using bird swarm algorithm based feature selection with classification (FLIDS-BSAFSC) model in IoT environment. The presented FLIDS-BSAFSC model undergoes training on multiple aspects of IoT dataset in a decentralized format to classify, detect, and defend against attacks. The proposed FLIDS-BSAFSC model initially applies min–max normalization technique to pre-process the IoT data. Besides, BSA based feature selection (BSA-FS) technique is designed to elect feature subsets. Finally, social group optimization algorithm with kernel extreme learning machine model is employed for identifying various kinds of classes. In the view of FL where the IoT dataset is not distributed to the server carries out profile aggregation competently with the advantage of peer learning. The experimental validation of the FLIDS-BSAFSC model is tested using benchmark datasets and the results are inspected under several aspects. The experimental values highlighted the better performance of the FLIDS-BSAFSC model over recent approaches.},
	language = {en},
	number = {5},
	urldate = {2024-04-12},
	journal = {Expert Systems},
	author = {Vaiyapuri, Thavavel and Algamdi, Shabbab and John, Rajan and Sbai, Zohra and Al-Helal, Munira and Alkhayyat, Ahmed and Gupta, Deepak},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/exsy.13138},
	keywords = {Internet of Things, attack detection, cybersecurity, federated learning, intrusion detection, machine learning},
	pages = {e13138},
}

@inproceedings{duy_federated_2021,
	title = {Federated learning-based intrusion detection in {SDN}-enabled {IIoT} networks},
	url = {https://ieeexplore.ieee.org/abstract/document/9701525},
	doi = {10.1109/NICS54270.2021.9701525},
	abstract = {Witnessing the explosion in the number of Internet of Things (IoTs) in industries, Software Defined Networking (SDN) is considered as a flexible, efficient, and programmable approach for network management and security policy enforcement. Particularly, it is more suitable in the context of industrial Internet of Things (IIoT) network comprising heterogeneous devices. Meanwhile, the demand of ensuring cyber threat resistance has more become the serious concern from both academia and industry due to incidents, cyberattacks, personal data breaches reported recently. Many intrusion detection systems (IDS) leverage the advances in machine learning (ML) to build the more efficient attack detector against the unknown malicious actions in the network. Such an approach requires gathering a large amount of network traffic for model training in a centralized platform. It obviously violates the data privacy protection since the network traffic is sensitive information if accessed and used by a third party. To take advantage of private network data from various sources for mutually training detection model, federated learning (FL) is recently introduced as a solution that can address the problem of violating data privacy for ML-based cybersecurity solution during training phase. Thus, this work introduces the FL approach for IDS to facilitate the privacy preserving in model training while collaboratively maintaining the efficiency of attack detection in IIoT context with the leverage of SDN.},
	urldate = {2024-04-12},
	booktitle = {2021 8th {NAFOSTED} {Conference} on {Information} and {Computer} {Science} ({NICS})},
	author = {Duy, Phan The and Hung, Tran Van and Ha, Nguyen Hong and Hoang, Hien Do and Pham, Van-Hau},
	month = dec,
	year = {2021},
	keywords = {Data privacy, IDS, Industries, Intrusion detection, Privacy, Resistance, SDN, Telecommunication traffic, Training, federated learning, intrusion detection},
	pages = {424--429},
}

@article{zhao_semisupervised_2023,
	title = {Semisupervised {Federated}-{Learning}-{Based} {Intrusion} {Detection} {Method} for {Internet} of {Things}},
	volume = {10},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/abstract/document/9777753},
	doi = {10.1109/JIOT.2022.3175918},
	abstract = {Federated learning (FL) has become an increasingly popular solution for intrusion detection to avoid data privacy leakage in Internet of Things (IoT) edge devices. Existing FL-based intrusion detection methods, however, suffer from three limitations: 1) model parameters transmitted in each round may be used to recover private data, which leads to security risks; 2) not independent and identically distributed (non-IID) private data seriously adversely affect the training of FL (especially distillation-based FL); and 3) high communication overhead caused by the large model size greatly hinders the actual deployment of the solution. To address these problems, this article develops an intrusion detection method based on a semisupervised FL scheme via knowledge distillation. First, our proposed method leverages unlabeled data via distillation method to enhance the classifier performance. Second, we build a model based on convolutional neural networks (CNNs) for extracting deep features of the traffic packets, and take this model as both the classifier network and discriminator network. Third, the discriminator is designed to improve the quality of each client’s predicted labels, and to avoid the failure of distillation training caused by a large number of incorrect predictions under private non-IID data. Moreover, the combination of the hard-label strategy and voting mechanism further reduces communication overhead. The experiments on the real-world traffic data set with three non-IID scenarios show that our proposed method can achieve better detection performance as well as lower communication overhead than state-of-the-art methods.},
	number = {10},
	urldate = {2024-04-12},
	journal = {IEEE Internet of Things Journal},
	author = {Zhao, Ruijie and Wang, Yijun and Xue, Zhi and Ohtsuki, Tomoaki and Adebisi, Bamidele and Gui, Guan},
	month = may,
	year = {2023},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Data models, Distributed databases, Feature extraction, Federated learning (FL), Internet of Things, Intrusion detection, Servers, Training, intrusion detection, knowledge distillation, semisupervised learning},
	pages = {8645--8657},
}

@article{wang_efficient_2022,
	title = {An {Efficient} {Intrusion} {Detection} {Method} {Based} on {Federated} {Transfer} {Learning} and an {Extreme} {Learning} {Machine} with {Privacy} {Preservation}},
	volume = {2022},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1939-0122, 1939-0114},
	url = {https://www.hindawi.com/journals/scn/2022/2913293/},
	doi = {10.1155/2022/2913293},
	abstract = {Current network security is becoming increasingly important, and intrusion detection is an effective method to protect the network from malicious attacks. This study proposes an intrusion detection algorithm FLTrELM based on federated transfer learning and an extreme learning machine to improve the effect of intrusion detection, which implements data aggregation through federated learning and facilitates the construction of personalized transfer learning for all organizations. FLTrELM first builds a transfer extreme learning machine model to solve the problem of insufficient samples and probability adaptation, then uses the model to learn to protect data privacy without sharing training data under the federated learning mechanism, and finally obtains an intrusion detection model. Experiments on the NSL-KDD, KDD99, and ISCX2012 datasets verify that the proposed method can achieve better detection results and robust performance, especially for small samples and new intrusions, and protects data privacy.},
	language = {en},
	urldate = {2024-04-12},
	journal = {Security and Communication Networks},
	author = {Wang, Kunpeng and Li, Jingmei and Wu, Weifei},
	editor = {Nazir, Shah},
	month = oct,
	year = {2022},
	pages = {1--13},
}

@article{tahir_experience-driven_2022,
	title = {Experience-{Driven} {Attack} {Design} and {Federated}-{Learning}-{Based} {Intrusion} {Detection} in {Industry} 4.0},
	volume = {18},
	issn = {1941-0050},
	url = {https://ieeexplore.ieee.org/abstract/document/9640584},
	doi = {10.1109/TII.2021.3133384},
	abstract = {The advent of Industry 4.0 facilitates the Int- ernet-of-Things-based-transactive energy system (IoTES), which enables innovative services with numerous independent distributed systems. These systems generate heterogeneous data in bulk, which become susceptible to cyber-attacks, particularly the stealthy false data injection attacks (FDIAs). The existing centralized FDIA detection algorithms often breach data privacy and fail to perform effectively in highly dynamic and distributed environments, such as IoTES. To resolve the issue, initially, a recurrent deep deterministic policy gradient is utilized to invent an experience-driven FDIA in a complex IoTES. The attacker intends to intelligently exploit the data integrity of smart energy meters with insufficient knowledge of the system. Subsequently, to countermove the stealth and enable independent clients to train a centralized model while keeping each client’s data privacy intact, a deep-federated-learning-based decentralized FDIA detection method using an attentive aggregation is exploited in this article. The proposed approach is capable of parallel computing and can reliably identify the stealthy FDIA on all the nodes simultaneously. Simulation results validate that the proposed scheme outperforms the state-of-the-art methods under a distributed environment with a significantly higher detection accuracy and lower computational complexity while keeping the data privacy intact.},
	number = {9},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Tahir, Bushra and Jolfaei, Alireza and Tariq, Muhammad},
	month = sep,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Industrial Informatics},
	keywords = {Collaborative work, Computational complexity, Data models, Data privacy, Deep federated learning, Fourth Industrial Revolution, Industry 4.0, Meters, Supply and demand, deep reinforcement learning, false data injection, privacy preservation},
	pages = {6398--6405},
}

@inproceedings{lian_decentralized_2022,
	address = {New York, NY, USA},
	series = {{ASIA} {CCS} '22},
	title = {Decentralized {Federated} {Learning} for {Internet} of {Things} {Anomaly} {Detection}},
	isbn = {978-1-4503-9140-5},
	url = {https://dl.acm.org/doi/10.1145/3488932.3527285},
	doi = {10.1145/3488932.3527285},
	abstract = {With the improvement of computing power and the development of network technology, Internet of Things (IoT) devices are widely used in many industries. But it also faces various security threats. Anomaly detection is a commonly used method, but traditional methods face shortcomings such as low accuracy. Therefore, in this paper, we introduce a decentralized federated learning method for anomaly detection, using neural networks to improve accuracy and take advantage of the characteristics of federated learning to protect local data security. The decentralized algorithm avoids the drawbacks of traditional federated learning such as the single point of failure. Finally, we conduct simulation experiments on the IoT23 dataset, which verify the performance of our system.},
	urldate = {2024-04-12},
	booktitle = {Proceedings of the 2022 {ACM} on {Asia} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {Association for Computing Machinery},
	author = {Lian, Zhuotao and Su, Chunhua},
	year = {2022},
	keywords = {anomaly detection, decentralized system, federated learning, internet of things},
	pages = {1249--1251},
}

@article{lai_two-phase_2023,
	title = {Two-phase {Defense} {Against} {Poisoning} {Attacks} on {Federated} {Learning}-based {Intrusion} {Detection}},
	volume = {129},
	issn = {0167-4048},
	url = {https://www.sciencedirect.com/science/article/pii/S0167404823001153},
	doi = {10.1016/j.cose.2023.103205},
	abstract = {The Machine Learning-based Intrusion Detection System (ML-IDS) becomes more popular because it doesn't need to manually update the rules and can recognize variants better, However, due to the data privacy issue in ML-IDS, the Federated Learning-based IDS (FL-IDS) was proposed. In each round of federated learning, each participant first trains its local model and sends the model's weights to the global server, which then aggregates the received weights and distributes the aggregated global model to participants. An attacker will use poisoning attacks, including label-flipping attacks and backdoor attacks, to directly generate a malicious local model and indirectly pollute the global model. Currently, a few studies defend against poisoning attacks, but they only discuss label-flipping attacks in the image field. Therefore, we propose a two-phase defense mechanism, called Defending Poisoning Attacks in Federated Learning (DPA-FL), applied to intrusion detection. The first phase employs relative differences to quickly compare weights between participants because the local models of attackers and benign participants are quite different. The second phase tests the aggregated model with the dataset and tries to find the attackers when its accuracy is low. Experiment results show that DPA-FL can reach 96.5\% accuracy in defending against poisoning attacks. Compared with other defense mechanisms, DPA-FL can improve F1-score by 20∼64\% under backdoor attacks. Also, DPA-FL can exclude the attackers within twelve rounds when the attackers are few.},
	urldate = {2024-04-12},
	journal = {Computers \& Security},
	author = {Lai, Yuan-Cheng and Lin, Jheng-Yan and Lin, Ying-Dar and Hwang, Ren-Hung and Lin, Po-Chin and Wu, Hsiao-Kuang and Chen, Chung-Kuan},
	month = jun,
	year = {2023},
	keywords = {Backdoor Attack, Federated Learning, Intrusion Detection, Local Outlier Factor, Poisoning Attack},
	pages = {103205},
}

@article{liang_intrusion_2023,
	title = {An {Intrusion} {Detection} {Method} for {Advanced} {Metering} {Infrastructure} {System} {Based} on {Federated} {Learning}},
	volume = {11},
	issn = {2196-5420},
	url = {https://ieeexplore.ieee.org/document/9808312},
	doi = {10.35833/MPCE.2021.000279},
	abstract = {An advanced metering infrastructure (AMI) system plays a key role in the smart grid (SG), but it is vulnerable to cyberattacks. Current detection methods for AMI cyberattacks mainly focus on the data center or a distributed independent node. On one hand, it is difficult to train an excellent detection intrusion model on a self-learning independent node. On the other hand, large amounts of data are shared over the network and uploaded to a central node for training. These processes may compromise data privacy, cause communication delay, and incur high communication costs. With these limitations, we propose an intrusion detection method for AMI system based on federated learning (FL). The intrusion detection system is deployed in the data concentrators for training, and only its model parameters are communicated to the data center. Furthermore, the data center distributes the learning to each data concentrator through aggregation and weight assignments for collaborative learning. An optimized deep neural network (DNN) is exploited for this proposed method, and extensive experiments based on the NSL-KDD dataset are carried out. From the results, this proposed method improves detection performance and reduces computation costs, communication delays, and communication overheads while guaranteeing data privacy.},
	number = {3},
	urldate = {2024-04-12},
	journal = {Journal of Modern Power Systems and Clean Energy},
	author = {Liang, Haolan and Liu, Dongqi and Zeng, Xiangjun and Ye, Chunxiao},
	month = may,
	year = {2023},
	note = {Conference Name: Journal of Modern Power Systems and Clean Energy},
	keywords = {Behavioral sciences, Data centers, Data models, Federated learning (FL), Intrusion detection, Smart meters, WiMAX, Wide area networks, advanced metering infrastructure (AMI) system, data concentrator, intrusion detection},
	pages = {927--937},
}

@article{chen_non_2023,
	title = {Non trust detection of decentralized federated learning based on historical gradient},
	volume = {120},
	issn = {0952-1976},
	url = {https://www.sciencedirect.com/science/article/pii/S0952197623000726},
	doi = {10.1016/j.engappai.2023.105888},
	abstract = {As a paradigm of distributed machine learning, federated learning is widely used in various real scenarios due to its excellent privacy protection performance on preventing local data from being disclosed. However, the traditional federated learning has the defect that a third-party server aggregates the models of various users since it’s difficult to guarantee the reliability of the third party, and multicentre phenomena frequently appeared in various applications, such as social networks, banking and finance, medical health, etc. Users can’t be reassured in decentralization setting due to the mixture of malicious and untrustworthy ones among them. Although untrustworthy users are benign, they may be classified as the saboteurs because of poor efficiency performance in decentralized federated learning which is caused by missing or ambiguity of data. In this paper, we propose Decentralized Federated Learning Historical Gradient (DFedHG) approach to distinguish normal users, untrustworthy users and malicious users in the decentralized federated learning setting. Simultaneously, by means of DFedHG, malicious users are sub-divided into targetless attacks and targeted attacks, which is verified by adopting two types of data sets for confirmation. The experimental results show that the proposed approach achieves better performance compared with the conventional decentralized federated learning without untrustworthy users, and further present excellent differentiation of malicious users.},
	urldate = {2024-04-12},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Chen, Yikuan and Liang, Li and Gao, Wei},
	month = apr,
	year = {2023},
	keywords = {Decentralized federated learning, Historical gradient, Malicious detection},
	pages = {105888},
}

@inproceedings{marfo_network_2022,
	title = {Network {Anomaly} {Detection} {Using} {Federated} {Learning}},
	url = {https://ieeexplore.ieee.org/abstract/document/10017793},
	doi = {10.1109/MILCOM55135.2022.10017793},
	abstract = {Due to the veracity and heterogeneity in network traffic, detecting anomalous events is challenging. The computational load on global servers is a significant challenge in terms of efficiency, accuracy, and scalability. Our primary motivation is to introduce a robust and scalable framework that enables efficient network anomaly detection. We address the issue of scalability and efficiency for network anomaly detection by leveraging federated learning, in which multiple participants train a global model jointly. Unlike centralized training architectures, federated learning does not require participants to upload their training data to the server, preventing attackers from exploiting the training data. Moreover, most prior works have focused on traditional centralized machine learning, making federated machine learning under-explored in network anomaly detection. Therefore, we propose a deep neural network framework that could work on low to mid-end devices detecting network anomalies while checking if a request from a specific IP address is malicious or not. Compared to multiple traditional centralized machine learning models, the deep neural federated model reduces training time overhead. The proposed method performs better than baseline machine learning techniques on the UNSW-NB15 data set as measured by experiments conducted with an accuracy of 97.21\% and a faster computation time.},
	urldate = {2024-04-12},
	booktitle = {{MILCOM} 2022 - 2022 {IEEE} {Military} {Communications} {Conference} ({MILCOM})},
	author = {Marfo, William and Tosh, Deepak K. and Moore, Shirley V.},
	month = nov,
	year = {2022},
	note = {ISSN: 2155-7586},
	keywords = {Anomaly Detection, Artificial Intelligence, Computational modeling, Deep Learning, Federated Learning, Federated learning, Machine Learning, Networks, Performance evaluation, Scalability, Security Attacks, Telecommunication traffic, Training, Training data},
	pages = {484--489},
}

@inproceedings{yu_privacy-preserving_2022,
	title = {Privacy-{Preserving} and {Models} {Intrusion} {Detection} {Federated} {Deep} {Learning} {Challenges}, {Schemas} and {Future} {Trajectories}},
	url = {https://ieeexplore.ieee.org/abstract/document/10016548},
	doi = {10.1109/ICCWAMTIP56608.2022.10016548},
	abstract = {Deep learning has made remarkable research advancements and wide-ranging applications in the domains of computer vision, multimodal, natural language processing, additionally, other areas. This has caused the academic community to pay increasingly close attention to the attack and defense technology in its training and testing phases, among which the federal deep learning has produced positive results. Federated deep learning models are prone to memorizing private and sensitive terminal participants' data, model parameters, when combined with the model's inherent vulnerability, they will result in privacy leakage, poisoning attack, model inference attack, adversarial attack. We briefly discuss the conception of federated deep learning as well as security challenges and open questions in this paper. In order to facilitate the understanding of these challenges and problems, we further propose a security system model. We also provide an overview and deduce the attack and mitigation approaches to the most sophisticated privacy-preserving and intrusion detection models. in the last two years. To tackle these challenges and enlighten further encryption techniques researches, finally, we discuss and describe current prospects and future trajectories of federated deep learning.},
	urldate = {2024-04-12},
	booktitle = {2022 19th {International} {Computer} {Conference} on {Wavelet} {Active} {Media} {Technology} and {Information} {Processing} ({ICCWAMTIP})},
	author = {Yu, Yang and Jianping, Li and Weiwei, Duan},
	month = dec,
	year = {2022},
	note = {ISSN: 2576-8964},
	keywords = {Adversarial attack, Computational modeling, Data models, Deep learning, Encryption techniques, Federated deep learning, Inference attack, Intrusion detection, Models intrusion detection, Poisoning attack, Privacy-preserving, Training, Training data, Trajectory},
	pages = {1--10},
}

@inproceedings{manyadza_fl-finder_2022,
	title = {{FL}-finder: {Detecting} {Unknown} {Network} {Anomaly} in {Federated} {Learning}},
	shorttitle = {{FL}-finder},
	url = {https://ieeexplore.ieee.org/abstract/document/9820480},
	doi = {10.1109/ICAIBD55127.2022.9820480},
	abstract = {The emergence of federated learning has ensured data and privacy security in deep learning models while enabling models to train more efficiently. However, the transmission of network parameters in federated learning may be subject to attacks by unknown anomalies. In this paper, we attempted to detect unknown anomalies in transmitted parameters in federated learning. We designed and implemented F1-finder, an unknown network anomaly detection framework in federated learning, which detects anomalies based on incremental learning. It retains the unknown anomalies to its prior knowledge base using the network updater, and adopts an online mode that reports new anomalies in a real-time. Extensive experimental results show that our model increased the average accuracy of unknown anomaly detection by 10.4\% and the average F1-Score improved to 19\%.},
	urldate = {2024-04-12},
	booktitle = {2022 5th {International} {Conference} on {Artificial} {Intelligence} and {Big} {Data} ({ICAIBD})},
	author = {Manyadza, Tinashe Justice and Du, Haizhou and Wang, Shiwei and Yang, Wenbin and Chen, Cheng and Tian, Fei},
	month = may,
	year = {2022},
	keywords = {Collaborative work, Data models, Detectors, Energy consumption, Federated Learning, Incremental learning, Knowledge based systems, Learning (artificial intelligence), Prior Knowledge, Real-time systems, Unknown Anomaly Detection},
	pages = {593--597},
}

@article{singh_dew-cloud-based_2023,
	title = {Dew-{Cloud}-{Based} {Hierarchical} {Federated} {Learning} for {Intrusion} {Detection} in {IoMT}},
	volume = {27},
	issn = {2168-2208},
	doi = {10.1109/JBHI.2022.3186250},
	abstract = {The coronavirus pandemic has overburdened medical institutions, forcing physicians to diagnose and treat their patients remotely. Moreover, COVID-19 has made humans more conscious about their health, resulting in the extensive purchase of IoT-enabled medical devices. The rapid boom in the market worth of the internet of medical things (IoMT) captured cyber attackers' attention. Like health, medical data is also sensitive and worth a lot on the dark web. Despite the fact that the patient's health details have not been protected appropriately, letting the trespassers exploit them. The system administrator is unable to fortify security measures due to the limited storage capacity and computation power of the resource-constrained network devices'. Although various supervised and unsupervised machine learning algorithms have been developed to identify anomalies, the primary undertaking is to explore the swift progressing malicious attacks before they deteriorate the wellness system's integrity. In this paper, a Dew-Cloud based model is designed to enable hierarchical federated learning (HFL). The proposed Dew-Cloud model provides a higher level of data privacy with greater availability of IoMT critical application(s). The hierarchical long-term memory (HLSTM) model is deployed at distributed Dew servers with a backend supported by cloud computing. Data pre-processing feature helps the proposed model achieve high training accuracy (99.31\%) with minimum training loss (0.034). The experiment results demonstrate that the proposed HFL-HLSTM model is superior to existing schemes in terms of performance metrics such as accuracy, precision, recall, and f-score.},
	language = {eng},
	number = {2},
	journal = {IEEE journal of biomedical and health informatics},
	author = {Singh, Parminder and Gaba, Gurjot Singh and Kaur, Avinash and Hedabou, Mustapha and Gurtov, Andrei},
	month = feb,
	year = {2023},
	pmid = {35816521},
	keywords = {Algorithms, COVID-19, Cloud Computing, Humans, Internet, Internet of Things},
	pages = {722--731},
}

@inproceedings{liu_federated_2023,
	address = {Cham},
	title = {Federated {Learning}-{Based} {Intrusion} {Detection} on {Non}-{IID} {Data}},
	isbn = {978-3-031-22677-9},
	doi = {10.1007/978-3-031-22677-9_17},
	abstract = {Intrusion detection is an effective means to deal with network attacks. Currently, the commonly used detection methods are based on machine learning. However, traditional machine learning-based methods are centralized architectures that require uploading data to cloud servers, which face serious latency and data security issues. Federated learning (FL) can collaboratively train a machine learning model with good performance while the data is kept locally on the client, which can effectively make up for the shortcomings of the centralized architecture. Most of the current research on using FL methods in machine learning-based intrusion detection ideally consider the data to be independent and identically distributed (IID), which doesn’t conform to real scenarios. In the real world, due to the different environment of the client, the types of attacks contained in the data owned by each client may be different. Therefore, we study the effects of various non-independent and identically distribution (non-IID) settings on FL in detail and give specific partitioning methods. In addition, we also propose a FL data rebalancing method based on auxiliary classifier generative adversarial networks (ACGAN), which is experimentally validated on the UNSW-NB15 dataset. Experiments show that the proposed data augmentation method can well improve the impact of non-IID data on FL.},
	language = {en},
	booktitle = {Algorithms and {Architectures} for {Parallel} {Processing}},
	publisher = {Springer Nature Switzerland},
	author = {Liu, Yongfei and Wu, Guangjun and Zhang, Wenyuan and Li, Jun},
	editor = {Meng, Weizhi and Lu, Rongxing and Min, Geyong and Vaidya, Jaideep},
	year = {2023},
	pages = {313--329},
}

@article{friha_2df-ids_2023,
	title = {{2DF}-{IDS}: {Decentralized} and differentially private federated learning-based intrusion detection system for industrial {IoT}},
	volume = {127},
	issn = {0167-4048},
	shorttitle = {{2DF}-{IDS}},
	url = {https://www.sciencedirect.com/science/article/pii/S016740482300007X},
	doi = {10.1016/j.cose.2023.103097},
	abstract = {Advanced technologies, such as the Internet of Things (IoT) and Artificial Intelligence (AI), underpin many of the innovations in Industry 4.0. However, the interconnectivity and open nature of such systems in smart industrial facilities can also be targeted and abused by malicious actors, which reinforces the importance of cyber security. In this paper, we present a secure, decentralized, and Differentially Private (DP) Federated Learning (FL)-based IDS (2DF-IDS), for securing smart industrial facilities. The proposed 2DF-IDS comprises three building blocks, namely: a key exchange protocol (for securing the communicated weights among all peers in the system), a differentially private gradient exchange scheme (achieve improved privacy of the FL approach), and a decentralized FL approach (that mitigates the single point of failure/attack risk associated with the aggregation server in the conventional FL approach). We evaluate our proposed system through detailed experiments using a real-world IoT/IIoT dataset, and the results show that the proposed 2DF-IDS system can identify different types of cyber attacks in an Industrial IoT system with high performance. For instance, the proposed system achieves comparable performance (94.37\%) with the centralized learning approach (94.37\%) and outperforms the FL-based approach (93.91\%) in terms of accuracy. The proposed system is also shown to improve the overall performance by 12\%, 13\%, and 9\% in terms of F1-score, recall, and precision, respectively, under strict privacy settings when compared to other competing FL-based IDS solutions.},
	urldate = {2024-04-12},
	journal = {Computers \& Security},
	author = {Friha, Othmane and Ferrag, Mohamed Amine and Benbouzid, Mohamed and Berghout, Tarek and Kantarci, Burak and Choo, Kim-Kwang Raymond},
	month = apr,
	year = {2023},
	keywords = {Cybersecurity, Decentralized federated learning, Differential privacy, Industry 4.0, Intrusion detection, IoT/IIoT security, Post-Quantum cryptography, Privacy},
	pages = {103097},
}

@article{pei_knowledge_2023,
	title = {A {Knowledge} {Transfer}-{Based} {Semi}-{Supervised} {Federated} {Learning} for {IoT} {Malware} {Detection}},
	volume = {20},
	issn = {1941-0018},
	url = {https://ieeexplore.ieee.org/abstract/document/9772293},
	doi = {10.1109/TDSC.2022.3173664},
	abstract = {As the demand for Internet of Things (IoT) technologies continues to grow, IoT devices have been viable targets for malware infections. Although deep learning-based malware detection has achieved great success, the detection models are usually trained based on the collected user records, thereby leading to significant privacy risks. One promising solution is to leverage federated learning (FL) to enable distributed on-device training without centralizing the private user records. However, it is non-trivial for IoT users to label these records, where the quality and the trustworthiness of data labeling are hard to guarantee. To address the above issues, this paper develops a semi-supervised federated IoT malware detection framework based on knowledge transfer technologies, named by FedMalDE. Specifically, FedMalDE explores the underlying correlation between labeled and unlabeled records to infer labels towards unlabeled samples by the knowledge transfer mechanism. Moreover, a specially designed subgraph aggregated capsule network (SACN) is used to efficiently capture varied malicious behaviors. The extensive experiments conducted on real-world data demonstrate the effectiveness of FedMalDE in detecting IoT malware and its sufficient privacy and robustness guarantee.},
	number = {3},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Dependable and Secure Computing},
	author = {Pei, Xinjun and Deng, Xiaoheng and Tian, Shengwei and Zhang, Lan and Xue, Kaiping},
	month = may,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Dependable and Secure Computing},
	keywords = {Collaborative work, Feature extraction, Malware, Malware detection, Privacy, Security, Semantics, Training, capsule network, federated learning, privacy-preserving, semi-supervised learning},
	pages = {2127--2143},
}

@article{he_cgan-based_2023,
	title = {{CGAN}-{Based} {Collaborative} {Intrusion} {Detection} for {UAV} {Networks}: {A} {Blockchain}-{Empowered} {Distributed} {Federated} {Learning} {Approach}},
	volume = {10},
	issn = {2327-4662},
	shorttitle = {{CGAN}-{Based} {Collaborative} {Intrusion} {Detection} for {UAV} {Networks}},
	url = {https://ieeexplore.ieee.org/abstract/document/9863068},
	doi = {10.1109/JIOT.2022.3200121},
	abstract = {Numerous resource-constrained Internet of Things (IoT) devices make the edge IoT consisting of unmanned aerial vehicles (UAVs) vulnerable to network intrusion. Therefore, it is critical to design an effective intrusion detection system (IDS). However, the differences in local data sets among UAVs show small samples and uneven distribution, further reducing the detection accuracy of network intrusion. This article proposes a conditional generative adversarial net (CGAN)-based collaborative intrusion detection algorithm with blockchain-empowered distributed federated learning to solve the above problems. This study introduces long short-term memory (LSTM) into the CGAN training to improve the effect of generative networks. Based on the feature extraction ability of LSTM networks, the generated data with CGAN are used as augmented data and applied in the detection and classification of intrusion data. Distributed federated learning with differential privacy ensures data security and privacy and allows collaborative training of CGAN models using multiple distributed data sets. Blockchain stores and shares the training models to ensure security when the global model’s aggregation and updating. The proposed method has good generalization ability, which can greatly improve the detection of intrusion data.},
	number = {1},
	urldate = {2024-04-12},
	journal = {IEEE Internet of Things Journal},
	author = {He, Xiaoqiang and Chen, Qianbin and Tang, Lun and Wang, Weili and Liu, Tong},
	month = jan,
	year = {2023},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Blockchain, Blockchains, Collaborative work, Data models, Data privacy, Internet of Things, Intrusion detection, Training, conditional generative adversarial network (CGAN), distributed federated learning, intrusion detection system (IDS), long short-term memory (LSTM), unmanned aerial vehicle (UAV) network},
	pages = {120--132},
}

@article{arisdakessian_survey_2023,
	title = {A {Survey} on {IoT} {Intrusion} {Detection}: {Federated} {Learning}, {Game} {Theory}, {Social} {Psychology}, and {Explainable} {AI} as {Future} {Directions}},
	volume = {10},
	issn = {2327-4662},
	shorttitle = {A {Survey} on {IoT} {Intrusion} {Detection}},
	url = {https://ieeexplore.ieee.org/abstract/document/9872110},
	doi = {10.1109/JIOT.2022.3203249},
	abstract = {In the past several years, the world has witnessed an acute surge in the production and usage of smart devices which are referred to as the Internet of Things (IoT). These devices interact with each other as well as with their surrounding environments to sense, gather and process data of various kinds. Such devices are now part of our everyday’s life and are being actively used in several verticals, such as transportation, healthcare, and smart homes. IoT devices, which usually are resource-constrained, often need to communicate with other devices, such as fog nodes and/or cloud computing servers to accomplish certain tasks that demand large resource requirements. These communications entail unprecedented security vulnerabilities, where malicious parties find in this heterogeneous and multiparty architecture a compelling platform to launch their attacks. In this work, we conduct an in-depth survey on the existing intrusion detection solutions proposed for the IoT ecosystem which includes the IoT devices as well as the communications between the IoT, fog computing, and cloud computing layers. Although some survey articles already exist, the originality of this work stems from the three following points: 1) discuss the security issues of the IoT ecosystem not only from the perspective of IoT devices but also taking into account the communications between the IoT, fog, and cloud computing layers; 2) propose a novel two-level classification scheme that first categorizes the literature based on the approach used to detect attacks and then classify each approach into a set of subtechniques; and 3) propose a comprehensive cybersecurity framework that combines the concepts of explainable artificial intelligence (XAI), federated learning, game theory, and social psychology to offer future IoT systems a strong protection against cyberattacks.},
	number = {5},
	urldate = {2024-04-12},
	journal = {IEEE Internet of Things Journal},
	author = {Arisdakessian, Sarhad and Wahab, Omar Abdel and Mourad, Azzam and Otrok, Hadi and Guizani, Mohsen},
	month = mar,
	year = {2023},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Cloud computing, Collaborative work, Cybersecurity, Edge computing, Game theory, Internet of Things, Intrusion detection, Taxonomy, explainable artificial intelligence (XAI), federated learning (FL), game theory, internet of Things (IoT), intrusion detection systems (IDSs)},
	pages = {4059--4092},
}

@inproceedings{wang_sdn_2022,
	title = {{SDN} traffic anomaly detection method based on convolutional autoencoder and federated learning},
	url = {https://ieeexplore.ieee.org/abstract/document/10001438},
	doi = {10.1109/GLOBECOM48099.2022.10001438},
	abstract = {With the rapid development of the Internet, people pay more and more attention to network security and data privacy. Using the characteristics of SDN data and control separation, it is easy to embed a traffic detection model in edge devices to achieve abnormal traffic detection. However, although the traditional intrusion detection model can provide good recognition accuracy, it requires many labeled samples for model training. Not only is it challenging to obtain labeled samples, but it also brings privacy issues. This paper combines federated learning and anomaly-based CAE model in the SDN network and realizes intrusion detection on encrypted traffic under the premise of effectively protecting data privacy and reducing the workload of data labeling. Furthermore, we design an aggregation model selection algorithm based on loss and data volume evaluation, which reduces the overall training time of the federation and improves the model's accuracy.},
	urldate = {2024-04-12},
	booktitle = {{GLOBECOM} 2022 - 2022 {IEEE} {Global} {Communications} {Conference}},
	author = {Wang, ZiXuan and Wang, Pan and Sun, ZhiXin},
	month = dec,
	year = {2022},
	keywords = {Convolutional autoencoder, Data privacy, Deep learning, Encrypted traffic identification, Federated learning, Intrusion detection, Network intrusion detection, Privacy, Solid modeling, Telecommunication traffic, Training},
	pages = {4154--4160},
}

@inproceedings{cai_cluster-based_2022,
	title = {Cluster-based {Federated} {Learning} {Framework} for {Intrusion} {Detection}},
	url = {https://ieeexplore.ieee.org/abstract/document/10010553},
	doi = {10.1109/PAAP56126.2022.10010553},
	abstract = {With the rapid development of Industrial Internet, the network intrusion detection has become particularly important. In the Industrial Internet, large-scale data is distributed in the edge nodes caused the joint analysis of network intrusion detection at each edge node has become necessary. Federated learning structure can avoid data out of local nodes to protect user privacy data. However, the data distribution is different for each edge nodes, which limits the effectiveness of federated learning models. We focus on the non-IID data features and propose a new cluster-based federated learning framework for network intrusion detection. In this method, we cluster clients into different communities by data labels, which the clients contain the similar proportion of data labels in the same community. Based on the clustering results, we decompose federated learning model aggregation into cluster aggregation and global aggregation by leveraging similarities both within and between clusters. We conduct extensive experiments based on UNSW\_NB15 dataset. The results show that our method has better performance than FedAvg and FedProx. It can work well in scenarios with different distributions of data samples while ensuring data security and privacy protection.},
	urldate = {2024-04-12},
	booktitle = {2022 {IEEE} 13th {International} {Symposium} on {Parallel} {Architectures}, {Algorithms} and {Programming} ({PAAP})},
	author = {Cai, Luxin and Chen, Naiyue and Wei, Yuanmeng and Chen, Huaping and Li, Yidong},
	month = nov,
	year = {2022},
	keywords = {Data privacy, Data security, Distributed databases, Federated learning, Image edge detection, Intrusion detection, Network intrusion detection, Programming, cluster, federated learning, non-IID, similarity},
	pages = {1--6},
}

@article{moustafa_dfsat_2022,
	title = {{DFSat}: {Deep} {Federated} {Learning} for {Identifying} {Cyber} {Threats} in {IoT}-based {Satellite} {Networks}},
	issn = {1941-0050},
	shorttitle = {{DFSat}},
	url = {https://ieeexplore.ieee.org/abstract/document/9925589},
	doi = {10.1109/TII.2022.3214652},
	abstract = {The integration of satellite systems with smart computing and networking technologies, such as the Internet of Things (IoT), has intensely augmented sophisticated cyberattacks against satellite environments. Resisting cyber threats to complex and large-scale satellite configurations has been enormously challenging, owing to the deficiency of high-quality samples of attack data collected from distributed satellite networks. This study proposes a novel federated learning-based deep learning framework for intrusion detection, named DFSat, to identify cyberattacks from IoT-integrated satellite networks. We develop a distributed deep learning-enabled attack detection method using a recurrent neural network. We then build a federated learning architecture which, utilizes several IoT-integrated satellite networks to preserve the privacy and security of DFSat's parameters throughout the learning process. Extensive experiments have been conducted using communication rounds on an IoT-based network dataset to validate the efficiency of DFSat. The results revealed that the proposed framework significantly distinguishes complex cyberattacks, outperforming recent state-of-the-art intrusion detection techniques, validating its usefulness as a viable deployment framework in IoT-integrated satellite networks.},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Moustafa, Nour and Khan, Izhar Ahmed and Hassanin, Mohammed and Ormrod, David and Pi, Dechang and Razzak, Imran and Slay, Jill},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Industrial Informatics},
	keywords = {Computer architecture, Cyber security, Earth, Federated learning, Internet of Things, Internet of Things (IoT), Intrusion Detection, Intrusion detection, Low earth orbit satellites, Satellite Systems, Satellites, Security, Smart Enterprise Systems},
	pages = {1--8},
}

@article{short_improving_2021,
	title = {Improving {Security} and {Fairness} in {Federated} {Learning} {Systems}},
	volume = {13},
	doi = {10.5121/ijnsa.2021.13604},
	abstract = {The ever-increasing use of Artificial Intelligence applications has made apparent that the quality of the training datasets affects the performance of the models. To this end, Federated Learning aims to engage multiple entities to contribute to the learning process with locally maintained data, without requiring them to share the actual datasets. Since the parameter server does not have access to the actual training datasets, it becomes challenging to offer rewards to users by directly inspecting the dataset quality. Instead, this paper focuses on ways to strengthen user engagement by offering “fair” rewards, proportional to the model improvement (in terms of accuracy) they offer. Furthermore, to enable objective judgment of the quality of contribution, we devise a point system to record user performance assisted by blockchain technologies. More precisely, we have developed a verification algorithm that evaluates the performance of users’ contributions by comparing the resulting accuracy of the global model against a verification dataset and we demonstrate how this metric can be used to offer security improvements in a Federated Learning process. Further on, we implement the solution in a simulation environment in order to assess the feasibility and collect baseline results using datasets of varying quality.},
	journal = {International Journal of Network Security \& Its Applications},
	author = {Short, Andrew and Orfanoudakis, Τheofanis and Helen, Leligou},
	month = nov,
	year = {2021},
	pages = {37--53},
}

@inproceedings{zaabar_intrusion_2022,
	title = {Intrusion {Detection} {System} for {IoMT} through {Blockchain}-based {Federated} {Learning}},
	url = {https://ieeexplore.ieee.org/abstract/document/9970536},
	doi = {10.1109/SIN56466.2022.9970536},
	abstract = {Federated Learning (FL) is a feasible technology to collaboratively train a model without sharing private data. This approach differs from traditional machine learning techniques, which aggregate local datasets in a single server. Thus, FL is adopted in the Healthcare sector to preserve the privacy of collected sensitive medical data from heterogenous and resource-constrained Internet of Medical Things (IoMT). However, FL requires aggregating all trained local models in a central server that presents a single point of failure. To address this issue, we propose a novel Blockchain-based Federated Learning architecture, which is applied to detect malicious network traffic in IoMT environments. In this paper, the proposed architecture takes advantage of a Hyperledger Fabric channel coupled with FL to manage efficiently and securely the learning process of an Intrusion Detection System (IDS). The Blockchain channel replaces the commonly used central server with the traditional FL approach. Moreover, the proposed approach benefits from the inherent features of Blockchain and FL. Besides, it secures patient data collection from the IoMT by examining the network traffic for unauthorised behaviour or policy breaches.},
	urldate = {2024-04-12},
	booktitle = {2022 15th {International} {Conference} on {Security} of {Information} and {Networks} ({SIN})},
	author = {Zaabar, Bessem and Cheikhrouhou, Omar and Abid, Mohamed},
	month = nov,
	year = {2022},
	keywords = {Blockchain, Data privacy, Distributed ledger, Fabrics, Fed-erated Learning (FL), Federated learning, Internet of Medical Things, Internet of Medical Things (IoMT), Intrusion Detection System (IDS), Intrusion detection, Security and Privacy, Telecommunication traffic},
	pages = {01--08},
}

@article{tang_federated_2022,
	title = {A federated learning method for network intrusion detection},
	volume = {34},
	copyright = {© 2021 John Wiley \& Sons Ltd.},
	issn = {1532-0634},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.6812},
	doi = {10.1002/cpe.6812},
	abstract = {Intrusion detection is a common network security defense technology. At present, there are many research using deep learning to realize network intrusion detection. This method has been proved to have high detection accuracy. However, deep learning requires large-scale data sets for training. The network intrusion detection data set of some institution is lacking. If the network traffic data set is uploaded for centralized deep learning training, it will face privacy problems. Combined with the characteristics of network traffic, this article proposes a network intrusion detection method based on federated learning. This method allows multiple ISPs or other institutions to conduct joint deep learning training on the premise of retaining local data. It not only improves the detection accuracy of the model but also protects privacy in network traffic. This article conducts experiments on the CICIDS2017 network intrusion detection data set. Experimental results show that worker participating in federated learning have higher detection accuracy. The accuracy and other performance of federated learning are almost equal to those of centralized deep learning models.},
	language = {en},
	number = {10},
	urldate = {2024-04-12},
	journal = {Concurrency and Computation: Practice and Experience},
	author = {Tang, Zhongyun and Hu, Haiyang and Xu, Chonghuan},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.6812},
	keywords = {CICIDS2017, GRU, deep learning, federated learning, network intrusion detection},
	pages = {e6812},
}

@inproceedings{zhang_survey_2021,
	title = {A survey on security and privacy threats to federated learning},
	url = {https://ieeexplore.ieee.org/abstract/document/9634881},
	doi = {10.1109/NaNA53684.2021.00062},
	abstract = {Federated learning (FL) has nourished a promising scheme to solve the data silo, which enables multiple clients to construct a joint model without centralizing data. The critical concerns for flourishing FL applications are that build a security and privacy-preserving learning environment. It is thus highly necessary to comprehensively identify and classify potential threats to utilize FL under security guarantees. This paper starts from the perspective of launched attacks with different computing participants to construct the unique threats classification, highlighting the significant attacks, e.g., poisoning attacks, inference attacks, and generative adversarial networks (GAN) attacks. Our study shows that existing FL protocols do not always provide sufficient security, containing various attacks from both clients and servers. GAN attacks lead to larger significant threats among the kinds of threats given the invisible of the attack process. Moreover, we summarize a detailed review of several defense mechanisms and approaches to resist privacy risks and security breaches. Then advantages and weaknesses are generalized, respectively. Finally, we conclude the paper to prospect the challenges and some potential research directions.},
	urldate = {2024-04-12},
	booktitle = {2021 {International} {Conference} on {Networking} and {Network} {Applications} ({NaNA})},
	author = {Zhang, Junpeng and Li, Mengqian and Zeng, Shuiguang and Xie, Bin and Zhao, Dongmei},
	month = oct,
	year = {2021},
	keywords = {Collaborative work, Computational modeling, Federated learning, GAN attacks., Generative adversarial networks, IEEE Standards, Privacy, Protocols, Resists, inference attacks, poisoning attacks, privacy-preserving, security threat},
	pages = {319--326},
}

@inproceedings{dong_towards_2021,
	title = {Towards {Fast} {Network} {Intrusion} {Detection} based on {Efficiency}-preserving {Federated} {Learning}},
	url = {https://ieeexplore.ieee.org/document/9644849},
	doi = {10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00071},
	abstract = {Network Intrusion Detection Systems (NIDSs) are extremely important in defending against emergent cyberattacks. However, current NIDSs for Internet-of-Things (IoT) devices have not taken actual device computation limitation into account, and are still based on resource-consuming neural networks. In this paper, we propose a simple but effective FL-based NIDS. Specifically, we leverage the characteristic of network traffic data (a kind of tabular data), i.e. slight value change does not affect inherent feature, and use data binning to extract feature data on clients. The feature data are then used for training the classifier on the server. We also use data masking to further enhance data protection. We evaluate our NIDS on the public DDoS attack classification benchmark, and the result shows that our NIDS can achieve comparable performance as locally trained NIDS while significantly reducing the communication cost.},
	urldate = {2024-04-12},
	booktitle = {2021 {IEEE} {Intl} {Conf} on {Parallel} \& {Distributed} {Processing} with {Applications}, {Big} {Data} \& {Cloud} {Computing}, {Sustainable} {Computing} \& {Communications}, {Social} {Computing} \& {Networking} ({ISPA}/{BDCloud}/{SocialCom}/{SustainCom})},
	author = {Dong, Tian and Qiu, Han and Lu, Jialiang and Qiu, Meikang and Fan, Chun},
	month = sep,
	year = {2021},
	keywords = {Benchmark testing, Communication-efficient, Costs, Feature extraction, Federated Learning, Internet-of-Things, Intrusion Detection, Network intrusion detection, Neural networks, Privacy-preserving, Telecommunication traffic, Training},
	pages = {468--475},
}

@article{huang_eefed_2023,
	title = {{EEFED}: {Personalized} {Federated} {Learning} of {Execution}\&{Evaluation} {Dual} {Network} for {CPS} {Intrusion} {Detection}},
	volume = {18},
	issn = {1556-6021},
	shorttitle = {{EEFED}},
	url = {https://ieeexplore.ieee.org/document/9919869},
	doi = {10.1109/TIFS.2022.3214723},
	abstract = {In the modern interconnected world, intelligent networks and computing technologies are increasingly being incorporated in industrial systems. However, this adoption of advanced technology has resulted in increased cyber threats to cyber-physical systems. Existing intrusion detection systems are continually challenged by constantly evolving cyber threats. Machine learning algorithms have been applied for intrusion detection. In these techniques, a classification model is trained by learning cyber behavior patterns. However, these models typically require considerable high-quality datasets. Limited attack samples are available because of the unpredictability and constant evolution of cyber threats. To address these problems, we propose a novel federated Execution \& Evaluation dual network framework (EEFED), which allows multiple federal participants to personalize their local detection models undermining the original purpose of Federated Learning. Thus, a general global detection model was developed for collaboratively improving the performance of a single local model against cyberattacks. The proposed personalized update algorithm and the optimizing backtracking parameters replacement policy effectively reduced the negative influence of federated learning in imbalanced and non-i.i.d distribution of data. The proposed method improved model stability. Furthermore, extensive experiments conducted on a network dataset in various cyber scenarios revealed that the proposed method outperformed single model and state-of-the-art methods.},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Huang, Xianting and Liu, Jing and Lai, Yingxu and Mao, Beifeng and Lyu, Hongshuo},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Computational modeling, Computer crime, Data models, Federated learning, Intrusion detection, Security, Training, cyber security, cyber-physical system (CPS), intrusion detection, personalized model},
	pages = {41--56},
}

@book{khan_federated_2022,
	title = {A {Federated} {Learning} {Based} {Security} for {Controller} {Pilot} {Data} {Link} {Communication}},
	abstract = {The safety of the passengers and goods in airplanes depends upon a number of combined factors. An airplane’s condition and the pilot’s experience are pivotal but another very crucial element is the synchronization among the pilots and the air traffic controller (ATC). The communication link between the two carries many uncertain aspects. The aviation sector often tends to give more priority to safety rather than cybersecurity. Although the controller-pilot data communication link (CPDLC) system has been proposed for consistent and reliable communication recently, it has some serious drawbacks. In this paper, we highlight the shortcomings of the CPDLC system from a cyber security perspective. We propose a federated learning-based privacypreserving intrusion detection system (IDS) to protect the CPDLC from uplink and downlink cyber attacks. To ensure a realistic and viable solution, we created our own training dataset by eavesdropping on the air-ground communication at a site near Arlanda airport, Sweden. The anomaly detection model constructed through federated learning has achieved higher accuracy, precision, recall and F1 score as compared to the centrally and locally trained models, enabling higher security. Due to the lower training loss and time, the proposed approach is highly suitable for the sensitive aviation communications.},
	author = {Khan, Suleman and Gaba, Gurjot and Gurtov, Andrei},
	month = sep,
	year = {2022},
}

@article{abubaker_blockchained_2022,
	title = {Blockchained service provisioning and malicious node detection via federated learning in scalable {Internet} of {Sensor} {Things} networks},
	volume = {204},
	issn = {1389-1286},
	url = {https://www.sciencedirect.com/science/article/pii/S1389128621005570},
	doi = {10.1016/j.comnet.2021.108691},
	abstract = {In this paper, a blockchained Beyond Fifth Generation (B5G) enabled malicious node detection model is proposed for the Internet of Sensor Things (IoSTs). Moreover, a secure service provisioning scheme using cascading encryption and feature evaluation process is also proposed for the IoSTs. The presence of malicious nodes causes severe issues in the localization and service provisioning, which discourages new entities to join the network. Therefore, it is very important to establish trust between all entities by detecting and removing such nodes. The proposed B5G enabled malicious node detection model uses federated learning for the detection of malicious nodes. The federated learning uses Support Vector Machine (SVM) and Random Forest (RF) classifiers to detect the malicious nodes. The malicious nodes are classified on the bases of their honesty and end-to-end delay. Moreover, the service provider nodes provide services to each other and get the reward. However, the service provisioning in the IoSTs has many issues like a repudiation of service providers as well as the clients. The feature evaluation and cascading encryption mechanisms are used to solve these issues. The digital signature in cascading encryption ensures the non-repudiation of the service provider. On the other hand, feature evaluation of service ensures that the client cannot repudiate about actually demanded services. Moreover, the conformance of services is also ensured by the feature evaluation process. The simulation results show the effectiveness of our proposed non-repudiation model. The SVM and RF classifiers are compared in terms of accuracy, precision, F1 score and recall. The accuracy, precision, F1 score and recall of SVM are 79\%, 1, 0.8795 and 0.78, respectively. On the other hand, the accuracy, precision, F1 score and recall of RF classifier are 95\%, 0.92, 0.96 and 1, respectively. The results show that RF has better accuracy than RF in malicious nodes detection.},
	urldate = {2024-04-12},
	journal = {Computer Networks},
	author = {Abubaker, Zain and Javaid, Nadeem and Almogren, Ahmad and Akbar, Mariam and Zuair, Mansour and Ben-Othman, Jalel},
	month = feb,
	year = {2022},
	keywords = {Beyond Fifth Generation, Blockchain, Cascading encryption, Internet of Sensor Things, Localization, Non-repudiation, Random Forest algorithm, Service provisioning, Support Vector Machine},
	pages = {108691},
}

@inproceedings{neto_collaborative_2022,
	title = {Collaborative {DDoS} {Detection} in {Distributed} {Multi}-{Tenant} {IoT} using {Federated} {Learning}},
	url = {https://ieeexplore.ieee.org/document/9851984},
	doi = {10.1109/PST55820.2022.9851984},
	abstract = {Nowadays, the Internet of Things (IoT) has attracted much attention from the industry, and new initiatives are expected to be developed in the next decade. IoT is establishing a globally connected sensor network in which many devices are connected to the Internet generating large amounts of data. Conversely, many challenges need to be overcome to enable efficient and secure IoT applications (e.g., interoperability, security, standards, and server technologies). Furthermore, edge computing presents a paramount role in the diverse range of IoT applications. In this sense, processing sensitive data for different tenants (e.g., e-health and smart cities applications) requires transactions to be protected and isolated from different flows. Thereupon, different tenants can be targeted by Distributed Denial of Service (DDoS) attacks. However, attacks performed against a tenant remain unknown to others, preventing the improvement of detection and mitigation capabilities for DDoS attacks. The main obstacle in this collaboration relies on maintaining privacy in a multi-tenant environment while sharing the characteristics of attacks faced in the past. In this paper, we propose a collaborative DDoS detection and classification approach for distributed multi-tenant IoT environments using Federated Learning. This approach enables multiples tenants to collaboratively enhance their DDoS detection and classification capabilities across all edge nodes while maintaining their privacy. To accomplish this, tenants train deep learning instances on locally scaled traffic data and share the model parameters with other tenants. This strategy enables safer IoT operations and can be adopted in different applications. The experiments performed on a simulated environment considered the CICD-DoS2019 dataset and showed that the proposed approach can classify different DDoS attacks types with over 84.2\% accuracy. The results demonstrate that collaborative DDoS detection enhances tenant protection compared to single detection.},
	urldate = {2024-04-12},
	booktitle = {2022 19th {Annual} {International} {Conference} on {Privacy}, {Security} \& {Trust} ({PST})},
	author = {Neto, Euclides Carlos Pinto and Dadkhah, Sajjad and Ghorbani, Ali A.},
	month = aug,
	year = {2022},
	keywords = {Collaboration, Collaborative work, Deep Learning, Denial-of-service attack, Distributed Denial of Service (DDoS), Federated Learning, Industries, Internet of Things, Internet of Things (IoT), Privacy, Security, Servers},
	pages = {1--10},
}

@article{rahman_icn-iot_2023,
	title = {On the {ICN}-{IoT} with federated learning integration of communication: {Concepts}, security-privacy issues, applications, and future perspectives},
	volume = {138},
	issn = {0167-739X},
	shorttitle = {On the {ICN}-{IoT} with federated learning integration of communication},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X22002667},
	doi = {10.1016/j.future.2022.08.004},
	abstract = {The individual and integration use of the Internet of Things (IoT), Information-Centric Networking (ICN), and Federated Learning (FL) have recently been used in several network-related scenarios and have consequently experienced a growing interest in the research community. Federated learning addresses the privacy and security issues of the IoT data in a decentralized manner. Also, it can be capable of training the multiple learning algorithms through local content except for exchanging data through intelligent Artificial Intelligence (AI)-based algorithms. Moreover, in ICN, the content is retrieved and stored based on the content name rather than the content location address. On the other hand, it is challenging to support the massive IoT devices by the fifth generation (5G) mobile-cellular networks. Therefore, the cellular 6G networks are expected to increase the connection capabilities by 10–100 times over 5G, which necessitates a convergence of Communication, Computing, and Caching (3C). At the same time, the in-network caching capabilities of ICN can be attractive features for IoT networks. IoT aspires to link anybody and/or everything at any time and location. However, integrating IoT with different areas is a new academic topic and is still in its infancy. As a result, this research highlights the potential of ICN for IoTs by conducting an exhaustive literature review. This work provides a comprehensive survey regarding these three recent research trends (i.e., FL, IoT, and ICN) and reviews the related state-of-the-art literature. We first describe the main features of each technology and discuss their most common and used variants. Furthermore, we envision the integration of such technologies to take advantage efficiently. Indeed, we consider their group-wise (FL-ICN-IoT) utilization based on the need for more robust security and privacy. Additionally, we cover the application fields of these technologies both individually and combinedly. Finally, we discuss the open issues of the reviewed research and describe potential directions for future avenues regarding integrating IoT, ICN, and FL technologies.},
	urldate = {2024-04-12},
	journal = {Future Generation Computer Systems},
	author = {Rahman, Anichur and Hasan, Kamrul and Kundu, Dipanjali and Islam, Md. Jahidul and Debnath, Tanoy and Band, Shahab S. and Kumar, Neeraj},
	month = jan,
	year = {2023},
	keywords = {Artificial Intelligence, Communication, Computing, Confidentiality, Federated Learning, Information-Centric Networking, Internet of Things, Machine Learning, Privacy, Security},
	pages = {61--88},
}

@inproceedings{hbaieb_federated_2022,
	address = {New York, NY, USA},
	series = {{ARES} '22},
	title = {Federated learning based {IDS} approach for the {IoV}},
	isbn = {978-1-4503-9670-7},
	url = {https://dl.acm.org/doi/10.1145/3538969.3544422},
	doi = {10.1145/3538969.3544422},
	abstract = {The Internet of Vehicles (IoV) is an Internet of Things (IoT) application that offers several utilities such as traffic analysis, safe driving, road optimization, and travel comfort. Software-Defined Networking (SDN) technology has been shown to provide various benefits to support the IoV. However, the construction of IoV makes it a complex system posing several challenges among which the important ones are security and privacy of data. Intrusion Detection Systems (IDSs) have been proposed in the IoV to identify cyber attacks and protect private data. Recently work has started to implement IDSs based on Federated learning as collaborative IDSs have proved effective security of IoV. In another hand, trust management has revolutionized the IoV filed, providing decision-making support to secure the network. Stating that an SDN-driven IoV architecture in which nodes trustworthiness gets assessed can provide a promising framework for IDS, we propose in this paper a Federated learning-based IDS for the IoV under the SDN structure. We integrate trust metrics to assist in securing the IoV network. Simulation experiments are conducted to validate the proposal.},
	urldate = {2024-04-12},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Availability}, {Reliability} and {Security}},
	publisher = {Association for Computing Machinery},
	author = {Hbaieb, Amal and Ayed, Samiha and Chaari, Lamia},
	year = {2022},
	keywords = {Federated learning, IDS, IoV, SDN, Trust management, VANET, Vehicular networks},
	pages = {1--6},
}

@article{abdel-basset_privacy-preserved_2022,
	title = {Privacy-{Preserved} {Cyberattack} {Detection} in {Industrial} {Edge} of {Things} ({IEoT}): {A} {Blockchain}-{Orchestrated} {Federated} {Learning} {Approach}},
	volume = {18},
	issn = {1941-0050},
	shorttitle = {Privacy-{Preserved} {Cyberattack} {Detection} in {Industrial} {Edge} of {Things} ({IEoT})},
	url = {https://ieeexplore.ieee.org/abstract/document/9760107},
	doi = {10.1109/TII.2022.3167663},
	abstract = {The Industrial Internet ofThings (IIoT) plays an essential role in the digital renovation of conventional industries to Industry 4.0. With the connectivity of sensors, actuators, appliances, and other industrial objects, IIoT enables data availability, improved analytics, and automatic control. Thanks to the complex distributed nature, a wide range of stealthy and evolving cyberattacks become a major threat to the trustworthiness and security of IIoT systems. This makes the standard security procedures unable to assure the trustworthiness of IIoT that protect against cyberattacks. As a remedy, this article presents a blockchain-orchestrated edge intelligence (BoEI) framework that integrates an innovative decentralized federated learning (called Fed-Trust) for cyberattack detection in IIoT. In the Fed-Trust, a temporal convolutional generative network is introduced to enable semi-supervised learning from semi-labeled data. BoEI includes reputation-based blockchain to enable decentralized recording and verification of the transactions for guaranteeing the security and privacy of data and gradients. Fog computing is exploited to offload the block mining operation from the edge side thereby improving the overall computation and communication performance of Fed-Trust. Proof of concept simulations using two public datasets validate the robustness and efficiency of the Fed-Trust over the cutting-edge cyberattack detection approaches.},
	number = {11},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Abdel-Basset, Mohamed and Moustafa, Nour and Hawash, Hossam},
	month = nov,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Industrial Informatics},
	keywords = {Blockchains, Cyberattack detection, Data models, Industrial Internet of Things, Privacy, Security, Servers, Training, federated learning (FL), industrial Internet of Things (IIoT), privacy, security, semi-supervised generative adversarial network (GAN), trustworthiness},
	pages = {7920--7934},
}

@article{zhang_secfednids_2022,
	title = {{SecFedNIDS}: {Robust} defense for poisoning attack against federated learning-based network intrusion detection system},
	volume = {134},
	issn = {0167-739X},
	shorttitle = {{SecFedNIDS}},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X22001339},
	doi = {10.1016/j.future.2022.04.010},
	abstract = {Federated learning-based network intrusion detection system (FL-based NIDS) has demonstrated tremendous potential in protecting the security of IoT network. It enables learning an effective intrusion detection model from massive traffic data collaboratively without data privacy leakage. However, FL-based NIDS has exhibited inherent vulnerabilities on the poisoning attacks launched by malicious clients. The poisoning attacks aim to corrupt the intrusion detection model and impair its protection capability, by injecting the poisoned traffic data into the local training dataset. We build a secure FL-based NIDS that is robust for the poisoning attacks, namely SecFedNIDS. Firstly, we propose the model-level defensive mechanism based on poisoned model detection. Specifically, we propose the gradient-based important model parameter selection method to provide the effective low-dimensional representations of the uploaded local model parameters, and then we propose the online unsupervised poisoned model detection method to identify the poisoned models and reject them to join in the global intrusion detection model. Subsequently, we design the data-level defensive mechanism based on poisoned data detection. Notably, we propose a novel poisoned data detection method based on class path similarity, to filter out the poisoned traffic data and avoid them participating in subsequent local training. We adopt layer-wise relevance propagation to extract the class path of clean traffic data, and transmit the class paths to the poisoned clients to help distinguish the poisoned traffic data. Results show that SecFedNIDS with the proposed model-level defense boosts the accuracy by up to 48\% under the poisoning attacks on UNSW-NB15 dataset and 36\% on CICIDS2018 dataset, and the proposed data-level defense further improves its accuracy by up to 13\% on CICIDS2018 dataset.},
	urldate = {2024-04-12},
	journal = {Future Generation Computer Systems},
	author = {Zhang, Zhao and Zhang, Yong and Guo, Da and Yao, Lei and Li, Zhao},
	month = sep,
	year = {2022},
	keywords = {Defensive mechanism, Federated learning, Network intrusion detection, Poisoned data detection, Poisoned model detection, Poisoning attacks},
	pages = {154--169},
}

@article{driss_federated_2022,
	title = {A federated learning framework for cyberattack detection in vehicular sensor networks},
	volume = {8},
	issn = {2198-6053},
	url = {https://doi.org/10.1007/s40747-022-00705-w},
	doi = {10.1007/s40747-022-00705-w},
	abstract = {Vehicular Sensor Networks (VSN) introduced a new paradigm for modern transportation systems by improving traffic management and comfort. However, the increasing adoption of smart sensing technologies with the Internet of Things (IoT) made VSN a high-value target for cybercriminals. In recent years, Machine Learning (ML) and Deep Learning (DL) techniques attracted the research community to develop security solutions for IoT networks. Traditional ML and DL approaches that operate with data stored on a centralized server raise major privacy problems for user data. On the other hand, the resource-constrained nature of a smart sensing network demands lightweight security solutions. To address these issues, this article proposes a Federated Learning (FL)-based attack detection framework for VSN. The proposed scheme utilizes a group of Gated Recurrent Units (GRU) with a Random Forest (RF)-based ensembler unit. The effectiveness of the suggested framework is investigated through multiple performance metrics. Experimental findings indicate that the proposed FL approach successfully detected the cyberattacks in VSN with the highest accuracy of 99.52\%. The other performance scores, precision, recall, and F1 are attained as 99.77\%, 99.54\%, and 99.65\%, respectively.},
	language = {en},
	number = {5},
	urldate = {2024-04-12},
	journal = {Complex \& Intelligent Systems},
	author = {Driss, Maha and Almomani, Iman and e Huma, Zil and Ahmad, Jawad},
	month = oct,
	year = {2022},
	keywords = {Cybersecurity, Internet of things, Intrusion detection, Vehicular sensor networks},
	pages = {4221--4235},
}

@article{truong_light-weight_2022,
	title = {Light-weight federated learning-based anomaly detection for time-series data in industrial control systems},
	volume = {140},
	issn = {0166-3615},
	url = {https://www.sciencedirect.com/science/article/pii/S0166361522000896},
	doi = {10.1016/j.compind.2022.103692},
	abstract = {With the emergence of the Industrial Internet of Things (IIoT), potential threats to smart manufacturing systems are increasingly becoming challenging, causing severe damage to production operations and vital industrial assets, even sensitive information. Hence, detecting irregularities for time-series data in industrial control systems that should operate continually is critical, ensuring security and minimizing maintenance costs. In this study, with the hybrid design of Federated learning, Autoencoder, Transformer, and Fourier mixing sublayer, we propose a robust distributed anomaly detection architecture that works more accurately than several most recent anomaly detection solutions within the ICS contexts, whilst being fast learning in minute time scale. This distributed architecture is also proven to achieve lightweight, consume little CPU and memory usage, have low communication costs in terms of bandwidth consumption, which makes it feasible to be deployed on top of edge devices with limited computing capacity.},
	urldate = {2024-04-12},
	journal = {Computers in Industry},
	author = {Truong, Huong Thu and Ta, Bac Phuong and Le, Quang Anh and Nguyen, Dan Minh and Le, Cong Thanh and Nguyen, Hoang Xuan and Do, Ha Thu and Nguyen, Hung Tai and Tran, Kim Phuc},
	month = sep,
	year = {2022},
	keywords = {Anomaly detection, Autoencoder, Federated learning, Fourier, ICS, Transformer},
	pages = {103692},
}

@article{pourahmadi_spotting_2023,
	title = {Spotting {Anomalies} at the {Edge}: {Outlier} {Exposure}-{Based} {Cross}-{Silo} {Federated} {Learning} for {DDoS} {Detection}},
	volume = {20},
	issn = {1941-0018},
	shorttitle = {Spotting {Anomalies} at the {Edge}},
	url = {https://ieeexplore.ieee.org/document/9964111},
	doi = {10.1109/TDSC.2022.3224896},
	abstract = {Distributed Denial-of-Service (DDoS) attacks are expected to continue plaguing service availability in emerging networks which rely on distributed edge clouds to offer critical, latency-sensitive applications. However, edge servers increase the network attack surface, which is exacerbated with the massive number of connected Internet of Things (IoT) devices that can be weaponized to launch DDoS attacks. Therefore, it is crucial to detect DDoS attacks early, i.e., at the network edge. In this paper, we empower the network edge with intelligent DDoS detection by learning from similarities between different data and DDoS attacks available across the edge servers. To this end, we develop a novel Outlier Exposure (OE)-enabled cross-silo Federated Learning framework, namely FedOE. FedOE enables distributed training of OE-based ML models using a limited number of labeled outliers (i.e., attack flows) experienced at edge servers. We propose a novel OE-based Autoencoder (oAE) that can better discriminate anomalies in comparison to the widely adopted traditional Autoencoder, using a tailored, OE-based loss function. We evaluate oAE in FedOE and demonstrate its ability to generalize to zero-day attacks, with just 50 labeled attack flows per edge server. The results show that oAE achieves a high F1-score for most DDoS attacks, outclassing its non-OE counterpart.},
	number = {5},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Dependable and Secure Computing},
	author = {Pourahmadi, Vahid and Alameddine, Hyame Assem and Salahuddin, Mohammad Ali and Boutaba, Raouf},
	month = sep,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Dependable and Secure Computing},
	keywords = {Anomaly detection, Computer crime, DDoS detection, Data models, Denial-of-service attack, Edge intelligence, Image edge detection, Servers, Training, anomaly detection, federated learning, outlier exposure},
	pages = {4002--4015},
}

@inproceedings{wijethilaka_federated_2022,
	title = {A {Federated} {Learning} {Approach} for {Improving} {Security} in {Network} {Slicing}},
	url = {https://ieeexplore.ieee.org/document/10001190},
	doi = {10.1109/GLOBECOM48099.2022.10001190},
	abstract = {Network Slicing (NS) is a predominant technology in future telecommunication networks, including Fifth Generation (5G), which supports the realization of heterogeneous applications and services. It allows the allocation of a dedicated logical network slice of the physical network to each application. Security is one of the paramount challenges in an NS ecosystem. Several technologies, including Machine Learning (ML), have been proposed to mitigate security challenges in 5G networks. However, the use of ML for NS security is not properly implemented. Especially, the scarcity of coordination and the difficulties of privacy-protected information sharing between slices cause failures and performance degradation of these ML based NS security solutions. To address this issue, this paper proposes a novel Federated Learning (FL) based coordinated security orchestration architecture named Federated Learning enabled Security Orchestrator (FLeSO) to centrally perform security operations in a slicing ecosystem while preserving the privacy of the data. In addition, the proposed FLeSO architecture enables features such as proactive security deployment and steady security level maintenance independent of the slicing strategy. The proposed architecture is implemented in a real-world slicing testbed, and a comprehensive set of experiments are performed to evaluate the effectiveness of the proposed FLeSO architecture. The test results illustrate the significant advantage of the proposed approach over the legacy system in terms of improving the security of an NS ecosystem.},
	urldate = {2024-04-12},
	booktitle = {{GLOBECOM} 2022 - 2022 {IEEE} {Global} {Communications} {Conference}},
	author = {Wijethilaka, Shalitha and Liyanage, Madhusanka},
	month = dec,
	year = {2022},
	keywords = {5G mobile communication, Deep Learning, Degradation, Ecosystems, Federated Learning, Federated learning, Information sharing, Maintenance engineering, Network Slicing, Network slicing, Security},
	pages = {915--920},
}

@inproceedings{ji_novel_2022,
	title = {A {Novel} {Method} of {Intrusion} {Detection} {Based} on {Federated} {Transfer} {Learning} and {Convolutional} {Neural} {Network}},
	volume = {10},
	url = {https://ieeexplore.ieee.org/abstract/document/9836871},
	doi = {10.1109/ITAIC54216.2022.9836871},
	abstract = {As a network security defense technology, intrusion detection system can effectively protect network security. At present, machine learning is widely used in intrusion detection and has achieved good application results. The detection methods based on traditional machine learning need enough available intrusion detection data samples, and the samples meet the conditions of independent and identically distributed. However, in reality, the intrusion detection data generated by a single institution is insufficient, and various institutions protect users' privacy and data security in the form of islands, which makes it difficult to maintain the same data distribution. In addition, there is the problem of data imbalance. To solve the above problems, this paper proposes a new intrusion detection method FTLCNN, which integrates federal transfer learning and convolutional neural network. FTLCNN constructs a transfer convolution neural network framework to solve the problems of sample scarcity, imbalance and probability adaptation; under the mechanism of federal learning, FTLCNN use the model to learn without sharing training data, protect data privacy and solve the problem of data island. The experimental on UNSW-NB15 shows that compared with the other four benchmark algorithms, FTLCNN has higher detection rate and lower false positive rate, and has significant advantages in solving the problem of scarcity and imbalance of in intrusion detection.},
	urldate = {2024-04-12},
	booktitle = {2022 {IEEE} 10th {Joint} {International} {Information} {Technology} and {Artificial} {Intelligence} {Conference} ({ITAIC})},
	author = {Ji, Xiang and Zhang, Hong and Ma, Xulun},
	month = jun,
	year = {2022},
	note = {ISSN: 2693-2865},
	keywords = {Convolutional neural network, Data privacy, Distributed databases, Federal transfer learning, Intrusion detection, Network security, Organizations, Training data, Transfer learning, Unbalanced data},
	pages = {338--343},
}

@article{aouedi_federated_2023,
	title = {Federated {Semisupervised} {Learning} for {Attack} {Detection} in {Industrial} {Internet} of {Things}},
	volume = {19},
	issn = {1941-0050},
	url = {https://ieeexplore.ieee.org/abstract/document/9729433},
	doi = {10.1109/TII.2022.3156642},
	abstract = {Security has become a critical issue for Industry4.0 due to different emerging cyber-security threats. Recently, many deep learning (DL) approaches have focused on intrusion detection. However, such approaches often require sending data to a central entity. This in turn raises concerns related to privacy, efficiency, and latency. Despite the huge amount of data generated by the Internet of Things (IoT) devices in Industry 4.0, it is difficult to get labeled data, because data labeling is costly and time-consuming. This poses many challenges for several DL approaches, which require labeled data. In order to deal with these issues, new approaches should be adopted. This article proposes a novel federated semisupervised learning scheme that takes advantage of both unlabeled and labeled data in a federated way. First, an autoencoder (AE) is trained on each device (using unlabeled local/private data) to learn the representative and low-dimensional features. Then, a cloud server aggregates these models into a global AE using federated learning (FL). Finally, the cloud server composes a supervised neural network, by adding fully connected layers (FCN) to the global encoder (the first part of the global AE) and trains the resulting model using publicly available labeled data. Extensive case studies on two real-world industrial datasets demonstrate that our model: (a) ensures that no local private data is exchanged; (b) detects attacks with high classification performance, (c) works even when only a few amounts of labeled data are available; and (d) haslow communication overhead.},
	number = {1},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Aouedi, Ons and Piamrat, Kandaraj and Muller, Guillaume and Singh, Kamal},
	month = jan,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Industrial Informatics},
	keywords = {Data models, Data privacy, Industrial Internet of Things, Intrusion detection, Radio frequency, Servers, Training, deep learning (DL), federated learning (FL), intrusion detection, machine learning, semisupervised learning},
	pages = {286--295},
}

@inproceedings{dagli_proposed_2021,
	title = {A {Proposed} {Solution} to {Build} a {Breast} {Cancer} {Detection} {Model} on {Confidential} {Patient} {Data} using {Federated} {Learning}},
	url = {https://ieeexplore.ieee.org/abstract/document/9672768},
	doi = {10.1109/IBSSC53889.2021.9672768},
	abstract = {Due to the increasing number of privacy breaches of personal data there is a need for the development of methods that function along with the intent of preserving user privacy. Keeping this in mind we have proposed an algorithm using a federated approach to predict whether or not a patient is suffering from breast cancer, using data from multiple hospitals. This approach ensures that the user data is protected. The federated approach provides the hospitals with a safe and secure way to train their models without having to send their data to a central server. We have compared our approach with the standard approach to evaluate the performance of the federated approach. We determined that the federated learning model was able to achieve an accuracy comparable with the conventional model. There are advantages as well as limitations of our approach, that have been discussed further. This paper discusses an overall idea of federated learning, the past works done in this field, and our approach to implement a solution.},
	urldate = {2024-04-12},
	booktitle = {2021 {IEEE} {Bombay} {Section} {Signature} {Conference} ({IBSSC})},
	author = {Dagli, Saloni and Dedhia, Kashvi and Sawant, Vinaya},
	month = nov,
	year = {2021},
	keywords = {Collaborative work, Data models, Hospitals, Prediction algorithms, Predictive models, Privacy breach, Training, breast cancer prediction, centralized learning, federated learning, healthcare, privacy},
	pages = {1--6},
}

@inproceedings{otoum_federated_2021,
	title = {Federated {Transfer} {Learning}-{Based} {IDS} for the {Internet} of {Medical} {Things} ({IoMT})},
	url = {https://ieeexplore.ieee.org/abstract/document/9682118},
	doi = {10.1109/GCWkshps52748.2021.9682118},
	abstract = {The Internet of Medical Things (IoMT) is a set of medical devices and applications that connect to healthcare systems through the Internet. Those devices are equipped with communication technologies that allow them to communicate with each other and the Internet. Reliance on the IoMT is increasing with the increase in epidemics and chronic diseases such as COVID-19 and diabetes; with the increase in the number of IoMT users and the need for electronic data sharing and virtual services, cyberattacks in the healthcare sector for accessing confidential patient data has been increasing in the recent years. The healthcare applications and their infrastructures have special requirements for handling sensitive users’ data and the need for high availability. Therefore, securing healthcare applications and data has attracted special attention from both industry and researchers. In this paper, we propose a Federated Transfer Learning-based Intrusion Detection System (IDS) to secure the patient’s healthcare-connected devices. The model uses Deep Neural Network (DNN) algorithm for training the network and transferring the knowledge from the connected edge models to build an aggregated global model and customizing it for each one of the connected edge devices without exposing data privacy. CICIDS2017 dataset has been used to evaluate the performance in terms of accuracy, detection rate, and average training time. In addition to preserving data privacy of edge devices and achieving better performance, our comparison indicates that the proposed model can be generalized better and learns incrementally compared to other baseline ML/DL algorithms used in the traditional centralized learning schemes.},
	urldate = {2024-04-12},
	booktitle = {2021 {IEEE} {Globecom} {Workshops} ({GC} {Wkshps})},
	author = {Otoum, Yazan and Wan, Yue and Nayak, Amiya},
	month = dec,
	year = {2021},
	keywords = {Data privacy, Deep learning, Federated Learning (FL), Image edge detection, Internet of Medical Things (IoMT), Intrusion Detection System (IDS), Medical devices, Neural networks, Performance evaluation, Training, Transfer Learning (TL)},
	pages = {1--6},
}

@article{otoum_feasibility_2023,
	title = {On the {Feasibility} of {Split} {Learning}, {Transfer} {Learning} and {Federated} {Learning} for {Preserving} {Security} in {ITS} {Systems}},
	volume = {24},
	issn = {1558-0016},
	url = {https://ieeexplore.ieee.org/abstract/document/9756883},
	doi = {10.1109/TITS.2022.3159092},
	abstract = {Due to the absence of distinct boundaries, wireless networks are vulnerable to a variety of intrusions. As the number of intruders has increased, the risks on critical infrastructures monitored by networked systems have also increased. Protecting shared information using effective and robust Intrusion Detection Systems (IDSs) remains a critical issue, especially with the growing implementation of vehicular networks. Building an IDS that detects threats efficiently with maximum accuracy and detection is a challenging undertaking. Machine Learning (ML) mechanisms have been successfully adopted in IDSs to detect a variety of network intruders. Split learning is considered one of the main developments in creating efficient ML approaches. In utilizing the Split Learning approach, an IDS is successful in performing at higher accuracy, and detection rate as well as a higher classification performance (Precision, Recall). In this work, a Split Learning-based IDS ( SplitLearn ) for Intelligent Transportation System (ITS) infrastructures has been proposed to address the potential security concerns. The proposed model has been evaluated and compared against other models (i.e., Federated Learning ( FedLearn ) and Transfer Learning ( TransLearn )-based solutions). With the highest accuracy and detection rates, the proposed model ( SplitLearn ) outperforms FedLearn and TransLearn by 2 to 5 \% respectively. We also see a decrease in power consumption when utilizing SplitLearn versus FedLearn .},
	number = {7},
	urldate = {2024-04-12},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Otoum, Safa and Guizani, Nadra and Mouftah, Hussein},
	month = jul,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Intelligent Transportation Systems},
	keywords = {Collaborative work, Federated learning, Industrial Internet of Things, Internet of Things (IoT), Medical services, Monitoring, Security, Task analysis, Transfer learning, split learning, transfer learning},
	pages = {7462--7470},
}

@article{alamleh_federated_2023,
	title = {Federated {Learning} for {IoMT} {Applications}: {A} {Standardization} and {Benchmarking} {Framework} of {Intrusion} {Detection} {Systems}},
	volume = {27},
	issn = {2168-2208},
	shorttitle = {Federated {Learning} for {IoMT} {Applications}},
	url = {https://ieeexplore.ieee.org/abstract/document/9756888},
	doi = {10.1109/JBHI.2022.3167256},
	abstract = {Efficient evaluation for machine learning (ML)-based intrusion detection systems (IDSs) for federated learning (FL) in the Internet of Medical Things (IoMTs) environment falls under the standardisation and multicriteria decision-making (MCDM) problems. Thus, this study is developing an MCDM framework for standardising and benchmarking the ML-based IDSs used in the FL architecture of IoMT applications. In the methodology, firstly, the evaluation criteria of ML-based IDSs are standardised using the fuzzy Delphi method (FDM). Secondly, the evaluation decision matrix (DM) is formulated based on the intersection of standardised evaluation criteria and a list of ML-based IDSs. Such formulation is achieved using a dataset with 125,973 records, and each record comprises 41 features. Thirdly, the integration of MCDM methods is formulated to determine the importance weights of the main and sub standardised security and performance criteria, followed by benchmarking and selecting the optimal ML-based IDSs. In this phase, the Borda voting method is used to unify the different ranks and perform a group benchmarking context. The following results are confirmed. (1) Using FDM, 17 out of 20 evaluation criteria (14 for security and 3 for performance) reach the consensus of experts. (2) The area under curve criterion has the lowest set of weights, whilst the CPU time criterion has the highest one. (3) VIKOR group ranking shows that the BayesNet is a best classifier, whilst SVM is the last choice. For evaluation, three assessments, namely, systematic ranking, computational cost and comparative analysis, are used.},
	number = {2},
	urldate = {2024-04-12},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Alamleh, Amneh and Albahri, O. S. and Zaidan, A. A. and Albahri, A. S. and Alamoodi, A. H. and Zaidan, B. B. and Qahtan, Sarah and Alsatar, H. A. and Al-Samarraay, Mohammed S. and Jasim, Ali Najm},
	month = feb,
	year = {2023},
	note = {Conference Name: IEEE Journal of Biomedical and Health Informatics},
	keywords = {Benchmark testing, Computational modeling, Data models, Data privacy, Intrusion detection systems, Security, Servers, Training, federate learning, internet of medical things, machine learning, multicriteria decision making},
	pages = {878--887},
}

@inproceedings{thi_federated_2022,
	title = {Federated {Learning}-{Based} {Cyber} {Threat} {Hunting} for {APT} {Attack} {Detection} in {SDN}-{Enabled} {Networks}},
	url = {https://ieeexplore.ieee.org/abstract/document/9931222},
	doi = {10.1109/ISCIT55906.2022.9931222},
	abstract = {Threat hunting is the action of seeking harmful actors lurking in the network or the system in the early stage with the assumption of attackers already broke the cy-ber defense solution. This defense solution requires collecting more knowledge inside and outside to search potential threats in each organization. To leverage the knowledge of multiple organizations and experts for cyber threat detection, there is a need for the collaboration without breaking data among data owners across the cybersecurity community. Meanwhile, Software Defined Networking (SDN) is the flexible and programmable network architecture, which enables network administrator to proactively enforce the security policy in the large-scale network. Obviously, it can help organizations to enforce dynamically threat hunting services. Thus, this work introduces a federated learning (FL) approach for cyber threat hunting in SDN-enabled networks to deploy a proactive APT attack detection and response by leveraging threat intelligence from collaborative parties. Our approach can enrich the outcome of machine learning (ML)-based or deep learning (DL)-based threat detectors in recognizing malicious indicators. The experimental results on NF-UQ-NIDS dataset and FedPlus model aggregation algorithm demonstrate the feasibility of FL-based cyber threat hunting with privacy preservation among data holders in SDN context.},
	urldate = {2024-04-12},
	booktitle = {2022 21st {International} {Symposium} on {Communications} and {Information} {Technologies} ({ISCIT})},
	author = {Thi, Huynh Thai and Hoang Son, Ngo Duc and Duy, Phan The and Pham, Van-Hau},
	month = sep,
	year = {2022},
	note = {ISSN: 2643-6175},
	keywords = {APT detection, Collaboration, Cyber threat hunting, Detectors, Machine learning algorithms, Organizations, Privacy, Protocols, Software Defined Networking, Training, cyberattack detection, federated learning},
	pages = {1--6},
}

@article{al-ameer_federated_2023,
	title = {Federated learning security mechanisms for protecting sensitive data},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by-sa/4.0},
	issn = {2302-9285, 2089-3191},
	url = {https://beei.org/index.php/EEI/article/view/4751},
	doi = {10.11591/eei.v12i4.4751},
	abstract = {One of the new trends in the field of artificial intelligence is federated learning (FL), which will have promising roles in many real-world applications due to the work characteristics of its architecture. The learning mechanism for this technique is based on making training in a distributed manner on the local data for each client using decentralized data, then collecting parameters for each local training and uploading it to the server, which in turn will send model updates to all clients to give the final learning result. To provide a broad study on FL from security and privacy aspects, this research paper introduces a general view of FL and its categories, most attacks that can befall it, the safety mechanisms used by existing works in attacks defense, enhancing the safety and privacy of FL whether in the transmission or collecting of data. Then, the usage of FL in network security by many research papers has been presented, and how good results were achieved, and finally a comparison has been made between these papers.},
	language = {en},
	number = {4},
	urldate = {2024-04-12},
	journal = {Bulletin of Electrical Engineering and Informatics},
	author = {Al-Ameer, Asraa A. Abd and Bhaya, Wesam Sameer},
	month = aug,
	year = {2023},
	pages = {2421--2427},
}

@article{verma_fldid_2022,
	title = {{FLDID}: {Federated} {Learning} {Enabled} {Deep} {Intrusion} {Detection} in {Smart} {Manufacturing} {Industries}},
	volume = {22},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	shorttitle = {{FLDID}},
	url = {https://www.mdpi.com/1424-8220/22/22/8974},
	doi = {10.3390/s22228974},
	abstract = {The rapid development in manufacturing industries due to the introduction of IIoT devices has led to the emergence of Industry 4.0 which results in an industry with intelligence, increased efﬁciency and reduction in the cost of manufacturing. However, the introduction of IIoT devices opens up the door for a variety of cyber threats in smart industries. The detection of cyber threats against such extensive, complex, and heterogeneous smart manufacturing industries is very challenging due to the lack of sufﬁcient attack traces. Therefore, in this work, a Federated Learning enabled Deep Intrusion Detection framework is proposed to detect cyber threats in smart manufacturing industries. The proposed FLDID framework allows multiple smart manufacturing industries to build a collaborative model to detect threats and overcome the limited attack example problem with individual industries. Moreover, to ensure the privacy of model gradients, Paillier-based encryption is used in communication between edge devices (representative of smart industries) and the server. The deep learning-based hybrid model, which consists of a Convolutional Neural Network, Long Short Term Memory, and Multi-Layer Perceptron is used in the intrusion detection model. An exhaustive set of experiments on the publically available dataset proves the effectiveness of the proposed framework for detecting cyber threats in smart industries over the state-of-the-art approaches.},
	language = {en},
	number = {22},
	urldate = {2024-04-12},
	journal = {Sensors},
	author = {Verma, Priyanka and Breslin, John G. and O’Shea, Donna},
	month = nov,
	year = {2022},
	pages = {8974},
}

@inproceedings{madala_federated_2022,
	title = {Federated {Learning} {Approach} for {Tracking} {Malicious} {Activities} in {Cyber}-{Physical} {Systems}},
	url = {https://ieeexplore.ieee.org/abstract/document/9936285},
	doi = {10.1109/ICECAA55415.2022.9936285},
	abstract = {The fast rise of the Internet and advanced technologies causes an increase in network traffic, making network infrastructure increasingly complicated and varied. Mobile phones, wearable gadgets, and driverless cars are all instances of dispersed networks that create massive amounts of data every day. The processing capability of these devices has also increased steadily, necessitating the need to transport data, store data locally, and direct network calculations to edge devices. Intrusion detection systems are essential in guaranteeing the safety and confidentiality of such equipment. Deep Learning (DL) combined Intrusion Detection Systems (IDS) have gained prominence due to their excellent categorization accuracy. However, the requirement to store and communicate data to a centralized server may jeopardize privacy and security concerns. Federated learning (FL), on the other hand, fits in nicely as private information decentralized learning approach that does not transport data but instead trains algorithms locally and sends the parameters to a centralized server. This work targets to offer an extensive overview of the FL in intrusion detection systems.},
	urldate = {2024-04-12},
	booktitle = {2022 {International} {Conference} on {Edge} {Computing} and {Applications} ({ICECAA})},
	author = {Madala, Chandu Jagan Sekhar and Yadav, G. Hemanth Kumar and Sivakumar, S. and Nithya, R. and M, Manjunatha K and Deivakani, M.},
	month = oct,
	year = {2022},
	keywords = {Computational modeling, Federated learning, Intrusion detection, Target tracking, Telecommunication traffic, Training, Training data, confidentiality, intrusion, learning, network evaluation},
	pages = {494--499},
}

@article{alam_fedsepsis_2023,
	title = {{FedSepsis}: {A} {Federated} {Multi}-{Modal} {Deep} {Learning}-{Based} {Internet} of {Medical} {Things} {Application} for {Early} {Detection} of {Sepsis} from {Electronic} {Health} {Records} {Using} {Raspberry} {Pi} and {Jetson} {Nano} {Devices}},
	volume = {23},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	shorttitle = {{FedSepsis}},
	url = {https://www.mdpi.com/1424-8220/23/2/970},
	doi = {10.3390/s23020970},
	abstract = {The concept of the Internet of Medical Things brings a promising option to utilize various electronic health records stored in different medical devices and servers to create practical but secure clinical decision support systems. To achieve such a system, we need to focus on several aspects, most notably the usability aspect of deploying it using low-end devices. This study introduces one such application, namely FedSepsis, for the early detection of sepsis using electronic health records. We incorporate several cutting-edge deep learning techniques for the prediction and natural-language processing tasks. We also explore the multimodality aspect for the better use of electronic health records. A secure distributed machine learning mechanism is essential to building such a practical internet of medical things application. To address this, we analyze two federated learning techniques. Moreover, we use two different kinds of low-computational edge devices, namely Raspberry Pi and Jetson Nano, to address the challenges of using such a system in a practical setting and report the comparisons. We report several critical system-level information about the devices, namely CPU utilization, disk utilization, process CPU threads in use, process memory in use (non-swap), process memory available (non-swap), system memory utilization, temperature, and network trafﬁc. We publish the prediction results with the evaluation metrics area under the receiver operating characteristic curve, the area under the precision–recall curve, and the earliness to predict sepsis in hours. Our results show that the performance is satisfactory, and with a moderate amount of devices, the federated learning setting results are similar to the single server-centric setting. Multimodality provides the best results compared to any single modality in the input features obtained from the electronic health records. Generative adversarial neural networks provide a clear superiority in handling the sparsity of electronic health records. Multimodality with the generative adversarial neural networks provides the best result: the area under the precision–recall curve is 96.55\%, the area under the receiver operating characteristic curve is 99.35\%, and earliness is 4.56 h. FedSepsis suggests that incorporating such a concept together with low-end computational devices could be beneﬁcial for all the medical sector stakeholders and should be explored further.},
	language = {en},
	number = {2},
	urldate = {2024-04-12},
	journal = {Sensors},
	author = {Alam, Mahbub Ul and Rahmani, Rahim},
	month = jan,
	year = {2023},
	pages = {970},
}

@article{gosselin_privacy_2022,
	title = {Privacy and {Security} in {Federated} {Learning}: {A} {Survey}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2076-3417},
	shorttitle = {Privacy and {Security} in {Federated} {Learning}},
	url = {https://www.mdpi.com/2076-3417/12/19/9901},
	doi = {10.3390/app12199901},
	abstract = {In recent years, privacy concerns have become a serious issue for companies wishing to protect economic models and comply with end-user expectations. In the same vein, some countries now impose, by law, constraints on data use and protection. Such context thus encourages machine learning to evolve from a centralized data and computation approach to decentralized approaches. Speciﬁcally, Federated Learning (FL) has been recently developed as a solution to improve privacy, relying on local data to train local models, which collaborate to update a global model that improves generalization behaviors. However, by deﬁnition, no computer system is entirely safe. Security issues, such as data poisoning and adversarial attack, can introduce bias in the model predictions. In addition, it has recently been shown that the reconstruction of private raw data is still possible. This paper presents a comprehensive study concerning various privacy and security issues related to federated learning. Then, we identify the state-of-the-art approaches that aim to counteract these problems. Findings from our study conﬁrm that the current major security threats are poisoning, backdoor, and Generative Adversarial Network (GAN)-based attacks, while inference-based attacks are the most critical to the privacy of FL. Finally, we identify ongoing research directions on the topic. This paper could be used as a reference to promote cybersecurity-related research on designing FL-based solutions for alleviating future challenges.},
	language = {en},
	number = {19},
	urldate = {2024-04-12},
	journal = {Applied Sciences},
	author = {Gosselin, Rémi and Vieu, Loïc and Loukil, Faiza and Benoit, Alexandre},
	month = oct,
	year = {2022},
	pages = {9901},
}

@article{arya_intruder_2023,
	title = {Intruder {Detection} in {VANET} {Data} {Streams} {Using} {Federated} {Learning} for {Smart} {City} {Environments}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/12/4/894},
	doi = {10.3390/electronics12040894},
	abstract = {Vehicular networks improve quality of life, security, and safety, making them crucial to smart city development. With the rapid advancement of intelligent vehicles, the conﬁdentiality and security concerns surrounding vehicular ad hoc networks (VANETs) have garnered considerable attention. VANETs are intrinsically more vulnerable to attacks than wired networks due to high mobility, common network medium, and lack of centrally managed security services. Intrusion detection (ID) servers are the ﬁrst protection layer against cyberattacks in this digital age. The most frequently used mechanism in a VANET is intrusion detection systems (IDSs), which rely on vehicle collaboration to identify attackers. Regrettably, existing cooperative IDSs get corrupted and cause the IDSs to operate abnormally. This article presents an approach to intrusion detection based on the distributed federated learning (FL) of heterogeneous neural networks for smart cities. It saves time and resources by using the most efﬁcient intruder detection approach. First, vehicles use a federated learning technique to develop local, deep learning-based IDS classiﬁers for VANET data streams. They then share their locally learned classiﬁers upon request, signiﬁcantly reducing communication overhead with neighboring vehicles. Then, an ensemble of federated heterogeneous neural networks is constructed for each vehicle, including locally and remotely trained classiﬁers. Finally, the global ensemble model is again shared with local devices for their updating. The effectiveness of the suggested method for intrusion detection in VANETs is evaluated using performance indicators such as attack detection rates, classiﬁcation accuracy, precision, recall, and F1 scores over a ToN-IoT data stream. The ID model shows 0.994 training and 0.981 testing accuracy.},
	language = {en},
	number = {4},
	urldate = {2024-04-12},
	journal = {Electronics},
	author = {Arya, Monika and Sastry, Hanumat and Dewangan, Bhupesh Kumar and Rahmani, Mohammad Khalid Imam and Bhatia, Surbhi and Muzaffar, Abdul Wahab and Bivi, Mariyam Aysha},
	month = feb,
	year = {2023},
	pages = {894},
}

@article{tabassum_fedgan-ids_2022,
	title = {{FEDGAN}-{IDS}: {Privacy}-preserving {IDS} using {GAN} and {Federated} {Learning}},
	volume = {192},
	issn = {0140-3664},
	shorttitle = {{FEDGAN}-{IDS}},
	url = {https://www.sciencedirect.com/science/article/pii/S0140366422002171},
	doi = {10.1016/j.comcom.2022.06.015},
	abstract = {Federated Learning (FL) is a promising distributed training model that aims to minimize the data sharing to enhance privacy and performance. FL requires sufficient and diverse training data to build efficient models. Lack of data balance as seen in rare classes affects the model accuracy. Generative Adversarial Networks (GAN) are remarkable in data augmentation to balance the available training data. In this article, we propose a novel Federated Deep Learning (DL) Intrusion Detection System (IDS) using GAN, named FEDGAN-IDS, to detect cyber threats in smart Internet of Things (IoT) systems; smarthomes, smart e-healthcare systems and smart cities. We distribute the GAN network over IoT devices to act as a classifier and train using augmented local data. We compare the convergence and accuracy of our model with other federated intrusion detection models. Extensive experiments with multiple datasets demonstrates the effectiveness of the proposed FEDGAN-IDS. The model performs better and converges earlier than the state-of-the-art standalone IDS.},
	urldate = {2024-04-12},
	journal = {Computer Communications},
	author = {Tabassum, Aliya and Erbad, Aiman and Lebda, Wadha and Mohamed, Amr and Guizani, Mohsen},
	month = aug,
	year = {2022},
	keywords = {Deep Learning (DL), Federated Learning (FL), Generative Adversarial Network (GAN), Internet of Things (IoT), Intrusion Detection System (IDS)},
	pages = {299--310},
}

@article{li_blockchain_2022,
	title = {Blockchain {Empowered} {Federated} {Learning} for {Distributed} {Network} {Security} {Behaviour} {Knowledge} {Base} in {6G}},
	volume = {2022},
	issn = {1939-0114},
	url = {https://www.hindawi.com/journals/scn/2022/4233238/},
	doi = {10.1155/2022/4233238},
	abstract = {The malicious flow originating from massive access devices in 6G network will increase sharply. In order to effectively reduce malicious flow, we hope to establish a new framework for coordination of security monitoring and malicious behaviour control in 6G network. Federated learning provides data and privacy protection for the distributed network security behaviour knowledge base. However, since the equipment of its participants needs to upload the original data to the central server for model training, this may lead to data leakage in the knowledge base. Therefore, in this article, we first use the knowledge graph to describe network security behaviours, then build a universal network security malicious behaviour knowledge base, and discuss its application scenarios. Then, we propose a blockchain empowered federated learning (BeFL) for distributed network security malicious behaviour knowledge base architecture to ensure the security of knowledge transmission. Finally, we deployed the designed distributed knowledge base in the prototype system and compared it with the other two baseline methods to verify the performance. Relevant results show that our method outperforms other methods in terms of user identification, flow detection, and attack source tracing.},
	language = {en},
	urldate = {2024-04-12},
	journal = {Security and Communication Networks},
	author = {Li, Kun and Zhou, Huachun and Tu, Zhe and Liu, Feiyang and Zhang, Hongke},
	month = apr,
	year = {2022},
	note = {Publisher: Hindawi},
	pages = {e4233238},
}

@article{alves_selection_nodate,
	title = {Sélection de mesures de similarité pour les données catégorielles},
	language = {fr},
	author = {Alves, Guilherme and Couceiro, Miguel and Napoli, Amedeo},
}

@article{raynaut_dissimilarites_2017,
	title = {Dissimilarités entre jeux de données},
	volume = {22},
	issn = {16331311},
	url = {https://isi.revuesonline.com/article.jsp?articleId=38718},
	doi = {10.3166/isi.22.3.35-63},
	abstract = {Characterizing datasets has long been an important issue for algorithm selection and meta-level learning. Most approaches share a potential weakness in the aggregation of informations about individual features of the datasets. We propose a dissimilarity based approach avoiding this particular issue, and show the benefits it can yield in characterizing the appropriateness of classification algorithms, and in the context of meta-level classification. MOTS-CLÉS : caractérisation de jeux de données, dissimilarité, méta-attributs, sélection d’algorithmes, méta-apprentissage.},
	language = {fr},
	number = {3},
	urldate = {2024-04-04},
	journal = {Ingénierie des systèmes d'information},
	author = {Raynaut, William and Soule-Dupuy, Chantal and Valles-Parlangeau, Nathalie},
	month = mar,
	year = {2017},
	pages = {35--63},
}

@article{hu_contribution-_2022,
	title = {Contribution- and {Participation}-based {Federated} {Learning} on non-{IID} {Data}},
	issn = {1541-1672, 1941-1294},
	url = {https://ieeexplore.ieee.org/document/9760086/},
	doi = {10.1109/MIS.2022.3168298},
	abstract = {The learning process takes place inside clients in federated learning (FL). How to effectively motivate clients and avoid the impact of statistical heterogeneity are challenges in FL. This paper proposes contribution- and participationbased federated learning (CPFL) to address these challenges. CPFL can effectively allocate client incentives and aggregate models according to client contribution ratios, by which it can reduce the impact of heterogeneous data. To get effective and approximately fair client contributions faster, we propose an extended Raiffa solution (ERS). Compared to the conventional solution Shapley Value, the time complexity of ERS goes from O(2n) down to O(n). We perform extensive experiments with the MNIST/EMNIST datasets, heterogeneous datasets, and with different ratios of participation reward. Experimental results demonstrate that CPFL generally has a better learning effect in the heterogeneous case.},
	language = {en},
	urldate = {2022-07-05},
	journal = {IEEE Intelligent Systems},
	author = {Hu, Fei and Zhou, Wuneng and Liao, Kaili and Li, Hongliang},
	year = {2022},
	pages = {1--1},
}

@article{cho_communication-efficient_2023,
	title = {Communication-{Efficient} and {Model}-{Heterogeneous} {Personalized} {Federated} {Learning} via {Clustered} {Knowledge} {Transfer}},
	issn = {1941-0484},
	doi = {10.1109/JSTSP.2022.3231527},
	abstract = {Personalized federated learning (PFL) aims to train model(s) that can perform well on the individual edge-devices' data where the edge-devices (clients) are usually IoT devices like our mobile phones. The participating clients for cross-device settings, in general, have heterogeneous system capabilities and limited communication bandwidth. Such practical properties of the edge-devices, however, are overlooked by many recent work in PFL, which use the same model architecture across all clients and incur high communication cost by directly communicating the model parameters. In our work, we propose a novel and practical PFL framework named COMET where clients can use heterogeneous models of their own choice and do not directly communicate their model parameters to other parties. Instead, COMET uses clustered codistillation, where clients use knowledge distillation to transfer their knowledge to other clients with similar data distributions. This presents a practical PFL framework for the edge-devices to train through IoT networks by lifting the heavy communication burden of communicating large models. We theoretically show the convergence and generalization properties of COMET and empirically show that COMET achieves high test accuracy with several orders of magnitude lower communication cost while allowing client model heterogeneity compared to the other state-of-the-art PFL methods.},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Cho, Yae Jee and Wang, Jianyu and Chirvolu, Tarun and Joshi, Gauri},
	year = {2023},
	note = {Conference Name: IEEE Journal of Selected Topics in Signal Processing},
	keywords = {Clustering, Comets, Communication Efficiency, Correlation, Costs, Data models, Federated Learning, Federated learning, Knowledge Transfer, Model Heterogeneity, Servers, Task analysis, Training, clustering, communication efficiency, knowledge transfer, model heterogeneity},
	pages = {1--14},
}

@inproceedings{yin_byzantine-robust_2018,
	title = {Byzantine-{Robust} {Distributed} {Learning}: {Towards} {Optimal} {Statistical} {Rates}},
	shorttitle = {Byzantine-{Robust} {Distributed} {Learning}},
	url = {https://proceedings.mlr.press/v80/yin18a.html},
	abstract = {In this paper, we develop distributed optimization algorithms that are provably robust against Byzantine failures—arbitrary and potentially adversarial behavior, in distributed computing systems, with a focus on achieving optimal statistical performance. A main result of this work is a sharp analysis of two robust distributed gradient descent algorithms based on median and trimmed mean operations, respectively. We prove statistical error rates for all of strongly convex, non-strongly convex, and smooth non-convex population loss functions. In particular, these algorithms are shown to achieve order-optimal statistical error rates for strongly convex losses. To achieve better communication efficiency, we further propose a median-based distributed algorithm that is provably robust, and uses only one communication round. For strongly convex quadratic loss, we show that this algorithm achieves the same optimal error rate as the robust distributed gradient descent algorithms.},
	language = {en},
	urldate = {2023-03-07},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Yin, Dong and Chen, Yudong and Kannan, Ramchandran and Bartlett, Peter},
	month = jul,
	year = {2018},
	note = {ISSN: 2640-3498},
	pages = {5650--5659},
}

@inproceedings{shen_auror_2016,
	address = {New York, NY, USA},
	title = {Auror: defending against poisoning attacks in collaborative deep learning systems},
	isbn = {978-1-4503-4771-6},
	url = {https://dl.acm.org/doi/10.1145/2991079.2991125},
	doi = {10.1145/2991079.2991125},
	booktitle = {Proceedings of the 32nd {Annual} {Conference} on {Computer} {Security} {Applications}},
	publisher = {ACM},
	author = {Shen, Shiqi and Tople, Shruti and Saxena, Prateek},
	month = dec,
	year = {2016},
	keywords = {obsidian},
	pages = {508--519},
}

@misc{dunnett_trusted_2022,
	title = {A {Trusted}, {Verifiable} and {Differential} {Cyber} {Threat} {Intelligence} {Sharing} {Framework} using {Blockchain}},
	url = {http://arxiv.org/abs/2208.12031},
	abstract = {Cyber Threat Intelligence (CTI) is the knowledge of cyber and physical threats that help mitigate potential cyber attacks. The rapid evolution of the current threat landscape has seen many organisations share CTI to strengthen their security posture for mutual beneﬁt. However, in many cases, CTI data contains attributes (e.g., software versions) that have the potential to leak sensitive information or cause reputational damage to the sharing organisation. While current approaches allow restricting CTI sharing to trusted organisations, they lack solutions where the shared data can be veriﬁed and disseminated ‘differentially’ (i.e., selective information sharing) with policies and metrics ﬂexibly deﬁned by an organisation. In this paper, we propose a blockchain-based CTI sharing framework that allows organisations to share sensitive CTI data in a trusted, veriﬁable and differential manner. We discuss the limitations associated with existing approaches and highlight the advantages of the proposed CTI sharing framework. We further present a detailed proof of concept using the Ethereum blockchain network. Our experimental results show that the proposed framework can facilitate the exchange of CTI without creating signiﬁcant additional overheads.},
	language = {en},
	urldate = {2022-08-30},
	publisher = {arXiv},
	author = {Dunnett, Kealan and Pal, Shantanu and Putra, Guntur Dharma and Jadidi, Zahra and Jurdak, Raja},
	month = aug,
	year = {2022},
	note = {arXiv:2208.12031 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Distributed, Parallel, and Cluster Computing},
}

@article{skopik_problem_2016,
	title = {A problem shared is a problem halved: {A} survey on the dimensions of collective cyber defense through security information sharing},
	volume = {60},
	issn = {01674048},
	doi = {10.1016/j.cose.2016.04.003},
	abstract = {The Internet threat landscape is fundamentally changing. A major shift away from hobby hacking toward well-organized cyber crime can be observed. These attacks are typically carried out for commercial reasons in a sophisticated and targeted manner, and specifically in a way to circumvent common security measures. Additionally, networks have grown to a scale and complexity, and have reached a degree of interconnectedness, that their protection can often only be guaranteed and financed as shared efforts. Consequently, new paradigms are required for detecting contemporary attacks and mitigating their effects. Today, many attack detection tasks are performed within individual organizations, and there is little cross-organizational information sharing. However, information sharing is a crucial step to acquiring a thorough understanding of large-scale cyber-attack situations, and is therefore seen as one of the key concepts to protect future networks. Discovering covert cyber attacks and new malware, issuing early warnings, advice about how to secure networks, and selectively distribute threat intelligence data are just some of the many use cases. In this survey article we provide a structured overview about the dimensions of cyber security information sharing. First, we motivate the need in more detail and work out the requirements for an information sharing system. Second, we highlight legal aspects and efforts from standardization bodies such as ISO and the National Institute of Standards and Technology (NIST). Third, we survey implementations in terms of both organizational and technological matters. In this regard, we study the structures of Computer Emergency Response Teams (CERTs) and Computer Security Incident Response Teams (CSIRTs), and evaluate what we could learn from them in terms of applied processes, available protocols and implemented tools. We conclude with a critical review of the state of the art and highlight important considerations when building effective security information sharing platforms for the future.},
	journal = {Computers \& Security},
	author = {Skopik, Florian and Settanni, Giuseppe and Fiedler, Roman},
	year = {2016},
	note = {Publisher: Elsevier Ltd},
	pages = {154--176},
}

@inproceedings{ozkara_personalized_2023,
	address = {Taipei, Taiwan},
	title = {Personalized {PCA} for {Federated} {Heterogeneous} {Data}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66547-554-9},
	url = {https://ieeexplore.ieee.org/document/10206971/},
	doi = {10.1109/ISIT54713.2023.10206971},
	abstract = {As the high dimensional data generation/storage shifts from data centers to millions of edge devices, PCA algorithms also need to adapt to federated systems to reveal insights about the distributed data. One of the prominent challenges in Federated Learning (FL) is that each edge device has a limited number of samples, and therefore collaboration among clients is necessary for learning tasks. Another challenge is heterogeneous distribution of data across devices, which necessitates careful design of algorithms that enable collaboration of devices with different data distributions. While many such federated supervised learning algorithms were proposed in recent years, heterogeneity for unsupervised FL algorithms (such as PCA) has received less attention. In this work, our goal is to enable collaborations of heterogeneous clients in learning personalized Principal Components (PCs). To this end, we develop a hierarchical Bayesian framework for discovering individual PCs; and inspired by this, we formulate an optimization problem related to maximum likelihood estimation of the PCs. To solve the optimization problem, we propose an alternating Stiefel gradient descent algorithm. Analytically, we prove the convergence result for our proposed algorithm; and empirically, we show that our method outperforms local and global estimation of PCs in various heterogeneous settings in terms of the reconstruction error.},
	language = {en},
	urldate = {2024-04-02},
	booktitle = {2023 {IEEE} {International} {Symposium} on {Information} {Theory} ({ISIT})},
	publisher = {IEEE},
	author = {Ozkara, Kaan and Huang, Bruce and Diggavi, Suhas},
	month = jun,
	year = {2023},
	pages = {168--173},
}

@article{ozkara_personalized_2023-1,
	title = {Personalized {PCA} for {Federated} {Heterogeneous} {Data}},
	copyright = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10206971/},
	doi = {10.1109/ISIT54713.2023.10206971},
	abstract = {As the high dimensional data generation/storage shifts from data centers to millions of edge devices, PCA algorithms also need to adapt to federated systems to reveal insights about the distributed data. One of the prominent challenges in Federated Learning (FL) is that each edge device has a limited number of samples, and therefore collaboration among clients is necessary for learning tasks. Another challenge is heterogeneous distribution of data across devices, which necessitates careful design of algorithms that enable collaboration of devices with different data distributions. While many such federated supervised learning algorithms were proposed in recent years, heterogeneity for unsupervised FL algorithms (such as PCA) has received less attention. In this work, our goal is to enable collaborations of heterogeneous clients in learning personalized Principal Components (PCs). To this end, we develop a hierarchical Bayesian framework for discovering individual PCs; and inspired by this, we formulate an optimization problem related to maximum likelihood estimation of the PCs. To solve the optimization problem, we propose an alternating Stiefel gradient descent algorithm. Analytically, we prove the convergence result for our proposed algorithm; and empirically, we show that our method outperforms local and global estimation of PCs in various heterogeneous settings in terms of the reconstruction error.},
	urldate = {2024-04-02},
	journal = {2023 IEEE International Symposium on Information Theory (ISIT)},
	author = {Ozkara, Kaan and Huang, Bruce and Diggavi, Suhas},
	month = jun,
	year = {2023},
	note = {Conference Name: 2023 IEEE International Symposium on Information Theory (ISIT)
ISBN: 9781665475549
Place: Taipei, Taiwan
Publisher: IEEE},
	pages = {168--173},
}

@article{wang_rflbat_2022,
	title = {{RFLBAT}: {A} {Robust} {Federated} {Learning} {Algorithm} against {Backdoor} {Attack}},
	shorttitle = {{RFLBAT}},
	url = {https://www.semanticscholar.org/paper/e2b38f5d7218b00690201fc608d8f20b283d902f},
	abstract = {Federated learning (FL) is a distributed machine learning paradigm where enormous scattered clients (e.g. mobile devices or IoT devices) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. Unfortunately, FL is susceptible to a variety of attacks, including backdoor attack, which is made substantially worse in the presence of malicious attackers. Most of algorithms usually assume that the malicious at tackers no more than benign clients or the data distribution is independent identically distribution (IID). However, no one knows the number of malicious attackers and the data distribution is usually non identically distribution (Non-IID). In this paper, we propose RFLBAT which utilizes principal component analysis (PCA) technique and Kmeans clustering algorithm to defend against backdoor attack. Our algorithm RFLBAT does not bound the number of backdoored attackers and the data distribution, and requires no auxiliary information outside of the learning process. We conduct extensive experiments including a variety of backdoor attack types. Experimental results demonstrate that RFLBAT outperforms the existing state-of-the-art algorithms and is able to resist various backdoor attack scenarios including different number of attackers (DNA), different Non-IID scenarios (DNS), different number of clients (DNC) and distributed backdoor attack (DBA).},
	urldate = {2024-04-02},
	journal = {ArXiv},
	author = {Wang, Yongkang and Zhai, Dihua and Zhan, Yufeng and Xia, Yuanqing},
	month = jan,
	year = {2022},
}

@article{dong_momentum-based_2023,
	title = {A {Momentum}-{Based} {Wireless} {Federated} {Learning} {Acceleration} {With} {Distributed} {Principle} {Decomposition}},
	copyright = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10193196/},
	doi = {10.1109/ICASSPW59220.2023.10193196},
	abstract = {In the uplink period of wireless federated learning (WFL), multiple workers frequently upload uncoded training information to a server via orthogonal wireless channels. Due to the scarcity of wireless spectrum, the communication bottleneck appears during the uplink transmission. A one-shot distributed principle component analysis (PCA) method is leveraged to relieve the communication bottleneck by reducing the dimension of uploaded training information. Based on the low-dimensional training information, a Nesterov’s momentum accelerated WFL algorithm (i.e., PCA-AWFL) is proposed to reduce the communication rounds for the training of the federated learning system. For the non-convex loss functions, the finite-time convergence rate quantifies the impacts of system hyperparameters on the PCA-AWFL algorithm. Numerical results are used to demonstrate the performance improvement of the proposed PCA-AWFL algorithm over the benchmarks.},
	urldate = {2024-04-02},
	journal = {2023 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)},
	author = {Dong, Yanjie and Wang, Luya and Chi, Yuanfang and Hu, Xiping and Zhang, Haijun and Yu, Fei Richard and Leung, Victor C. M.},
	month = jun,
	year = {2023},
	note = {Conference Name: 2023 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)
ISBN: 9798350302615
Place: Rhodes Island, Greece
Publisher: IEEE},
	pages = {1--5},
}

@article{kazmi_threat_2023,
	title = {Threat {Intelligence} with {Non}-{IID} {Data} in {Federated} {Learning} enabled {Intrusion} {Detection} for {SDN}: {An} {Experimental} {Study}},
	copyright = {https://doi.org/10.15223/policy-029},
	shorttitle = {Threat {Intelligence} with {Non}-{IID} {Data} in {Federated} {Learning} enabled {Intrusion} {Detection} for {SDN}},
	url = {https://ieeexplore.ieee.org/document/10453867/},
	doi = {10.1109/ACIT58888.2023.10453867},
	abstract = {In the realm of cybersecurity, the ever-evolving threat landscape necessitates innovative approaches to design Intrusion Detection Systems (IDS). Software-Defined Networking (SDN) integrated with Deep Learning (DL) has emerged as a transformative paradigm of threat intelligence in IDS. However, centralized data processing in DL based IDS causes privacy issues. Within this context, Federated Learning (FL) has gained significant attention for its potential to enhance intrusion detection while maintaining privacy. This study presents an experimental investigation into the efficacy of FL-enabled intrusion detection in SDN environments, specifically addressing the challenging aspect of threat specific features selection in Non-IID (Non-Independently and Identically Distributed) data. We used the InSDN intrusion dataset containing different attacks including Denial-of-Service (DoS), Distributed-DoS (DDoS), brute force, probe, web and botnet attacks. After data pre-processing, Principal Component Analysis (PCA) is applied to analyze the impact of Non-IID data on features importance. The detailed results of simulations show large variations in features importance for Non-IID data in terms of quantity and threat type distribution. Furthermore, we discuss the implications of our results for future research directions.},
	urldate = {2024-04-02},
	journal = {2023 24th International Arab Conference on Information Technology (ACIT)},
	author = {Kazmi, Syed Hussain Ali and Qamar, Faizan and Hassan, Rosilah and Nisar, Kashif and Dahnil, Dahlila Putri Binti and Al-Betar, Mohammed Azmi},
	month = dec,
	year = {2023},
	note = {Conference Name: 2023 24th International Arab Conference on Information Technology (ACIT)
ISBN: 9798350384307
Place: Ajman, United Arab Emirates
Publisher: IEEE},
	pages = {1--6},
}

@article{liang_improved_2014,
	title = {Improved {Distributed} {Principal} {Component} {Analysis}},
	url = {https://www.semanticscholar.org/paper/525f6256d85d08dc3383d3c80030aa4b5bb12990},
	abstract = {We study the distributed computing setting in which there are multiple servers, each holding a set of points, who wish to compute functions on the union of their point sets. A key task in this setting is Principal Component Analysis (PCA), in which the servers would like to compute a low dimensional subspace capturing as much of the variance of the union of their point sets as possible. Given a procedure for approximate PCA, one can use it to approximately solve problems such as k-means clustering and low rank approximation. The essential properties of an approximate distributed PCA algorithm are its communication cost and computational efficiency for a given desired accuracy in downstream applications. We give new algorithms and analyses for distributed PCA which lead to improved communication and computational costs for k-means clustering and related problems. Our empirical study on real world data shows a speedup of orders of magnitude, preserving communication with only a negligible degradation in solution quality. Some of these techniques we develop, such as a general transformation from a constant success probability subspace embedding to a high success probability subspace embedding with a dimension and sparsity independent of the success probability, may be of independent interest.},
	urldate = {2024-04-02},
	journal = {ArXiv},
	author = {Liang, Yingyu and Balcan, Maria-Florina and Kanchanapally, Vandana and Woodruff, David P.},
	month = aug,
	year = {2014},
}

@article{dong_accelerating_2023,
	title = {Accelerating {Wireless} {Federated} {Learning} via {Nesterov}'s {Momentum} and {Distributed} {Principle} {Component} {Analysis}},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2303.17885},
	doi = {10.48550/ARXIV.2303.17885},
	abstract = {A wireless federated learning system is investigated by allowing a server and workers to exchange uncoded information via orthogonal wireless channels. Since the workers frequently upload local gradients to the server via bandwidth-limited channels, the uplink transmission from the workers to the server becomes a communication bottleneck. Therefore, a one-shot distributed principle component analysis (PCA) is leveraged to reduce the dimension of uploaded gradients such that the communication bottleneck is relieved. A PCA-based wireless federated learning (PCA-WFL) algorithm and its accelerated version (i.e., PCA-AWFL) are proposed based on the low-dimensional gradients and the Nesterov's momentum. For the non-convex loss functions, a finite-time analysis is performed to quantify the impacts of system hyper-parameters on the convergence of the PCA-WFL and PCA-AWFL algorithms. The PCA-AWFL algorithm is theoretically certified to converge faster than the PCA-WFL algorithm. Besides, the convergence rates of PCA-WFL and PCA-AWFL algorithms quantitatively reveal the linear speedup with respect to the number of workers over the vanilla gradient descent algorithm. Numerical results are used to demonstrate the improved convergence rates of the proposed PCA-WFL and PCA-AWFL algorithms over the benchmarks.},
	urldate = {2024-04-02},
	author = {Dong, Yanjie and Wang, Luya and Chi, Yuanfang and Wang, Jia and Zhang, Haijun and Yu, Fei Richard and Leung, Victor C. M. and Hu, Xiping},
	year = {2023},
	note = {Publisher: [object Object]
Version Number: 1},
	keywords = {FOS: Computer and information sciences, Information Theory (cs.IT), Machine Learning (cs.LG)},
}

@inproceedings{zang_traffic_2022,
	title = {Traffic {Flow} {Prediction} {Based} on {Federated} {Learning} with {Joint} {PCA} {Compression} and {Bayesian} {Optimization}},
	url = {https://ieeexplore.ieee.org/document/9945217},
	doi = {10.1109/SMC53654.2022.9945217},
	abstract = {Traffic flow prediction (TFP) is of great significance in the field of traffic congestion mitigation on the Internet of Vehicle(Iov). To be capable of a trade-off between data privacy protection and accurate prediction, we introduce a training paradigm based on Federated Learning (FL). However, the implementation of federal learning in practice is confronted with high communication and data heterogeneity. In this paper, Principal component analysis (PCA) is introduced to minimize the scale of data transmission on both the client and server. Due to the errors arising from the compression and reversion of the transmission model, we add an additional error term in the local objective function. To address the imbalanced data distribution and to accelerate the federal learning convergence, we then propose a mechanism that incorporates Bayesian optimization to dynamically determine the weights of clients during aggregation. With extensive experiments on real data, it can be demonstrated that communication costs can be minimized by 60-70\% while ensuring fewer errors.},
	urldate = {2024-04-02},
	booktitle = {2022 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})},
	author = {Zang, Lu and Qin, Yang and Li, Ruonan},
	month = oct,
	year = {2022},
	note = {ISSN: 2577-1655},
	keywords = {Bayes methods, Federated learning, Linear programming, Prediction algorithms, Privacy, Servers, Training, bayesian optimization, principal component analysis, traffic flow prediction},
	pages = {3330--3335},
}

@misc{noauthor_traffic_nodate,
	title = {Traffic {Flow} {Prediction} {Based} on {Federated} {Learning} with {Joint} {PCA} {Compression} and {Bayesian} {Optimization} {\textbar} {IEEE} {Conference} {Publication} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/document/9945217},
	urldate = {2024-04-02},
}

@inproceedings{zang_traffic_2022-1,
	title = {Traffic {Flow} {Prediction} {Based} on {Federated} {Learning} with {Joint} {PCA} {Compression} and {Bayesian} {Optimization}},
	url = {https://ieeexplore.ieee.org/document/9945217},
	doi = {10.1109/SMC53654.2022.9945217},
	abstract = {Traffic flow prediction (TFP) is of great significance in the field of traffic congestion mitigation on the Internet of Vehicle(Iov). To be capable of a trade-off between data privacy protection and accurate prediction, we introduce a training paradigm based on Federated Learning (FL). However, the implementation of federal learning in practice is confronted with high communication and data heterogeneity. In this paper, Principal component analysis (PCA) is introduced to minimize the scale of data transmission on both the client and server. Due to the errors arising from the compression and reversion of the transmission model, we add an additional error term in the local objective function. To address the imbalanced data distribution and to accelerate the federal learning convergence, we then propose a mechanism that incorporates Bayesian optimization to dynamically determine the weights of clients during aggregation. With extensive experiments on real data, it can be demonstrated that communication costs can be minimized by 60-70\% while ensuring fewer errors.},
	urldate = {2024-04-02},
	booktitle = {2022 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})},
	author = {Zang, Lu and Qin, Yang and Li, Ruonan},
	month = oct,
	year = {2022},
	note = {ISSN: 2577-1655},
	keywords = {Bayes methods, Federated learning, Linear programming, Prediction algorithms, Privacy, Servers, Training, bayesian optimization, principal component analysis, traffic flow prediction},
	pages = {3330--3335},
}

@article{zang_traffic_2022-2,
	title = {Traffic {Flow} {Prediction} {Based} on {Federated} {Learning} with {Joint} {PCA} {Compression} and {Bayesian} {Optimization}},
	copyright = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/9945217/},
	doi = {10.1109/SMC53654.2022.9945217},
	abstract = {Traffic flow prediction (TFP) is of great significance in the field of traffic congestion mitigation on the Internet of Vehicle(Iov). To be capable of a trade-off between data privacy protection and accurate prediction, we introduce a training paradigm based on Federated Learning (FL). However, the implementation of federal learning in practice is confronted with high communication and data heterogeneity. In this paper, Principal component analysis (PCA) is introduced to minimize the scale of data transmission on both the client and server. Due to the errors arising from the compression and reversion of the transmission model, we add an additional error term in the local objective function. To address the imbalanced data distribution and to accelerate the federal learning convergence, we then propose a mechanism that incorporates Bayesian optimization to dynamically determine the weights of clients during aggregation. With extensive experiments on real data, it can be demonstrated that communication costs can be minimized by 60-70\% while ensuring fewer errors.},
	urldate = {2024-04-02},
	journal = {2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
	author = {Zang, Lu and Qin, Yang and Li, Ruonan},
	month = oct,
	year = {2022},
	note = {Conference Name: 2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC)
ISBN: 9781665452588
Place: Prague, Czech Republic
Publisher: IEEE},
	pages = {3330--3335},
}

@inproceedings{zhou_modeling_2022,
	title = {Modeling {Adversarial} {Noise} for {Adversarial} {Training}},
	url = {https://proceedings.mlr.press/v162/zhou22k.html},
	abstract = {Deep neural networks have been demonstrated to be vulnerable to adversarial noise, promoting the development of defense against adversarial attacks. Motivated by the fact that adversarial noise contains well-generalizing features and that the relationship between adversarial data and natural data can help infer natural data and make reliable predictions, in this paper, we study to model adversarial noise by learning the transition relationship between adversarial labels (i.e. the flipped labels used to generate adversarial data) and natural labels (i.e. the ground truth labels of the natural data). Specifically, we introduce an instance-dependent transition matrix to relate adversarial labels and natural labels, which can be seamlessly embedded with the target model (enabling us to model stronger adaptive adversarial noise). Empirical evaluations demonstrate that our method could effectively improve adversarial accuracy.},
	language = {en},
	urldate = {2024-03-28},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Zhou, Dawei and Wang, Nannan and Han, Bo and Liu, Tongliang},
	month = jun,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {27353--27366},
}

@inproceedings{natarajan_learning_2013,
	title = {Learning with {Noisy} {Labels}},
	volume = {26},
	url = {https://proceedings.neurips.cc/paper_files/paper/2013/hash/3871bd64012152bfb53fdf04b401193f-Abstract.html},
	abstract = {In this paper, we theoretically study the problem of binary classification in the presence of random classification noise --- the learner, instead of seeing the true labels, sees labels that have independently been flipped with some small probability. Moreover, random label noise is {\textbackslash}emph\{class-conditional\} --- the flip probability depends on the class. We provide two approaches to suitably modify any given surrogate loss function. First, we provide a simple unbiased estimator of any loss, and obtain performance bounds for empirical risk minimization in the presence of iid data with noisy labels. If the loss function satisfies a simple symmetry condition, we show that the method leads to an efficient algorithm for empirical minimization. Second, by leveraging a reduction of risk minimization under noisy labels to classification with weighted 0-1 loss, we suggest the use of a simple weighted surrogate loss, for which we are able to obtain strong empirical risk bounds. This approach has a very remarkable consequence --- methods used in practice such as biased SVM and weighted logistic regression are provably noise-tolerant. On a synthetic non-separable dataset, our methods achieve over 88{\textbackslash}\% accuracy even when 40{\textbackslash}\% of the labels are corrupted, and are competitive with respect to recently proposed methods for dealing with label noise in several benchmark datasets.},
	urldate = {2024-03-28},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Natarajan, Nagarajan and Dhillon, Inderjit S and Ravikumar, Pradeep K and Tewari, Ambuj},
	year = {2013},
}

@inproceedings{aryal_analysis_2022,
	title = {Analysis of {Label}-{Flip} {Poisoning} {Attack} on {Machine} {Learning} {Based} {Malware} {Detector}},
	url = {https://ieeexplore.ieee.org/abstract/document/10020528},
	doi = {10.1109/BigData55660.2022.10020528},
	abstract = {With the increase in machine learning (ML) applications in different domains, incentives for deceiving these models have reached more than ever. As data is the core backbone of ML algorithms, attackers shifted their interest towards polluting the training data itself. Data credibility is at even higher risk with the rise of state-of-art research topics like open design principles, federated learning, and crowd-sourcing. Since the machine learning model depends on different stakeholders for obtaining data, there are no existing reliable automated mechanisms to verify the veracity of data from each source.Malware detection is arduous due to its malicious nature with the addition of metamorphic and polymorphic ability in the evolving samples. ML has proven to solve the zero-day malware detection problem, which is unresolved by traditional signature- based approaches. The poisoning of malware training data can allow the malware files to go undetected by the ML-based malware detectors, helping the attackers to fulfill their malicious goals. A feasibility analysis of the data poisoning threat in the malware detection domain is still lacking. Our work will focus on two major sections: training ML-based malware detectors and poisoning the training data using the label-poisoning approach. We will analyze the robustness of different machine learning models against data poisoning with varying volumes of poisoning data.},
	urldate = {2024-03-28},
	booktitle = {2022 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Aryal, Kshitiz and Gupta, Maanak and Abdelsalam, Mahmoud},
	month = dec,
	year = {2022},
	keywords = {Adversarial Malware Analysis, Big Data, Cybersecurity, Detectors, Federated learning, Machine Learning, Machine learning algorithms, Malware, Malware Detectors, Poisoning Attacks, Training, Training data},
	pages = {4236--4245},
}

@article{xu_rethinking_2023,
	title = {Rethinking {Label} {Flipping} {Attack}: {From} {Sample} {Masking} to {Sample} {Thresholding}},
	volume = {45},
	issn = {1939-3539},
	shorttitle = {Rethinking {Label} {Flipping} {Attack}},
	url = {https://ieeexplore.ieee.org/abstract/document/9944159},
	doi = {10.1109/TPAMI.2022.3220849},
	abstract = {Nowadays, machine learning (ML) and deep learning (DL) methods have become fundamental building blocks for a wide range of AI applications. The popularity of these methods also makes them widely exposed to malicious attacks, which may cause severe security concerns. To understand the security properties of the ML/DL methods, researchers have recently started to turn their focus to adversarial attack algorithms that could successfully corrupt the model or clean data owned by the victim with imperceptible perturbations. In this paper, we study the Label Flipping Attack (LFA) problem, where the attacker expects to corrupt an ML/DL model's performance by flipping a small fraction of the labels in the training data. Prior art along this direction adopts combinatorial optimization problems, leading to limited scalability toward deep learning models. To this end, we propose a novel minimax problem which provides an efficient reformulation of the sample selection process in LFA. In the new optimization problem, the sample selection operation could be implemented with a single thresholding parameter. This leads to a novel training algorithm called Sample Thresholding. Since the objective function is differentiable and the model complexity does not depend on the sample size, we can apply Sample Thresholding to attack deep learning models. Moreover, since the victim's behavior is not predictable in a poisonous attack setting, we have to employ surrogate models to simulate the true model employed by the victim model. Seeing the problem, we provide a theoretical analysis of such a surrogate paradigm. Specifically, we show that the performance gap between the true model employed by the victim and the surrogate model is small under mild conditions. On top of this paradigm, we extend Sample Thresholding to the crowdsourced ranking task, where labels collected from the annotators are vulnerable to adversarial attacks. Finally, experimental analyses on three real-world datasets speak to the efficacy of our method.},
	number = {6},
	urldate = {2024-03-28},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Xu, Qianqian and Yang, Zhiyong and Zhao, Yunrui and Cao, Xiaochun and Huang, Qingming},
	month = jun,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Data models, Deep learning, Label flipping attack, Optimization, Predictive models, Testing, Training, Training data, machine learning},
	pages = {7668--7685},
}

@inproceedings{arazo_unsupervised_2019,
	title = {Unsupervised {Label} {Noise} {Modeling} and {Loss} {Correction}},
	url = {https://proceedings.mlr.press/v97/arazo19a.html},
	abstract = {Despite being robust to small amounts of label noise, convolutional neural networks trained with stochastic gradient methods have been shown to easily fit random labels. When there are a mixture of correct and mislabelled targets, networks tend to fit the former before the latter. This suggests using a suitable two-component mixture model as an unsupervised generative model of sample loss values during training to allow online estimation of the probability that a sample is mislabelled. Specifically, we propose a beta mixture to estimate this probability and correct the loss by relying on the network prediction (the so-called bootstrapping loss). We further adapt mixup augmentation to drive our approach a step further. Experiments on CIFAR-10/100 and TinyImageNet demonstrate a robustness to label noise that substantially outperforms recent state-of-the-art. Source code is available at https://git.io/fjsvE and Appendix at https://arxiv.org/abs/1904.11238.},
	language = {en},
	urldate = {2024-03-28},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Arazo, Eric and Ortego, Diego and Albert, Paul and O’Connor, Noel and Mcguinness, Kevin},
	month = may,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {312--321},
}

@article{hao_inaccurate_2020,
	title = {Inaccurate {Labels} in {Weakly}-{Supervised} {Deep} {Learning}: {Automatic} {Identification} and {Correction} and {Their} {Impact} on {Classification} {Performance}},
	volume = {24},
	issn = {2168-2208},
	shorttitle = {Inaccurate {Labels} in {Weakly}-{Supervised} {Deep} {Learning}},
	url = {https://ieeexplore.ieee.org/abstract/document/9000595},
	doi = {10.1109/JBHI.2020.2974425},
	abstract = {In data-driven deep learning-based modeling, data quality may substantially influence classification performance. Correct data labeling for deep learning modeling is critical. In weakly-supervised learning, a challenge lies in dealing with potentially inaccurate or mislabeled training data. In this paper, we proposed an automated methodological framework to identify mislabeled data using two metric functions, namely, Cross-entropy Loss that indicates divergence between a prediction and ground truth, and Influence function that reflects the dependence of a model on data. After correcting the identified mislabels, we measured their impact on the classification performance. We also compared the mislabeling effects in three experiments on two different real-world clinical questions. A total of 10,500 images were studied in the contexts of clinical breast density category classification and breast cancer malignancy diagnosis. We used intentionally flipped labels as mislabels to evaluate the proposed method at a varying proportion of mislabeled data included in model training. We also compared the effects of our method to two published schemes for breast density category classification. Experiment results show that when the dataset contains 10\% of mislabeled data, our method can automatically identify up to 98\% of these mislabeled data by examining/checking the top 30\% of the full dataset. Furthermore, we show that correcting the identified mislabels leads to an improvement in the classification performance. Our method provides a feasible solution for weakly-supervised deep learning modeling in dealing with inaccurate labels.},
	number = {9},
	urldate = {2024-03-28},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Hao, Degan and Zhang, Lei and Sumkin, Jules and Mohamed, Aly and Wu, Shandong},
	month = sep,
	year = {2020},
	note = {Conference Name: IEEE Journal of Biomedical and Health Informatics},
	keywords = {Breast cancer, Data models, Deep learning, Imaging, Noise measurement, Training, inaccurate label, mammogram, metric function, weakly-supervised learning},
	pages = {2701--2710},
}

@article{zhang_iflipper_2023,
	title = {{iFlipper}: {Label} {Flipping} for {Individual} {Fairness}},
	volume = {1},
	shorttitle = {{iFlipper}},
	url = {https://dl.acm.org/doi/10.1145/3588688},
	doi = {10.1145/3588688},
	abstract = {As machine learning becomes prevalent, mitigating any unfairness present in the training data becomes critical. Among the various notions of fairness, this paper focuses on the well-known individual fairness, which states that similar individuals should be treated similarly. While individual fairness can be improved when training a model (in-processing), we contend that fixing the data before model training (pre-processing) is a more fundamental solution. In particular, we show that label flipping is an effective pre-processing technique for improving individual fairness. Our system iFlipper solves the optimization problem of minimally flipping labels given a limit to the individual fairness violations, where a violation occurs when two similar examples in the training data have different labels. We first prove that the problem is NP-hard. We then propose an approximate linear programming algorithm and provide theoretical guarantees on how close its result is to the optimal solution in terms of the number of label flips. We also propose techniques for making the linear programming solution more optimal without exceeding the violations limit. Experiments on real datasets show that iFlipper significantly outperforms other pre-processing baselines in terms of individual fairness and accuracy on unseen test sets. In addition, iFlipper can be combined with in-processing techniques for even better results.},
	number = {1},
	urldate = {2024-03-28},
	journal = {Proceedings of the ACM on Management of Data},
	author = {Zhang, Hantian and Tae, Ki Hyun and Park, Jaeyoung and Chu, Xu and Whang, Steven Euijong},
	year = {2023},
	keywords = {data labeling, data pre-processing, individual fairness},
	pages = {8:1--8:26},
}

@inproceedings{li_sample-level_2021,
	title = {Sample-level {Data} {Selection} for {Federated} {Learning}},
	url = {https://ieeexplore.ieee.org/abstract/document/9488723},
	doi = {10.1109/INFOCOM42981.2021.9488723},
	abstract = {Federated learning (FL) enables participants to collaboratively construct a global machine learning model without sharing their local training data to the remote server. In FL systems, the selection of training samples has a significant impact on model performances, e.g., selecting participants whose datasets have erroneous samples, skewed categorical distributions, and low content diversity would result in low accuracy and unstable models. In this work, we aim to solve the exigent optimization problem that selects a collection of high-quality training samples for a given FL task under a monetary budget in a privacy-preserving way, which is extremely challenging without visibility to participants’ local data and training process. We provide a systematic analysis of important data related factors affecting the model performance and propose a holistic design to privately and efficiently select high-quality data samples considering all these factors. We verify the merits of our proposed solution with extensive experiments on a real AIoT system with 50 clients, including 20 edge computers, 20 laptops, and 10 desktops. The experimental results validates that our solution achieves accurate and efficient selection of high-quality data samples, and consequently an FL model with a faster convergence speed and higher accuracy than that achieved by existing solutions.},
	urldate = {2024-03-27},
	booktitle = {{IEEE} {INFOCOM} 2021 - {IEEE} {Conference} on {Computer} {Communications}},
	author = {Li, Anran and Zhang, Lan and Tan, Juntao and Qin, Yaxuan and Wang, Junhao and Li, Xiang-Yang},
	month = may,
	year = {2021},
	note = {ISSN: 2641-9874},
	keywords = {Collaborative work, Computational modeling, Computers, Data privacy, Systematics, Training, Training data},
	pages = {1--10},
}

@inproceedings{jain_overview_2020,
	address = {New York, NY, USA},
	series = {{KDD} '20},
	title = {Overview and {Importance} of {Data} {Quality} for {Machine} {Learning} {Tasks}},
	isbn = {978-1-4503-7998-4},
	url = {https://dl.acm.org/doi/10.1145/3394486.3406477},
	doi = {10.1145/3394486.3406477},
	abstract = {It is well understood from literature that the performance of a machine learning (ML) model is upper bounded by the quality of the data. While researchers and practitioners have focused on improving the quality of models (such as neural architecture search and automated feature selection), there are limited efforts towards improving the data quality. One of the crucial requirements before consuming datasets for any application is to understand the dataset at hand and failure to do so can result in inaccurate analytics and unreliable decisions. Assessing the quality of the data across intelligently designed metrics and developing corresponding transformation operations to address the quality gaps helps to reduce the effort of a data scientist for iterative debugging of the ML pipeline to improve model performance. This tutorial highlights the importance of analysing data quality in terms of its value for machine learning applications. This tutorial surveys all the important data quality related approaches discussed in literature, focusing on the intuition behind them, highlighting their strengths and similarities, and illustrates their applicability to real-world problems. Finally we will discuss the interesting work IBM Research is doing in this space.},
	urldate = {2024-03-28},
	booktitle = {Proceedings of the 26th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Jain, Abhinav and Patel, Hima and Nagalapatti, Lokesh and Gupta, Nitin and Mehta, Sameep and Guttula, Shanmukha and Mujumdar, Shashank and Afzal, Shazia and Sharma Mittal, Ruhi and Munigala, Vitobha},
	year = {2020},
	keywords = {data quality, machine learning, quality metrics},
	pages = {3561--3562},
}

@article{deng_auction_2022,
	title = {{AUCTION}: {Automated} and {Quality}-{Aware} {Client} {Selection} {Framework} for {Efficient} {Federated} {Learning}},
	volume = {33},
	issn = {1558-2183},
	shorttitle = {{AUCTION}},
	url = {https://ieeexplore.ieee.org/abstract/document/9647925},
	doi = {10.1109/TPDS.2021.3134647},
	abstract = {The emergency of federated learning (FL) enables distributed data owners to collaboratively build a global model without sharing their raw data, which creates a new business chance for building data market. However, in practical FL scenarios, the hardware conditions and data resources of the participant clients can vary significantly, leading to different positive/negative effects on the FL performance, where the client selection problem becomes crucial. To this end, we propose AUCTION, an Automated and qUality-aware Client selecTION framework for efficient FL, which can evaluate the learning quality of clients and select them automatically with quality-awareness for a given FL task within a limited budget. To design AUCTION, multiple factors such as data size, data quality, and learning budget that can affect the learning performance should be properly balanced. It is nontrivial since their impacts on the FL model are intricate and unquantifiable. Therefore, AUCTION is designed to encode the client selection policy into a neural network and employ reinforcement learning to automatically learn client selection policies based on the observed client status and feedback rewards quantified by the federated learning performance. In particular, the policy network is built upon an encoder-decoder deep neural network with an attention mechanism, which can adapt to dynamic changes of the number of candidate clients and make sequential client selection actions to reduce the learning space significantly. Extensive experiments are carried out based on real-world datasets and well-known learning models to demonstrate the efficiency, robustness, and scalability of AUCTION.},
	number = {8},
	urldate = {2024-03-27},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Deng, Yongheng and Lyu, Feng and Ren, Ju and Wu, Huaqing and Zhou, Yuezhi and Zhang, Yaoxue and Shen, Xuemin},
	month = aug,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Parallel and Distributed Systems},
	keywords = {Collaborative work, Data integrity, Data models, Data privacy, Distributed databases, Federated learning, Task analysis, Training, client selection, data quality, distributed system, reinforcement learning},
	pages = {1996--2009},
}

@article{pejo_quality_2023,
	title = {Quality {Inference} in {Federated} {Learning} {With} {Secure} {Aggregation}},
	volume = {9},
	issn = {2332-7790},
	url = {https://ieeexplore.ieee.org/abstract/document/10138056},
	doi = {10.1109/TBDATA.2023.3280406},
	abstract = {Federated learning algorithms are developed both for efficiency reasons and to ensure the privacy and confidentiality of personal and business data, respectively. Despite no data being shared explicitly, recent studies showed that the mechanism could still leak sensitive information. Hence, secure aggregation is utilized in many real-world scenarios to prevent attribution to specific participants. In this paper, we focus on the quality (i.e., the ratio of correct labels) of individual training datasets and show that such quality information could be inferred and attributed to specific participants even when secure aggregation is applied. Specifically, through a series of image recognition experiments, we infer the relative quality ordering of participants. Moreover, we apply the inferred quality information to stabilize training performance, measure the individual contribution of participants, and detect misbehavior.},
	number = {5},
	urldate = {2024-03-27},
	journal = {IEEE Transactions on Big Data},
	author = {Pejó, Balázs and Biczók, Gergely},
	month = oct,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Big Data},
	keywords = {Big Data, Computational modeling, Correlation, Data integrity, Data models, Quality inference, Task analysis, Training, contribution score, federated learning, misbehavior detection, secure aggregation},
	pages = {1430--1437},
}

@inproceedings{deng_fair_2021,
	address = {Vancouver, BC, Canada},
	title = {{FAIR}: {Quality}-{Aware} {Federated} {Learning} with {Precise} {User} {Incentive} and {Model} {Aggregation}},
	isbn = {978-1-66540-325-2},
	shorttitle = {{FAIR}},
	url = {https://ieeexplore.ieee.org/document/9488743/},
	doi = {10.1109/INFOCOM42981.2021.9488743},
	abstract = {Federated learning enables distributed learning in a privacy-protected manner, but two challenging reasons can affect learning performance signiﬁcantly. First, mobile users are not willing to participate in learning due to computation and energy consumption. Second, with various factors (e.g., training data size/quality), the model update quality of mobile devices can vary dramatically, inclusively aggregating low-quality model updates can deteriorate the global model quality. In this paper, we propose a novel system named FAIR, i.e., Federated leArning with qualIty awaReness. FAIR integrates three major components: 1) learning quality estimation: we leverage historical learning records to estimate the user learning quality, where the record freshness is considered and the exponential forgetting function is utilized for weight assignment; 2) quality-aware incentive mechanism: within the recruiting budget, we model a reverse auction problem to encourage the participation of high-quality learning users, and the method is proved to be truthful, individually rational, and computationally efﬁcient; and 3) model aggregation: we devise an aggregation algorithm that integrates the model quality into aggregation and ﬁlters out non-ideal model updates, to further optimize the global learning model. Based on real-world datasets and practical learning tasks, extensive experiments are carried out to demonstrate the efﬁcacy of FAIR.},
	language = {en},
	urldate = {2024-03-27},
	booktitle = {{IEEE} {INFOCOM} 2021 - {IEEE} {Conference} on {Computer} {Communications}},
	publisher = {IEEE},
	author = {Deng, Yongheng and Lyu, Feng and Ren, Ju and Chen, Yi-Chao and Yang, Peng and Zhou, Yuezhi and Zhang, Yaoxue},
	month = may,
	year = {2021},
	pages = {1--10},
}

@article{zhang_feddqa_2024,
	title = {{FedDQA}: {A} novel regularization-based deep learning method for data quality assessment in federated learning},
	volume = {180},
	issn = {0167-9236},
	shorttitle = {{FedDQA}},
	url = {https://www.sciencedirect.com/science/article/pii/S0167923624000162},
	doi = {10.1016/j.dss.2024.114183},
	abstract = {Researchers strive to design artificial intelligence (AI) models that can fully utilize the potentials of data while protecting privacy. Federated learning is a promising solution because it utilizes data but shields them from those who do not own them. However, assessing data quality becomes a challenge in federated learning. We propose a data quality assessment method, Federated Data Quality Assessment (FedDQA), and compare it with traditional federated learning methods. FedDQA identifies low-quality data from participants and reduces their influence on the global model. We integrate data quality regularization strategies at the instance, feature, and participant levels into federate learning model. In various data poisoning settings, FedDQA outperforms existing federated learning methods in prediction performance and the accuracy in detecting low-quality data.},
	urldate = {2024-03-27},
	journal = {Decision Support Systems},
	author = {Zhang, Zongxiang and Chen, Gang and Xu, Yunjie and Huang, Lihua and Zhang, Chenghong and Xiao, Shuaiyong},
	month = may,
	year = {2024},
	keywords = {Data heterogeneity, Data quality, Federated learning, Regularization-based strategies},
	pages = {114183},
}

@article{jiang_data_2023,
	title = {Data {Quality} {Detection} {Mechanism} {Against} {Label} {Flipping} {Attacks} in {Federated} {Learning}},
	volume = {18},
	issn = {1556-6021},
	url = {https://ieeexplore.ieee.org/abstract/document/10054157},
	doi = {10.1109/TIFS.2023.3249568},
	abstract = {Federated learning (FL) is an emerging framework that enables massive clients (e.g., mobile devices or enterprises) to collaboratively construct a global model without sharing their local data. However, due to the lack of direct access to clients’ data, the global model is vulnerable to be attacked by malicious clients with their poisoned data. Many strategies have been proposed to mitigate the threat of label flipping attacks, but they either require considerable computational overhead, or lack robustness, and some even cause privacy concerns. In this paper, we propose Malicious Clients Detection Federated Learning (MCDFL) to defense against the label flipping attack. It can identify malicious clients by recovering a distribution over a latent feature space to detect the data quality of each client. We demonstrate the effectiveness of our proposed strategy on two benchmark datasets, i.e., CIFAR-10 and Fashion-MNIST, by considering different neural network models and different attack scenarios. The results show that, our solution is robust to detect malicious clients without excessive costs under various conditions, where the proportion of malicious clients is in the range of 5\% and 40\%.},
	urldate = {2024-03-27},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Jiang, Yifeng and Zhang, Weiwen and Chen, Yanxi},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Computational modeling, Data integrity, Data models, Data privacy, Federated learning, Servers, Training, Training data, data poisoning, deep learning, label flipping},
	pages = {1625--1637},
}

@article{webber_bi-symmetric_2012,
	title = {A bi-symmetric log transformation for wide-range data},
	volume = {24},
	issn = {0957-0233},
	url = {https://dx.doi.org/10.1088/0957-0233/24/2/027001},
	doi = {10.1088/0957-0233/24/2/027001},
	abstract = {The logarithmic transformation has long been used to present data that have both large and small components that are significant, such as neutron scattering data, or to present data that perhaps cover a wide range of time-scales, such as NMR relaxation data. A more general transformation, which is applicable to many different disciplines, is offered here, and is particularly suitable for representing wide-range data that have both positive and negative (or zero) components. The proposed transform smoothly modifies the gradient of the transformation so that in the region near zero it remains finite. A single constant is provided to tune this behavior, so as to adjust the meaning of ‘region near zero’. This modified logarithmic transformation can be one-sided or symmetric, and thus can transform negative data to scaled negative data. It can be applied to both the X and Y data, when it becomes a bi-symmetric log transform.},
	language = {en},
	number = {2},
	urldate = {2024-03-13},
	journal = {Measurement Science and Technology},
	author = {Webber, J. Beau W.},
	month = dec,
	year = {2012},
	note = {Publisher: IOP Publishing},
	pages = {027001},
}

@incollection{lamport_byzantine_1982,
	address = {New York, NY, USA},
	title = {The {Byzantine} generals problem},
	isbn = {978-1-4503-7270-1},
	url = {https://doi.org/10.1145/3335772.3335936},
	urldate = {2024-03-12},
	booktitle = {Concurrency: the {Works} of {Leslie} {Lamport}},
	publisher = {Association for Computing Machinery},
	author = {Lamport, Leslie and Shostak, Robert and Pease, Marshall},
	month = jul,
	year = {1982},
	keywords = {interactive consistency},
	pages = {203--226},
}

@phdthesis{li_enhancing_nodate,
	title = {Enhancing {Federated} {Learning} {Robustness} and {Fairness} in {Non}-{IID} {Scenarios}},
	language = {en},
	author = {Li, Yanli},
}

@inproceedings{tolpegin_data_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Data {Poisoning} {Attacks} {Against} {Federated} {Learning} {Systems}},
	isbn = {978-3-030-58951-6},
	doi = {10.1007/978-3-030-58951-6_24},
	abstract = {Federated learning (FL) is an emerging paradigm for distributed training of large-scale deep neural networks in which participants’ data remains on their own devices with only model updates being shared with a central server. However, the distributed nature of FL gives rise to new threats caused by potentially malicious participants. In this paper, we study targeted data poisoning attacks against FL systems in which a malicious subset of the participants aim to poison the global model by sending model updates derived from mislabeled data. We first demonstrate that such data poisoning attacks can cause substantial drops in classification accuracy and recall, even with a small percentage of malicious participants. We additionally show that the attacks can be targeted, i.e., they have a large negative impact only on classes that are under attack. We also study attack longevity in early/late round training, the impact of malicious participant availability, and the relationships between the two. Finally, we propose a defense strategy that can help identify malicious participants in FL to circumvent poisoning attacks, and demonstrate its effectiveness.},
	language = {en},
	booktitle = {Computer {Security} – {ESORICS} 2020},
	publisher = {Springer International Publishing},
	author = {Tolpegin, Vale and Truex, Stacey and Gursoy, Mehmet Emre and Liu, Ling},
	editor = {Chen, Liqun and Li, Ninghui and Liang, Kaitai and Schneider, Steve},
	year = {2020},
	keywords = {Adversarial machine learning, Data poisoning, Deep learning, Federated learning, Label flipping, obsidian},
	pages = {480--501},
}

@book{bureau_international_des_poids_et_mesures_international_2012,
	title = {International vocabulary of metrology: {Basic} and general concepts and associated terms ({VIM})},
	url = {https://www.bipm.org/en/committees/jc/jcgm/publications},
	author = {Bureau International des Poids et Mesures},
	year = {2012},
}

@inproceedings{fang_local_2020,
	title = {Local {Model} {Poisoning} {Attacks} to \{{Byzantine}-{Robust}\} {Federated} {Learning}},
	isbn = {978-1-939133-17-5},
	url = {https://www.usenix.org/conference/usenixsecurity20/presentation/fang},
	language = {en},
	urldate = {2024-03-06},
	author = {Fang, Minghong and Cao, Xiaoyu and Jia, Jinyuan and Gong, Neil},
	year = {2020},
	pages = {1605--1622},
}

@inproceedings{nguyen_flame_2022,
	title = {{FLAME}: {Taming} {Backdoors} in {Federated} {Learning}},
	isbn = {978-1-939133-31-1},
	shorttitle = {{FLAME}},
	url = {https://www.usenix.org/conference/usenixsecurity22/presentation/nguyen},
	language = {en},
	urldate = {2024-03-06},
	author = {Nguyen, Thien Duc and Rieger, Phillip and Chen, Huili and Yalame, Hossein and Möllering, Helen and Fereidooni, Hossein and Marchal, Samuel and Miettinen, Markus and Mirhoseini, Azalia and Zeitouni, Shaza and Koushanfar, Farinaz and Sadeghi, Ahmad-Reza and Schneider, Thomas},
	year = {2022},
	pages = {1415--1432},
}

@inproceedings{blanchard_machine_2017,
	title = {Machine {Learning} with {Adversaries}: {Byzantine} {Tolerant} {Gradient} {Descent}},
	volume = {30},
	shorttitle = {Machine {Learning} with {Adversaries}},
	url = {https://proceedings.neurips.cc/paper/2017/hash/f4b9ec30ad9f68f89b29639786cb62ef-Abstract.html},
	urldate = {2024-03-06},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Blanchard, Peva and El Mhamdi, El Mahdi and Guerraoui, Rachid and Stainer, Julien},
	year = {2017},
}

@incollection{enthoven_overview_2021,
	address = {Cham},
	series = {Studies in {Computational} {Intelligence}},
	title = {An {Overview} of {Federated} {Deep} {Learning} {Privacy} {Attacks} and {Defensive} {Strategies}},
	isbn = {978-3-030-70604-3},
	url = {https://doi.org/10.1007/978-3-030-70604-3_8},
	abstract = {With the increased attention and legislation for data-privacy, collaborative machine learning (ML) algorithms are being developed to ensure the protection of private data used for processing. Federated learning (FL) is the most popular of these methods, which provides privacy preservation by facilitating collaborative training of a shared model without the need to exchange any private data with a centralized server. Rather, an abstraction of the data in the form of a machine learning model update is sent. Recent studies showed that such model updates may still very well leak private information and thus a more structured risk assessment is needed. In this chapter, we analyze existing vulnerabilities of FL and subsequently perform a literature review of the possible attack methods targeting FL privacy protection capabilities. These attack methods are then categorized by a basic taxonomy. Additionally, we provide a literature study of the most recent defensive strategies and algorithms for FL aimed to overcome these attacks. These defensive strategies are categorized by their respective underlying defense principle. The chapter advocates that the application of a single defensive strategy is not enough to provide adequate protection against all available attack methods.},
	language = {en},
	urldate = {2024-03-06},
	booktitle = {Federated {Learning} {Systems}: {Towards} {Next}-{Generation} {AI}},
	publisher = {Springer International Publishing},
	author = {Enthoven, David and Al-Ars, Zaid},
	editor = {Rehman, Muhammad Habib ur and Gaber, Mohamed Medhat},
	year = {2021},
	doi = {10.1007/978-3-030-70604-3_8},
	pages = {173--196},
}

@article{kumar_fedclean_nodate,
	title = {{FEDCLEAN}: {A} {DEFENSE} {MECHANISM} {AGAINST} {PARAMETER} {POISONING} {ATTACKS} {IN} {FEDERATED} {LEARNING}},
	doi = {10.1109/ICASSP43922.2022.9747497},
	abstract = {In Federated learning (FL) systems, a centralized entity (server), instead of access to the training data, has access to model parameter updates computed by each participant independently and based solely on their samples. Unfortunately, FL is susceptible to model poisoning attacks, in which malicious or malfunctioning entities share polluted updates that can compromise the model’s accuracy. In this study, we propose FedClean, an FL mechanism that is robust to model poisoning attacks. The accuracy of the models trained with the assistance of FedClean is close to the one where malicious entities do not participate.},
	language = {en},
	author = {Kumar, Abhishek and Khimani, Vivek and Chatzopoulos, Dimitris and Hui, Pan},
	keywords = {agent selection, cosin similarity},
	pages = {5},
}

@misc{CSE-CIC-IDS-2018_url,
	title = {{IDS} 2018},
	url = {https://registry.opendata.aws/cse-cic-ids2018/},
	abstract = {A collaboration between CSE and CIC. The dataset includes 7 attack scenarios: Brute-force, Heartbleed, Botnet, DoS, DDoS, Web attacks and inside infiltration.},
	language = {en},
	urldate = {2023-03-22},
}

@misc{noauthor_technical_nodate,
	title = {Technical {Support} - {Clarivate} {Analytics}},
	url = {https://support.clarivate.com/ScientificandAcademicResearch/s/Product-or-technical-question?language=en_US},
	urldate = {2023-05-05},
}

@misc{ToN_IoT_url,
	title = {The {TON}\_IoT {Datasets}},
	url = {https://research.unsw.edu.au/projects/toniot-datasets},
	urldate = {2023-03-22},
}

@misc{UNSW-NB15_url,
	title = {The {UNSW}-{NB15} {Dataset}},
	url = {https://research.unsw.edu.au/projects/unsw-nb15-dataset},
	urldate = {2023-03-22},
}

@article{resnick_reputation_2000,
	title = {Reputation systems},
	volume = {43},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/355112.355122},
	doi = {10.1145/355112.355122},
	number = {12},
	urldate = {2023-02-01},
	journal = {Communications of the ACM},
	author = {Resnick, Paul and Kuwabara, Ko and Zeckhauser, Richard and Friedman, Eric},
	year = {2000},
	pages = {45--48},
}

@misc{Bot-IoT_url,
	title = {The {Bot}-{IoT} {Dataset}},
	url = {https://research.unsw.edu.au/projects/bot-iot-dataset},
	urldate = {2023-03-22},
}

@inproceedings{douceur_sybil_2002,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Sybil} {Attack}},
	isbn = {978-3-540-45748-0},
	doi = {10.1007/3-540-45748-8_24},
	abstract = {Large-scale peer-to-peer systems face security threats from faulty or hostile remote computing elements. To resist these threats, many such systems employ redundancy. However, if a single faulty entity can present multiple identities, it can control a substantial fraction of the system, thereby undermining this redundancy. One approach to preventing these “Sybil attacks” is to have a trusted agency certify identities. This paper shows that, without a logically centralized authority, Sybil attacks are always possible except under extreme and unrealistic assumptions of resource parity and coordination among entities.},
	language = {en},
	booktitle = {Peer-to-{Peer} {Systems}},
	publisher = {Springer},
	author = {Douceur, John R.},
	editor = {Druschel, Peter and Kaashoek, Frans and Rowstron, Antony},
	year = {2002},
	keywords = {Distinct Identity, Hash Function, Local Entity, Multiple Identity, Random Oracle},
	pages = {251--260},
}

@article{shafiq_selection_2020,
	title = {Selection of effective machine learning algorithm and {Bot}-{IoT} attacks traffic identification for internet of things in smart city},
	volume = {107},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X19334880},
	doi = {10.1016/j.future.2020.02.017},
	abstract = {Identifying cyber attacks traffic is very important for the Internet of things (IoT) security in smart city. Recently, the research community in the field of IoT Security endeavor hard to build anomaly, intrusion and cyber attacks traffic identification model using Machine Learning (ML) algorithms for IoT security analysis. However, the critical and significant problem still not studied in depth that is how to select an effective ML algorithm when there are numbers of ML algorithms for cyber attacks detection system for IoT security. In this paper, we proposed a new framework model and a hybrid algorithm to solve this problem. Firstly BoT-IoT identification dataset is applied and its 44 effective features are selected from a number of features for the machine learning algorithm. Then five effective machine learning algorithm is selected for the identification of malicious and anomaly traffic identification and also select the most widely ML algorithm performance evaluation metrics. To find out which ML algorithm is effective and should be used to select for IoT anomaly and intrusion traffic identification, a bijective soft set approach and its algorithm is applied. Then we applied the proposed algorithm based on bijective soft set approach. Our experimental results show that the proposed model with the algorithm is effective for the selection ML algorithm out of numbers of ML algorithms.},
	language = {en},
	urldate = {2023-03-22},
	journal = {Future Generation Computer Systems},
	author = {Shafiq, Muhammad and Tian, Zhihong and Sun, Yanbin and Du, Xiaojiang and Guizani, Mohsen},
	month = jun,
	year = {2020},
	keywords = {Bot-IoT attacks, Identification, IoT, Machine learning, Selection, Smart city},
	pages = {433--442},
}

@article{xiong_peertrust_2004,
	title = {{PeerTrust}: supporting reputation-based trust for peer-to-peer electronic communities},
	volume = {16},
	issn = {1558-2191},
	shorttitle = {{PeerTrust}},
	url = {https://ieeexplore.ieee.org/document/1318566},
	doi = {10.1109/TKDE.2004.1318566},
	abstract = {Peer-to-peer (P2P) online communities are commonly perceived as an environment offering both opportunities and threats. One way to minimize threats in such communities is to use community-based reputations to help estimate the trustworthiness of peers. We present PeerTrust - a reputation-based trust supporting framework, which includes a coherent adaptive trust model for quantifying and comparing the trustworthiness of peers based on a transaction-based feedback system, and a decentralized implementation of such a model over a structured P2P network. PeerTrust model has two main features. First, we introduce three basic trust parameters and two adaptive factors in computing trustworthiness of peers, namely, feedback a peer receives from other peers, the total number of transactions a peer performs, the credibility of the feedback sources, transaction context factor, and the community context factor. Second, we define a general trust metric to combine these parameters. Other contributions of the paper include strategies used for implementing the trust model in a decentralized P2P environment, evaluation mechanisms to validate the effectiveness and cost of PeerTrust model, and a set of experiments that show the feasibility and benefit of our approach.},
	number = {7},
	urldate = {2024-01-08},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Xiong, Li and Liu, Ling},
	month = jul,
	year = {2004},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	pages = {843--857},
}

@inproceedings{fung_trust_2008,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Trust {Management} for {Host}-{Based} {Collaborative} {Intrusion} {Detection}},
	isbn = {978-3-540-87353-2},
	doi = {10.1007/978-3-540-87353-2_9},
	abstract = {The accuracy of detecting an intrusion within a network of intrusion detection systems (IDSes) depends on the efficiency of collaboration between member IDSes. The security itself within this network is an additional concern that needs to be addressed. In this paper, we present a trust-based framework for secure and effective collaboration within an intrusion detection network (IDN). In particular, we define a trust model that allows each IDS to evaluate the trustworthiness of others based on personal experience. We prove the correctness of our approach in protecting the IDN. Additionally, experimental results demonstrate that our system yields a significant improvement in detecting intrusions. The trust model further improves the robustness of the collaborative system against malicious attacks.},
	language = {en},
	booktitle = {Managing {Large}-{Scale} {Service} {Deployment}},
	publisher = {Springer},
	author = {Fung, Carol J. and Baysal, Olga and Zhang, Jie and Aib, Issam and Boutaba, Raouf},
	editor = {De Turck, Filip and Kellerer, Wolfgang and Kormentzas, George},
	year = {2008},
	keywords = {Collaboration, Decay, Intrusion detection Network, Peer-to-Peer, Security, Trust Management},
	pages = {109--122},
}

@techreport{enisa_incentives_2010,
	title = {Incentives and {Challenges} for {Information} {Sharing} in the {Context} of {Network} and {Information} {Security}},
	url = {http://www.google.com/#sclient=psy&hl=en&safe=off&q=literature+review+information+sharing+law+enforcement&aq=f&aqi=&aql=&oq=&gs_rfai=&pbx=1&fp=9bef8cda26d1a6ec},
	abstract = {The importance of information sharing to ensuring network and information security is widely acknowledged by both policy-makers and by the technical and practitioner community – for example, in the European Programme on Critical Infrastructure Protection (EPCIP) and in the 2004 Availability and Robustness of Electronic Communications Infrastructures (ARECI) study, which noted that formal means for sharing information should be set up in order to ―improve the protection and rapid restoration of infrastructure critical to the reliability of communications within and throughout Europe‖. A 2009 gap analysis conducted by ENISA of good practice in respect of telecommunication network operators identified information sharing as a set of useful best practice. Given the acknowledged importance of information sharing, this report sets out findings from a research project into the barriers to and incentives for information sharing in the field of network and information security, in the context of peer-to-peer groups such as Information Exchanges (IE) and Information Sharing Analysis Centres (ISACs).{\textbackslash}nMethods and approach The information in this report is drawn from three sources: {\textbackslash}n A review of available literature – both academic and non-academic publications,  Interviews with key informants working in the field of network and information {\textbackslash}nsecurity and in IEs,  A two-round Delphi exercise with network and information security professionals. {\textbackslash}n The aim of this project is to identify those barriers and incentives which are most important in day-to-day practice in IEs and ISACs. This research differs from other work in this field in being firmly grounded in the experiences of practitioners and those involved in IE and Information Sharing activities. Nonetheless we only managed to speak to a limited number of experts from a handful of countries. Therefore, the findings of this research are a first step to developing an evidence base in this field, but we do not claim they are generalisable to all kinds of IEs. {\textbackslash}nIncentives and challenges for information sharing Our findings indicate that many of the barriers and incentives commonly identified in the {\textbackslash}navailable literature are of relatively low importance to practitioners and security officials currently working in IEs. As part of this research we asked practitioners to rank a list of barriers and incentives in terms of their relative importance. Our findings indicate that the incentives which are most important are: {\textbackslash}n Economic incentives stemming from cost savings;  Incentives stemming from the quality, value, and use of information shared. {\textbackslash}n While the barriers which are the most important are: {\textbackslash}n Poor quality information;  Misaligned economic incentives stemming from reputational risks;  Poor management.},
	author = {{ENISA}},
	year = {2010},
	note = {Volume: 10},
	pages = {52},
}

@article{fung_dirichlet-based_2011,
	title = {Dirichlet-{Based} {Trust} {Management} for {Effective} {Collaborative} {Intrusion} {Detection} {Networks}},
	volume = {8},
	issn = {1932-4537},
	doi = {10.1109/TNSM.2011.050311.100028},
	abstract = {The accuracy of detecting intrusions within a Collaborative Intrusion Detection Network (CIDN) depends on the efficiency of collaboration between peer Intrusion Detection Systems (IDSes) as well as the security itself of the CIDN. In this paper, we propose Dirichlet-based trust management to measure the level of trust among IDSes according to their mutual experience. An acquaintance management algorithm is also proposed to allow each IDS to manage its acquaintances according to their trustworthiness. Our approach achieves strong scalability properties and is robust against common insider threats, resulting in an effective CIDN. We evaluate our approach based on a simulated CIDN, demonstrating its improved robustness, efficiency and scalability for collaborative intrusion detection in comparison with other existing models.},
	number = {2},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Fung, Carol J and Zhang, Jie and Aib, Issam and Boutaba, Raouf},
	month = jun,
	year = {2011},
	note = {Conference Name: IEEE Transactions on Network and Service Management},
	keywords = {Collaboration, Collaborative intrusion detection system, Equations, Intrusion detection, Mathematical model, Peer to peer computing, Robustness, Scalability, admission control, computer security, security management, trust management},
	pages = {79--91},
}

@article{gil_perez_repcidn_2013,
	title = {{RepCIDN}: {A} {Reputation}-based {Collaborative} {Intrusion} {Detection} {Network} to {Lessen} the {Impact} of {Malicious} {Alarms}},
	volume = {21},
	issn = {1573-7705},
	shorttitle = {{RepCIDN}},
	url = {https://doi.org/10.1007/s10922-012-9230-8},
	doi = {10.1007/s10922-012-9230-8},
	abstract = {Distributed and coordinated attacks in computer networks are causing considerable economic losses worldwide in recent years. This is mainly due to the transition of attackers’ operational patterns towards a more sophisticated and more global behavior. This fact is leading current intrusion detection systems to be more likely to generate false alarms. In this context, this paper describes the design of a collaborative intrusion detection network (CIDN) that is capable of building and sharing collective knowledge about isolated alarms in order to efficiently and accurately detect distributed attacks. It has been also strengthened with a reputation mechanism aimed to improve the detection coverage by dropping false or bogus alarms that arise from malicious or misbehaving nodes. This model will enable a CIDN to detect malicious behaviors according to the trustworthiness of the alarm issuers, calculated from previous interactions with the system. Experimental results will finally demonstrate how entities are gradually isolated as their behavior worsens throughout the time.},
	language = {en},
	number = {1},
	urldate = {2022-07-07},
	journal = {Journal of Network and Systems Management},
	author = {Gil Pérez, Manuel and Gómez Mármol, Félix and Martínez Pérez, Gregorio and Skarmeta Gómez, Antonio F.},
	month = mar,
	year = {2013},
	keywords = {Collaboration networks, Group reputation, Intrusion detection systems, Reputation systems, Security, Trust management},
	pages = {128--167},
}

@article{Chismon2015,
	title = {Threat {Intelligence}: {Collecting}, {Analysing}, {Evaluating}},
	abstract = {Threat intelligence is rapidly becoming an ever-higher business priority. There is a general awareness of the need to ‘do’ threat intelligence, and vendors are falling over themselves to offer a confusingly diverse array of threat intelligence products. Figure},
	journal = {Cert-Uk},
	author = {Chismon, David and Ruks, Martyn},
	year = {2015},
	keywords = {⛔ No DOI found},
	pages = {36},
}

@article{fung_facid_2016,
	title = {{FACID}: {A} trust-based collaborative decision framework for intrusion detection networks},
	volume = {53},
	issn = {1570-8705},
	shorttitle = {{FACID}},
	url = {https://www.sciencedirect.com/science/article/pii/S1570870516302062},
	doi = {10.1016/j.adhoc.2016.08.014},
	abstract = {Computer systems evolve to be more complex and vulnerable. Cyber attacks have also grown to be more sophisticated and harder to detect. Intrusion detection is the process of monitoring and identifying unauthorized system access or manipulation. It becomes increasingly difficult for a single intrusion detection system (IDS) to detect all attacks due to limited knowledge about attacks. Collaboration among intrusion detection devices can be used to gain higher detection accuracy and cost efficiency as compared to its traditional single host-based counterpart. Through cooperation, a local IDS can detect new attacks that may be known to other IDSs, which may be from different vendors. However, how to utilize the diagnosis from different IDSs to perform intrusion detection is the key challenge. This paper proposes a system architecture of a collaborative intrusion detection network (CIDN), in which trustworthy and efficient feedback aggregation is a key component. To achieve a reliable and trustworthy CIDN, we present a framework called FACID, which leverages data analytical models and hypothesis testing methods for efficient, distributed and sequential feedback aggregations. FACID provides an inherent trust evaluation mechanism and reduces communication overhead needed for IDSs as well as the computational resources and memory needed to achieve satisfactory feedback aggregation results when the number of collaborators of an IDS is large. Our simulation results corroborate our theoretical results and demonstrate the properties of cost efficiency and accuracy compared to other heuristic methods. The analytical result on the lower-bound of the average number of acquaintances for consultation is essential for the design and configuration of IDSs in a collaborative environment.},
	language = {en},
	urldate = {2022-07-07},
	journal = {Ad Hoc Networks},
	author = {Fung, Carol J. and Zhu, Quanyan},
	month = dec,
	year = {2016},
	keywords = {Cooperative networks, Distributed algorithms, Intrusion detection networks, Resource allocations},
	pages = {17--31},
}

@misc{NIS2016,
	title = {Directive ({EU}) 2016/1148 of 6 {July} 2016 concerning measures for a high common level of security of network and information systems across the {Union}},
	url = {https://eur-lex.europa.eu/eli/dir/2016/1148/oj},
	abstract = {It proposes a wide-ranging set of measures to boost the level of security of network and information systems (cybersecurity*) to secure services vital to the EU economy and society. It aims to ensure that EU countries are well-prepared and are ready to handle and respond to cyberattacks through: the designation of competent authorities, the set-up of computer-security incident response teams (CSIRTs), and the adoption of national cybersecurity strategies. It also establishes EU-level cooperation both at strategic and technical level. Lastly, it introduces the obligation on essential-services providers and digital service providers to take the appropriate security measures and to notify the relevant national authorities about serious incidents.},
	author = {{The European Parliament and The Counsil}},
	year = {2016},
}

@inproceedings{fong_interpretable_2017,
	title = {Interpretable {Explanations} of {Black} {Boxes} by {Meaningful} {Perturbation}},
	url = {https://openaccess.thecvf.com/content_iccv_2017/html/Fong_Interpretable_Explanations_of_ICCV_2017_paper.html},
	urldate = {2023-03-11},
	author = {Fong, Ruth C. and Vedaldi, Andrea},
	year = {2017},
	pages = {3429--3437},
}

@article{blanchard_machine_2017-1,
	title = {Machine learning with adversaries: {Byzantine} tolerant gradient descent},
	volume = {30},
	shorttitle = {Machine learning with adversaries},
	journal = {Advances in Neural Information Processing Systems},
	author = {Blanchard, Peva and El Mhamdi, El Mahdi and Guerraoui, Rachid and Stainer, Julien},
	year = {2017},
	keywords = {⛔ No DOI found},
}

@inproceedings{lundberg_unified_2017,
	title = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html},
	abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
	urldate = {2023-03-11},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Lundberg, Scott M and Lee, Su-In},
	year = {2017},
	keywords = {⛔ No DOI found},
}

@inproceedings{vasilomanolakis_towards_2017,
	address = {Cham},
	series = {{IFIP} {Advances} in {Information} and {Communication} {Technology}},
	title = {Towards {Trust}-{Aware} {Collaborative} {Intrusion} {Detection}: {Challenges} and {Solutions}},
	isbn = {978-3-319-59171-1},
	shorttitle = {Towards {Trust}-{Aware} {Collaborative} {Intrusion} {Detection}},
	doi = {10.1007/978-3-319-59171-1_8},
	abstract = {Collaborative Intrusion Detection Systems (CIDSs) are an emerging field in cyber-security. In such an approach, multiple sensors collaborate by exchanging alert data with the goal of generating a complete picture of the monitored network. This can provide significant improvements in intrusion detection and especially in the identification of sophisticated attacks. However, the challenge of deciding to which extend a sensor can trust others, has not yet been holistically addressed in related work. In this paper, we firstly propose a set of requirements for reliable trust management in CIDSs. Afterwards, we carefully investigate the most dominant CIDS trust schemes. The main contribution of the paper is mapping the results of the analysis to the aforementioned requirements, along with a comparison of the state of the art. Furthermore, this paper identifies and discusses the research gaps and challenges with regard to trust and CIDSs.},
	language = {en},
	booktitle = {Trust {Management} {XI}},
	publisher = {Springer International Publishing},
	author = {Vasilomanolakis, Emmanouil and Habib, Sheikh Mahbub and Milaszewicz, Pavlos and Malik, Rabee Sohail and Mühlhäuser, Max},
	editor = {Steghöfer, Jan-Philipp and Esfandiari, Babak},
	year = {2017},
	keywords = {Computational Trust, Initial Trust, Intrusion Detection System, Trust Level, Trust Management, decay},
	pages = {94--109},
}

@inproceedings{alexopoulos_towards_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Towards {Blockchain}-{Based} {Collaborative} {Intrusion} {Detection} {Systems}},
	isbn = {978-3-319-99843-5},
	doi = {10.1007/978-3-319-99843-5_10},
	abstract = {In an attempt to cope with the increased number of cyber-attacks, research in Intrusion Detection System IDSs is moving towards more collaborative mechanisms. Collaborative IDSs (CIDSs) are such an approach; they combine the knowledge of a plethora of monitors to generate a holistic picture of the monitored network. Despite the research done in this field, CIDSs still face a number of fundamental challenges, especially regarding maintaining trust among the collaborating parties. Recent advances in distributed ledger technologies, e.g. various implementations of blockchain protocols, are a good fit to the problem of enhancing trust in collaborative environments. This paper touches the intersection of CIDSs and blockchains. Particularly, it introduces the idea of utilizing blockchain technologies as a mechanism for improving CIDSs. We argue that certain properties of blockchains can be of significant benefit for CIDSs; namely for the improvement of trust between monitors, and for providing accountability and consensus. For this, we study the related work and highlight the research gaps and challenges towards such a task. Finally, we propose a generic architecture for the incorporation of blockchains into the field of CIDSs and an analysis of the design decisions that need to be made to implement such an architecture.},
	language = {en},
	booktitle = {Critical {Information} {Infrastructures} {Security}},
	publisher = {Springer International Publishing},
	author = {Alexopoulos, Nikolaos and Vasilomanolakis, Emmanouil and Ivánkó, Natália Réka and Mühlhäuser, Max},
	editor = {D'Agostino, Gregorio and Scala, Antonio},
	year = {2018},
	pages = {107--118},
}

@article{cordero_sphinx_2018,
	title = {Sphinx: a {Colluder}-{Resistant} {Trust} {Mechanism} for {Collaborative} {Intrusion} {Detection}},
	volume = {6},
	issn = {2169-3536},
	shorttitle = {Sphinx},
	doi = {10.1109/ACCESS.2018.2880297},
	abstract = {The destructive effects of cyber-attacks demand more proactive security approaches. One such promising approach is the idea of collaborative intrusion detection systems (CIDSs). These systems combine the knowledge of multiple sensors (e.g., intrusion detection systems, honeypots, or firewalls) to create a holistic picture of a monitored network. Sensors monitor parts of a network and exchange alert data to learn from each other, improve their detection capabilities and ultimately identify sophisticated attacks. Nevertheless, if one or a group of sensors is unreliable (due to incompetence or malice), the system might miss important information needed to detect attacks. In this paper, we propose Sphinx, an evidence-based trust mechanism capable of detecting unreliable sensors within a CIDS. The Sphinx detects, both, single sensors or coalitions of dishonest sensors that lie about the reliability of others to boost or worsen their trust score. Our evaluation shows that, given an honest majority of sensors, dishonesty is punished in a timely manner. Moreover, if several coalitions exist, even when more than 50\% of all sensors are dishonest, dishonesty is punished.},
	journal = {IEEE Access},
	author = {Cordero, Carlos Garcia and Traverso, Giulia and Nojoumian, Mehrdad and Habib, Sheikh Mahbub and Mühlhäuser, Max and Buchmann, Johannes and Vasilomanolakis, Emmanouil},
	year = {2018},
	note = {Conference Name: IEEE Access},
	keywords = {Clustering, Collaboration, Electronic mail, Intrusion detection, Machine learning, Monitoring, Reliability, Sensors, collaborative intrusion detection, machine learning, mixture models, sensor reliability, trust management},
	pages = {72427--72438},
}

@inproceedings{sharafaldin_toward_2018,
	address = {Funchal, Madeira, Portugal},
	title = {Toward {Generating} a {New} {Intrusion} {Detection} {Dataset} and {Intrusion} {Traffic} {Characterization}},
	isbn = {978-989-758-282-0},
	shorttitle = {Toward {Generating} a {New} {Intrusion} {Detection} {Dataset} and {Intrusion} {Traffic} {Characterization}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006639801080116},
	doi = {10.5220/0006639801080116},
	abstract = {Intrusion Detection, IDS Dataset, DoS, Web Attack, Inﬁltration, Brute Force.},
	language = {en},
	urldate = {2023-03-22},
	booktitle = {Proceedings of the 4th {International} {Conference} on {Information} {Systems} {Security} and {Privacy}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Sharafaldin, Iman and Habibi Lashkari, Arash and Ghorbani, Ali A.},
	year = {2018},
	pages = {108--116},
}

@inproceedings{cao_understanding_2019,
	title = {Understanding {Distributed} {Poisoning} {Attack} in {Federated} {Learning}},
	doi = {10.1109/ICPADS47876.2019.00042},
	abstract = {Federated learning is inherently vulnerable to poisoning attacks, since no training samples will be released to and checked by trustworthy authority. Poisoning attacks are widely investigated in centralized learning paradigm, however distributed poisoning attacks, in which more than one attacker colludes with each other, and injects malicious training samples into local models of their own, may result in a greater catastrophe in federated learning intuitively. In this paper, through real implementation of a federated learning system and distributed poisoning attacks, we obtain several observations about the relations between the number of poisoned training samples, attackers, and attack success rate. Moreover, we propose a scheme, Sniper, to eliminate poisoned local models from malicious participants during training. Sniper identifies benign local models by solving a maximum clique problem, and suspected (poisoned) local models will be ignored during global model updating. Experimental results demonstrate the efficacy of Sniper. The attack success rates are reduced to around 2\% even a third of participants are attackers.},
	booktitle = {2019 {IEEE} 25th {International} {Conference} on {Parallel} and {Distributed} {Systems} ({ICPADS})},
	author = {Cao, Di and Chang, Shan and Lin, Zhijian and Liu, Guohua and Sun, Donghong},
	month = dec,
	year = {2019},
	note = {ISSN: 1521-9097},
	keywords = {federated learning, distributed poisoning attack, defense, attack success rate, label-flipping},
	pages = {233--239},
}

@inproceedings{jia_towards_2019,
	title = {Towards {Efficient} {Data} {Valuation} {Based} on the {Shapley} {Value}},
	url = {https://proceedings.mlr.press/v89/jia19a.html},
	abstract = {\{{\textbackslash}em “How much is my data worth?”\} is an increasingly common question posed by organizations and individuals alike. An answer to this question could allow, for instance, fairly distributing profits among multiple data contributors and determining prospective compensation when data breaches happen. In this paper, we study the problem of {\textbackslash}emph\{data valuation\} by utilizing the Shapley value, a popular notion of value which originated in coopoerative game theory. The Shapley value defines a unique payoff scheme that satisfies many desiderata for the notion of data value. However, the Shapley value often requires {\textbackslash}emph\{exponential\} time to compute. To meet this challenge, we propose a repertoire of efficient algorithms for approximating the Shapley value. We also demonstrate the value of each training instance for various benchmark datasets.},
	language = {en},
	urldate = {2022-08-25},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Jia, Ruoxi and Dao, David and Wang, Boxin and Hubis, Frances Ann and Hynes, Nick and Gürel, Nezihe Merve and Li, Bo and Zhang, Ce and Song, Dawn and Spanos, Costas J.},
	month = apr,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {1167--1176},
}

@article{Chaabouni2019,
	title = {Network {Intrusion} {Detection} for {IoT} {Security} {Based} on {Learning} {Techniques}},
	volume = {21},
	issn = {1553-877X},
	url = {https://ieeexplore.ieee.org/document/8629941/},
	doi = {10.1109/COMST.2019.2896380},
	abstract = {Pervasive growth of Internet of Things (IoT) is visible across the globe. The 2016 Dyn cyberattack exposed the critical fault-lines among smart networks. Security of IoT has become a critical concern. The danger exposed by infested Internet-connected Things not only affects the security of IoT but also threatens the complete Internet eco-system which can possibly exploit the vulnerable Things (smart devices) deployed as botnets. Mirai malware compromised the video surveillance devices and paralyzed Internet via distributed denial of service attacks. In the recent past, security attack vectors have evolved bothways, in terms of complexity and diversity. Hence, to identify and prevent or detect novel attacks, it is important to analyze techniques in IoT context. This survey classifies the IoT security threats and challenges for IoT networks by evaluating existing defense techniques. Our main focus is on network intrusion detection systems (NIDSs); hence, this paper reviews existing NIDS implementation tools and datasets as well as free and open-source network sniffing software. Then, it surveys, analyzes, and compares state-of-the-art NIDS proposals in the IoT context in terms of architecture, detection methodologies, validation strategies, treated threats, and algorithm deployments. The review deals with both traditional and machine learning (ML) NIDS techniques and discusses future directions. In this survey, our focus is on IoT NIDS deployed via ML since learning algorithms have a good success rate in security and privacy. The survey provides a comprehensive review of NIDSs deploying different aspects of learning techniques for IoT, unlike other top surveys targeting the traditional systems. We believe that, this paper will be useful for academia and industry research, first, to identify IoT threats and challenges, second, to implement their own NIDS and finally to propose new smart techniques in IoT context considering IoT limitations. Moreover, the survey will enable security individuals differentiate IoT NIDS from traditional ones.},
	number = {3},
	journal = {IEEE Communications Surveys \& Tutorials},
	author = {Chaabouni, Nadia and Mosbah, Mohamed and Zemmari, Akka and Sauvignac, Cyrille and Faruki, Parvez},
	year = {2019},
	note = {Publisher: IEEE},
	pages = {2671--2701},
}

@article{koroniotis_towards_2019,
	title = {Towards the development of realistic botnet dataset in the {Internet} of {Things} for network forensic analytics: {Bot}-{IoT} dataset},
	volume = {100},
	issn = {0167-739X},
	shorttitle = {Towards the development of realistic botnet dataset in the {Internet} of {Things} for network forensic analytics},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X18327687},
	doi = {10.1016/j.future.2019.05.041},
	abstract = {The proliferation of IoT systems, has seen them targeted by malicious third parties. To address this challenge, realistic protection and investigation countermeasures, such as network intrusion detection and network forensic systems, need to be effectively developed. For this purpose, a well-structured and representative dataset is paramount for training and validating the credibility of the systems. Although there are several network datasets, in most cases, not much information is given about the Botnet scenarios that were used. This paper proposes a new dataset, so-called Bot-IoT, which incorporates legitimate and simulated IoT network traffic, along with various types of attacks. We also present a realistic testbed environment for addressing the existing dataset drawbacks of capturing complete network information, accurate labeling, as well as recent and complex attack diversity. Finally, we evaluate the reliability of the BoT-IoT dataset using different statistical and machine learning methods for forensics purposes compared with the benchmark datasets. This work provides the baseline for allowing botnet identification across IoT-specific networks. The Bot-IoT dataset can be accessed at Bot-iot (2018) [1].},
	language = {en},
	urldate = {2023-03-22},
	journal = {Future Generation Computer Systems},
	author = {Koroniotis, Nickolaos and Moustafa, Nour and Sitnikova, Elena and Turnbull, Benjamin},
	month = nov,
	year = {2019},
	keywords = {Bot-IoT dataset, Forensics analytics, Network flow, Network forensics},
	pages = {779--796},
}

@inproceedings{rajput_detox_2019,
	title = {{DETOX}: {A} {Redundancy}-based {Framework} for {Faster} and {More} {Robust} {Gradient} {Aggregation}},
	volume = {32},
	shorttitle = {{DETOX}},
	url = {https://proceedings.neurips.cc/paper/2019/hash/415185ea244ea2b2bedeb0449b926802-Abstract.html},
	abstract = {To improve the resilience of distributed  training to worst-case, or Byzantine node failures, several recent methods have replaced gradient averaging with robust aggregation methods. Such techniques can have high computational costs, often quadratic in the number of compute nodes, and only have limited robustness guarantees. Other methods have instead used redundancy to guarantee robustness, but can only tolerate limited numbers of Byzantine failures. In this work, we present DETOX, a Byzantine-resilient distributed training framework that combines algorithmic redundancy with robust aggregation. DETOX operates in two steps, a filtering step that uses limited redundancy to significantly reduce the effect of Byzantine nodes, and a hierarchical aggregation step that can be used in tandem with any state-of-the-art robust aggregation method. We show theoretically that this leads to a substantial increase in robustness, and has a per iteration runtime that can be nearly linear in the number of compute nodes. We provide extensive experiments over real distributed setups across a variety of large-scale machine learning tasks, showing that DETOX leads to orders of magnitude accuracy and speedup improvements over many state-of-the-art Byzantine-resilient approaches.},
	urldate = {2022-10-12},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Rajput, Shashank and Wang, Hongyi and Charles, Zachary and Papailiopoulos, Dimitris},
	year = {2019},
	keywords = {⛔ No DOI found},
}

@article{kang_incentive_2019,
	title = {Incentive {Mechanism} for {Reliable} {Federated} {Learning}: {A} {Joint} {Optimization} {Approach} to {Combining} {Reputation} and {Contract} {Theory}},
	volume = {6},
	issn = {2327-4662},
	shorttitle = {Incentive {Mechanism} for {Reliable} {Federated} {Learning}},
	doi = {10.1109/JIOT.2019.2940820},
	abstract = {Federated learning is an emerging machine learning technique that enables distributed model training using local datasets from large-scale nodes, e.g., mobile devices, but shares only model updates without uploading the raw training data. This technique provides a promising privacy preservation for mobile devices while simultaneously ensuring high learning performance. The majority of existing work has focused on designing advanced learning algorithms with an aim to achieve better learning performance. However, the challenges, such as incentive mechanisms for participating in training and worker (i.e., mobile devices) selection schemes for reliable federated learning, have not been explored yet. These challenges have hindered the widespread adoption of federated learning. To address the above challenges, in this article, we first introduce reputation as the metric to measure the reliability and trustworthiness of the mobile devices. We then design a reputation-based worker selection scheme for reliable federated learning by using a multiweight subjective logic model. We also leverage the blockchain to achieve secure reputation management for workers with nonrepudiation and tamper-resistance properties in a decentralized manner. Moreover, we propose an effective incentive mechanism combining reputation with contract theory to motivate high-reputation mobile devices with high-quality data to participate in model learning. Numerical results clearly indicate that the proposed schemes are efficient for reliable federated learning in terms of significantly improving the learning accuracy.},
	number = {6},
	journal = {IEEE Internet of Things Journal},
	author = {Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Xie, Shengli and Zhang, Junshan},
	month = dec,
	year = {2019},
	keywords = {Blockchain, Contracts, Data models, Mobile handsets, Reliability, Task analysis, Training, contract theory, federated learning, mobile networks, reputation, security and privacy},
	pages = {10700--10714},
}

@inproceedings{song_profit_2019,
	title = {Profit {Allocation} for {Federated} {Learning}},
	doi = {10.1109/BigData47090.2019.9006327},
	abstract = {Due to stricter data management regulations such as General Data Protection Regulation (GDPR), traditional production mode of machine learning services is shifting to federated learning, a paradigm that allows multiple data providers to train a joint model collaboratively with their data kept locally. A key enabler for practical adoption of federated learning is how to allocate the prolit earned by the joint model to each data provider. For fair prolit allocation, a metric to quantify the contribution of each data provider to the joint model is essential. Shapley value is a classical concept in cooperative game theory which assigns a unique distribution (among the players) of a total surplus generated by the coalition of all players and has been used for data valuation in machine learning services. However, prior Shapley value based data valuation schemes either do not apply to federated learning or involve extra model training which leads to high cost. In this paper, given n data providers with data sets D1, D2, ⋯, Dn, a federated learning algorithm A and a standard test set T, we propose the contribution index, a new Shapley value based metric lit for assessing the contribution of each data provider for the joint model trained by federated learning. The contribution index shares the same properties as Shapley value. However, direct calculation of the contribution index is time consuming, since a large number of joint models with different combinations of data sets are required to be trained and evaluated. To solve this problem, we propose two gradient based methods. The idea is to reconstruct approximately the models on different combinations of the data sets through the intermediate results of the training process of federated learning so as to avoid extra training. The lirst method reconstructs models by updating the initial global model in federated learning with the gradients in different rounds. Then it calculates the contribution index by the performance of these reconstructed models. The second method calculates contribution index in each round by updating the global model in the previous round with the gradients in the current round. Contribution indexes of multiple rounds are then added with elaborated weights to get the linal result. We conduct extensive experiments on the MNIST data set in different settings. The results demonstrate that the proposed methods can approximate the exact contribution index effectively and achieve a time speed up of up to 2x-100x compared with the exact calculation and other baselines extended from existing work.},
	booktitle = {2019 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Song, Tianshu and Tong, Yongxin and Wei, Shuyue},
	month = dec,
	year = {2019},
	keywords = {Data models, Federated Learning, Google, Incentive Mechanism, Indexes, Machine learning, Servers, Shapley Value, Task analysis, Training},
	pages = {2577--2586},
}

@inproceedings{briggs_federated_2020,
	title = {Federated learning with hierarchical clustering of local updates to improve training on non-{IID} data},
	doi = {10.1109/IJCNN48605.2020.9207469},
	abstract = {Federated learning (FL) is a well established method for performing machine learning tasks over massively distributed data. However in settings where data is distributed in a non-iid (not independent and identically distributed) fashion - as is typical in real world situations - the joint model produced by FL suffers in terms of test set accuracy and/or communication costs compared to training on iid data. We show that learning a single joint model is often not optimal in the presence of certain types of non-iid data. In this work we present a modification to FL by introducing a hierarchical clustering step (FL+HC) to separate clusters of clients by the similarity of their local updates to the global joint model. Once separated, the clusters are trained independently and in parallel on specialised models. We present a robust empirical analysis of the hyperparameters for FL+HC for several iid and non-iid settings. We show how FL+HC allows model training to converge in fewer communication rounds (significantly so under some non-iid settings) compared to FL without clustering. Additionally, FL+HC allows for a greater percentage of clients to reach a target accuracy compared to standard FL. Finally we make suggestions for good default hyperparameters to promote superior performing specialised models without modifying the the underlying federated learning communication protocol.},
	booktitle = {2020 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Briggs, Christopher and Fan, Zhong and Andras, Peter},
	month = jul,
	year = {2020},
	note = {ISSN: 2161-4407},
	keywords = {Cats, Clustering algorithms, Data models, Distributed databases, Merging, Task analysis, Training, clustering applications, distributed machine learning, federated learning},
	pages = {1--9},
}

@article{kang_reliable_2020,
	title = {Reliable {Federated} {Learning} for {Mobile} {Networks}},
	volume = {27},
	issn = {1558-0687},
	doi = {10.1109/MWC.001.1900119},
	abstract = {Federated learning, as a promising machine learning approach, has emerged to leverage a distributed personalized dataset from a number of nodes, for example, mobile devices, to improve performance while simultaneously providing privacy preservation for mobile users. In federated learning, training data is widely distributed and maintained on the mobile devices as workers. A central aggregator updates a global model by collecting local updates from mobile devices using their local training data to train the global model in each iteration. However, unreliable data may be uploaded by the mobile devices (i.e., workers), leading to frauds in tasks of federated learning. The workers may perform unreliable updates intentionally, for example, the data poisoning attack, or unintentionally, for example, low-quality data caused by energy constraints or high-speed mobility. Therefore, finding out trusted and reliable workers in federated learning tasks becomes critical. In this article, the concept of reputation is introduced as a metric. Based on this metric, a reliable worker selection scheme is proposed for federated learning tasks. Consortium blockchain is leveraged as a decentralized approach for achieving efficient reputation management of the workers without repudiation and tampering. By numerical analysis, the proposed approach is demonstrated to improve the reliability of federated learning tasks in mobile networks.},
	number = {2},
	journal = {IEEE Wireless Communications},
	author = {Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Zou, Yuze and Zhang, Yang and Guizani, Mohsen},
	month = apr,
	year = {2020},
	note = {Conference Name: IEEE Wireless Communications},
	keywords = {Data models, Data privacy, Machine learning, Metasearch, Mobile handsets, Task analysis, Training data, \_obsidian},
	pages = {72--80},
}

@inproceedings{fung_limitations_2020,
	address = {San Sebastian},
	title = {The limitations of federated learning in sybil settings},
	isbn = {978-1-939133-18-2},
	url = {https://www.usenix.org/conference/raid2020/presentation/fung},
	booktitle = {23rd international symposium on research in attacks, intrusions and defenses ({RAID} 2020)},
	publisher = {USENIX Association},
	author = {Fung, Clement and Yoon, Chris J. M. and Beschastnikh, Ivan},
	month = oct,
	year = {2020},
	pages = {301--316},
}

@inproceedings{hsieh_non-iid_2020,
	title = {The {Non}-{IID} {Data} {Quagmire} of {Decentralized} {Machine} {Learning}},
	url = {https://proceedings.mlr.press/v119/hsieh20a.html},
	abstract = {Many large-scale machine learning (ML) applications need to perform decentralized learning over datasets generated at different devices and locations. Such datasets pose a significant challenge to decentralized learning because their different contexts result in significant data distribution skew across devices/locations. In this paper, we take a step toward better understanding this challenge by presenting a detailed experimental study of decentralized DNN training on a common type of data skew: skewed distribution of data labels across devices/locations. Our study shows that: (i) skewed data labels are a fundamental and pervasive problem for decentralized learning, causing significant accuracy loss across many ML applications, DNN models, training datasets, and decentralized learning algorithms; (ii) the problem is particularly challenging for DNN models with batch normalization; and (iii) the degree of data skew is a key determinant of the difficulty of the problem. Based on these findings, we present SkewScout, a system-level approach that adapts the communication frequency of decentralized learning algorithms to the (skew-induced) accuracy loss between data partitions. We also show that group normalization can recover much of the accuracy loss of batch normalization.},
	language = {en},
	urldate = {2022-09-01},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Hsieh, Kevin and Phanishayee, Amar and Mutlu, Onur and Gibbons, Phillip},
	month = nov,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {4387--4398},
}

@inproceedings{short_using_2020,
	title = {Using {Blockchain} {Technologies} to {Improve} {Security} in {Federated} {Learning} {Systems}},
	doi = {10.1109/COMPSAC48688.2020.00-96},
	abstract = {The potential of Federated Learning (FL) deployment increases rapidly as the number of connected devices increases, the value of artificial intelligence is recognized and networking technologies and edge computing evolves. However, as in any distributed system, a set of security issues arise in FL systems. In this paper, we discuss the use of blockchain technology to address diverse security aspects of FL systems and focus on the model poisoning attack for which we propose a novel Blockchain-based defense scheme. An assessment using data from the MNIST database has shown that the proposed approach, which has been designed to be implemented on blockchain technology, offers significant protection against adversaries attempting model poisoning attacks. The approach adopts a novel algorithm for evaluating the model updates, by verifying each model update separately against a verification dataset, without requiring information about the training dataset size, which is often unavailable or easily falsified.},
	booktitle = {2020 {IEEE} 44th {Annual} {Computers}, {Software}, and {Applications} {Conference} ({COMPSAC})},
	author = {Short, Andrew Ronald and Leligou, Helen C. and Papoutsidakis, Michael and Theocharis, Efstathios},
	month = jul,
	year = {2020},
	note = {ISSN: 0730-3157},
	keywords = {Blockchain, Federated Learning, Security attacks, Computers, Conferences, Software},
	pages = {1183--1188},
}

@inproceedings{sun_intrusion_2020,
	title = {Intrusion {Detection} with {Segmented} {Federated} {Learning} for {Large}-{Scale} {Multiple} {LANs}},
	doi = {10.1109/IJCNN48605.2020.9207094},
	abstract = {Traditional approaches to cybersecurity issues usually protect users from attacks after the occurrence of specific types of attacks. Besides, patterns of recent cyberattacks tend to be changeable, which add up to unpredictability of them. On the other hand, machine learning, as a new method used to detect intrusion, is attracting more and more attention. Moreover, through the sharing of local training data, the centralized learning approach has proven to improve a model's performance. In this research, a segmented federated learning is proposed, different from a collaborative learning based on single global model in a traditional federated learning model, it keeps multiple global models which allow each segment of participants to conduct collaborative learning separately and rearranges the segmentation of participants dynamically as well. Furthermore, these multiple global models interact with each other for updating parameters, thus being adaptable to various participants' LANs. A dataset covering two months' traffic data from 20 participants' LANs in the LAN-Security Monitoring Project is used. We adopt three types of knowledge-based methods for labeling network events and train a CNN model based on the dataset. At last, we achieve validation accuracies of 0.923, 0.813 and 0.877 individually with these labeling methods.},
	booktitle = {2020 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Sun, Yuwei and Ochiai, Hideya and Esaki, Hiroshi},
	month = jul,
	year = {2020},
	note = {ISSN: 2161-4407},
	keywords = {Adaptation models, CNN, Data models, Intrusion detection, LAN, Machine learning, Monitoring, Servers, Telecommunication traffic, cybersecurity, machine learning, segmented federated learning},
	pages = {1--8},
}

@inproceedings{peri_deep_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Deep k-{NN} {Defense} {Against} {Clean}-{Label} {Data} {Poisoning} {Attacks}},
	isbn = {978-3-030-66415-2},
	doi = {10.1007/978-3-030-66415-2_4},
	abstract = {Targeted clean-label data poisoning is a type of adversarial attack on machine learning systems in which an adversary injects a few correctly-labeled, minimally-perturbed samples into the training data, causing a model to misclassify a particular test sample during inference. Although defenses have been proposed for general poisoning attacks, no reliable defense for clean-label attacks has been demonstrated, despite the attacks’ effectiveness and realistic applications. In this work, we propose a simple, yet highly-effective Deep k-NN defense against both feature collision and convex polytope clean-label attacks on the CIFAR-10 dataset. We demonstrate that our proposed strategy is able to detect over 99\% of poisoned examples in both attacks and remove them without compromising model performance. Additionally, through ablation studies, we discover simple guidelines for selecting the value of k as well as for implementing the Deep k-NN defense on real-world datasets with class imbalance. Our proposed defense shows that current clean-label poisoning attack strategies can be annulled, and serves as a strong yet simple-to-implement baseline defense to test future clean-label poisoning attacks. Our code is available on GitHub.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2020 {Workshops}},
	publisher = {Springer International Publishing},
	author = {Peri, Neehar and Gupta, Neal and Huang, W. Ronny and Fowl, Liam and Zhu, Chen and Feizi, Soheil and Goldstein, Tom and Dickerson, John P.},
	editor = {Bartoli, Adrien and Fusiello, Andrea},
	year = {2020},
	keywords = {Adversarial attacks, Clean label poisoning, Deep k-NN, Machine learning},
	pages = {55--70},
}

@misc{zhao_shielding_2020,
	title = {Shielding {Collaborative} {Learning}: {Mitigating} {Poisoning} {Attacks} through {Client}-{Side} {Detection}},
	shorttitle = {Shielding {Collaborative} {Learning}},
	url = {http://arxiv.org/abs/1910.13111},
	abstract = {Collaborative learning allows multiple clients to train a joint model without sharing their data with each other. Each client performs training locally and then submits the model updates to a central server for aggregation. Since the server has no visibility into the process of generating the updates, collaborative learning is vulnerable to poisoning attacks where a malicious client can generate a poisoned update to introduce backdoor functionality to the joint model. The existing solutions for detecting poisoned updates, however, fail to defend against the recently proposed attacks, especially in the non-IID setting. In this paper, we present a novel defense scheme to detect anomalous updates in both IID and non-IID settings. Our key idea is to realize client-side cross-validation, where each update is evaluated over other clients' local data. The server will adjust the weights of the updates based on the evaluation results when performing aggregation. To adapt to the unbalanced distribution of data in the non-IID setting, a dynamic client allocation mechanism is designed to assign detection tasks to the most suitable clients. During the detection process, we also protect the client-level privacy to prevent malicious clients from stealing the training data of other clients, by integrating differential privacy with our design without degrading the detection performance. Our experimental evaluations on two real-world datasets show that our scheme is significantly robust to two representative poisoning attacks.},
	urldate = {2022-08-28},
	publisher = {arXiv},
	author = {Zhao, Lingchen and Hu, Shengshan and Wang, Qian and Jiang, Jianlin and Shen, Chao and Luo, Xiangyang and Hu, Pengfei},
	month = mar,
	year = {2020},
	note = {arXiv:1910.13111 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@inproceedings{ur_rehman_towards_2020,
	address = {Toronto, ON, Canada},
	title = {Towards {Blockchain}-{Based} {Reputation}-{Aware} {Federated} {Learning}},
	isbn = {978-1-72818-695-5},
	url = {https://ieeexplore.ieee.org/document/9163027/},
	doi = {10.1109/INFOCOMWKSHPS50562.2020.9163027},
	abstract = {Federated learning (FL) is the collaborative machine learning (ML) technique whereby the devices collectively train and update a shared ML model while preserving their personal datasets. FL systems solve the problems of communicationefﬁciency, bandwidth-optimization, and privacy-preservation. Despite the potential beneﬁts of FL, one centralized shared ML model across all the devices produce coarse-grained predictions which, in essence, are not required in many application areas involving personalized prediction services. In this paper, we present a novel concept of ﬁne-grained FL to decentralize the shared ML models on the edge servers. We then present a formal extended deﬁnition of ﬁne-grained FL process in mobile edge computing systems. In addition, we deﬁne the core requirements of ﬁnegrained FL systems including personalization, decentralization, ﬁne-grained FL, incentive mechanisms, trust, activity monitoring, heterogeneity and context-awareness, model synchronization, and communication and bandwidth-efﬁciency. Moreover, we present the concept of blockchain-based reputation-aware ﬁne-grained FL in order to ensure trustworthy collaborative training in mobile edge computing systems. Finally, we perform the qualitative comparison of proposed approach with state-of-the-art related work and found some promising initial results.},
	language = {en},
	urldate = {2021-10-29},
	booktitle = {{IEEE} {INFOCOM} 2020 - {IEEE} {Conference} on {Computer} {Communications} {Workshops} ({INFOCOM} {WKSHPS})},
	publisher = {IEEE},
	author = {ur Rehman, Muhammad Habib and Salah, Khaled and Damiani, Ernesto and Svetinovic, Davor},
	month = jul,
	year = {2020},
	keywords = {\_read},
	pages = {183--188},
}

@inproceedings{wang_novel_2020,
	title = {A {Novel} {Reputation}-aware {Client} {Selection} {Scheme} for {Federated} {Learning} within {Mobile} {Environments}},
	doi = {10.1109/CAMAD50429.2020.9209263},
	abstract = {This paper studies the problem of training federated deep learning models over a mobile environment. Stemming from the federated learning (FL) concept, deep learning models on mobile devices can be trained for various use cases including but not limited to image sorting and prediction of upcoming words. Mobile devices have access to rich data sets through embedded sensors and as well as installed software, and these feature rich data can facilitate solid training models, including personal images and other behaviometric features. However, utilizing the data through conventional approaches can potentially lead to privacy leakages. In this paper, we propose an alternate strategy that builds on the Federated Learning (FL) concept, to keep the training data on distributed mobile devices, and train a shared model by aggregating updated local models. The contribution of this study is an optimal user selection method for the federated learning environment based on reputation scores. Through extensive validation experiments considering two different model architectures and three datasets, our experiments show that the proposed approach is stable over data that is not independent nor identically distributed (i.e., non-IID) and under imbalanced distribution. Experimental results show that the proposed reputation-aware FL scheme can achieve improvements in the test accuracy up to 9.30\% under different data sets.},
	booktitle = {2020 {IEEE} 25th {International} {Workshop} on {Computer} {Aided} {Modeling} and {Design} of {Communication} {Links} and {Networks} ({CAMAD})},
	author = {Wang, Yuwei and Kantarci, Burak},
	month = sep,
	year = {2020},
	note = {ISSN: 2378-4873},
	keywords = {Computational modeling, Data models, Data privacy, Federated learning, Machine learning, Mobile handsets, Servers, Training, client selection, data sharing, deep learning models, mobile networks},
	pages = {1--6},
}

@article{bougueroua_survey_2021,
	title = {A {Survey} on {Multi}-{Agent} {Based} {Collaborative} {Intrusion} {Detection} {Systems}},
	volume = {11},
	doi = {10.2478/jaiscr-2021-0008},
	abstract = {Multi-Agent Systems (MAS) have been widely used in many areas like modeling and simulation of complex phenomena, and distributed problem solving. Likewise, MAS have been used in cyber-security, to build more efficient Intrusion Detection Systems (IDS), namely Collaborative Intrusion Detection Systems (CIDS). This work presents a taxonomy for classifying the methods used to design intrusion detection systems, and how such methods were used alongside with MAS in order to build IDS that are deployed in distributed environments, resulting in the emergence of CIDS. The proposed taxonomy, consists of three parts: 1) general architecture of CIDS, 2) the used agent technology, and 3) decision techniques, in which used technologies are presented. The proposed taxonomy reviews and classifies the most relevant works in this topic and highlights open research issues in view of recent and emerging threats. Thus, this work provides a good insight regarding past, current, and future solutions for CIDS, and helps both researchers and professionals design more effective solutions.},
	journal = {Journal of Artificial Intelligence and Soft Computing Research},
	author = {Bougueroua, Nassima and Mazouzi, Smaine and Belaoued, Mohamed and Seddari, Noureddine and Derhab, Abdelouahid and Bouras, Abdelghani},
	month = apr,
	year = {2021},
	pages = {111--142},
}

@inproceedings{chen_fedequal_2021,
	title = {{FedEqual}: {Defending} {Model} {Poisoning} {Attacks} in {Heterogeneous} {Federated} {Learning}},
	shorttitle = {{FedEqual}},
	doi = {10.1109/GLOBECOM46510.2021.9685082},
	abstract = {With the upcoming edge AI, federated learning (FL) is a privacy-preserving framework to meet the General Data Protection Regulation (GDPR). Unfortunately, FL is vulnerable to an up-to-date security threat, model poisoning attacks. By successfully replacing the global model with the targeted poisoned model, malicious end devices can trigger backdoor attacks and manipulate the whole learning process. The traditional researches under a homogeneous environment can ideally exclude the outliers with scarce side-effects on model performance. However, in privacy-preserving FL, each end device possibly owns a few data classes and different amounts of data, forming into a substantial heterogeneous environment where outliers could be malicious or benign. To achieve the system performance and robustness of FL's framework, we should not assertively remove any local model from the global model updating procedure. Therefore, in this paper, we propose a defending strategy called FedEqual to mitigate model poisoning attacks while preserving the learning task's performance without excluding any benign models. The results show that FedEqual outperforms other state-of-the-art baselines under different heterogeneous environments based on reproduced up-to-date model poisoning attacks.},
	booktitle = {2021 {IEEE} {Global} {Communications} {Conference} ({GLOBECOM})},
	author = {Chen, Ling-Yuan and Chiu, Te-Chuan and Pang, Ai-Chun and Cheng, Li-Chen},
	month = dec,
	year = {2021},
	keywords = {Collaborative work, Conferences, Edge AI, Federated Learning, Global communication, Model Poisoning Attacks, Model Security, Performance evaluation, Robustness, Security, System Robustness, System performance},
	pages = {1--6},
}

@inproceedings{awan_contra_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{CONTRA}: {Defending} {Against} {Poisoning} {Attacks} in {Federated} {Learning}},
	isbn = {978-3-030-88418-5},
	shorttitle = {{CONTRA}},
	doi = {10.1007/978-3-030-88418-5_22},
	abstract = {Federated learning (FL) is an emerging machine learning paradigm. With FL, distributed data owners aggregate their model updates to train a shared deep neural network collaboratively, while keeping the training data locally. However, FL has little control over the local data and the training process. Therefore, it is susceptible to poisoning attacks, in which malicious or compromised clients use malicious training data or local updates as the attack vector to poison the trained global model. Moreover, the performance of existing detection and defense mechanisms drops significantly in a scaled-up FL system with non-iid data distributions. In this paper, we propose a defense scheme named CONTRA to defend against poisoning attacks, e.g., label-flipping and backdoor attacks, in FL systems. CONTRA implements a cosine-similarity-based measure to determine the credibility of local model parameters in each round and a reputation scheme to dynamically promote or penalize individual clients based on their per-round and historical contributions to the global model. With extensive experiments, we show that CONTRA significantly reduces the attack success rate while achieving high accuracy with the global model. Compared with a state-of-the-art (SOTA) defense, CONTRA reduces the attack success rate by 70\% and reduces the global model performance degradation by 50\%.},
	language = {en},
	booktitle = {Computer {Security} – {ESORICS} 2021},
	publisher = {Springer International Publishing},
	author = {Awan, Sana and Luo, Bo and Li, Fengjun},
	editor = {Bertino, Elisa and Shulman, Haya and Waidner, Michael},
	year = {2021},
	keywords = {Adversarial machine learning, Backdoor attacks, Data poisoning, Federated learning, Label-flipping attacks},
	pages = {455--475},
}

@article{chen_zero_2021,
	title = {Zero {Knowledge} {Clustering} {Based} {Adversarial} {Mitigation} in {Heterogeneous} {Federated} {Learning}},
	volume = {8},
	issn = {2327-4697},
	doi = {10.1109/TNSE.2020.3002796},
	abstract = {The simultaneous development of deep learning techniques and Internet of Things (IoT)/Cyber-physical Systems (CPS) technologies has afforded untold possibilities for improving distributed computing, sensing, and data analysis. Among these technologies, federated learning has received increased attention as a privacy-preserving collaborative learning paradigm, and has shown significant potential in IoT/CPS-driven large-scale smart-world systems. At the same time, the vulnerabilities of deep neural networks, especially to adversarial attacks, cannot be overstated and should not be minimized. Moreover, the distributed nature of federated learning makes defense against such adversarial attacks a more challenging problem due to the unavailability of local data and resource heterogeneity. To tackle these challenges, in this paper, we propose ZeKoC, a Zero Knowledge Clustering approach to mitigating adversarial attacks. Particularly, we first formulate the problem of resource-constrained adversarial mitigation. Specifically, noting that a global server has no access to training samples, we reformulate the unsupervised weight clustering problem. Our proposed ZeKoC approach allows the server to automatically split and merge weight clusters for weight selection and aggregation. Theoretical analysis demonstrates that convergence is guaranteed. Further, our experimental results illustrate that, in a non-i.i.d. (i.e., independent and identically distributed) data setting, the proposed ZeKoC approach successfully mitigates general attacks while outperforming state-of-art schemes.},
	number = {2},
	journal = {IEEE Transactions on Network Science and Engineering},
	author = {Chen, Zheyi and Tian, Pu and Liao, Weixian and Yu, Wei},
	month = apr,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Network Science and Engineering},
	keywords = {Data models, Distributed databases, Machine learning, Non-i.i.d. data, Peer-to-peer computing, Security, Servers, Training, adversarial mitigation, federated learning},
	pages = {1070--1083},
}

@misc{guo_robust_2021,
	title = {Robust and {Privacy}-{Preserving} {Collaborative} {Learning}: {A} {Comprehensive} {Survey}},
	shorttitle = {Robust and {Privacy}-{Preserving} {Collaborative} {Learning}},
	url = {http://arxiv.org/abs/2112.10183},
	doi = {10.48550/arXiv.2112.10183},
	abstract = {With the rapid demand of data and computational resources in deep learning systems, a growing number of algorithms to utilize collaborative machine learning techniques, for example, federated learning, to train a shared deep model across multiple participants. It could effectively take advantage of the resources of each participant and obtain a more powerful learning system. However, integrity and privacy threats in such systems have greatly obstructed the applications of collaborative learning. And a large amount of works have been proposed to maintain the model integrity and mitigate the privacy leakage of training data during the training phase for different collaborative learning systems. Compared with existing surveys that mainly focus on one specific collaborative learning system, this survey aims to provide a systematic and comprehensive review of security and privacy researches in collaborative learning. Our survey first provides the system overview of collaborative learning, followed by a brief introduction of integrity and privacy threats. In an organized way, we then detail the existing integrity and privacy attacks as well as their defenses. We also list some open problems in this area and opensource the related papers on GitHub: https://github.com/csl-cqu/awesome-secure-collebrative-learning-papers.},
	urldate = {2022-09-01},
	publisher = {arXiv},
	author = {Guo, Shangwei and Zhang, Xu and Yang, Fei and Zhang, Tianwei and Gan, Yan and Xiang, Tao and Liu, Yang},
	month = dec,
	year = {2021},
	note = {arXiv:2112.10183 [cs]},
	keywords = {Computer Science - Cryptography and Security},
}

@inproceedings{karimireddy_learning_2021,
	title = {Learning from {History} for {Byzantine} {Robust} {Optimization}},
	url = {https://proceedings.mlr.press/v139/karimireddy21a.html},
	abstract = {Byzantine robustness has received significant attention recently given its importance for distributed and federated learning. In spite of this, we identify severe flaws in existing algorithms even when the data across the participants is identically distributed. First, we show realistic examples where current state of the art robust aggregation rules fail to converge even in the absence of any Byzantine attackers. Secondly, we prove that even if the aggregation rules may succeed in limiting the influence of the attackers in a single round, the attackers can couple their attacks across time eventually leading to divergence. To address these issues, we present two surprisingly simple strategies: a new robust iterative clipping procedure, and incorporating worker momentum to overcome time-coupled attacks. This is the first provably robust method for the standard stochastic optimization setting.},
	language = {en},
	urldate = {2022-10-21},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Karimireddy, Sai Praneeth and He, Lie and Jaggi, Martin},
	month = jul,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {5311--5319},
}

@inproceedings{mao_romoa_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Romoa: {Robust} {Model} {Aggregation} for the {Resistance} of {Federated} {Learning} to {Model} {Poisoning} {Attacks}},
	isbn = {978-3-030-88418-5},
	shorttitle = {Romoa},
	doi = {10.1007/978-3-030-88418-5_23},
	abstract = {Training a deep neural network requires substantial data and intensive computing resources. Unaffordable price holds back many potential applications of deep learning. Besides, it is risky to gather user’s private data for training centrally. Then federated learning appears as a promising solution to having users learned jointly while keeping training data local. However, security issues keep coming up in federated learning applications. One of the most threatening attacks is the model poisoning attack which can manipulate the inference result of a jointly learned model. Some recent studies show that elaborate model poisoning approaches can even breach the existing Byzantine-robust federated learning solutions. Hence, it is critical to discuss alternative solutions to secure federated learning. In this paper, we propose to protect federated learning against model poisoning attacks by introducing a robust model aggregation solution named Romoa. Unlike previous studies, Romoa can deal with targeted and untargeted poisoning attacks with a unified approach. Moreover, Romoa achieves more precise attack detection and better fairness for federated learning participants by constructing a new similarity measurement. We conclude that through a comprehensive evaluation of standard datasets, Romoa can provide a satisfying defense effect against model poisoning attacks, including those attacks breaching Byzantine-robust federated learning solutions.},
	language = {en},
	booktitle = {Computer {Security} – {ESORICS} 2021},
	publisher = {Springer International Publishing},
	author = {Mao, Yunlong and Yuan, Xinyu and Zhao, Xinyang and Zhong, Sheng},
	editor = {Bertino, Elisa and Shulman, Haya and Waidner, Michael},
	year = {2021},
	keywords = {Federated learning, Model poisoning attack, Robust model aggregation},
	pages = {476--496},
}

@inproceedings{putra_decentralised_2021,
	title = {Decentralised {Trustworthy} {Collaborative} {Intrusion} {Detection} {System} for {IoT}},
	doi = {10.1109/Blockchain53845.2021.00048},
	abstract = {Intrusion Detection Systems (IDS) have been the industry standard for securing IoT networks against known attacks. To increase the capability of an IDS, researchers proposed the concept of blockchain-based Collaborative-IDS (CIDS), wherein blockchain acts as a decentralised platform allowing collaboration between CIDS nodes to share intrusion related information, such as intrusion alarms and detection rules. However, proposals in blockchain-based CIDS overlook the importance of continuous evaluation of the trustworthiness of each node and generally work based on the assumption that the nodes are always honest. In this paper, we propose a decentralised CIDS that emphasises the importance of building trust between CIDS nodes. In our proposed solution, each CIDS node exchanges detection rules to help other nodes detect new types of intrusion. Our architecture offloads the trust computation to the blockchain and utilises a decentralised storage to host the shared trustworthy detection rules, ensuring scalability. Our implementation in a lab-scale testbed shows that the our solution is feasible and performs within the expected benchmarks of the Ethereum platform.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Blockchain} ({Blockchain})},
	author = {Putra, Guntur Dharma and Dedeoglu, Volkan and Pathak, Abhinav and Kanhere, Salil S. and Jurdak, Raja},
	month = dec,
	year = {2021},
	keywords = {Benchmark testing, Blockchains, Collaboration, Computer architecture, Economics, Intrusion detection, IoT, Scalability, blockchain, collaborative, intrusion detection system, scalability, trust management},
	pages = {306--313},
}

@inproceedings{ouyang_clusterfl_2021,
	address = {Virtual Event Wisconsin},
	title = {{ClusterFL}: a similarity-aware federated learning system for human activity recognition},
	isbn = {978-1-4503-8443-8},
	shorttitle = {{ClusterFL}},
	url = {https://dl.acm.org/doi/10.1145/3458864.3467681},
	doi = {10.1145/3458864.3467681},
	abstract = {Federated Learning (FL) has recently received signiﬁcant interests thanks to its capability of protecting data privacy. However, existing FL paradigms yield unsatisfactory performance for a wide class of human activity recognition (HAR) applications since they are oblivious to the intrinsic relationship between data of diﬀerent users. We propose ClusterFL, a similarity-aware federated learning system that can provide high model accuracy and low communication overhead for HAR applications. ClusterFL features a novel clustered multi-task federated learning framework that maximizes the training accuracy of multiple learned models while automatically capturing the intrinsic clustering relationship among the data of diﬀerent nodes. Based on the learned cluster relationship, ClusterFL can eﬃciently drop out the nodes that converge slower or have little correlation with other nodes in each cluster, signiﬁcantly speeding up the convergence while maintaining the accuracy performance. We evaluate the performance of ClusterFL on an NVIDIA edge testbed using four new HAR datasets collected from total 145 users. The results show that, ClusterFL outperforms several state-of-the-art FL paradigms in terms of overall accuracy, and save more than 50\% communication overhead at the expense of negligible accuracy degradation.},
	language = {en},
	urldate = {2023-02-02},
	booktitle = {Proceedings of the 19th {Annual} {International} {Conference} on {Mobile} {Systems}, {Applications}, and {Services}},
	publisher = {ACM},
	author = {Ouyang, Xiaomin and Xie, Zhiyuan and Zhou, Jiayu and Huang, Jianwei and Xing, Guoliang},
	month = jun,
	year = {2021},
	pages = {54--66},
}

@article{pontes_new_2021,
	title = {A {New} {Method} for {Flow}-{Based} {Network} {Intrusion} {Detection} {Using} the {Inverse} {Potts} {Model}},
	volume = {18},
	issn = {1932-4537},
	doi = {10.1109/TNSM.2021.3075503},
	abstract = {Network Intrusion Detection Systems (NIDS) play an important role as tools for identifying potential network threats. In the context of ever-increasing traffic volume on computer networks, flow-based NIDS arise as good solutions for real-time traffic classification. In recent years, different flow-based classifiers have been proposed using Machine Learning (ML) algorithms. Nevertheless, classical ML-based classifiers have some limitations. For instance, they require large amounts of labeled data for training, which might be difficult to obtain. Additionally, most ML-based classifiers are not capable of domain adaptation, i.e., after being trained on an specific data distribution, they are not general enough to be applied to other related data distributions. And, finally, many of the models inferred by these algorithms are black boxes, which do not provide explainable results. To overcome these limitations, we propose a new algorithm, called Energy-based Flow Classifier (EFC). This anomaly-based classifier uses inverse statistics to infer a statistical model based on labeled benign examples. We show that EFC is capable of accurately performing binary flow classification and is more adaptable to different data distributions than classical ML-based classifiers. Given the positive results obtained on three different datasets (CIDDS-001, CICIDS17 and CICDDoS19), we consider EFC to be a promising algorithm to perform robust flow-based traffic classification.},
	number = {2},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Pontes, Camila F. T. and de Souza, Manuela M. C. and Gondim, João J. C. and Bishop, Matt and Marotta, Marcelo Antonio},
	month = jun,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Network and Service Management},
	keywords = {Adaptation models, Data models, Flow-based network intrusion detection, Machine learning algorithms, Network intrusion detection, Real-time systems, Security, Training, anomaly-based network intrusion detection, domain adaptation, energy-based flow classifier, inverse Potts model, network flow classification, network intrusion detection systems},
	pages = {1125--1136},
}

@inproceedings{popoola_federated_2021,
	title = {Federated {Deep} {Learning} for {Collaborative} {Intrusion} {Detection} in {Heterogeneous} {Networks}},
	doi = {10.1109/VTC2021-Fall52928.2021.9625505},
	abstract = {In this paper, we propose Federated Deep Learning (FDL) for intrusion detection in heterogeneous networks. Local Deep Neural Network (DNN) models are used to learn the hierarchical representations of the private network traffic data in multiple edge nodes. A dedicated central server receives the parameters of the local DNN models from the edge nodes, and it aggregates them to produce an FDL model using the Fed+ fusion algorithm. Simulation results show that the FDL model achieved an accuracy of 99.27 ± 0.79\%, a precision of 97.03 ± 4.22\%, a recall of 98.06 ± 1.72\%, an F1 score of 97.50 ± 2.55\%, and a False Positive Rate (FPR) of 2.40 ± 2.47\%. The classification performance and the generalisation ability of the FDL model are better than those of the local DNN models. The Fed+ algorithm outperformed two state-of-the-art fusion algorithms, namely federated averaging (FedAvg) and Coordinate Median (CM). Therefore, the DNN-Fed+ model is preferable for intrusion detection in heterogeneous wireless networks.},
	booktitle = {2021 {IEEE} 94th {Vehicular} {Technology} {Conference} ({VTC2021}-{Fall})},
	author = {Popoola, Segun I. and Gui, Guan and Adebisi, Bamidele and Hammoudeh, Mohammad and Gacanin, Haris},
	month = sep,
	year = {2021},
	note = {ISSN: 2577-2465},
	keywords = {Deep learning, Heterogeneous networks, Image edge detection, Intrusion detection, Simulation, Telecommunication traffic, Wireless networks, deep learning, federated learning, heterogeneous wireless networks, intrusion detection, smart city},
	pages = {1--6},
}

@inproceedings{uprety_mitigating_2021,
	title = {Mitigating {Poisoning} {Attack} in {Federated} {Learning}},
	doi = {10.1109/SSCI50451.2021.9659839},
	abstract = {Adversarial machine learning (AML) has emerged as one of the significant research areas in machine learning (ML) because models we train lack robustness and trustworthiness. Federated learning (FL) trains models over distributed devices and model parameters are shared instead of actual data in a privacy-preserving manner. Unfortunately, FL is also vulnerable to attacks including parameter/data poisoning attacks. In this paper, we first analyze the impact of the data poisoning attack on this training method with a label-flipping attack. We propose a poisoning attack mitigation technique based on the reputation of nodes' involved in the training process. The reputation score for each client is calculated using the beta probability distribution method. This is the first work to show the removal of malicious nodes with the poisoned dataset from the training environment based on the calculated reputation score. The improvement in model performance after filtering malicious nodes is validated using the benchmark MNIST dataset. At the same time, our work contributes to preventing denial of service attacks by considering a blockchain-based server network. Our results hold for two different attack settings with different proportions of poisoned data samples.},
	booktitle = {2021 {IEEE} {Symposium} {Series} on {Computational} {Intelligence} ({SSCI})},
	author = {Uprety, Aashma and Rawat, Danda B.},
	month = dec,
	year = {2021},
	keywords = {Collaborative work, Computational modeling, Data models, Data poisoning attack, Data privacy, Distance learning, Filtering, Training, reputation model, secure federated learning},
	pages = {01--07},
}

@inproceedings{wang_reputation-enabled_2021,
	title = {Reputation-enabled {Federated} {Learning} {Model} {Aggregation} in {Mobile} {Platforms}},
	doi = {10.1109/ICC42927.2021.9500928},
	abstract = {Federated Learning (FL) builds on a mobile network of participating nodes that train local models and contribute to the learning model parameters at a central server without being obliged to share their raw data. The server aggregates the uploaded model parameters to generate a global model. Common practice for the uploaded local models is an evenly weighted aggregation, assuming that each node of the network contributes to advancing the global model equally. Due to the heterogeneous nature of the devices and collected data, it is inevitable to have variations between the contributions of the users to the global model. Therefore, users (i.e., devices) with higher contributions should be weighted higher during aggregation. With this in mind, this paper proposes a reputation-enabled aggregation methodology that scales the aggregation weights of users by their reputation scores. Reputation score of a user is computed according to the performance metrics of their trained local models during each training round, therefore it can be a metric to evaluate the direct contributions of their trained local model. Numerical comparison of the proposed aggregation methodology to a baseline that utilizes standard averaging as well as a second baseline that is scoped to a reputation-based client selection shows an improvement of 17.175\% over the standard baseline for not independent and identically distributed (non-IID) scenarios for an FL network of 100 participants. Consistent improvements over the first and second baselines under smaller FL networks with users ranging from 20 to 100 are also shown.},
	booktitle = {{ICC} 2021 - {IEEE} {International} {Conference} on {Communications}},
	author = {Wang, Yuwei and Kantarci, Burak},
	month = jun,
	year = {2021},
	note = {ISSN: 1938-1883},
	keywords = {Collaborative work, Computational modeling, Data aggregation, Data models, Deep Learning, Deep Neural Networks, Distance measurement, Distributed Learning, Federated Learning, Mobile Networks, Neural networks, Reputation systems, Training},
	pages = {1--6},
}

@inproceedings{xia_tofi_2021,
	address = {Cham},
	series = {Lecture {Notes} of the {Institute} for {Computer} {Sciences}, {Social} {Informatics} and {Telecommunications} {Engineering}},
	title = {{ToFi}: {An} {Algorithm} to {Defend} {Against} {Byzantine} {Attacks} in {Federated} {Learning}},
	isbn = {978-3-030-90019-9},
	shorttitle = {{ToFi}},
	doi = {10.1007/978-3-030-90019-9_12},
	abstract = {In distributed gradient descent based machine learning model training, workers periodically upload locally computed gradients or weights to the parameter server (PS). Byzantine attacks take place when some workers upload wrong gradients or weights, i.e., the information received by the PS is not always the true values computed by workers. Approaches such as score-based, median-based, and distance-based defense algorithms were proposed previously, but all of them made the asumptions: (1) the dataset on each worker is independent and identically distributed (i.i.d.), and (2) the majority of all participating workers are honest. These assumptions are not realistic in federated learning where each worker may keep its non-i.i.d. private dataset and malicious workers may take over the majority in some iterations. In this paper, we propose a novel reference dataset based algorithm along with a practical Two-Filter algorithm (ToFi) to defend against Byzantine attacks in federated learning. Our experiments highlight the effectiveness of our algorithm compared with previous algorithms in different settings.},
	language = {en},
	booktitle = {Security and {Privacy} in {Communication} {Networks}},
	publisher = {Springer International Publishing},
	author = {Xia, Qi and Tao, Zeyi and Li, Qun},
	editor = {Garcia-Alfaro, Joaquin and Li, Shujun and Poovendran, Radha and Debar, Hervé and Yung, Moti},
	year = {2021},
	keywords = {Byzantine attacks, Federated learning},
	pages = {229--248},
}

@inproceedings{zhang_blockchain_2021,
	title = {Blockchain {Empowered} {Reliable} {Federated} {Learning} by {Worker} {Selection}: {A} {Trustworthy} {Reputation} {Evaluation} {Method}},
	shorttitle = {Blockchain {Empowered} {Reliable} {Federated} {Learning} by {Worker} {Selection}},
	doi = {10.1109/WCNCW49093.2021.9420026},
	abstract = {Federated learning is a distributed machine learning framework that enables distributed model training with local datasets, which can effectively protect the data privacy of workers (i.e., intelligent edge nodes). The majority of federated learning algorithms assume that the workers are trusted and voluntarily participate in the cooperative model training process. However, the situation in practical application is not consistent with this. There are many challenges such as worker selection schemes for participating workers, which hamper the widespread adoption of federated learning. The existing research about worker selection scheme focused on multi-weight subjective logic model to calculate reputation value and adopted contract theory to motivate workers, which may exist subjective judgmental factors and unfair profit distribution. To address above challenges, we calculate the reputation value by model quality parameters to evaluate the reliability of workers. Blockchain is designed to store historical reputation value that realized tamperresistance and non-repudiation. Numerical results indicate that the worker selection scheme can improve the accuracy of the model and accelerate the model convergence.},
	booktitle = {2021 {IEEE} {Wireless} {Communications} and {Networking} {Conference} {Workshops} ({WCNCW})},
	author = {Zhang, Qinnan and Ding, Qingyang and Zhu, Jianming and Li, Dandan},
	month = mar,
	year = {2021},
	keywords = {Analytical models, Blockchain, Conferences, Data privacy, Machine learning, Predictive models, Training, blockchain, consensus algorithm, federated learning, reputation evaluation},
	pages = {1--6},
}

@article{alkhalidy_new_2022,
	title = {A {New} {Scheme} for {Detecting} {Malicious} {Nodes} in {Vehicular} {Ad} {Hoc} {Networks} {Based} on {Monitoring} {Node} {Behavior}},
	doi = {10.3390/fi14080223},
	abstract = {Vehicular ad hoc networks have played a key role in intelligent transportation systems that considerably improve road safety and management. This new technology allows vehicles to communicate and share road information. However, malicious users may inject false emergency alerts into vehicular ad hoc networks, preventing nodes from accessing accurate road information. In order to assure the reliability and trustworthiness of information through the networks, assessing the credibility of nodes has become a critical task in vehicular ad hoc networks. A new scheme for malicious node detection is proposed in this work. Multiple factors are fed into a fuzzy logic model for evaluating the trust for each node. Vehicles are divided into clusters in our approach, and a road side unit manages each cluster. The road side unit assesses the credibility of nodes before accessing vehicular ad hoc networks. The road side unit evicts a malicious node based on trust value. Simulations are used to validate our technique. We demonstrate that our scheme can detect and evict all malicious nodes in the vehicular ad hoc network over time, lowering the ratio of malicious nodes. Furthermore, it has a positive impact on selﬁsh node participation. The scheme increases the success rate of delivered data to the same level as the ideal cases when no selﬁsh node is present.},
	language = {en},
	journal = {Future Internet},
	author = {Alkhalidy, Muhsen and Al-Serhan, Atalla Fahed and Alsarhan, Ayoub and Igried, Bashar},
	year = {2022},
	pages = {11},
}

@misc{chu_securing_2022,
	title = {Securing {Federated} {Sensitive} {Topic} {Classification} against {Poisoning} {Attacks}},
	url = {http://arxiv.org/abs/2201.13086},
	doi = {10.48550/arXiv.2201.13086},
	abstract = {We present a Federated Learning (FL) based solution for building a distributed classifier capable of detecting URLs containing GDPR-sensitive content related to categories such as health, sexual preference, political beliefs, etc. Although such a classifier addresses the limitations of previous offline/centralised classifiers,it is still vulnerable to poisoning attacks from malicious users that may attempt to reduce the accuracy for benign users by disseminating faulty model updates. To guard against this, we develop a robust aggregation scheme based on subjective logic and residual-based attack detection. Employing a combination of theoretical analysis, trace-driven simulation, as well as experimental validation with a prototype and real users, we show that our classifier can detect sensitive content with high accuracy, learn new labels fast, and remain robust in view of poisoning attacks from malicious users, as well as imperfect input from non-malicious ones.},
	urldate = {2022-10-20},
	publisher = {arXiv},
	author = {Chu, Tianyue and Garcia-Recuero, Alvaro and Iordanou, Costas and Smaragdakis, Georgios and Laoutaris, Nikolaos},
	month = jan,
	year = {2022},
	note = {arXiv:2201.13086 [cs]},
	keywords = {68M25, Computer Science - Cryptography and Security, Computer Science - Distributed, Parallel, and Cluster Computing, I.2.11, K.4.1},
}

@misc{cao_fltrust_2022,
	title = {{FLTrust}: {Byzantine}-robust {Federated} {Learning} via {Trust} {Bootstrapping}},
	shorttitle = {{FLTrust}},
	url = {http://arxiv.org/abs/2012.13995},
	doi = {10.48550/arXiv.2012.13995},
	abstract = {Byzantine-robust federated learning aims to enable a service provider to learn an accurate global model when a bounded number of clients are malicious. The key idea of existing Byzantine-robust federated learning methods is that the service provider performs statistical analysis among the clients' local model updates and removes suspicious ones, before aggregating them to update the global model. However, malicious clients can still corrupt the global models in these methods via sending carefully crafted local model updates to the service provider. The fundamental reason is that there is no root of trust in existing federated learning methods. In this work, we bridge the gap via proposing FLTrust, a new federated learning method in which the service provider itself bootstraps trust. In particular, the service provider itself collects a clean small training dataset (called root dataset) for the learning task and the service provider maintains a model (called server model) based on it to bootstrap trust. In each iteration, the service provider first assigns a trust score to each local model update from the clients, where a local model update has a lower trust score if its direction deviates more from the direction of the server model update. Then, the service provider normalizes the magnitudes of the local model updates such that they lie in the same hyper-sphere as the server model update in the vector space. Our normalization limits the impact of malicious local model updates with large magnitudes. Finally, the service provider computes the average of the normalized local model updates weighted by their trust scores as a global model update, which is used to update the global model. Our extensive evaluations on six datasets from different domains show that our FLTrust is secure against both existing attacks and strong adaptive attacks.},
	urldate = {2022-08-09},
	publisher = {arXiv},
	author = {Cao, Xiaoyu and Fang, Minghong and Liu, Jia and Gong, Neil Zhenqiang},
	month = apr,
	year = {2022},
	note = {arXiv:2012.13995 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Distributed, Parallel, and Cluster Computing},
}

@inproceedings{de_melo_generalizing_2022,
	title = {Generalizing {Flow} {Classification} for {Distributed} {Denial}-of-{Service} over {Different} {Networks}},
	doi = {10.1109/GLOBECOM48099.2022.10001530},
	abstract = {With the growth in connected devices and network traffic, these systems require automated and fast approaches to achieve secure operations. Hence, machine learning-based network intrusion detection has become the state-of-the-art approach to tackle uncertainties and new attacks. However, the generalization of the models when exposed to different domains and workloads remains an open issue. In this paper, we propose using federated learning (FL) with sampling methods and feature selection to improve the generalization of the trained global model when evaluated in different network contexts. We evaluate this approach to classify network flows representing benign traffic and distributed denial-of-service attacks. Our proposed approach results in an 85\% improvement compared with the naive evaluation of training in one context and evaluating others. Moreover, it presented a similar performance to a statistical algorithm with the reported generalization capability on flow-based network traffic classification. Additionally, this FL-based approach brings data privacy and distributed learning capability to the table.},
	booktitle = {{GLOBECOM} 2022 - 2022 {IEEE} {Global} {Communications} {Conference}},
	author = {de Melo, Leonardo H and de C Bertoli, Gustavo and Pereira, Lourenco A and Saotome, Osamu and Domingues, Marcelo F and dos Santos, Aldri Luiz},
	month = dec,
	year = {2022},
	keywords = {DDoS, Distance learning, Distributed denial-of-service attack, Federated learning, Network intrusion detection, Telecommunication traffic, Training, Uncertainty, federated learning, network intrusion detection, security},
	pages = {879--884},
}

@article{deng_improving_2022,
	title = {Improving {Federated} {Learning} {With} {Quality}-{Aware} {User} {Incentive} and {Auto}-{Weighted} {Model} {Aggregation}},
	issn = {1558-2183},
	doi = {10.1109/TPDS.2022.3195207},
	abstract = {Federated learning enables distributed model training over various computing nodes, e.g., mobile devices, where instead of sharing raw user data, computing nodes can solely commit model updates without compromising data privacy. The quality of federated learning relies on the model updates contributed by computing nodes training with their local data. However, with various factors (e.g., training data size, mislabeled data samples, skewed data distributions), the model update qualities of computing nodes can vary dramatically, while inclusively aggregating low-quality model updates can deteriorate the global model quality. To achieve efficient federated learning, in this paper, we propose a novel framework named FAIR, i.e., Federated leArning with qualIty awaReness. Particularly, FAIR integrates three major components: 1) learning quality estimation: we adopt the model aggregation weight (learned in the third component) to reversely quantify the individual learning quality of nodes in a privacy-preserving manner, and leverage the historical learning records to infer the next-round learning quality; 2) quality-aware incentive mechanism: within the recruiting budget, we model a reverse auction problem to stimulate the participation of high-quality and low-cost computing nodes, and the method is proved to be truthful, individually rational, and computationally efficient; and 3) auto-weighted model aggregation: based on the gradient descent method, we devise an auto-weighted model aggregation algorithm to automatically learn the optimal aggregation weights to further enhance the global model quality. Based on real-world datasets and learning tasks, extensive experiments are conducted to demonstrate the efficacy of FAIR.},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Deng, Yongheng and Lyu, Feng and Ren, Ju and Chen, Yi-Chao and Yang, Peng and Zhou, Yuezhi and Zhang, Yaoxue},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Parallel and Distributed Systems},
	keywords = {Collaborative work, Computational modeling, Data models, Edge computing, Resource management, Task analysis, Training, Training data, federated learning, incentive mechanism, learning quality, mobile computing, model aggregation},
	pages = {1--15},
}

@article{huang_eefed_2022,
	title = {{EEFED}: {Personalized} federated learning of {Execution}\&{Evaluation} dual network for {CPS} intrusion detection},
	issn = {1556-6021},
	shorttitle = {{EEFED}},
	doi = {10.1109/TIFS.2022.3214723},
	abstract = {In the modern interconnected world, intelligent networks and computing technologies are increasingly being incorporated in industrial systems. However, this adoption of advanced technology has resulted in increased cyber threats to cyber-physical systems. Existing intrusion detection systems are continually challenged by constantly evolving cyber threats. Machine learning algorithms have been applied for intrusion detection. In these techniques, a classification model is trained by learning cyber behavior patterns. However, these models typically require considerable high-quality datasets. Limited attack samples are available because of the unpredictability and constant evolution of cyber threats. To address these problems, we propose a novel federated Execution\&Evaluation dual network framework (EEFED), which allows multiple federal participants to personalize their local detection models undermining the original purpose of Federated Learning. Thus, a general global detection model was developed for collaboratively improving the performance of a single local model against cyberattacks. The proposed personalized update algorithm and the optimizing backtracking parameters replacement policy effectively reduced the negative influence of federated learning in imbalanced and non-i.i.d distribution of data. The proposed method improved model stability. Furthermore, extensive experiments conducted on a network dataset in various cyber scenarios revealed that the proposed method outperformed single model and state-of-the-art methods.},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Huang, Xianting and Liu, Jing and Lai, Yingxu and Mao, Beifeng and Lyu, Hongshuo},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Computational modeling, Computer crime, Data models, Federated learning, Intrusion detection, Security, Training, cyber security, cyber-physical system (CPS), intrusion detection, personalized model},
	pages = {1--1},
}

@book{haji_mirzaee_chfl_2022,
	title = {{CHFL}: {A} {Collaborative} {Hierarchical} {Federated} {Intrusion} {Detection} {System} for {Vehicular} {Networks}},
	shorttitle = {{CHFL}},
	abstract = {Wireless interfaces, remote control schemes, and increased autonomy have raised the attacks surface of vehicular networks. As powerful monitoring entities, intrusion detection systems (IDS) must be updated and customised to respond to emerging networks' requirements. As server-based monitoring schemes were prone to significant privacy concerns, new privacy constrained learning methods such as federated learning (FL) have received considerable attention in designing IDS. However, to alleviate the efficiency and enhance the scalability of the original FL, this paper proposes a novel collaborative hierarchical federated IDS, named CHFL for the vehicular network. In the CHFL model, a group of vehicles assisted by vehicle-to-everything (V2X) communication technologies can exchange intrusion detection information collaboratively in a private format. Each group nominates a leader, and the leading vehicle serves as the intermediate in the second level detection system of the hierarchical federated model. The leader communicates directly with the server to transmit and receive model updates of its nearby end vehicles. By reducing the number of direct communications to the server, our proposed system reduces network uplink traffic and queuing-processing latency. In addition, CHFL improved the prediction loss and the accuracy of the whole system. We are achieving an accuracy of 99.10\% compared with 97.01\% accuracy of the original FL.},
	author = {Haji Mirzaee, Parya and Shojafar, Mohammad and Cruickshank, Haitham and Tafazolli, Rahim},
	month = apr,
	year = {2022},
}

@inproceedings{liu_federated_2022,
	title = {Federated {Learning} with {Anomaly} {Client} {Detection} and {Decentralized} {Parameter} {Aggregation}},
	doi = {10.1109/DSN-W54100.2022.00016},
	abstract = {Federated learning is a framework for machine learning that is dedicated to data privacy protection. In federated learning, system cannot fully control the behavior of clients which can be faulty. These behaviors include sharing arbitrary faulty gradients and delaying the process of sharing due to Byzantine attacks or clients’ own software and hardware failures. In federated learning, the parameter server may also be faulty during gradient collection and aggregation, mainly including gradient-based training data inference and model parameter faulty update. The above problems may lead to reduced accuracy of federated learning model training, leakage of client privacy, etc. Existing research enhances the robustness of federated learning by exploiting the decentralization and immutability of Blockchain. For untrusted clients, most research is based on Byzantine fault tolerance to defend against clients indiscriminately, and may cause model accuracy reduction. In addition, most of the research focus on unencrypted gradients, and there is insufficient research on dealing with client anomalies in the case of gradient encryption. For untrusted parameter servers, existing research has problems in energy overhead and scalability. Aiming at the problems above, this paper studies the robustness of federated learning, and proposes a blockchain-based federated learning parameter update architecture PUS-FL. Through experiments simulating distributed machine learning on neural networks, we demonstrate that the anomaly detection algorithm of PUS-FL outperforms conventional gradient filters including geometric median, Multi-Krum and trimmed mean. In addition, our experiments also verify that the scalability-enhanced parameter aggregation consensus algorithm proposed in this paper(SE-PBFT) improves consensus scalability by reducing communication complexity.},
	booktitle = {2022 52nd {Annual} {IEEE}/{IFIP} {International} {Conference} on {Dependable} {Systems} and {Networks} {Workshops} ({DSN}-{W})},
	author = {Liu, Shu and Shang, Yanlei},
	month = jun,
	year = {2022},
	note = {ISSN: 2325-6664},
	keywords = {Blockchain, Byzantine Attack, Collaborative work, Consensus Algorithm, Fault tolerant systems, Federated learning, Inference algorithms, Machine learning, Privacy, Robustness, Scalability, Trusted Computing},
	pages = {37--43},
}

@inproceedings{manyadza_fl-finder_2022,
	title = {{FL}-finder: {Detecting} {Unknown} {Network} {Anomaly} in {Federated} {Learning}},
	shorttitle = {{FL}-finder},
	doi = {10.1109/ICAIBD55127.2022.9820480},
	abstract = {The emergence of federated learning has ensured data and privacy security in deep learning models while enabling models to train more efficiently. However, the transmission of network parameters in federated learning may be subject to attacks by unknown anomalies. In this paper, we attempted to detect unknown anomalies in transmitted parameters in federated learning. We designed and implemented F1-finder, an unknown network anomaly detection framework in federated learning, which detects anomalies based on incremental learning. It retains the unknown anomalies to its prior knowledge base using the network updater, and adopts an online mode that reports new anomalies in a real-time. Extensive experimental results show that our model increased the average accuracy of unknown anomaly detection by 10.4\% and the average F1-Score improved to 19\%.},
	booktitle = {2022 5th {International} {Conference} on {Artificial} {Intelligence} and {Big} {Data} ({ICAIBD})},
	author = {Manyadza, Tinashe Justice and Du, Haizhou and Wang, Shiwei and Yang, Wenbin and Chen, Cheng and Tian, Fei},
	month = may,
	year = {2022},
	keywords = {Collaborative work, Data models, Detectors, Energy consumption, Federated Learning, Incremental learning, Knowledge based systems, Learning (artificial intelligence), Prior Knowledge, Real-time systems, Unknown Anomaly Detection},
	pages = {593--597},
}

@article{miao_privacy-preserving_2022,
	title = {Privacy-{Preserving} {Byzantine}-{Robust} {Federated} {Learning} via {Blockchain} {Systems}},
	volume = {17},
	issn = {1556-6021},
	doi = {10.1109/TIFS.2022.3196274},
	abstract = {Federated learning enables clients to train a machine learning model jointly without sharing their local data. However, due to the centrality of federated learning framework and the untrustworthiness of clients, traditional federated learning solutions are vulnerable to poisoning attacks from malicious clients and servers. In this paper, we aim to mitigate the impact of the central server and malicious clients by designing a Privacy-preserving Byzantine-robust Federated Learning (PBFL) scheme based on blockchain. Specifically, we use cosine similarity to judge the malicious gradients uploaded by malicious clients. Then, we adopt fully homomorphic encryption to provide secure aggregation. Finally, we use blockchain system to facilitate transparent processes and implementation of regulations. Our formal analysis proves that our scheme achieves convergence and provides privacy protection. Our extensive experiments on different datasets demonstrate that our scheme is robust and efficient. Even if the root dataset is small, our scheme can achieve the same efficiency as FedSGD.},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Miao, Yinbin and Liu, Ziteng and Li, Hongwei and Choo, Kim-Kwang Raymond and Deng, Robert H.},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Blockchains, Collaborative work, Computational modeling, Federated learning, Privacy, Resists, Servers, Training, blockchain, fully homomorphic encryption, poisoning attacks},
	pages = {2848--2861},
}

@article{ng_reputation-aware_2022,
	title = {Reputation-{Aware} {Hedonic} {Coalition} {Formation} for {Efficient} {Serverless} {Hierarchical} {Federated} {Learning}},
	volume = {33},
	issn = {1558-2183},
	doi = {10.1109/TPDS.2021.3139039},
	abstract = {Amid growing concerns on data privacy, Federated Learning (FL) has emerged as a promising privacy preserving distributed machine learning paradigm. Given that the FL network is expected to be implemented at scale, several studies have proposed system architectures towards improving the network scalability and efficiency. Specifically, the Hierarchical FL (HFL) network utilizes cluster heads, e.g., base stations, for the intermediate aggregation and relay of model parameters. Serverless FL is also proposed recently, in which the data owners, i.e., workers, exchange the local model parameters among a neighborhood of workers. This decentralized approach reduces the risk of a single point of failure but inevitably incurs significant communication overheads. To achieve the best of both worlds, we propose the Serverless Hierarchical Federated Learning (SHFL) framework in this article. The SHFL framework adopts a two-layer system architecture. In the lower layer, the FL workers are grouped into clusters under cluster heads. In the upper layer, the cluster heads exchange the intermediate parameters with their one-hop neighbors without the aid of a central server. To improve the sustainable efficiency of the FL system while taking into account the incentive design for workers’ marginal contributions in the system, we propose the reputation-aware hedonic coalition formation game in this article. Specifically, the workers are rewarded for their marginal contribution to the cluster, whereas the reputation opinions of each cluster head is updated in a decentralized manner, thereby deterring malicious behaviors by the cluster head. This improves the performance of the network since cluster heads with higher reputation scores are more reliable in relaying the intermediate model parameters. The simulation results show that our proposed hedonic coalition formation algorithm converges to a Nash-stable partition and improves the network efficiency.},
	number = {11},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Ng, Jer Shyuan and Lim, Wei Yang Bryan and Xiong, Zehui and Cao, Xianbin and Jin, Jiangming and Niyato, Dusit and Leung, Cyril and Miao, Chunyan},
	month = nov,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Parallel and Distributed Systems},
	keywords = {Base stations, Collaborative work, Computational modeling, Costs, Federated learning, Magnetic heads, Servers, Training, decentralized edge intelligence, hedonic coalition formation, serverless federated learning},
	pages = {2675--2686},
}

@article{nguyen_federated_2022,
	title = {Federated {Learning} for {Smart} {Healthcare}: {A} {Survey}},
	volume = {55},
	issn = {0360-0300},
	shorttitle = {Federated {Learning} for {Smart} {Healthcare}},
	url = {https://doi.org/10.1145/3501296},
	doi = {10.1145/3501296},
	abstract = {Recent advances in communication technologies and the Internet-of-Medical-Things (IOMT) have transformed smart healthcare enabled by artificial intelligence (AI). Traditionally, AI techniques require centralized data collection and processing that may be infeasible in realistic healthcare scenarios due to the high scalability of modern healthcare networks and growing data privacy concerns. Federated Learning (FL), as an emerging distributed collaborative AI paradigm, is particularly attractive for smart healthcare, by coordinating multiple clients (e.g., hospitals) to perform AI training without sharing raw data. Accordingly, we provide a comprehensive survey on the use of FL in smart healthcare. First, we present the recent advances in FL, the motivations, and the requirements of using FL in smart healthcare. The recent FL designs for smart healthcare are then discussed, ranging from resource-aware FL, secure and privacy-aware FL to incentive FL and personalized FL. Subsequently, we provide a state-of-the-art review on the emerging applications of FL in key healthcare domains, including health data management, remote health monitoring, medical imaging, and COVID-19 detection. Several recent FL-based smart healthcare projects are analyzed, and the key lessons learned from the survey are also highlighted. Finally, we discuss interesting research challenges and possible directions for future FL research in smart healthcare.},
	number = {3},
	urldate = {2023-03-11},
	journal = {ACM Computing Surveys},
	author = {Nguyen, Dinh C. and Pham, Quoc-Viet and Pathirana, Pubudu N. and Ding, Ming and Seneviratne, Aruna and Lin, Zihuai and Dobre, Octavia and Hwang, Won-Joo},
	year = {2022},
	keywords = {Federated learning, privacy, smart healthcare},
	pages = {60:1--60:37},
}

@misc{severi_network-level_2022,
	title = {Network-{Level} {Adversaries} in {Federated} {Learning}},
	url = {http://arxiv.org/abs/2208.12911},
	abstract = {Federated learning is a popular strategy for training models on distributed, sensitive data, while preserving data privacy. Prior work identiﬁed a range of security threats on federated learning protocols that poison the data or the model. However, federated learning is a networked system where the communication between clients and server plays a critical role for the learning task performance. We highlight how communication introduces another vulnerability surface in federated learning and study the impact of network-level adversaries on training federated learning models. We show that attackers dropping the network trafﬁc from carefully selected clients can signiﬁcantly decrease model accuracy on a target population. Moreover, we show that a coordinated poisoning campaign from a few clients can amplify the dropping attacks. Finally, we develop a server-side defense which mitigates the impact of our attacks by identifying and up-sampling clients likely to positively contribute towards target accuracy. We comprehensively evaluate our attacks and defenses on three datasets, assuming encrypted communication channels and attackers with partial visibility of the network.},
	language = {en},
	urldate = {2022-09-05},
	publisher = {arXiv},
	author = {Severi, Giorgio and Jagielski, Matthew and Yar, Gökberk and Wang, Yuxuan and Oprea, Alina and Nita-Rotaru, Cristina},
	month = aug,
	year = {2022},
	note = {arXiv:2208.12911 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Networking and Internet Architecture},
}

@misc{ramirez_poisoning_2022,
	title = {Poisoning {Attacks} and {Defenses} on {Artificial} {Intelligence}: {A} {Survey}},
	shorttitle = {Poisoning {Attacks} and {Defenses} on {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/2202.10276},
	doi = {10.48550/arXiv.2202.10276},
	abstract = {Machine learning models have been widely adopted in several fields. However, most recent studies have shown several vulnerabilities from attacks with a potential to jeopardize the integrity of the model, presenting a new window of research opportunity in terms of cyber-security. This survey is conducted with a main intention of highlighting the most relevant information related to security vulnerabilities in the context of machine learning (ML) classifiers; more specifically, directed towards training procedures against data poisoning attacks, representing a type of attack that consists of tampering the data samples fed to the model during the training phase, leading to a degradation in the models accuracy during the inference phase. This work compiles the most relevant insights and findings found in the latest existing literatures addressing this type of attacks. Moreover, this paper also covers several defense techniques that promise feasible detection and mitigation mechanisms, capable of conferring a certain level of robustness to a target model against an attacker. A thorough assessment is performed on the reviewed works, comparing the effects of data poisoning on a wide range of ML models in real-world conditions, performing quantitative and qualitative analyses. This paper analyzes the main characteristics for each approach including performance success metrics, required hyperparameters, and deployment complexity. Moreover, this paper emphasizes the underlying assumptions and limitations considered by both attackers and defenders along with their intrinsic properties such as: availability, reliability, privacy, accountability, interpretability, etc. Finally, this paper concludes by making references of some of main existing research trends that provide pathways towards future research directions in the field of cyber-security.},
	urldate = {2022-09-01},
	publisher = {arXiv},
	author = {Ramirez, Miguel A. and Kim, Song-Kyoo and Hamadi, Hussam Al and Damiani, Ernesto and Byon, Young-Ji and Kim, Tae-Yeon and Cho, Chung-Suk and Yeun, Chan Yeob},
	month = feb,
	year = {2022},
	note = {arXiv:2202.10276 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
}

@misc{sun_dpauc_2022,
	title = {{DPAUC}: {Differentially} {Private} {AUC} {Computation} in {Federated} {Learning}},
	shorttitle = {{DPAUC}},
	url = {http://arxiv.org/abs/2208.12294},
	abstract = {Federated learning (FL) has gained signiﬁcant attention recently as a privacyenhancing tool to jointly train a machine learning model by multiple participants. The prior work on FL has mostly studied how to protect label privacy during model training. However, model evaluation in FL might also lead to potential leakage of private label information. In this work, we propose an evaluation algorithm that can accurately compute the widely used AUC (area under the curve) metric when using the label differential privacy (DP) in FL. Through extensive experiments, we show our algorithms can compute accurate AUCs compared to the ground truth.},
	language = {en},
	urldate = {2022-09-05},
	publisher = {arXiv},
	author = {Sun, Jiankai and Yang, Xin and Yao, Yuanshun and Xie, Junyuan and Wu, Di and Wang, Chong},
	month = aug,
	year = {2022},
	note = {arXiv:2208.12294 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@article{song_reputation-based_2022,
	title = {Reputation-{Based} {Federated} {Learning} for {Secure} {Wireless} {Networks}},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2021.3079104},
	abstract = {The dilemma between the ever-increasing demands for data processing, and the limited capabilities of mobile devices in a wireless communication system calls for the appearance of federated learning (FL). As a distributed machine learning (ML) method, FL executes in an iterative manner by distributing the global model parameters and aggregating the local model parameters, which avoids the transmission of huge raw data and preserves data privacy during the training process. However, since FL cannot control the local training and transmission process, this gives malicious users the opportunity to deteriorate the global aggregation. We adopt a reputation model based on beta distribution function to measure the credibility of local users, and propose a reputation-based scheduling policy with user fairness constraint. By taking into account the impact of wireless channel conditions and malicious attack features, we derive tractable expressions for the convergence rate of FL in a wireless setting. Moreover, we validate the superiority of the proposed reputation-based scheduling policy via numerical analysis and empirical simulations. The results show that the proposed secure wireless FL framework can not only distinguish malicious users from normal users but also effectively defend against several typical attack types featured in attack intensity and attack frequency. The analysis also reveals that the effect of average attack intensity on the convergence performance of FL is dominated by the percentage of malicious user equipments (UEs), and imposes even greater negative effect on the convergence performance of FL as the percentage of malicious UEs increases.},
	number = {2},
	journal = {IEEE Internet of Things Journal},
	author = {Song, Zhendong and Sun, Hongguang and Yang, Howard H. and Wang, Xijun and Zhang, Yan and Quek, Tony Q. S.},
	month = jan,
	year = {2022},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Communication system security, Convergence, Convergence analysis, Data models, Reliability, Scheduling, Training, Wireless networks, federated learning (FL), malicious users, reputation-based scheduling policy, secure wireless networks},
	pages = {1212--1226},
}

@article{sun_data_2022,
	title = {Data {Poisoning} {Attacks} on {Federated} {Machine} {Learning}},
	volume = {9},
	issn = {2327-4662, 2372-2541},
	url = {https://ieeexplore.ieee.org/document/9618642/},
	doi = {10.1109/JIOT.2021.3128646},
	language = {en},
	number = {13},
	urldate = {2023-12-04},
	journal = {IEEE Internet of Things Journal},
	author = {Sun, Gan and Cong, Yang and Dong, Jiahua and Wang, Qiang and Lyu, Lingjuan and Liu, Ji},
	month = jul,
	year = {2022},
	pages = {11365--11375},
}

@article{tan_reputation-aware_2022,
	title = {Reputation-{Aware} {Federated} {Learning} {Client} {Selection} based on {Stochastic} {Integer} {Programming}},
	issn = {2332-7790},
	doi = {10.1109/TBDATA.2022.3191332},
	abstract = {Federated Learning(FL) has attracted wide research interest due to its potential in building machine learning models while preserving users' data privacy. However, due to the distributive nature of FL, it is vulnerable to misbehavior from participating worker nodes. Thus, it is important to select clients to participate in FL. Recent studies on FL client selection focus on the perspective of improving model training efficiency and performance, without holistically considering potential misbehavior and the cost of hiring. To bridge this gap, we propose a first-of-its-kind reputation-aware Stochastic integer programming-based FL Client Selection method (SCS). It can optimally select and compensate clients with different reputation profiles. Extensive experiments show that SCS achieves the most advantageous performance-cost trade-off compared to other existing state-of-the-art approaches.},
	journal = {IEEE Transactions on Big Data},
	author = {Tan, Xavier and Ng, Wei Chong and Lim, Wei Yang Bryan and Xiong, Zehui and Niyato, Dusit and Yu, Han},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Big Data},
	keywords = {Biological system modeling, Computational modeling, Costs, Data models, Federated learning, Stochastic processes, Training, Uncertainty, client selection, reputation, stochastic integer programming},
	pages = {1--12},
}

@article{tian_comprehensive_2022,
	title = {A {Comprehensive} {Survey} on {Poisoning} {Attacks} and {Countermeasures} in {Machine} {Learning}},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3551636},
	doi = {10.1145/3551636},
	abstract = {The prosperity of machine learning has been accompanied by increasing attacks on the training process. Among them, poisoning attacks have become an emerging threat during model training. Poisoning attacks have profound impacts on the target models, e.g., making them unable to converge or manipulating their prediction results. Moreover, the rapid development of recent distributed learning frameworks, especially federated learning, has further stimulated the development of poisoning attacks. Defending against poisoning attacks is challenging and urgent. However, the systematic review from a unified perspective remains blank. This survey provides an in-depth and up-to-date overview of poisoning attacks and corresponding countermeasures in both centralized and federated learning. We firstly categorize attack methods based on their goals. Secondly, we offer detailed analysis of the differences and connections among the attack techniques. Furthermore, we present countermeasures in different learning framework and highlight their advantages and disadvantages. Finally, we discuss the reasons for the feasibility of poisoning attacks and address the potential research directions from attacks and defenses perspectives, separately.},
	urldate = {2022-09-01},
	journal = {ACM Computing Surveys},
	author = {Tian, Zhiyi and Cui, Lei and Liang, Jie and Yu, Shui},
	year = {2022},
	note = {Just Accepted},
	keywords = {Deep learning, backdoor attack, federated learning, poisoning attack},
}

@inproceedings{wang_flare_2022,
	address = {Nagasaki Japan},
	title = {{FLARE}: {Defending} {Federated} {Learning} against {Model} {Poisoning} {Attacks} via {Latent} {Space} {Representations}},
	isbn = {978-1-4503-9140-5},
	shorttitle = {{FLARE}},
	url = {https://dl.acm.org/doi/10.1145/3488932.3517395},
	doi = {10.1145/3488932.3517395},
	abstract = {Federated learning (FL) has been shown vulnerable to a new class of adversarial attacks, known as model poisoning attacks (MPA), where one or more malicious clients try to poison the global model by sending carefully crafted local model updates to the central parameter server. Existing defenses that have been fixated on analyzing model parameters show limited effectiveness in detecting such carefully crafted poisonous models. In this work, we propose FLARE, a robust model aggregation mechanism for FL, which is resilient against state-of-the-art MPAs. Instead of solely depending on model parameters, FLARE leverages the penultimate layer representations (PLRs) of the model for characterizing the adversarial influence on each local model update. PLRs demonstrate a better capability to differentiate malicious models from benign ones than model parameter-based solutions. We further propose a trust evaluation method that estimates a trust score for each model update based on pairwise PLR discrepancies among all model updates. Under the assumption that honest clients make up the majority, FLARE assigns a trust score to each model update in a way that those far from the benign cluster are assigned low scores. FLARE then aggregates the model updates weighted by their trust scores and finally updates the global model. Extensive experimental results demonstrate the effectiveness of FLARE in defending FL against various MPAs, including semantic backdoor attacks, trojan backdoor attacks, and untargeted attacks, and safeguarding the accuracy of FL.},
	language = {en},
	urldate = {2022-07-05},
	booktitle = {Proceedings of the 2022 {ACM} on {Asia} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Wang, Ning and Xiao, Yang and Chen, Yimin and Hu, Yang and Lou, Wenjing and Hou, Y. Thomas},
	month = may,
	year = {2022},
	pages = {946--958},
}

@article{wang_threats_2022,
	title = {Threats to {Training}: {A} {Survey} of {Poisoning} {Attacks} and {Defenses} on {Machine} {Learning} {Systems}},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Threats to {Training}},
	url = {https://dl.acm.org/doi/10.1145/3538707},
	doi = {10.1145/3538707},
	abstract = {Machine learning (ML) has been universally adopted for automated decisions in a variety of ields, including recognition and classiication applications, recommendation systems, natural language processing, etc. However, in the light of high expenses on training data and computing resources, recent years have witnessed a rapid increase in outsourced ML training, either partially or completely, which provides vulnerabilities for adversaries to exploit. A prime threat in training phase is called poisoning attack, where adversaries strive to subvert the behavior of machine learning systems by poisoning training data or other means of interference. Although a growing number of relevant studies have been proposed, the research among poisoning attack is still overly scattered, with each paper focusing on a particular task in a speciic domain. In this survey, we summarize and categorize existing attack methods and corresponding defenses, as well as demonstrate compelling application scenarios, thus providing a uniied framework to analyze poisoning attacks. Besides, we also discuss the main limitations of current works, along with the corresponding future directions to facilitate further researches. Our ultimate motivation is to provide a comprehensive and self-contained survey of this growing ield of research and lay the foundation for a more standardized approach to reproducible studies. CCS Concepts: · Theory of computation → Adversarial learning; · Security and privacy → Systems security.},
	language = {en},
	urldate = {2022-09-01},
	journal = {ACM Computing Surveys},
	author = {Wang, Zhibo and Ma, Jingjing and Wang, Xue and Hu, Jiahui and Qin, Zhan and Ren, Kui},
	month = may,
	year = {2022},
	pages = {3538707},
}

@article{yang_personalized_2022,
	title = {Personalized {Federated} {Learning} on {Non}-{IID} {Data} via {Group}-{Based} {Meta}-{Learning}},
	issn = {1556-4681},
	url = {https://doi.org/10.1145/3558005},
	doi = {10.1145/3558005},
	abstract = {Personalized federated learning (PFL) has emerged as a paradigm to provide a personalized model that can fit the local data distribution of each client. One natural choice for PFL is to leverage the fast adaptation capability of meta-learning, where it first obtains a single global model, and each client achieves a personalized model by fine-tuning the global one with its local data. However, existing meta-learning-based approaches implicitly assume that the data distribution among different clients is similar, which may not be applicable due to the property of data heterogeneity in federated learning. In this work, we propose a Group-based Federated Meta-Learning framework, called G-FML, which adaptively divides the clients into groups based on the similarity of their data distribution, and the personalized models are obtained with meta-learning within each group. In particular, we develop a simple yet effective grouping mechanism to adaptively partition the clients into multiple groups. Our mechanism ensures that each group is formed by the clients with similar data distribution such that the group-wise meta-model can achieve “personalization” at large. By doing so, our framework can be generalized to a highly heterogeneous environment. We evaluate the effectiveness of our proposed G-FML framework on three heterogeneous benchmarking datasets. The experimental results show that our framework improves the model accuracy by up to 13.15\% relative to the state-of-the-art federated meta-learning.},
	urldate = {2022-08-29},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Yang, Lei and Huang, Jiaming and Lin, Wanyu and Cao, Jiannong},
	year = {2022},
	note = {Just Accepted},
	keywords = {Federated learning, clustering methods, meta learning, neural networks},
}

@inproceedings{you_poisoning_2022,
	title = {Poisoning attack detection using client historical similarity in non-iid environments},
	doi = {10.1109/Confluence52989.2022.9734158},
	abstract = {Federated learning has drawn widespread attention as privacy-preserving solution, which has a protective effect on data security and privacy. It has unique distributed machine learning mechanism, namely model sharing instead of data sharing. However, the mechanism also leads to the fact that malicious clients can easily train local model based on poisoned data and upload it to the server for contaminating the global model, thus severely hampering the development of federated learning. In this paper, we build a federated learning system and simulate heterogeneous data on each client for training. Although we cannot directly differentiate malicious customers by the uploaded model in a heterogeneous data environment, by experiments we found some features that are used to distinguish malicious customers from benign customers during training. Given above, we propose a federated learning poisoning attack detection method for detecting malicious clients and ensuring aggregation quality. The method can filter out anomaly models by comparing the similarity of the historical changes of clients and gradually identifying attacker clients through reputation mechanism. We experimentally demonstrate that the method significantly improves the performance of the global model even when the proportion of malicious clients is as high as one-third.},
	booktitle = {2022 12th {International} {Conference} on {Cloud} {Computing}, {Data} {Science} \& {Engineering} ({Confluence})},
	author = {You, XinTong and Liu, Zhengqi and Yang, Xu and Ding, Xuyang},
	month = jan,
	year = {2022},
	keywords = {Collaborative work, Distributed Machine Learning, Distributed databases, Euclidean distance, Federated Learning, Heterogeneous Data, Machine learning, Market research, Poisoning Attack Detection, Resists, Training},
	pages = {439--447},
}

@article{zhou_differentially_2022,
	title = {A {Differentially} {Private} {Federated} {Learning} {Model} against {Poisoning} {Attacks} in {Edge} {Computing}},
	issn = {1941-0018},
	doi = {10.1109/TDSC.2022.3168556},
	abstract = {Federated learning is increasingly popular, as it allows us to circumvent challenges due to data islands, by training a global model using data from one or more data owners/sources. However, in edge computing, resource-constrained end devices are vulnerable to be compromised and abused to facilitate poisoning attacks. Privacy-preserving is another important property to consider when dealing with sensitive user data on end devices. Most existing approaches only consider either defending against poisoning attacks or supporting privacy, but not both properties simultaneously. In this paper, we propose a differentially private federated learning model against poisoning attacks, designed for edge computing deployment. First, we design a weight-based algorithm to perform anomaly detection on the parameters uploaded by end devices in edge nodes, which improves detection rate using only small-size validation datasets and minimizes the communication cost. Then, differential privacy technology is leveraged to protect the privacy of both data and model in an edge computing setting. We also evaluate and compare the detection performance in the presence of random and customized malicious end devices with the state-of-the-art, in terms of attack resiliency, communication and computation costs. Experimental results demonstrate that our scheme can achieve an optimal tradeoff between security, efficiency and accuracy.},
	journal = {IEEE Transactions on Dependable and Secure Computing},
	author = {Zhou, Jun and Wu, Nan and Wang, Yisong and Gu, Shouzhen and Cao, Zhenfu and Dong, Xiaolei and Choo, Kim-Kwang Raymond},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Dependable and Secure Computing},
	keywords = {Collaborative work, Computational modeling, Data models, Differential privacy, Edge computing, Federated learning, High-practicability, Image edge detection, Poisoning attack, Privacy, Training},
	pages = {1--1},
}

@inproceedings{sharafaldin_toward_2023,
	title = {Toward {Generating} a {New} {Intrusion} {Detection} {Dataset} and {Intrusion} {Traffic} {Characterization}},
	isbn = {978-989-758-282-0},
	url = {https://www.scitepress.org/Link.aspx?doi=10.5220/0006639801080116},
	abstract = {Digital Library},
	urldate = {2023-03-22},
	author = {Sharafaldin, Iman and Lashkari, Arash Habibi and Ghorbani, Ali A.},
	month = mar,
	year = {2023},
	pages = {108--116},
}

@article{singh_fair_2023,
	title = {Fair detection of poisoning attacks in federated learning on non-i.i.d. data},
	issn = {1573-756X},
	url = {https://doi.org/10.1007/s10618-022-00912-6},
	doi = {10.1007/s10618-022-00912-6},
	abstract = {Reconciling machine learning with individual privacy is one of the main motivations behind federated learning (FL), a decentralized machine learning technique that aggregates partial models trained by clients on their own private data to obtain a global deep learning model. Even if FL provides stronger privacy guarantees to the participating clients than centralized learning collecting the clients’ data in a central server, FL is vulnerable to some attacks whereby malicious clients submit bad updates in order to prevent the model from converging or, more subtly, to introduce artificial bias in the classification (poisoning). Poisoning detection techniques compute statistics on the updates to identify malicious clients. A downside of anti-poisoning techniques is that they might lead to discriminate minority groups whose data are significantly and legitimately different from those of the majority of clients. This would not only be unfair, but would yield poorer models that would fail to capture the knowledge in the training data, especially when data are not independent and identically distributed (non-i.i.d.). In this work, we strive to strike a balance between fighting poisoning and accommodating diversity to help learning fairer and less discriminatory federated learning models. In this way, we forestall the exclusion of diverse clients while still ensuring detection of poisoning attacks. Empirical work on three data sets shows that employing our approach to tell legitimate from malicious updates produces models that are more accurate than those obtained with state-of-the-art poisoning detection techniques. Additionally, we explore the impact of our proposal on the performance of models on non-i.i.d local training data.},
	language = {en},
	urldate = {2023-08-06},
	journal = {Data Mining and Knowledge Discovery},
	author = {Singh, Ashneet Khandpur and Blanco-Justicia, Alberto and Domingo-Ferrer, Josep},
	month = jan,
	year = {2023},
	keywords = {Fairness, Federated learning, Minorities., Privacy, Security},
}

@inproceedings{xu_efficient_2023,
	title = {An {Efficient} {2D} {Method} for {Training} {Super}-{Large} {Deep} {Learning} {Models}},
	doi = {10.1109/IPDPS54959.2023.00031},
	abstract = {Since the rise of Transformer [22] and BERT [6], large language models [7], [12] have been proposed and shown unprecedented performance in tasks like translation, classification, and text generation. However, due to the memory constraint, model parallelism must be used to split the model across multiple processors. Inter-layer partition, intra-layer partition, and sparse activation are the major approaches to achieve model parallelism. Among them, inter-layer partition [10], [11] often requires the model to be explicitly expressed as a stack of sub-modules, the number of which equals to the number of processors, and would introduce either gradient staleness or bubble overhead; while the sparse activation [12] is primarily designed for Google TPU cluster and hard to deploy on GPU servers, intra-layer partition [17], especially Megatron-LM [18], can be easily deployed on GPU servers and has been adopted in subsequent works like Turing-NLG and M6. Though as pioneers of intra-layer parallelism, they still show memory redundancy and sub-optimal communication efficiency, which reveals the space for further improvements. In this work, we leverage SUMMA [21] and propose Optimus, a highly efficient and scalable paradigm for training super-large language models. In Optimus, activations and gradients are partitioned and distributed along processors all the way through forward and backward propagations, with hardly any memory redundancy. The isoefficiency of communication in pure model parallelism improves from W p3 for Megatron-LM, to W{\textbackslash}sim ({\textbackslash}sqrt p {\textbackslash}log p){\textasciicircum}3 for our Optimus. This framework is implemented with open-source deep learning framework, PyTorch, and consolidates existing techniques such as mixed precision training [13], activation checkpointing [5], and data parallelism. In experiments on TACC Frontera supercomputers, Optimus shows 1.48× the speed for training, 1.78× speed for inference, and 8× the maximum batch size over Megatron-LM on 64 GPUs in pure model parallelism; and 1.73× speed for training, 2.32× speed for inference with data parallelism size equaling 2 on 128 GPUs. In pure model parallelism, Optimus surpasses Megatron-LM in weak scaling efficiency by a great margin, and shows an extraordinary increasing strong scaling efficiency. Optimus would facilitate the scaling of language models and serve as a strong thrust in the space exploration of artificial intelligence.},
	booktitle = {2023 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} ({IPDPS})},
	author = {Xu, Qifan and You, Yang},
	month = may,
	year = {2023},
	note = {ISSN: 1530-2075},
	keywords = {Deep learning, Graphics processing units, Memory management, Parallel processing, Redundancy, Training, Transformers, distributed training, matrix-matrix multiplication, natural language processing, neural networks},
	pages = {222--232},
}

@inproceedings{wu_qos-aware_2023,
	title = {{QoS}-{Aware} and {Cost}-{Efficient} {Dynamic} {Resource} {Allocation} for {Serverless} {ML} {Workflows}},
	doi = {10.1109/IPDPS54959.2023.00093},
	abstract = {Machine Learning (ML) workflows are increasingly deployed on serverless computing platforms to benefit from their elasticity and fine-grain pricing. Proper resource allocation is crucial to achieve fast and cost-efficient execution of serverless ML workflows (specially for hyperparameter tuning and model training). Unfortunately, existing resource allocation methods are static, treat functions equally, and rely on offline prediction, which limit their efficiency. In this paper, we introduce CE-scaling – a Cost-Efficient autoscaling framework for serverless ML work-flows. During the hyperparameter tuning, CE-scaling partitions resources across stages according to their exact usage to minimize resource waste. Moreover, it incorporates an online prediction method to dynamically adjust resources during model training. We implement and evaluate CE-scaling on AWS Lambda using various ML models. Evaluation results show that compared to state-of-the-art static resource allocation methods, CE-scaling can reduce the job completion time and the monetary cost by up to 63\% and 41\% for hyperparameter tuning, respectively; and by up to 58\% and 38\% for model training.},
	booktitle = {2023 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} ({IPDPS})},
	author = {Wu, Hao and Deng, Junxiao and Fan, Hao and Ibrahim, Shadi and Wu, Song and Jin, Hai},
	month = may,
	year = {2023},
	note = {ISSN: 1530-2075},
	keywords = {Computational modeling, Costs, Predictive models, Pricing, Quality of service, Serverless computing, Training, distributed machine learning, resource provisioning, serverless computing},
	pages = {886--896},
}

@inproceedings{ye_pfedsa_2023,
	title = {{PFedSA}: {Personalized} {Federated} {Multi}-{Task} {Learning} via {Similarity} {Awareness}},
	shorttitle = {{PFedSA}},
	doi = {10.1109/IPDPS54959.2023.00055},
	abstract = {Federated Learning (FL) constructs a distributed machine learning framework that involves multiple remote clients collaboratively training models. However in real-world situations, the emergence of non-Independent and Identically Distributed (non-IID) data makes the global model generated by traditional FL algorithms no longer meet the needs of all clients, and the accuracy is greatly reduced. In this paper, we propose a personalized federated multi-task learning method via similarity awareness (PFedSA), which captures the similarity between client data through model parameters uploaded by clients, thus facilitating collaborative training of similar clients and providing personalized models based on each client’s data distribution. Specifically, it generates the intrinsic cluster structure among clients and introduces personalized patch layers into the cluster to personalize the cluster model. PFedSA also maintains the generalization ability of models, which allows each client to benefit from nodes with similar data distributions when training data, and the greater the similarity, the more benefit. We evaluate the performance of the PFedSA method using MNIST, EMNIST and CIFAR10 datasets, and investigate the impact of different data setting schemes on the performance of PFedSA. The results show that in all data setting scenarios, the PFedSA method proposed in this paper can achieve the best personalization performance, having more clients with higher accuracy, and it is especially effective when the client’s data is non-IID.},
	booktitle = {2023 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} ({IPDPS})},
	author = {Ye, Chuyao and Zheng, Hao and Hu, Zhigang and Zheng, Meiguang},
	month = may,
	year = {2023},
	note = {ISSN: 1530-2075},
	keywords = {Collaboration, Distributed databases, Federated learning, Learning systems, Machine learning algorithms, Training, Training data, clustering, federated learning, multi-task learning, similarity awareness},
	pages = {480--488},
}

@inproceedings{zhang_dynasparse_2023,
	title = {Dynasparse: {Accelerating} {GNN} {Inference} through {Dynamic} {Sparsity} {Exploitation}},
	shorttitle = {Dynasparse},
	doi = {10.1109/IPDPS54959.2023.00032},
	abstract = {Graph Neural Network (GNN) inference is used in many real-world applications. Data sparsity in GNN inference, including sparsity in the input graph and the GNN model, offer opportunities to further speed up inference. Also, many pruning techniques have been proposed for model compression that increase the data sparsity of GNNs.We propose Dynasparse, a comprehensive hardware-software codesign on FPGA to accelerate GNN inference through dynamic sparsity exploitation. For this, we decouple the GNN computation kernels from the basic computation primitives, and explore hardware-software codesign as follows: 1) Hardware design: We propose a novel unified accelerator design on FPGA to efficiently execute various computation primitives. We develop a customized soft processor that is tightly coupled with the accelerator to execute a runtime system. Moreover, we develop efficient hardware mechanisms to profile the data sparsity and perform on-the-fly data format transformation to prepare the input data for various computation primitives; 2) Software design: We develop a runtime system that works synergistically with the accelerator to perform dynamic kernel-to-primitive mapping based on data sparsity. We implement Dynasparse on a state-of-the-art FPGA platform, Xilinx Alveo U250, and evaluate the design using widely used GNN models (GCN, GraphSAGE, GIN and SGC). For the above GNN models and various input graphs, the proposed accelerator and dynamic kernel-to-primitive mapping reduces the inference latency by 3.73× on the average compared with the static mapping strategies employed in the state-of-the-art GNN accelerators. Compared with state-of-the-art CPU (GPU) implementations, Dynasparse achieves up to 56.9× (2.37×) speedup in end-to-end latency. Compared with state-of-the-art FPGA implementations, Dynasparse achieves 2.7× speedup in accelerator execution latency.},
	booktitle = {2023 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} ({IPDPS})},
	author = {Zhang, Bingyi and Prasanna, Viktor},
	month = may,
	year = {2023},
	note = {ISSN: 1530-2075},
	keywords = {Computational modeling, Data models, Graph neural network, Graph neural networks, Graphics processing units, Hardware, Runtime, Software design, hardware architecture, hardware-software code-sign, runtime system},
	pages = {233--244},
}

@inproceedings{zhou_accelerating_2023,
	title = {Accelerating {Distributed} {Deep} {Learning} {Training} with {Compression} {Assisted} {Allgather} and {Reduce}-{Scatter} {Communication}},
	doi = {10.1109/IPDPS54959.2023.00023},
	abstract = {Fully Sharded Data Parallel (FSDP) technology achieves higher performance by scaling out data-parallel training of Deep Learning (DL) models. It shards the model parameters, gradients, and optimizer states of the model among multiple GPUs. Consequently, this requires data-intensive Allgather and Reduce-Scatter communication to share the model parameters, which becomes a bottleneck. Existing schemes that use GPU-aware MPI libraries are highly prone to saturating the interconnect bandwidth. Therefore, integrating GPU-based compression into MPI libraries has proven efficient to achieve faster training time. In this paper, we propose an optimized Ring algorithm of Allgather and Reduce-Scatter collectives that encompass an efficient collective-level online compression scheme. At the microbenchmark level, Allgather achieves benefits of up to 83.6\% and 30.3\% compared to the baseline and existing point-to-point-based compression in a state-of-the-art MPI library on modern GPU clusters. Reduce-Scatter achieves 88.1\% and 40.6\% compared to baseline and point-to-point compression, respectively. For distributed DL training with PyTorch-FSDP, our approach yields 31.7\% faster training than the baseline, and up to 12.5\% compared to the existing point-to-point-based compression while maintaining similar accuracy.},
	booktitle = {2023 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} ({IPDPS})},
	author = {Zhou, Qinghua and Anthony, Quentin and Xu, Lang and Shafi, Aamir and Abduljabbar, Mustafa and Subramoni, Hari and Panda, Dhabaleswar K. DK},
	month = may,
	year = {2023},
	note = {ISSN: 1530-2075},
	keywords = {Allgather, Bandwidth, Clustering algorithms, Compression, Deep Learning, Deep learning, Distributed databases, Distributed processing, FSDP, GPU-Aware MPI, Graphics processing units, Reduce-Scatter, Training},
	pages = {134--144},
}

@inproceedings{steinhardt_certified_2017,
	title = {Certified {Defenses} for {Data} {Poisoning} {Attacks}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/9d7311ba459f9e45ed746755a32dcd11-Abstract.html},
	abstract = {Machine learning systems trained on user-provided data are susceptible to data poisoning attacks, whereby malicious users inject false training data with the aim of corrupting the learned model. While recent work has proposed a number of attacks and defenses, little is understood about the worst-case loss of a defense in the face of a determined attacker. We address this by constructing approximate upper bounds on the loss across a broad family  of attacks, for defenders that first perform outlier removal followed by empirical risk minimization. Our approximation relies on two assumptions: (1) that the dataset is large enough for  statistical concentration between train and test error to hold, and (2) that outliers  within the clean (non-poisoned) data do not have a strong effect on the model. Our bound comes paired with a candidate attack that often nearly matches the upper bound, giving us a powerful tool for quickly assessing defenses on a given dataset. Empirically, we find that even under a simple defense, the MNIST-1-7 and Dogfish datasets are resilient to attack, while in contrast the IMDB sentiment dataset can be driven from 12\% to 23\% test error by adding only 3\% poisoned data.},
	urldate = {2024-03-06},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Steinhardt, Jacob and Koh, Pang Wei W and Liang, Percy S},
	year = {2017},
}

@incollection{yang_federated_2021,
	address = {Cham},
	title = {Federated {Learning}-{Based} {Intrusion} {Detection} in the {Context} of {IIoT} {Networks}: {Poisoning} {Attack} and {Defense}},
	volume = {13041},
	isbn = {978-3-030-92707-3 978-3-030-92708-0},
	shorttitle = {Federated {Learning}-{Based} {Intrusion} {Detection} in the {Context} of {IIoT} {Networks}},
	url = {https://link.springer.com/10.1007/978-3-030-92708-0_8},
	abstract = {The emerging of Federated Learning (FL) paradigm in training has been drawn much attention from research community because of the demand of privacy preservation in widespread machine learning adoption. This is more serious in the context of industrial Internet of Things (IIoT) with the distributed data resources and the sensitive local data in each data owner. FL in IIoT context can help to ensure the sensitive data from being exploited by adversaries while facilitating the acceptable performance by aggregating additional knowledge from distributed collaborators. Sharing the similar trend, Intrusion detection system (IDS) leveraging the FL approach can encourage the cooperation in building an eﬃcient privacy-preserving solution among multiple participants owning the sensitive network data. But a rogue collaborator can manipulate the local dataset and send malicious updates to the model aggregation, aiming to reduce the global model’s prediction accuracy rate. The reason for this case is that the collaborator is a compromised participant, or due to the weak defenses of the local training device. This paper introduces a FL-based IDS, named Fed-IDS which facilitates collaborative training between many organizations to enhance their robustness against diverse and unknown attacks in the context of IIoT. Next, we perform the poisoning attack against such an IDS, including label-ﬂipping strategy and Generative Adversarial Networks (GANs). Then, a validation approach is utilized as a countermeasure of rejecting the malicious updates to protect the global model from poisoning attacks. The experiments conducted on Kitsune, a real-world attack dataset, demonstrate the high eﬀectiveness of the validation function in Fed-IDS framework against data poisoning.},
	language = {en},
	urldate = {2024-03-05},
	booktitle = {Network and {System} {Security}},
	publisher = {Springer International Publishing},
	author = {Vy, Nguyen Chi and Quyen, Nguyen Huu and Duy, Phan The and Pham, Van-Hau},
	editor = {Yang, Min and Chen, Chao and Liu, Yang},
	year = {2021},
	doi = {10.1007/978-3-030-92708-0_8},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {131--147},
}

@article{yang_dependable_2023,
	title = {Dependable federated learning for {IoT} intrusion detection against poisoning attacks},
	volume = {132},
	issn = {0167-4048},
	url = {https://www.sciencedirect.com/science/article/pii/S0167404823002912},
	doi = {10.1016/j.cose.2023.103381},
	abstract = {Network intrusion detection methods based on federated learning (FL) and edge computing have great potential for protecting the cybersecurity of the Internet of Things. It overcomes the disadvantages of the traditional centralized method, such as high latency, overloaded network, and privacy leakage. At the same time, it can combine private data from multiple participants to train models, and the rich data can train more effective models. However, the inherent security vulnerabilities of the FL framework do not ensure the robustness of the global models trained collaboratively. Towards FL, each participant has access to model parameters and training data, and malicious participants can affect the global model by tampering with data or weights. This paper studies label-flipping attacks in FL-based IoT intrusion detection. We propose a lightweight detection mechanism to mitigate the impact of poisoning attacks on FL-based intrusion detection methods in IoT networks. The detection mechanism on a central server filters anomalous participants and excludes their uploaded models from the global model aggregation. Specifically, we propose a scoring mechanism for evaluating participants based on the loss of the local model and the training dataset size. Afterwards, the Manhattan similarity between each participant will be calculated according to the scores. Finally, the anomalous participants will be found by clustering algorithm for similarity cluster analysis. The experimental results show that our proposed detection method can defend against label-flipping attacks in FL. On the CIC-IDS-2017 dataset, our method can improve the accuracy of the intrusion detection model trained based on FL from 84.3\% to 97.1\%, while enhancing the protection of IoT network security.},
	urldate = {2024-03-04},
	journal = {Computers \& Security},
	author = {Yang, Run and He, Hui and Wang, Yulong and Qu, Yue and Zhang, Weizhe},
	month = sep,
	year = {2023},
	keywords = {Cyber-physical systems, Federated learning, Internet of thing, Label-flipping attacks, Network intrusion detection, obsidian},
	pages = {103381},
}

@inproceedings{mai_towards_2019,
	title = {Towards {Content}-{Centric} {Control} {Plane} {Supporting} {Efficient} {Anomaly} {Detection} {Functions}},
	doi = {10.23919/CNSM46954.2019.9012668},
	abstract = {Anomaly detection remains a challenging task due to both the ever more complex functions that need to be executed and the evolution of current networking devices which induces limitation of computational resources such as the Internet of Things (IoT). Furthermore, results of anomaly function computations can be repeated gradually over time or executed in neighboring nodes, thus leading to a waste of such limited computing resources in constrained nodes. To tackle these issues, the content-centric paradigm enhanced with computing features offers a promising solution to reduce the computation resources and finally improve the scalability of anomaly detection functions. In this paper, we propose a first step toward a content-oriented control plane which enables the distribution of the processing and the sharing of results of anomaly detection functions in the network. We present the way we leverage NFN to support Bayesian Network inference to detect anomalies in network traffic. The relevance and performance of our proposed approach are demonstrated by considering the Content Poisoning Attack (CPA) through numerous experiment data.},
	booktitle = {2019 15th {International} {Conference} on {Network} and {Service} {Management} ({CNSM})},
	author = {Mai, Hoang Long and Doyen, Guillaume and Mallouli, Wissam and de Oca, Edgardo Montes and Festor, Olivier},
	month = oct,
	year = {2019},
	note = {ISSN: 2165-963X},
	keywords = {Anomaly detection, Bayes methods, Bayesian Network, Computer architecture, Distributed anomaly detection, Inference algorithms, Internet of Things, Named Function Networking, Random variables, Security},
	pages = {1--9},
}

@article{miao_privacy-preserving_2022,
	title = {Privacy-{Preserving} {Byzantine}-{Robust} {Federated} {Learning} via {Blockchain} {Systems}},
	issn = {1556-6021},
	doi = {10.1109/TIFS.2022.3196274},
	abstract = {Federated learning enables clients to train a machine learning model jointly without sharing their local data. However, due to the centrality of federated learning framework and the untrustworthiness of clients, traditional federated learning solutions are vulnerable to poisoning attacks from malicious clients and servers. In this paper, we aim to mitigate the impact of the central server and malicious clients by designing a Privacy-preserving Byzantine-robust Federated Learning (PBFL) scheme based on blockchain. Specifically, we use cosine similarity to judge the malicious gradients uploaded by malicious clients. Then, we adopt fully homomorphic encryption to provide secure aggregation. Finally, we use blockchain system to facilitate transparent processes and implementation of regulations. Our formal analysis proves that our scheme achieves convergence and provides privacy protection. Our extensive experiments on different datasets demonstrate that our scheme is robust and efficient. Even if the root dataset is small, our scheme can achieve the same efficiency as FedSGD.},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Miao, Yinbin and Liu, Ziteng and Li, Hongwei and Choo, Kim-Kwang Raymond and Deng, Robert H.},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Blockchain, Blockchains, Collaborative work, Computational modeling, Federated Learning, Federated learning, Fully Homomorphic Encryption, Poisoning Attacks, Privacy, Resists, Servers, Training, blockchain, fully homomorphic encryption, poisoning attacks},
	pages = {1--1},
}

@article{liu_privacy-preserving_2022,
	title = {Privacy-{Preserving} {Aggregation} in {Federated} {Learning}: {A} {Survey}},
	shorttitle = {Privacy-{Preserving} {Aggregation} in {Federated} {Learning}},
	url = {http://arxiv.org/abs/2203.17005},
	abstract = {Over the recent years, with the increasing adoption of Federated Learning (FL) algorithms and growing concerns over personal data privacy, Privacy-Preserving Federated Learning (PPFL) has attracted tremendous attention from both academia and industry. Practical PPFL typically allows multiple participants to individually train their machine learning models, which are then aggregated to construct a global model in a privacy-preserving manner. As such, Privacy-Preserving Aggregation (PPAgg) as the key protocol in PPFL has received substantial research interest. This survey aims to ﬁll the gap between a large number of studies on PPFL, where PPAgg is adopted to provide a privacy guarantee, and the lack of a comprehensive survey on the PPAgg protocols applied in FL systems. In this survey, we review the PPAgg protocols proposed to address privacy and security issues in FL systems. The focus is placed on the construction of PPAgg protocols with an extensive analysis of the advantages and disadvantages of these selected PPAgg protocols and solutions. Additionally, we discuss the open-source FL frameworks that support PPAgg. Finally, we highlight important challenges and future research directions for applying PPAgg to FL systems and the combination of PPAgg with other technologies for further security improvement.},
	language = {en},
	urldate = {2023-04-03},
	author = {Liu, Ziyao and Guo, Jiale and Yang, Wenzhuo and Fan, Jiani and Lam, Kwok-Yan and Zhao, Jun},
	month = jul,
	year = {2022},
	note = {arXiv:2203.17005 [cs]},
	keywords = {Computer Science - Cryptography and Security},
}

@inproceedings{nguyen_poisoning_2020,
	address = {San Diego, CA},
	title = {Poisoning {Attacks} on {Federated} {Learning}-based {IoT} {Intrusion} {Detection} {System}},
	isbn = {978-1-891562-64-8},
	url = {https://www.ndss-symposium.org/wp-content/uploads/2020/04/diss2020-23003-paper.pdf},
	doi = {10.14722/diss.2020.23003},
	abstract = {Federated Learning (FL) is an appealing method for applying machine learning to large scale systems due to the privacy and efﬁciency advantages that its training mechanism provides. One important ﬁeld for FL deployment is emerging IoT applications. In particular, FL has been recently used for IoT intrusion detection systems where clients, e.g., a home security gateway, monitors trafﬁc data generated by IoT devices in its network, trains a local intrusion detection model, and send this model to a central entity, the aggregator, who then computes a global model (using the models of all gateways) that is distributed back to clients. This approach protects the privacy of users as it does not require local clients to share their potentially private IoT data with any other parties, and it is in general more efﬁcient than a centralized system. However, FL schemes have been subject to poising attacks, in particular to backdoor attacks.},
	language = {en},
	urldate = {2024-01-29},
	booktitle = {Proceedings 2020 {Workshop} on {Decentralized} {IoT} {Systems} and {Security}},
	publisher = {Internet Society},
	author = {Nguyen, Thien Duc and Rieger, Phillip and Miettinen, Markus and Sadeghi, Ahmad-Reza},
	year = {2020},
}

@inproceedings{fang_local_2020,
	title = {Local {Model} {Poisoning} {Attacks} to {Byzantine}-{Robust} {Federated} {Learning}},
	isbn = {978-1-939133-17-5},
	url = {https://www.usenix.org/conference/usenixsecurity20/presentation/fang},
	language = {en},
	urldate = {2023-02-23},
	author = {Fang, Minghong and Cao, Xiaoyu and Jia, Jinyuan and Gong, Neil},
	year = {2020},
	pages = {1605--1622},
}

@misc{Tuli2022,
	title = {{DRAGON}: {Decentralized} {Fault} {Tolerance} in {Edge} {Federations}},
	shorttitle = {{DRAGON}},
	url = {http://arxiv.org/abs/2208.07658},
	abstract = {Edge Federation is a new computing paradigm that seamlessly interconnects the resources of multiple edge service providers. A key challenge in such systems is the deployment of latency-critical and AI based resource-intensive applications in constrained devices. To address this challenge, we propose a novel memory-efﬁcient deep learning based model, namely generative optimization networks (GON). Unlike GANs, GONs use a single network to both discriminate input and generate samples, signiﬁcantly reducing their memory footprint. Leveraging the low memory footprint of GONs, we propose a decentralized faulttolerance method called DRAGON that runs simulations (as per a digital modeling twin) to quickly predict and optimize the performance of the edge federation. Extensive experiments with real-world edge computing benchmarks on multiple RaspberryPi based federated edge conﬁgurations show that DRAGON can outperform the baseline methods in fault-detection and Quality of Service (QoS) metrics. Speciﬁcally, the proposed method gives higher F1 scores for fault-detection than the best deep learning (DL) method, while consuming lower memory than the heuristic methods. This allows for improvement in energy consumption, response time and service level agreement violations by up to 74, 63 and 82 percent, respectively.},
	language = {en},
	urldate = {2022-08-22},
	publisher = {arXiv},
	author = {Tuli, Shreshth and Casale, Giuliano and Jennings, Nicholas R.},
	month = aug,
	year = {2022},
	note = {arXiv:2208.07658 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Performance},
}

@inproceedings{bhagoji_analyzing_2019,
	title = {Analyzing {Federated} {Learning} through an {Adversarial} {Lens}},
	url = {https://proceedings.mlr.press/v97/bhagoji19a.html},
	abstract = {Federated learning distributes model training among a multitude of agents, who, guided by privacy concerns, perform training using their local data but share only model parameter updates, for iterative aggregation at the server to train an overall global model. In this work, we explore how the federated learning setting gives rise to a new threat, namely model poisoning, which differs from traditional data poisoning. Model poisoning is carried out by an adversary controlling a small number of malicious agents (usually 1) with the aim of causing the global model to misclassify a set of chosen inputs with high conﬁdence. We explore a number of strategies to carry out this attack on deep neural networks, starting with targeted model poisoning using a simple boosting of the malicious agent’s update to overcome the effects of other agents. We also propose two critical notions of stealth to detect malicious updates. We bypass these by including them in the adversarial objective to carry out stealthy model poisoning. We improve its stealth with the use of an alternating minimization strategy which alternately optimizes for stealth and the adversarial objective. We also empirically demonstrate that Byzantine-resilient aggregation strategies are not robust to our attacks. Our results indicate that highly constrained adversaries can carry out model poisoning attacks while maintaining stealth, thus highlighting the vulnerability of the federated learning setting and the need to develop effective defense strategies.},
	language = {en},
	urldate = {2023-02-23},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Bhagoji, Arjun Nitin and Chakraborty, Supriyo and Mittal, Prateek and Calo, Seraphin},
	month = may,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {634--643},
}

@inproceedings{merzouk_parameterizing_2023,
	address = {New York, NY, USA},
	series = {{ARES} '23},
	title = {Parameterizing poisoning attacks in federated learning-based intrusion detection},
	isbn = {9798400707728},
	url = {https://dl.acm.org/doi/10.1145/3600160.3605090},
	doi = {10.1145/3600160.3605090},
	abstract = {Federated learning is a promising research direction in network intrusion detection. It enables collaborative training of machine learning models without revealing sensitive data. However, the lack of transparency in federated learning creates a security threat. Since the server cannot ensure the clients’ reliability by analyzing their data, malicious clients have the opportunity to insert a backdoor in the model and activate it to evade detection. To maximize their chances of success, adversaries must fine-tune the attack parameters. Here we evaluate the impact of four attack parameters on the effectiveness, stealthiness, consistency, and timing of data poisoning attacks. Our results show that each parameter is decisive for the success of poisoning attacks, provided they are carefully adjusted to avoid damaging the model’s accuracy or the data’s consistency. Our findings serve as guidelines for the security evaluation of federated learning systems and insights for defense strategies. Our experiments are carried out on the UNSW-NB15 dataset, and their implementation is available in a public code repository.},
	urldate = {2024-01-29},
	booktitle = {Proceedings of the 18th {International} {Conference} on {Availability}, {Reliability} and {Security}},
	publisher = {Association for Computing Machinery},
	author = {Merzouk, Mohamed Amine and Cuppens, Frédéric and Boulahia-Cuppens, Nora and Yaich, Reda},
	year = {2023},
	keywords = {adversarial attack, backdoor, data poisoning, federated learning, intrusion detection, obsidian},
	pages = {1--8},
}

@article{zhao_reviewer_2022,
	title = {Reviewer assignment algorithms for peer review automation: {A} survey},
	volume = {59},
	issn = {0306-4573},
	shorttitle = {Reviewer assignment algorithms for peer review automation},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457322001388},
	doi = {10.1016/j.ipm.2022.103028},
	abstract = {Assigning paper to suitable reviewers is of great significance to ensure the accuracy and fairness of peer review results. In the past three decades, many researchers have made a wealth of achievements on the reviewer assignment problem (RAP). In this survey, we provide a comprehensive review of the primary research achievements on reviewer assignment algorithm from 1992 to 2022. Specially, this survey first discusses the background and necessity of automatic reviewer assignment, and then systematically summarize the existing research work from three aspects, i.e., construction of candidate reviewer database, computation of matching degree between reviewers and papers, and reviewer assignment optimization algorithm, with objective comments on the advantages and disadvantages of the current algorithms. Afterwards, the evaluation metrics and datasets of reviewer assignment algorithm are summarized. To conclude, we prospect the potential research directions of RAP. Since there are few comprehensive survey papers on reviewer assignment algorithm in the past ten years, this survey can serve as a valuable reference for the related researchers and peer review organizers.},
	number = {5},
	urldate = {2024-02-12},
	journal = {Information Processing \& Management},
	author = {Zhao, Xiquan and Zhang, Yangsen},
	month = sep,
	year = {2022},
	keywords = {Information retrieval, Matching degree, Natural language processing, Optimization algorithm, Peer review, Reviewer assignment problem},
	pages = {103028},
}

@article{cormode_how_2009,
	title = {How {NOT} to review a paper: the tools and techniques of the adversarial reviewer},
	volume = {37},
	issn = {0163-5808},
	shorttitle = {How {NOT} to review a paper},
	url = {https://dl.acm.org/doi/10.1145/1519103.1519122},
	doi = {10.1145/1519103.1519122},
	abstract = {There are several useful guides available for how to review a paper in Computer Science [10, 6, 12, 7, 2]. These are soberly presented, carefully reasoned and sensibly argued. As a result, they are not much fun. So, as a contrast, this note is a checklist of how not to review a paper. It details techniques that are unethical, unfair, or just plain nasty. Since in Computer Science we often present arguments about how an adversary would approach a particular problem, this note describes the adversary’s strategy.},
	language = {en},
	number = {4},
	urldate = {2024-02-06},
	journal = {ACM SIGMOD Record},
	author = {Cormode, Graham},
	month = mar,
	year = {2009},
	pages = {100--104},
}

@article{ouyang_clusterfl_2022,
	title = {{ClusterFL}: {A} {Clustering}-based {Federated} {Learning} {System} for {Human} {Activity} {Recognition}},
	volume = {19},
	issn = {1550-4859},
	shorttitle = {{ClusterFL}},
	url = {https://dl.acm.org/doi/10.1145/3554980},
	doi = {10.1145/3554980},
	abstract = {Federated Learning (FL) has recently received significant interest, thanks to its capability of protecting data privacy. However, existing FL paradigms yield unsatisfactory performance for a wide class of human activity recognition (HAR) applications, since they are oblivious to the intrinsic relationship between data of different users. We propose ClusterFL, a clustering-based federated learning system that can provide high model accuracy and low communication overhead for HAR applications. ClusterFL features a novel clustered multi-task federated learning framework that minimizes the empirical training loss of multiple learned models while automatically capturing the intrinsic clustering relationship among the nodes. We theoretically prove the convergence of proposed FL framework for non-convex and strongly convex models and provide the guidance on selection of hyper-parameters for achieving such convergence. Based on the learned cluster relationship, ClusterFL can efficiently drop the nodes that converge slower or have little correlations with others in each cluster, significantly speeding up the convergence while maintaining the accuracy performance. We evaluate the performance of ClusterFL on an NVIDIA edge testbed using four new HAR datasets collected from 145 users. The results show that ClusterFL outperforms several state-of-the-art FL paradigms in terms of overall accuracy and can save more than 50\% communication overhead.},
	number = {1},
	urldate = {2024-01-12},
	journal = {ACM Transactions on Sensor Networks},
	author = {Ouyang, Xiaomin and Xie, Zhiyuan and Zhou, Jiayu and Xing, Guoliang and Huang, Jianwei},
	year = {2022},
	keywords = {Activity recognition, clustering, federated learning, multi-task learning},
	pages = {17:1--17:32},
}

@inproceedings{kim_exploring_2023,
	address = {New York, NY, USA},
	series = {{RAID} '23},
	title = {Exploring {Clustered} {Federated} {Learning}’s {Vulnerability} against {Property} {Inference} {Attack}},
	isbn = {9798400707650},
	url = {https://dl.acm.org/doi/10.1145/3607199.3607218},
	doi = {10.1145/3607199.3607218},
	abstract = {Clustered federated learning (CFL) is an advanced technique in the field of federated learning (FL) that addresses the issue of catastrophic forgetting caused by non-independent and identically distributed (non-IID) datasets. CFL achieves this by clustering clients based on the similarity of their datasets and training a global model for each cluster. Despite the effectiveness of CFL in mitigating performance degradation resulting from non-IID datasets, the potential risk of privacy leakages in CFL has not been thoroughly studied. Previous work evaluated the risk of privacy leakages in FL using the property inference attack (PIA), which extracts information about unintended properties (i.e., attributes that differ from the target attribute of the global model’s main task). In this paper, we explore the potential risk of unintended property leakage in CFL by subjecting it to both passive and active PIAs. Our empirical analysis shows that the passive PIA performance on CFL is substantially better than that on FL in terms of the attack AUC score. Moreover, we propose an enhanced active PIA method tailored for CFL to improve the attack performance. Our method introduces a scale-up parameter that amplifies the impact of malicious local updates, resulting in better performance than the previous technique. Furthermore, we demonstrate that the vulnerability of CFL can be alleviated by applying differential privacy (DP) mechanisms at the client-level. Unlike previous works, which have shown that applying DP to FL can induce a high utility loss, our empirical results indicate that DP can be used as a defense mechanism in CFL, leading to a better trade-off between privacy and utility.},
	urldate = {2024-01-10},
	booktitle = {Proceedings of the 26th {International} {Symposium} on {Research} in {Attacks}, {Intrusions} and {Defenses}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Hyunjun and Cho, Yungi and Lee, Younghan and Bae, Ho and Paek, Yunheung},
	month = oct,
	year = {2023},
	keywords = {\_read\_urgently, clustered federated learning, differential privacy, property inference attack},
	pages = {236--249},
}

@inproceedings{tu_feddl_2021,
	address = {New York, NY, USA},
	series = {{SenSys} '21},
	title = {{FedDL}: {Federated} {Learning} via {Dynamic} {Layer} {Sharing} for {Human} {Activity} {Recognition}},
	isbn = {978-1-4503-9097-2},
	shorttitle = {{FedDL}},
	url = {https://doi.org/10.1145/3485730.3485946},
	doi = {10.1145/3485730.3485946},
	abstract = {Deep learning has been increasingly applied to improve human activity recognition (HAR) accuracy and reduce the human efforts of handcrafted feature extractions. Federated Learning (FL) is an emerging learning paradigm that enables the collaborative learning of a global model without exposing users' raw data. However, existing FL approaches yield unsatisfactory HAR performance as they fail to dynamically aggregate models according to the statistical diversity of users' data. In this paper, we propose FedDL, a novel federated learning system for HAR that can capture the underlying user relationships and apply them to learn personalized models for different users dynamically. Specifically, we design a dynamic layer sharing scheme that learns the similarity among users' model weights to form the sharing structure and merges models accordingly in an iterative, bottom-up layer-wise manner. FedDL merges local models based on the dynamic sharing scheme, significantly speeding up the convergence while maintaining high accuracy. We have implemented FedDL and evaluated using a new data set we collected using LiDAR and four public real-world datasets involving 178 users in total. The results show that FedDL outperforms several state-of-the-art FL paradigms in terms of model accuracy (by more than 15\%), converging rate (by more than 70\%), and communication overhead (about 30\% reduction). Moreover, the testing results on the datasets of different scales show that FedDL has high scalability and hence can be deployed for large-scale real-world applications.},
	urldate = {2023-12-05},
	booktitle = {Proceedings of the 19th {ACM} {Conference} on {Embedded} {Networked} {Sensor} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Tu, Linlin and Ouyang, Xiaomin and Zhou, Jiayu and He, Yuze and Xing, Guoliang},
	month = nov,
	year = {2021},
	keywords = {Federated Learning Personalization, Federated learning, Human activity recognition, Multi-task learning, obsidian},
	pages = {15--28},
}

@techreport{abdul_wahab_intrusion_2022,
	type = {preprint},
	title = {Intrusion {Detection} in the {IoT} under {Data} and {Concept} {Drifts}: {Online} {Deep} {Learning} {Approach}},
	shorttitle = {Intrusion {Detection} in the {IoT} under {Data} and {Concept} {Drifts}},
	url = {https://www.techrxiv.org/articles/preprint/Intrusion_Detection_in_the_IoT_under_Data_and_Concept_Drifts_Online_Deep_Learning_Approach/19210197/1},
	abstract = {Although the existing machine learning-based intrusion detection systems in the Internet of Things (IoT) usually perform well in static environments, they struggle to preserve their performance over time, in dynamic environments. Yet, the IoT is a highly dynamic and heterogeneous environment, leading to what is known as data drift and concept drift. Data drift is a phenomenon which embodies the change that happens in the relationships among the independent features, which is mainly due to changes in the data quality over time. Concept drift is a phenomenon which depicts the change in the relationships between input and output data in the machine learning model over time. To detect data and concept drifts, we ﬁrst propose a drift detection technique that capitalizes on the Principal Component Analysis (PCA) method to study the change in the variance of the features across the intrusion detection data streams. We also discuss an online outlier detection technique that identiﬁes the outliers that diverge both from historical and temporally close data points. To counter these drifts, we discuss an online deep neural network that dynamically adjusts the sizes of the hidden layers based on the Hedge weighting mechanism, thus enabling the model to steadily learn and adapt as new intrusion data come. Experiments conducted on an IoT-based intrusion detection dataset suggest that our solution stabilizes the performance of the intrusion detection on both the training and testing data compared to the static deep neural network model, which is widely used for intrusion detection.},
	language = {en},
	urldate = {2022-03-04},
	author = {Abdul Wahab, Omar},
	month = feb,
	year = {2022},
	doi = {10.36227/techrxiv.19210197.v1},
	keywords = {obsidian},
}

@inproceedings{uetz_reproducible_2021,
	address = {Virtual Event USA},
	title = {Reproducible and {Adaptable} {Log} {Data} {Generation} for {Sound} {Cybersecurity} {Experiments}},
	isbn = {978-1-4503-8579-4},
	url = {https://dl.acm.org/doi/10.1145/3485832.3488020},
	doi = {10.1145/3485832.3488020},
	abstract = {Artifacts such as log data and network traffic are fundamental for cybersecurity research, e.g., in the area of intrusion detection. Yet, most research is based on artifacts that are not available to others or cannot be adapted to own purposes, thus making it difficult to reproduce and build on existing work. In this paper, we identify the challenges of artifact generation with the goal of conducting sound experiments that are valid, controlled, and reproducible. We argue that testbeds for artifact generation have to be designed specifically with reproducibility and adaptability in mind. To achieve this goal, we present SOCBED, our proof-of-concept implementation and the first testbed with a focus on generating realistic log data for cybersecurity experiments in a reproducible and adaptable manner. SOCBED enables researchers to reproduce testbed instances on commodity computers, adapt them according to own requirements, and verify their correct functionality. We evaluate SOCBED with an exemplary, practical experiment on detecting a multi-step intrusion of an enterprise network and show that the resulting experiment is indeed valid, controlled, and reproducible. Both SOCBED and the log dataset underlying our evaluation are freely available.},
	language = {en},
	urldate = {2022-08-08},
	booktitle = {Annual {Computer} {Security} {Applications} {Conference}},
	publisher = {ACM},
	author = {Uetz, Rafael and Hemminghaus, Christian and Hackländer, Louis and Schlipper, Philipp and Henze, Martin},
	month = dec,
	year = {2021},
	pages = {690--705},
}

@inproceedings{wang_feco_2022,
	title = {{FeCo}: {Boosting} {Intrusion} {Detection} {Capability} in {IoT} {Networks} via {Contrastive} {Learning}},
	shorttitle = {{FeCo}},
	doi = {10.1109/INFOCOM48880.2022.9796926},
	abstract = {Over the last decade, Internet of Things (IoT) has permeated our daily life with a broad range of applications. However, a lack of sufficient security features in IoT devices renders IoT ecosystems vulnerable to various network intrusion attacks, potentially causing severe damage. Previous works have explored using machine learning to build anomaly detection models for defending against such attacks. In this paper, we propose FeCo, a federated-contrastive-learning framework that coordinates in-network IoT devices to jointly learn intrusion detection models. FeCo utilizes federated learning to alleviate users’ privacy concerns as participating devices only submit their model parameters rather than local data. Compared to previous works, we develop a novel representation learning method based on contrastive learning that is able to learn a more accurate model for the benign class. FeCo significantly improves the intrusion detection accuracy compared to previous works. Besides, we implement a two-step feature selection scheme to avoid overfitting and reduce computation time. Through extensive experiments on the NSL-KDD dataset, we demonstrate that FeCo achieves as high as 8\% accuracy improvement compared to the state-of-the-art and is robust to non-IID data. Evaluations on convergence, computation overhead, and scalability further confirm the suitability of FeCo for IoT intrusion detection.},
	booktitle = {{IEEE} {INFOCOM} 2022 - {IEEE} {Conference} on {Computer} {Communications}},
	author = {Wang, Ning and Chen, Yimin and Hu, Yang and Lou, Wenjing and Hou, Y. Thomas},
	month = may,
	year = {2022},
	note = {ISSN: 2641-9874},
	keywords = {Biological system modeling, Data privacy, Feature extraction, Intrusion detection, Representation learning, Scalability, Telecommunication traffic},
	pages = {1409--1418},
}

@article{liu_intrusion_2022,
	title = {Intrusion {Detection} for {Maritime} {Transportation} {Systems} {With} {Batch} {Federated} {Aggregation}},
	issn = {1558-0016},
	doi = {10.1109/TITS.2022.3181436},
	abstract = {As a fast-growing and promising technology, Internet of Things (IoT) significantly promotes the informationization and intelligentization of Maritime Transportation System (MTS). The massive data collected during the voyage is usually disposed of with the assistance of cloud or edge computing, which imposes serious cyber security threats. For multifarious cyber-attacks, Intrusion Detection System (IDS) is one of the efficient mechanisms to prevent IoT devices from network intrusion. However, most of the methods based on deep learning train their models in a centralized manner, which needs uploading all data to the central server for training, increasing the risk of privacy disclosure. In this paper, we consider the characteristics of IoT-based MTS and propose a CNN-MLP based model for intrusion detection which is trained through Federated Learning, named FedBatch. Federated Learning keeps the model training local and only updates the global model through the exchange of model parameters, preserving the privacy of local data on vessels. First, the characteristics of the communication between different vessels are discussed to model the federated learning process during the voyage. Then, the lightweight local model constructed by Convolutional Neural Network (CNN) and Multi-Layer Perception (MLP) is designed to save on computing and storage overhead. Moreover, to mitigate the straggler problem during the federated learning in MTS, we proposed an adaptive aggregation method, named Batch Federated Aggregation, which suppresses the oscillations of model parameters during federated learning. Finally, the simulation results on the NSL-KDD dataset demonstrate the effectiveness and efficiency of FedBatch.},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Liu, Wentao and Xu, Xiaolong and Wu, Lianxiang and Qi, Lianyong and Jolfaei, Alireza and Ding, Weiping and Khosravi, Mohammad R.},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Intelligent Transportation Systems},
	keywords = {Collaborative work, Convolutional neural networks, Data models, Internet of Things, Intrusion detection, IoT, Servers, Training, federated learning, maritime transportation systems, privacy preservation},
	pages = {1--12},
}

@article{ashraf_fidchain_2022,
	title = {{FIDChain}: {Federated} {Intrusion} {Detection} {System} for {Blockchain}-{Enabled} {IoT} {Healthcare} {Applications}},
	volume = {10},
	issn = {2227-9032},
	shorttitle = {{FIDChain}},
	url = {https://www.mdpi.com/2227-9032/10/6/1110},
	doi = {10.3390/healthcare10061110},
	abstract = {Recently, there has been considerable growth in the internet of things (IoT)-based healthcare applications; however, they suffer from a lack of intrusion detection systems (IDS). Leveraging recent technologies, such as machine learning (ML), edge computing, and blockchain, can provide suitable and strong security solutions for preserving the privacy of medical data. In this paper, FIDChain IDS is proposed using lightweight artiﬁcial neural networks (ANN) in a federated learning (FL) way to ensure healthcare data privacy preservation with the advances of blockchain technology that provides a distributed ledger for aggregating the local weights and then broadcasting the updated global weights after averaging, which prevents poisoning attacks and provides full transparency and immutability over the distributed system with negligible overhead. Applying the detection model at the edge protects the cloud if an attack happens, as it blocks the data from its gateway with smaller detection time and lesser computing and processing capacity as FL deals with smaller sets of data. The ANN and eXtreme Gradient Boosting (XGBoost) models were evaluated using the BoT-IoT dataset. The results show that ANN models have higher accuracy and better performance with the heterogeneity of data in IoT devices, such as intensive care unit (ICU) in healthcare systems. Testing the FIDChain with different datasets (CSE-CIC-IDS2018, Bot Net IoT, and KDD Cup 99) reveals that the BoT-IoT dataset has the most stable and accurate results for testing IoT applications, such as those used in healthcare systems.},
	language = {en},
	number = {6},
	urldate = {2022-07-05},
	journal = {Healthcare},
	author = {Ashraf, Eman and Areed, Nihal F. F. and Salem, Hanaa and Abdelhay, Ehab H. and Farouk, Ahmed},
	month = jun,
	year = {2022},
	pages = {1110},
}

@inproceedings{aouedi_fluids_2022,
	title = {{FLUIDS}: {Federated} {Learning} with semi-supervised approach for {Intrusion} {Detection} {System}},
	shorttitle = {{FLUIDS}},
	doi = {10.1109/CCNC49033.2022.9700632},
	abstract = {In this paper, we present FLUIDS, a Federated Learning with semi-sUpervised approach for Intrusion Detection System. FLUIDS formulates the intrusion detection into a semi-supervised learning where both supervised learning (using labeled data) and unsupervised learning (no label data) are combined in a collaborative way. The combination of federated learning and semi-supervised Learning allows the solution to: better preserve the privacy, improve training and inference efficiency, achieve better accuracy, and be cheaper to deploy.},
	booktitle = {2022 {IEEE} 19th {Annual} {Consumer} {Communications} \& {Networking} {Conference} ({CCNC})},
	author = {Aouedi, Ons and Piamrat, Kandaraj and Muller, Guillaume and Singh, Kamal},
	month = jan,
	year = {2022},
	note = {ISSN: 2331-9860},
	keywords = {Auto-Encoder (AE), Collaborative work, Deep Learning (DL), Federated Learning (FL), Fluids, Intrusion Detection System (IDS), Intrusion detection, Machine Learning (ML), Privacy, Semi-Supervised Learning, Semisupervised learning, Supervised learning, Training},
	pages = {523--524},
}

@article{pei_knowledge_2022,
	title = {A {Knowledge} {Transfer}-based {Semi}-{Supervised} {Federated} {Learning} for {IoT} {Malware} {Detection}},
	issn = {1941-0018},
	doi = {10.1109/TDSC.2022.3173664},
	abstract = {As the demand for Internet of Things (IoT) technologies continues to grow, IoT devices have been viable targets for malware infections. Although deep learning-based malware detection has achieved great success, the detection models are usually trained based on the collected user records, thereby leading to significant privacy risks. One promising solution is to leverage federated learning (FL) to enable distributed on-device training without centralizing the private user records. However, it is non-trivial for IoT users to label these records, where the quality and the trustworthiness of data labeling are hard to guarantee. To address the above issues, this paper develops a semi-supervised federated IoT malware detection framework based on knowledge transfer technologies, named by FedMalDE. Specifically, FedMalDE explores the underlying correlation between labeled and unlabeled records to infer labels towards unlabeled samples by the knowledge transfer mechanism. Moreover, a specially designed subgraph aggregated capsule network (SACN) is used to efficiently capture varied malicious behaviors. The extensive experiments conducted on real-world data demonstrate the effectiveness of FedMalDE in detecting IoT malware and its sufficient privacy and robustness guarantee.},
	journal = {IEEE Transactions on Dependable and Secure Computing},
	author = {Pei, Xinjun and Deng, Xiaoheng and Tian, Shengwei and Zhang, Lan and Xue, Kaiping},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Dependable and Secure Computing},
	keywords = {Capsule Network, Collaborative work, Feature extraction, Federated Learning, Malware, Malware Detection, Privacy, Privacy-Preserving, Security, Semantics, Semi-Supervised Learning, Training},
	pages = {1--1},
}

@article{kang_reliable_2020,
	title = {Reliable {Federated} {Learning} for {Mobile} {Networks}},
	volume = {27},
	issn = {1558-0687},
	doi = {10.1109/MWC.001.1900119},
	abstract = {Federated learning, as a promising machine learning approach, has emerged to leverage a distributed personalized dataset from a number of nodes, for example, mobile devices, to improve performance while simultaneously providing privacy preservation for mobile users. In federated learning, training data is widely distributed and maintained on the mobile devices as workers. A central aggregator updates a global model by collecting local updates from mobile devices using their local training data to train the global model in each iteration. However, unreliable data may be uploaded by the mobile devices (i.e., workers), leading to frauds in tasks of federated learning. The workers may perform unreliable updates intentionally, for example, the data poisoning attack, or unintentionally, for example, low-quality data caused by energy constraints or high-speed mobility. Therefore, finding out trusted and reliable workers in federated learning tasks becomes critical. In this article, the concept of reputation is introduced as a metric. Based on this metric, a reliable worker selection scheme is proposed for federated learning tasks. Consortium blockchain is leveraged as a decentralized approach for achieving efficient reputation management of the workers without repudiation and tampering. By numerical analysis, the proposed approach is demonstrated to improve the reliability of federated learning tasks in mobile networks.},
	number = {2},
	journal = {IEEE Wireless Communications},
	author = {Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Zou, Yuze and Zhang, Yang and Guizani, Mohsen},
	month = apr,
	year = {2020},
	note = {Conference Name: IEEE Wireless Communications},
	keywords = {Data models, Data privacy, Machine learning, Metasearch, Mobile handsets, Task analysis, Training data},
	pages = {72--80},
}

@misc{Zakerinia2022,
	title = {{QuAFL}: {Federated} {Averaging} {Can} {Be} {Both} {Asynchronous} and {Communication}-{Efficient}},
	shorttitle = {{QuAFL}},
	url = {http://arxiv.org/abs/2206.10032},
	abstract = {Federated Learning (FL) is an emerging paradigm to enable the largescale distributed training of machine learning models, while still providing privacy guarantees. In this work, we jointly address two of the main practical challenges when scaling federated optimization to large node counts: the need for tight synchronization between the central authority and individual computing nodes, and the large communication cost of transmissions between the central server and clients. Speciﬁcally, we present a new variant of the classic federated averaging (FedAvg) algorithm, which supports both asynchronous communication and communication compression. We provide a new analysis technique showing that, in spite of these system relaxations, our algorithm essentially matches the best known bounds for FedAvg, under reasonable parameter settings. On the experimental side, we show that our algorithm ensures fast practical convergence for standard federated tasks.},
	language = {en},
	urldate = {2022-07-25},
	publisher = {arXiv},
	author = {Zakerinia, Hossein and Talaei, Shayan and Nadiradze, Giorgi and Alistarh, Dan},
	month = jun,
	year = {2022},
	note = {arXiv:2206.10032 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@incollection{sun_multi-level_2022,
	address = {Cham},
	title = {Multi-level {Federated} {Learning} {Mechanism} with {Reinforcement} {Learning} {Optimizing} in {Smart} {City}},
	volume = {13340},
	isbn = {978-3-031-06790-7 978-3-031-06791-4},
	url = {https://link.springer.com/10.1007/978-3-031-06791-4_35},
	abstract = {While taking account into data privacy protection, federated learning can mine local data knowledge and gather data value, which has been widely concerned by the Smart city and Internet of Things. At present, a large amount of data is generated by the massive edge network in the smart city, but the resources of the edge side are limited. How to reduce the communication overhead between the edge and the centralized cloud server, improve the convergence speed of data model, and avoid resource waste caused by synchronized blocking of federated learning has become the core issue for the integration of federated learning and the Internet of Things in the smart city. For this reason, this paper designs a multi-level federated learning mechanism in the smart city, and uses reinforcement learning agents to select nodes to offset the inﬂuence of the non-IID data that is not independent and identically distributed. At the same time, asynchronous nonblocking updating method is used to perform model aggregation and updating of federated learning to release the resources of faster devices and improving the efﬁciency and stability of federated learning. Finally, simulation results show that the proposed method can improve the efﬁciency of federated learning tasks in edge network scenarios with a lot of devices in the smart city.},
	language = {en},
	urldate = {2022-07-25},
	booktitle = {Artificial {Intelligence} and {Security}},
	publisher = {Springer International Publishing},
	author = {Guo, Shaoyong and Xiang, Baoyu and Chen, Liandong and Yang, Huifeng and Yu, Dongxiao},
	editor = {Sun, Xingming and Zhang, Xiaorui and Xia, Zhihua and Bertino, Elisa},
	year = {2022},
	doi = {10.1007/978-3-031-06791-4_35},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {441--454},
}

@misc{sidd_dataset,
	title = {{SIDD} ({Segmented} {Intrusion} {Detection} {Dataset})},
	url = {https://www.kaggle.com/datasets/yuweisunut/sidd-segmented-intrusion-detection-dataset},
	abstract = {A Large-Scale Network Intrusion Image Dataset},
	language = {en},
	urldate = {2022-07-05},
	author = {Sun, Yuwei},
	year = {2020},
	keywords = {pinned},
}

@misc{Doriguzzi-Corin2022,
	title = {{FLAD}: {Adaptive} {Federated} {Learning} for {DDoS} {Attack} {Detection}},
	shorttitle = {{FLAD}},
	url = {http://arxiv.org/abs/2205.06661},
	abstract = {Federated Learning (FL) has been recently receiving increasing consideration from the cybersecurity community as a way to collaboratively train deep learning models with distributed proﬁles of cyberthreats, with no disclosure of training data. Nevertheless, the adoption of FL in cybersecurity is still in its infancy, and a range of practical aspects have not been properly addressed yet. Indeed, the Federated Averaging algorithm at the core of the FL concept requires the availability of test data to control the FL process. Although this might be feasible in some domains, test network trafﬁc of newly discovered attacks cannot be always shared without disclosing sensitive information.},
	language = {en},
	urldate = {2022-07-05},
	publisher = {arXiv},
	author = {Doriguzzi-Corin, Roberto and Siracusa, Domenico},
	month = may,
	year = {2022},
	note = {arXiv:2205.06661 [cs]},
	keywords = {Computer Science - Cryptography and Security},
}

@inproceedings{neto_fedsa_2022,
	address = {Milan, Italy},
	title = {{FedSA}: {Accelerating} {Intrusion} {Detection} in {Collaborative} {Environments} with {Federated} {Simulated} {Annealing}},
	abstract = {Fast identification of new network attack patterns is crucial for improving network security. Nevertheless, identifying an ongoing attack in a heterogeneous network is a non-trivial task. Federated learning emerges as a solution to collaborative training for an Intrusion Detection System (IDS). The federated learning-based IDS trains a global model using local machine learning models provided by federated participants without sharing local data. However, optimization challenges are intrinsic to federated learning. This paper proposes the Federated Simulated Annealing (FedSA) metaheuristic to select the hyperparameters and a subset of participants for each aggregation round in federated learning. FedSA optimizes hyperparameters linked to the global model convergence. The proposal reduces aggregation rounds and speeds up convergence. Thus, FedSA accelerates learning extraction from local models, requiring fewer IDS updates. The proposal assessment shows that the FedSA global model converges in less than ten communication rounds. The proposal requires up to 50\% fewer aggregation rounds to achieve approximately 97\% accuracy in attack detection than the conventional aggregation approach.},
	language = {en},
	booktitle = {2022 {IEEE} 8th {International} {Conference} on {Network} {Softwarization} ({NetSoft})},
	publisher = {IEEE},
	author = {Neto, Helio N. Cunha and Dusparic, Ivana and Mattos, Diogo M. F. and Fernandes, Natalia C.},
	year = {2022},
	keywords = {⛔ No DOI found},
}

@inproceedings{phan_fear_2022,
	title = {{FEAR}: {Federated} {Cyber}-{Attack} {Reaction} in {Distributed} {Software}-{Defined} {Networks} with {Deep} {Q}-{Network}},
	shorttitle = {{FEAR}},
	doi = {10.1109/WTS53620.2022.9768169},
	abstract = {In this paper, we propose a FEderated cyber-Attack Reaction (FEAR) system using Deep Q-Network algorithm for distributed software-defined networks. In our recent study [1], we propose a Q-learning based cyber-attack reaction control system, called CARS, for a single SDN. However, for real network deployments that are usually distributed over the Internet, the CARS suffers from two main shortcomings, i.e., a slow-convergence rate of Q-learning algorithm and the scalability issue. Therefore, in this paper, we first develop a Deep Q-Network (DQN) based cyber-attack reaction control algorithm to assist the control agent in obtaining the optimal policy quickly. Next, we propose a federated DQN based cyber-attack reaction control system, which eliminates the scalability problem and improves the learning performance of the DQN algorithm in a distributed manner. As our case study on denial-of-service (DoS) attacks, the obtained results show that the FEAR can effectively protect the victim from malicious packets, i.e., approximately 90\% of attack packets are discarded. Furthermore, by deploying the optimal cyber-attack reaction policy, the FEAR can reduce the ratio of QoS (Quality-of-Service) violated traffic flows compared to the CARS (by approx. 44\%) and the GATE (by approx. 63\%).},
	booktitle = {2022 {Wireless} {Telecommunications} {Symposium} ({WTS})},
	author = {Phan, Trung V. and Gia Nguyen, Tri},
	month = apr,
	year = {2022},
	note = {ISSN: 2690-8336},
	keywords = {Control systems, Cyber-Attack Reaction, Deep Q-learning, Denial-of-service attack, DoS Attacks, Federated Learning, Logic gates, Q-learning, Quality of service, Scalability, Wireless communication, and Software-Defined Networks},
	pages = {1--7},
}

@inproceedings{shafee_mimic_2020,
	address = {Las Vegas, NV, USA},
	title = {Mimic {Learning} to {Generate} a {Shareable} {Network} {Intrusion} {Detection} {Model}},
	isbn = {978-1-72813-893-0},
	url = {https://ieeexplore.ieee.org/document/9045236/},
	doi = {10.1109/CCNC46108.2020.9045236},
	abstract = {Purveyors of malicious network attacks continue to increase the complexity and the sophistication of their techniques, and their ability to evade detection continues to improve as well. Hence, intrusion detection systems must also evolve to meet these increasingly challenging threats. Machine learning is often used to support this needed improvement. However, training a good prediction model can require a large set of labeled training data. Such datasets are difﬁcult to obtain because privacy concerns prevent the majority of intrusion detection agencies from sharing their sensitive data. In this paper, we propose the use of mimic learning to enable the transfer of intrusion detection knowledge through a teacher model trained on private data to a student model. This student model provides a mean of publicly sharing knowledge extracted from private data without sharing the data itself. Our results conﬁrm that the proposed scheme can produce a student intrusion detection model that mimics the teacher model without requiring access to the original dataset.},
	language = {en},
	urldate = {2022-07-05},
	booktitle = {2020 {IEEE} 17th {Annual} {Consumer} {Communications} \& {Networking} {Conference} ({CCNC})},
	publisher = {IEEE},
	author = {Shafee, Ahmed and Baza, Mohamed and Talbert, Douglas A. and Fouda, Mostafa M. and Nabil, Mahmoud and Mahmoud, Mohamed},
	month = jan,
	year = {2020},
	pages = {1--6},
}

@article{zhang_secfednids_2022,
	title = {{SecFedNIDS}: {Robust} defense for poisoning attack against federated learning-based network intrusion detection system},
	volume = {134},
	issn = {0167739X},
	shorttitle = {{SecFedNIDS}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X22001339},
	doi = {10.1016/j.future.2022.04.010},
	abstract = {Federated learning-based network intrusion detection system (FL-based NIDS) has demonstrated tremendous potential in protecting the security of IoT network. It enables learning an effective intrusion detection model from massive traffic data collaboratively without data privacy leakage. However, FL-based NIDS has exhibited inherent vulnerabilities on the poisoning attacks launched by malicious clients. The poisoning attacks aim to corrupt the intrusion detection model and impair its protection capability, by injecting the poisoned traffic data into the local training dataset. We build a secure FL-based NIDS that is robust for the poisoning attacks, namely SecFedNIDS. Firstly, we propose the model-level defensive mechanism based on poisoned model detection. Specifically, we propose the gradient-based important model parameter selection method to provide the effective low-dimensional representations of the uploaded local model parameters, and then we propose the online unsupervised poisoned model detection method to identify the poisoned models and reject them to join in the global intrusion detection model. Subsequently, we design the data-level defensive mechanism based on poisoned data detection. Notably, we propose a novel poisoned data detection method based on class path similarity, to filter out the poisoned traffic data and avoid them participating in subsequent local training. We adopt layer-wise relevance propagation to extract the class path of clean traffic data, and transmit the class paths to the poisoned clients to help distinguish the poisoned traffic data. Results show that SecFedNIDS with the proposed model-level defense boosts the accuracy by up to 48\% under the poisoning attacks on UNSW-NB15 dataset and 36\% on CICIDS2018 dataset, and the proposed data-level defense further improves its accuracy by up to 13\% on CICIDS2018 dataset.},
	language = {en},
	urldate = {2022-07-05},
	journal = {Future Generation Computer Systems},
	author = {Zhang, Zhao and Zhang, Yong and Guo, Da and Yao, Lei and Li, Zhao},
	month = sep,
	year = {2022},
	pages = {154--169},
}

@article{truong_light-weight_2022,
	title = {Light-weight federated learning-based anomaly detection for time-series data in industrial control systems},
	volume = {140},
	issn = {01663615},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0166361522000896},
	doi = {10.1016/j.compind.2022.103692},
	abstract = {With the emergence of the Industrial Internet of Things (IIoT), potential threats to smart manufacturing systems are increasingly becoming challenging, causing severe damage to production operations and vital industrial assets, even sensitive information. Hence, detecting irregularities for timeseries data in industrial control systems that should operate continually is critical, ensuring security and minimizing maintenance costs. In this study, with the hybrid design of Federated learning, Autoencoder, Transformer, and Fourier mixing sublayer, we propose a robust distributed anomaly detection architecture that works more accurately than several most recent anomaly detection solutions within the ICS contexts, whilst being fast learning in minute time scale. This distributed architecture is also proven to achieve lightweight, consume little CPU and memory usage, have low communication costs in terms of bandwidth consumption, which makes it feasible to be deployed on top of edge devices with limited computing capacity.},
	language = {en},
	urldate = {2022-06-30},
	journal = {Computers in Industry},
	author = {Truong, Huong Thu and Ta, Bac Phuong and Le, Quang Anh and Nguyen, Dan Minh and Le, Cong Thanh and Nguyen, Hoang Xuan and Do, Ha Thu and Nguyen, Hung Tai and Tran, Kim Phuc},
	month = sep,
	year = {2022},
	pages = {103692},
}

@article{novikova_federated_2022,
	title = {Federated {Learning} for {Intrusion} {Detection} in the {Critical} {Infrastructures}: {Vertically} {Partitioned} {Data} {Use} {Case}},
	volume = {15},
	issn = {1999-4893},
	shorttitle = {Federated {Learning} for {Intrusion} {Detection} in the {Critical} {Infrastructures}},
	url = {https://www.mdpi.com/1999-4893/15/4/104},
	doi = {10.3390/a15040104},
	abstract = {One of the challenges in the Internet of Things systems is the security of the critical data, for example, data used for intrusion detection. The paper research construction of an intrusion detection system that ensures the confidentiality of critical data at a given level of intrusion detection accuracy. For this goal, federated learning is used to train an intrusion detection model. Federated learning is a computational model for distributed machine learning that allows different collaborating entities to train one global model without sharing data. This paper considers the case when entities have data that are different in attributes. Authors believe that it is a common situation for the critical systems constructed using Internet of Things (IoT) technology, when industrial objects are monitored by different sets of sensors. To evaluate the applicability of the federated learning for this case, the authors developed an approach and an architecture of the intrusion detection system for vertically partitioned data that consider the principles of federated learning and conducted the series of experiments. To model vertically partitioned data, the authors used the Secure Water Treatment (SWaT) data set that describes the functioning of the water treatment facility. The conducted experiments demonstrate that the accuracy of the intrusion detection model trained using federated learning is compared with the accuracy of the intrusion detection model trained using the centralized machine learning model. However, the computational efficiency of the learning and inference process is currently extremely low. It is explained by the application of homomorphic encryption for input data protection from different data owners or data sources. This defines the necessity to elaborate techniques for generating attributes that could model horizontally partitioned data even for the cases when the collaborating entities share datasets that differ in their attributes.},
	language = {en},
	number = {4},
	urldate = {2022-07-05},
	journal = {Algorithms},
	author = {Novikova, Evgenia and Doynikova, Elena and Golubev, Sergey},
	month = mar,
	year = {2022},
	pages = {104},
}

@article{driss_federated_2022,
	title = {A federated learning framework for cyberattack detection in vehicular sensor networks},
	issn = {2199-4536, 2198-6053},
	url = {https://link.springer.com/10.1007/s40747-022-00705-w},
	doi = {10.1007/s40747-022-00705-w},
	abstract = {Vehicular Sensor Networks (VSN) introduced a new paradigm for modern transportation systems by improving trafﬁc management and comfort. However, the increasing adoption of smart sensing technologies with the Internet of Things (IoT) made VSN a high-value target for cybercriminals. In recent years, Machine Learning (ML) and Deep Learning (DL) techniques attracted the research community to develop security solutions for IoT networks. Traditional ML and DL approaches that operate with data stored on a centralized server raise major privacy problems for user data. On the other hand, the resourceconstrained nature of a smart sensing network demands lightweight security solutions. To address these issues, this article proposes a Federated Learning (FL)-based attack detection framework for VSN. The proposed scheme utilizes a group of Gated Recurrent Units (GRU) with a Random Forest (RF)-based ensembler unit. The effectiveness of the suggested framework is investigated through multiple performance metrics. Experimental ﬁndings indicate that the proposed FL approach successfully detected the cyberattacks in VSN with the highest accuracy of 99.52\%. The other performance scores, precision, recall, and F1 are attained as 99.77\%, 99.54\%, and 99.65\%, respectively.},
	language = {en},
	urldate = {2022-07-05},
	journal = {Complex \& Intelligent Systems},
	author = {Driss, Maha and Almomani, Iman and e Huma, Zil and Ahmad, Jawad},
	month = mar,
	year = {2022},
}

@inproceedings{nguyen_cars_2021,
	title = {{CARS}: {Dynamic} {Cyber}-attack {Reaction} in {SDN}-based {Networks} with {Q}-learning},
	shorttitle = {{CARS}},
	doi = {10.1109/ATC52653.2021.9598233},
	abstract = {In this paper, we propose a dynamic cyber-attack reaction system based on Q-learning, namely CARS, to effectively defeat cyber-attacks in Software-Defined Networks (SDN). In particular, we first examine a cyber-attack reaction system that operates at the SDN control plane. Then, we propose a dynamic cyber-attack reaction solution to maximize the attack defense performance while minimizing the negative influence on benign traffic forwarding in the data plane. Next, we model the cyber-attack reaction system based on a Markov decision process (MDP) and formulate its optimization problem. Afterward, we develop a Q-learning based cyber-attack reaction control algorithm to solve the optimization problem, obtaining the optimal cyber-attack reaction policy. As our case study on denial-of-service (DoS) attacks, the obtained results verify that CARS can effectively prevent malicious packets from reaching the victim server in all DoS attacks, i.e., approximately 80\% of abnormal packets are dropped. In addition, by implementing the optimal cyber-attack reaction policy, CARS can significantly reduce the ratio of QoS (Quality-of-Service) violated traffic flows compared to two existing solutions, i.e., GATE (by approx. 66\%) and GTAC-IRS (by approx. 75\%).},
	booktitle = {2021 {International} {Conference} on {Advanced} {Technologies} for {Communications} ({ATC})},
	author = {Nguyen, Hai Hoang and Nguyen, Tri Gia and Hoang, Dinh Thai and Le, Duc Tran and Phan, Trung V.},
	month = oct,
	year = {2021},
	note = {ISSN: 2162-1039},
	keywords = {Approximation algorithms, Automobiles, Cyber-attack Reaction System, Denial-of-Service attacks and Software-Defined Networking, Denial-of-service attack, Heuristic algorithms, Logic gates, Markov processes, Q-learning, Quality of service},
	pages = {156--161},
}

@article{preuveneers_chained_2018,
	title = {Chained {Anomaly} {Detection} {Models} for {Federated} {Learning}: {An} {Intrusion} {Detection} {Case} {Study}},
	volume = {8},
	issn = {2076-3417},
	shorttitle = {Chained {Anomaly} {Detection} {Models} for {Federated} {Learning}},
	url = {http://www.mdpi.com/2076-3417/8/12/2663},
	doi = {10.3390/app8122663},
	abstract = {The adoption of machine learning and deep learning is on the rise in the cybersecurity domain where these AI methods help strengthen traditional system monitoring and threat detection solutions. However, adversaries too are becoming more effective in concealing malicious behavior amongst large amounts of benign behavior data. To address the increasing time-to-detection of these stealthy attacks, interconnected and federated learning systems can improve the detection of malicious behavior by joining forces and pooling together monitoring data. The major challenge that we address in this work is that in a federated learning setup, an adversary has many more opportunities to poison one of the local machine learning models with malicious training samples, thereby inﬂuencing the outcome of the federated learning and evading detection. We present a solution where contributing parties in federated learning can be held accountable and have their model updates audited. We describe a permissioned blockchain-based federated learning method where incremental updates to an anomaly detection machine learning model are chained together on the distributed ledger. By integrating federated learning with blockchain technology, our solution supports the auditing of machine learning models without the necessity to centralize the training data. Experiments with a realistic intrusion detection use case and an autoencoder for anomaly detection illustrate that the increased complexity caused by blockchain technology has a limited performance impact on the federated learning, varying between 5 and 15\%, while providing full transparency over the distributed training process of the neural network. Furthermore, our blockchain-based federated learning solution can be generalized and applied to more sophisticated neural network architectures and other use cases.},
	language = {en},
	number = {12},
	urldate = {2021-06-07},
	journal = {Applied Sciences},
	author = {Preuveneers, Davy and Rimmer, Vera and Tsingenopoulos, Ilias and Spooren, Jan and Joosen, Wouter and Ilie-Zudor, Elisabeth},
	month = dec,
	year = {2018},
	keywords = {\_read},
	pages = {2663},
}

@article{santin_framework_2022,
	title = {A {Framework} for {Verifiable} and {Auditable} {Federated} {Anomaly} {Detection}},
	url = {http://arxiv.org/abs/2203.07802},
	abstract = {Federated Leaning is an emerging approach to manage cooperation between a group of agents for the solution of Machine Learning tasks, with the goal of improving each agent's performance without disclosing any data. In this paper we present a novel algorithmic architecture that tackle this problem in the particular case of Anomaly Detection (or classification or rare events), a setting where typical applications often comprise data with sensible information, but where the scarcity of anomalous examples encourages collaboration. We show how Random Forests can be used as a tool for the development of accurate classifiers with an effective insight-sharing mechanism that does not break the data integrity. Moreover, we explain how the new architecture can be readily integrated in a blockchain infrastructure to ensure the verifiable and auditable execution of the algorithm. Furthermore, we discuss how this work may set the basis for a more general approach for the design of federated ensemble-learning methods beyond the specific task and architecture discussed in this paper.},
	language = {en},
	urldate = {2022-03-23},
	journal = {arXiv:2203.07802 [cs]},
	author = {Santin, Gabriele and Skarbovsky, Inna and Fournier, Fabiana and Lepri, Bruno},
	month = mar,
	year = {2022},
	note = {arXiv: 2203.07802},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, ⛔ No DOI found},
}

@incollection{bayro-corrochano_industrial_2014,
	address = {Cham},
	title = {Industrial {Control} {System} {Traffic} {Data} {Sets} for {Intrusion} {Detection} {Research}},
	volume = {8827},
	isbn = {978-3-319-12567-1 978-3-319-12568-8},
	url = {http://link.springer.com/10.1007/978-3-662-45355-1_5},
	abstract = {Supervisory control and data acquisition (SCADA) systems monitor and control physical processes associated with the critical infrastructure. Weaknesses in the application layer protocols, however, leave SCADA networks vulnerable to attack. In response, cyber security researchers have developed myriad intrusion detection systems. Researchers primarily rely on unique threat models and the corresponding network traﬃc data sets to train and validate their intrusion detection systems. This leads to a situation in which researchers cannot independently verify the results, cannot compare the eﬀectiveness of diﬀerent instruction detection systems, and cannot adequately validate the ability of intrusion detection systems to detect various classes of attacks. Indeed, a common data set is needed that can be used by researchers to compare intrusion detection approaches and implementations. This paper describes four data sets, which include network traﬃc, process control and process measurement features from a set of 28 attacks against two laboratory-scale industrial control systems that use the MODBUS application layer protocol. The data sets, which are freely available, enable eﬀective comparisons of intrusion detection solutions for SCADA systems.},
	language = {en},
	urldate = {2021-06-10},
	booktitle = {Progress in {Pattern} {Recognition}, {Image} {Analysis}, {Computer} {Vision}, and {Applications}},
	publisher = {Springer International Publishing},
	author = {Morris, Thomas and Gao, Wei},
	editor = {Bayro-Corrochano, Eduardo and Hancock, Edwin},
	year = {2014},
	doi = {10.1007/978-3-662-45355-1_5},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {65--78},
}

@inproceedings{tavallaee_detailed_2009,
	title = {A detailed analysis of the {KDD} {CUP} 99 data set},
	isbn = {978-1-4244-3763-4},
	url = {http://ieeexplore.ieee.org/document/5356528/},
	doi = {10.1109/CISDA.2009.5356528},
	abstract = {During the last decade, anomaly detection has attracted the attention of many researchers to overcome the weakness of signature-based IDSs in detecting novel attacks, and KDDCUP'99 is the mostly widely used data set for the evaluation of these systems. Having conducted a statistical analysis on this data set, we found two important issues which highly affects the performance of evaluated systems, and results in a very poor evaluation of anomaly detection approaches. To solve these issues, we have proposed a new data set, NSL-KDD, which consists of selected records of the complete KDD data set and does not suffer from any of mentioned shortcomings. © 2009 IEEE.},
	booktitle = {2009 {IEEE} {Symposium} on {Computational} {Intelligence} for {Security} and {Defense} {Applications}},
	publisher = {IEEE},
	author = {Tavallaee, Mahbod and Bagheri, Ebrahim and Lu, Wei and Ghorbani, Ali A.},
	month = jul,
	year = {2009},
	note = {Issue: Cisda},
	pages = {1--6},
}

@inproceedings{sharafaldin_toward_2018,
	address = {Funchal, Madeira, Portugal},
	title = {Toward {Generating} a {New} {Intrusion} {Detection} {Dataset} and {Intrusion} {Traffic} {Characterization}},
	isbn = {978-989-758-282-0},
	shorttitle = {Toward {Generating} a {New} {Intrusion} {Detection} {Dataset} and {Intrusion} {Traffic} {Characterization}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006639801080116},
	doi = {10.5220/0006639801080116},
	abstract = {Intrusion Detection, IDS Dataset, DoS, Web Attack, Inﬁltration, Brute Force.},
	language = {en},
	urldate = {2021-10-14},
	booktitle = {Proceedings of the 4th {International} {Conference} on {Information} {Systems} {Security} and {Privacy}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Sharafaldin, Iman and Habibi Lashkari, Arash and Ghorbani, Ali A.},
	year = {2018},
	pages = {108--116},
}

@article{rosa_intrusion_2021,
	title = {Intrusion and anomaly detection for the next-generation of industrial automation and control systems},
	volume = {119},
	issn = {0167739X},
	url = {https://doi.org/10.1016/j.future.2021.01.033},
	doi = {10.1016/j.future.2021.01.033},
	journal = {Future Generation Computer Systems},
	author = {Rosa, Luis and Cruz, Tiago and Freitas, Miguel Borges de and Quitério, Pedro and Henriques, João and Caldeira, Filipe and Monteiro, Edmundo and Simões, Paulo},
	month = jun,
	year = {2021},
	note = {Publisher: Elsevier B.V.},
	pages = {50--67},
}

@article{sun_data_2022-1,
	title = {Data {Poisoning} {Attacks} on {Federated} {Machine} {Learning}},
	volume = {9},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/abstract/document/9618642},
	doi = {10.1109/JIOT.2021.3128646},
	abstract = {Federated machine learning which enables resource-constrained node devices (e.g., Internet of Things (IoT) devices and smartphones) to establish a knowledge-shared model while keeping the raw data local, could provide privacy preservation, and economic benefit by designing an effective communication protocol. However, this communication protocol can be adopted by attackers to launch data poisoning attacks for different nodes, which has been shown as a big threat to most machine learning models. Therefore, we in this article intend to study the model vulnerability of federated machine learning, and even on IoT systems. To be specific, we here attempt to attacking a popular federated multitask learning framework, which uses a general multitask learning framework to handle statistical challenges in the federated learning setting. The problem of calculating optimal poisoning attacks on federated multitask learning is formulated as a bilevel program, which is adaptive to the arbitrary selection of target nodes and source attacking nodes. We then propose a novel systems-aware optimization method, called as attack on federated learning (AT2FL), to efficiently derive the implicit gradients for poisoned data, and further attain optimal attack strategies in the federated machine learning. This is an earlier work, to our knowledge, that explores attacking federated machine learning via data poisoning. Finally, experiments on several real-world data sets demonstrate that when the attackers directly poison the target nodes or indirectly poison the related nodes via using the communication protocol, the federated multitask learning model is sensitive to both poisoning attacks.},
	number = {13},
	urldate = {2023-12-06},
	journal = {IEEE Internet of Things Journal},
	author = {Sun, Gan and Cong, Yang and Dong, Jiahua and Wang, Qiang and Lyu, Lingjuan and Liu, Ji},
	month = jul,
	year = {2022},
	note = {Conference Name: IEEE Internet of Things Journal},
	pages = {11365--11375},
}

@inproceedings{hartmann_mofld_2023,
	title = {{MOFL}/{D}: {A} {Federated} {Multi}-objective {Learning} {Framework} with {Decomposition}},
	shorttitle = {{MOFL}/{D}},
	url = {https://openreview.net/forum?id=Pj6BPHZy56},
	abstract = {Multi-objective learning problems occur in all aspects of life and have been studied for decades, including in the field of machine learning. Many such problems also exist in distributed settings, where data cannot easily be shared. In recent years, joint machine learning has been made possible in such settings through the development of the Federated Learning (FL) paradigm. However, there is as of now very little research on the general problem of extending the FL concept to multi- objective learning, limiting such problems to non-cooperative individual learning. We address this gap by presenting a general framework for multi-objective FL, based on decomposition (MOFL/D). Our framework addresses the a posteriori type of multi-objective problem, where user preferences are not known during the optimisation process, allowing multiple participants to jointly find a set of solutions, each optimised for some distribution of preferences. We present an instantiation of the framework and validate it through experiments on a set of multi-objective benchmarking problems that are extended from well-known single- objective benchmarks.},
	language = {en},
	urldate = {2023-12-05},
	author = {Hartmann, Maria and Danoy, Grégoire and Alswaitti, Mohammed and Bouvry, Pascal},
	month = oct,
	year = {2023},
}

@inproceedings{ye_pfedsa_2023-1,
	title = {{PFedSA}: {Personalized} {Federated} {Multi}-{Task} {Learning} via {Similarity} {Awareness}},
	shorttitle = {{PFedSA}},
	url = {https://ieeexplore.ieee.org/document/10177489},
	doi = {10.1109/IPDPS54959.2023.00055},
	abstract = {Federated Learning (FL) constructs a distributed machine learning framework that involves multiple remote clients collaboratively training models. However in real-world situations, the emergence of non-Independent and Identically Distributed (non-IID) data makes the global model generated by traditional FL algorithms no longer meet the needs of all clients, and the accuracy is greatly reduced. In this paper, we propose a personalized federated multi-task learning method via similarity awareness (PFedSA), which captures the similarity between client data through model parameters uploaded by clients, thus facilitating collaborative training of similar clients and providing personalized models based on each client’s data distribution. Specifically, it generates the intrinsic cluster structure among clients and introduces personalized patch layers into the cluster to personalize the cluster model. PFedSA also maintains the generalization ability of models, which allows each client to benefit from nodes with similar data distributions when training data, and the greater the similarity, the more benefit. We evaluate the performance of the PFedSA method using MNIST, EMNIST and CIFAR10 datasets, and investigate the impact of different data setting schemes on the performance of PFedSA. The results show that in all data setting scenarios, the PFedSA method proposed in this paper can achieve the best personalization performance, having more clients with higher accuracy, and it is especially effective when the client’s data is non-IID.},
	urldate = {2023-12-05},
	booktitle = {2023 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} ({IPDPS})},
	author = {Ye, Chuyao and Zheng, Hao and Hu, Zhigang and Zheng, Meiguang},
	month = may,
	year = {2023},
	note = {ISSN: 1530-2075},
	pages = {480--488},
}

@inproceedings{naseri_cerberus_2022,
	address = {New York, NY, USA},
	series = {{CCS} '22},
	title = {Cerberus: {Exploring} {Federated} {Prediction} of {Security} {Events}},
	isbn = {978-1-4503-9450-5},
	shorttitle = {Cerberus},
	url = {https://doi.org/10.1145/3548606.3560580},
	doi = {10.1145/3548606.3560580},
	abstract = {Modern defenses against cyberattacks increasingly rely on proactive approaches, e.g., to predict the adversary's next actions based on past events. Building accurate prediction models requires knowledge from many organizations; alas, this entails disclosing sensitive information, such as network structures, security postures, and policies, which might often be undesirable or outright impossible. In this paper, we explore the feasibility of using Federated Learning (FL) to predict future security events. To this end, we introduce Cerberus, a system enabling collaborative training of Recurrent Neural Network (RNN) models for participating organizations. The intuition is that FL could potentially offer a middle-ground between the non-private approach where the training data is pooled at a central server and the low-utility alternative of only training local models. We instantiate Cerberus on a dataset obtained from a major security company's intrusion prevention product and evaluate it vis-à-vis utility, robustness, and privacy, as well as how participants contribute to and benefit from the system. Overall, our work sheds light on both the positive aspects and the challenges of using FL for this task and paves the way for deploying federated approaches to predictive security.},
	urldate = {2023-11-20},
	booktitle = {Proceedings of the 2022 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {Association for Computing Machinery},
	author = {Naseri, Mohammad and Han, Yufei and Mariconti, Enrico and Shen, Yun and Stringhini, Gianluca and De Cristofaro, Emiliano},
	month = nov,
	year = {2022},
	keywords = {federated learning, predictive security, privacy, robustness},
	pages = {2337--2351},
}

@article{huang_personalized_2021,
	title = {Personalized {Cross}-{Silo} {Federated} {Learning} on {Non}-{IID} {Data}},
	volume = {35},
	issn = {2374-3468, 2159-5399},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/16960},
	doi = {10.1609/aaai.v35i9.16960},
	abstract = {Non-IID data present a tough challenge for federated learning. In this paper, we explore a novel idea of facilitating pairwise collaborations between clients with similar data. We propose FedAMP, a new method employing federated attentive message passing to facilitate similar clients to collaborate more. We establish the convergence of FedAMP for both convex and non-convex models, and propose a heuristic method to further improve the performance of FedAMP when clients adopt deep neural networks as personalized models. Our extensive experiments on benchmark data sets demonstrate the superior performance of the proposed methods.},
	language = {en},
	number = {9},
	urldate = {2022-09-26},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Huang, Yutao and Chu, Lingyang and Zhou, Zirui and Wang, Lanjun and Liu, Jiangchuan and Pei, Jian and Zhang, Yong},
	month = may,
	year = {2021},
	pages = {7865--7873},
}

@article{lecun_gradient-based_1998,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	issn = {1558-2256},
	url = {https://ieeexplore.ieee.org/document/726791},
	doi = {10.1109/5.726791},
	abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
	number = {11},
	urldate = {2023-11-09},
	journal = {Proceedings of the IEEE},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	month = nov,
	year = {1998},
	note = {Conference Name: Proceedings of the IEEE},
	pages = {2278--2324},
}

@techreport{shen_blockchain-assisted_2023,
	type = {preprint},
	title = {Blockchain-{Assisted} {Cross}-silo {Graph} {Federated} {Learning} for {Network} {Intrusion} {Detection}},
	url = {https://www.researchsquare.com/article/rs-3330608/v1},
	abstract = {In this paper, a blockchain-assisted cross-silo graph federated learning (B-CGFL) framework is presented for large-scale network intrusion detection, aiming to break down barriers among different organizations and achieve a secure and transparent multi-party collaboration ecosystem. The network scenario is divided into multiple regions. Organizations in each region leverage graph neural networks to analyze local network flow topology information and identify traffic types accurately. With cross-silo graph federated learning, coordinators and organizations collaboratively complete the training and updating of global intrusion detection models. Multiple coordinators jointly maintain a chain to improve the global model’s scalability and storage security. Oracle nodes bridge the off-chain data provider and on-chain smart contracts, enabling secure transmission in off-chain model accuracy testing. For fair competition, a reputation-aware model incentive mechanism is designed to improve global model quality. Security analysis confirms that B-CGFL can defend against inference attacks, model plagiarism, and tampering with model test results. Experiments on three challenging datasets ToN-IoT, CSE-CIC-IDS2018, and BoT-IoT demonstrate that compared with benchmark machine learning methods, B-CGFL exhibits superior performance in accuracy and F1-score and facilitates model quality improvement.},
	language = {en},
	urldate = {2023-10-13},
	institution = {In Review},
	author = {Shen, Hang and Zhou, Yanjing and Wang, Tianjing and Zhang, Yu and Bai, Guangwei and Miao, Xiaodong},
	month = sep,
	year = {2023},
	doi = {10.21203/rs.3.rs-3330608/v1},
	keywords = {\_unpublished},
}

@inproceedings{qureshi_performance_2021,
	address = {New York, NY, USA},
	series = {{UbiComp}/{ISWC} '21 {Adjunct}},
	title = {On the {Performance} {Impact} of {Poisoning} {Attacks} on {Load} {Forecasting} in {Federated} {Learning}},
	isbn = {978-1-4503-8461-2},
	url = {https://dl.acm.org/doi/10.1145/3460418.3479285},
	doi = {10.1145/3460418.3479285},
	abstract = {This article examines a poisoning attack on federated learning. While recent studies are actively exploring this topic in classification models of learning such as image recognition, there are few studies that address the topic in regression models. In particular, this research investigates the impacts of poisoning attacks on the performance of load forecasting, which has hardly studied yet in academia. This research implements two poisoning attacks on a federated learning setting and runs experiments to enumerate their impacts on prediction accuracy of load forecasting. With initial results, we plan to bring a couple of research questions for open discussion to audience.},
	urldate = {2023-11-02},
	booktitle = {Adjunct {Proceedings} of the 2021 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} and {Proceedings} of the 2021 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {Association for Computing Machinery},
	author = {Qureshi, Naik Bakht Sania and Kim, Dong-Hoon and Lee, Jiwoo and Lee, Eun-Kyu},
	month = sep,
	year = {2021},
	keywords = {Artificial Intelligence, Distributed System, Energy Data, Federated Learning, Load Forecasting, Poisoning Attack, Security},
	pages = {64--66},
}

@misc{abdelmoniem_impact_2021,
	title = {On the {Impact} of {Device} and {Behavioral} {Heterogeneity} in {Federated} {Learning}},
	url = {http://arxiv.org/abs/2102.07500},
	abstract = {Federated learning (FL) is becoming a popular paradigm for collaborative learning over distributed, private datasets owned by non-trusting entities. FL has seen successful deployment in production environments, and it has been adopted in services such as virtual keyboards, autocompletion, item recommendation, and several IoT applications. However, FL comes with the challenge of performing training over largely heterogeneous datasets, devices, and networks that are out of the control of the centralized FL server. Motivated by this inherent setting, we make a ﬁrst step towards characterizing the impact of device and behavioral heterogeneity on the trained model. We conduct an extensive empirical study spanning close to 1.5K unique conﬁgurations on ﬁve popular FL benchmarks. Our analysis shows that these sources of heterogeneity have a major impact on both model performance and fairness, thus sheds light on the importance of considering heterogeneity in FL system design.},
	language = {en},
	urldate = {2023-11-02},
	publisher = {arXiv},
	author = {Abdelmoniem, Ahmed M. and Ho, Chen-Yu and Papageorgiou, Pantelis and Bilal, Muhammad and Canini, Marco},
	month = feb,
	year = {2021},
	note = {arXiv:2102.07500 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Computer Science - Performance},
}

@misc{kamp_federated_2023,
	title = {Federated {Learning} from {Small} {Datasets}},
	url = {http://arxiv.org/abs/2110.03469},
	doi = {10.48550/arXiv.2110.03469},
	abstract = {Federated learning allows multiple parties to collaboratively train a joint model without sharing local data. This enables applications of machine learning in settings of inherently distributed, undisclosable data such as in the medical domain. In practice, joint training is usually achieved by aggregating local models, for which local training objectives have to be in expectation similar to the joint (global) objective. Often, however, local datasets are so small that local objectives differ greatly from the global objective, resulting in federated learning to fail. We propose a novel approach that intertwines model aggregations with permutations of local models. The permutations expose each local model to a daisy chain of local datasets resulting in more efficient training in data-sparse domains. This enables training on extremely small local datasets, such as patient data across hospitals, while retaining the training efficiency and privacy benefits of federated learning.},
	urldate = {2023-11-02},
	publisher = {arXiv},
	author = {Kamp, Michael and Fischer, Jonas and Vreeken, Jilles},
	month = oct,
	year = {2023},
	note = {arXiv:2110.03469 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
}

@inproceedings{zhang_evaluation_2022,
	title = {Evaluation of data poisoning attacks on federated learning-based network intrusion detection system},
	url = {https://ieeexplore.ieee.org/document/10074658},
	doi = {10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00330},
	abstract = {Recently, federated learning-based network intrusion detection system (FL-based NIDS) has been considered as an essential tool to protect network security. It enables learning an effective intrusion detection model collaboratively without data privacy leakage. However, FL- based NIDS has exhibited inherent vulnerabilities on the data poisoning attacks launched by malicious clients. In this paper, we conduct the first systematic robustness evaluations of FL-based NIDS under data poisoning attack. Firstly, in consideration of the traffic domain constraints, we design the clean-label data poisoning attack against FL-based NIDS. Specifically, we propose an improved poisoned sample generation model based on Generative Adversarial Network, called PT-GAN, which optimizes with a new loss function that incorporates the feedback of the target intrusion detection model. The minimally-perturbed and correctly-labeled traffic samples generated by PT-GAN are then injected in the local training dataset to corrupt the intrusion detection model. Then, we explore the potential defense mechanism for these data poisoning attacks against FL- based NIDS and propose a novel defense method based on poisoned sample detection. Concretely, we propose the important neuron activations extraction method based on the layerwise relevance propagation method and then apply Oneclass-SVM to detect the poisoned sample. Experiments show that the proposed PT-GAN can degrade the performance of FL-based NIDS up to 28\% on UNSW-NB15 dataset. We also demonstrate the robustness of our proposed defense methods against data poisoning attacks.},
	urldate = {2023-10-31},
	booktitle = {2022 {IEEE} 24th {Int} {Conf} on {High} {Performance} {Computing} \& {Communications}; 8th {Int} {Conf} on {Data} {Science} \& {Systems}; 20th {Int} {Conf} on {Smart} {City}; 8th {Int} {Conf} on {Dependability} in {Sensor}, {Cloud} \& {Big} {Data} {Systems} \& {Application} ({HPCC}/{DSS}/{SmartCity}/{DependSys})},
	author = {Zhang, Yuemeng and Zhang, Yong and Zhang, Zhao and Bai, Haonan and Zhong, Tianyi and Song, Mei},
	month = dec,
	year = {2022},
	pages = {2235--2242},
}

@misc{MUD_rfc,
	title = {Manufacturer usage description specification},
	url = {https://rfc-editor.org/rfc/rfc8520.txt},
	abstract = {This memo specifies a component-based architecture for Manufacturer Usage Descriptions (MUDs). The goal of MUD is to provide a means for end devices to signal to the network what sort of access and network functionality they require to properly function. The initial focus is on access control. Later work can delve into other aspects. This memo specifies two YANG modules, IPv4 and IPv6 DHCP options, a Link Layer Discovery Protocol (LLDP) TLV, a URL, an X.509 certificate extension, and a means to sign and verify the descriptions.},
	publisher = {RFC Editor},
	author = {Lear, Eliot and Droms, Ralph and Romascanu, Dan},
	month = mar,
	year = {2019},
	doi = {10.17487/RFC8520},
	note = {Number: 8520
Series: Request for comments
tex.howpublished: RFC 8520
tex.pagetotal: 60},
	keywords = {pinned},
}

@misc{Hydra,
	title = {Hydra - {A} framework for elegantly configuring complex applications},
	url = {https://github.com/facebookresearch/hydra},
	author = {Yadan, Omry},
	year = {2019},
	note = {tex.howpublished: Github},
	keywords = {pinned},
}

@misc{NIS_directive,
	title = {Directive ({EU}) 2016/1148 of 6 {July} 2016 concerning measures for a high common level of security of network and information systems across the {Union}},
	url = {https://eur-lex.europa.eu/eli/dir/2016/1148/oj},
	abstract = {It proposes a wide-ranging set of measures to boost the level of security of network and information systems (cybersecurity*) to secure services vital to the EU economy and society. It aims to ensure that EU countries are well-prepared and are ready to handle and respond to cyberattacks through: the designation of competent authorities, the set-up of computer-security incident response teams (CSIRTs), and the adoption of national cybersecurity strategies. It also establishes EU-level cooperation both at strategic and technical level. Lastly, it introduces the obligation on essential-services providers and digital service providers to take the appropriate security measures and to notify the relevant national authorities about serious incidents.},
	author = {{The European Parliament and The Counsil}},
	year = {2016},
	keywords = {pinned},
}

@misc{GDPR,
	title = {{REGULATION} ({EU}) 2016/679 {OF} {THE} {EUROPEAN} {PARLIAMENT} {AND} {OF} {THE} {COUNCIL} of 27 {April} 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing {Directive} 95/46/{EC} ({General} {Data} {Protection} {Regulation})},
	url = {https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32016R0679},
	language = {en},
	author = {The European Parliament {and} The Counsil},
	year = {2016},
	keywords = {pinned},
	pages = {88},
}

@misc{kddcup99,
	title = {{KDD} {Cup} 1999 {Dataset}},
	url = {https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html},
	urldate = {2021-04-26},
	author = {{SigKDD}},
	year = {1999},
	keywords = {pinned},
}

@misc{jayalaxmi_debot_2022,
	title = {{DeBot}: {A} deep learning-based model for bot detection in industrial internet-of-things {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {{DeBot}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0045790622004530?token=4E14C31C17A9FF85CDC88A77D85258F179CBBA6C3A1FD68BA24FF99B40E096CBAE42EBCF9408CE7BF160E1A559785314&originRegion=eu-west-1&originCreation=20220811054018},
	abstract = {In this paper, we show a deep learning model for bot detection, named as DeBot, for industrial network traffic. DeBot uses a novel Cascade Forward Back Propagation Neural Network (CFBPNN) model with a subset of features using the Correlation-based Feature Selection (CFS) technique. A time series-based Nonlinear Auto-regressive Network with eXogenous inputs (NARX) technique analyzes the factors having a higher impact on the target variable and predict the behavioral pattern. To the best of our knowledge, we pioneer the use of optimal feature selection and integration with the cascading model of deep learning in bot detection of IIoTs. We conduct a thorough set of experiments on five popular bot datasets: NF-UNSW-NB15, NFToN-IoT, NF-BoT-IoT, NF-CSE-CIC-IDS2018, and ToN-IoT-Windows. We compare CFBPNN with other existing neural network models. We observe that CFBPNN in DeBot shows 100\% accuracy in all the datasets with subset evaluation and obtains optimum F1-score and zero precision.},
	language = {en},
	urldate = {2022-08-11},
	author = {Jayalaxmi, P. L. S. and Kumar, Gulshan and Saha, Rahul and Conti, Mauro and Kim, Tai-hoon and Thomas, Reji},
	year = {2022},
	doi = {10.1016/j.compeleceng.2022.108214},
}

@misc{herzberg_breaking_2016,
	title = {Breaking {Down} {Mirai}: {An} {IoT} {DDoS} {Botnet} {Analysis}},
	url = {https://www.imperva.com/blog/malware-analysis-mirai-ddos-botnet/?redirect=Incapsula},
	urldate = {2021-03-12},
	author = {Herzberg, Ben and Zeifman, Igal and Bekerman, Dima},
	year = {2016},
}

@techreport{ENISA2010,
	title = {Incentives and {Challenges} for {Information} {Sharing} in the {Context} of {Network} and {Information} {Security}},
	url = {http://www.google.com/#sclient=psy&hl=en&safe=off&q=literature+review+information+sharing+law+enforcement&aq=f&aqi=&aql=&oq=&gs_rfai=&pbx=1&fp=9bef8cda26d1a6ec},
	abstract = {The importance of information sharing to ensuring network and information security is widely acknowledged by both policy-makers and by the technical and practitioner community – for example, in the European Programme on Critical Infrastructure Protection (EPCIP) and in the 2004 Availability and Robustness of Electronic Communications Infrastructures (ARECI) study, which noted that formal means for sharing information should be set up in order to ―improve the protection and rapid restoration of infrastructure critical to the reliability of communications within and throughout Europe‖. A 2009 gap analysis conducted by ENISA of good practice in respect of telecommunication network operators identified information sharing as a set of useful best practice. Given the acknowledged importance of information sharing, this report sets out findings from a research project into the barriers to and incentives for information sharing in the field of network and information security, in the context of peer-to-peer groups such as Information Exchanges (IE) and Information Sharing Analysis Centres (ISACs).{\textbackslash}nMethods and approach The information in this report is drawn from three sources: {\textbackslash}n A review of available literature – both academic and non-academic publications,  Interviews with key informants working in the field of network and information {\textbackslash}nsecurity and in IEs,  A two-round Delphi exercise with network and information security professionals. {\textbackslash}n The aim of this project is to identify those barriers and incentives which are most important in day-to-day practice in IEs and ISACs. This research differs from other work in this field in being firmly grounded in the experiences of practitioners and those involved in IE and Information Sharing activities. Nonetheless we only managed to speak to a limited number of experts from a handful of countries. Therefore, the findings of this research are a first step to developing an evidence base in this field, but we do not claim they are generalisable to all kinds of IEs. {\textbackslash}nIncentives and challenges for information sharing Our findings indicate that many of the barriers and incentives commonly identified in the {\textbackslash}navailable literature are of relatively low importance to practitioners and security officials currently working in IEs. As part of this research we asked practitioners to rank a list of barriers and incentives in terms of their relative importance. Our findings indicate that the incentives which are most important are: {\textbackslash}n Economic incentives stemming from cost savings;  Incentives stemming from the quality, value, and use of information shared. {\textbackslash}n While the barriers which are the most important are: {\textbackslash}n Poor quality information;  Misaligned economic incentives stemming from reputational risks;  Poor management.},
	author = {{ENISA}},
	year = {2010},
	note = {Volume: 10},
	keywords = {pinned},
	pages = {52},
}

@techreport{ENISA2017,
	title = {Exploring the opportunities and limitations of current {Threat} {Intelligence} {Platforms}},
	abstract = {The main objective of this report is to understand the limitations of threat information sharing and the analysis tools that are currently in use. Moreover, the second objective is to provide the relevant recommendations so that these limitations can be addressed and overcome. To achieve this, the report presents an overview of the users of these platforms, the main functional areas of TIPs as well as the current landscape of the TIPs used by different teams globally (CTI teams, SOCs, CSIRTs/CERTs, ISACs, etc.)},
	author = {{ENISA}},
	year = {2017},
	note = {Issue: December},
	keywords = {pinned},
	pages = {42},
}

@techreport{ENISA2014,
	title = {Actionable {Information} for {Security} {Incident} {Response}},
	abstract = {The European Union Agency for Network and Information Security (ENISA) is a centre of network and information security expertise for the EU, its member states, the private sector and Europe's citizens. ENISA works with these groups to develop advice and recommendations on good practice in information security. It assists EU member states in implementing relevant EU legislation and works to improve the resilience of Europe's critical information infrastructure and networks. ENISA seeks to enhance existing expertise in EU member states by supporting the development of cross-border communities committed to improving network and information security throughout the EU. More information about ENISA and its work can be found at www.enisa.europa.eu.},
	author = {{ENISA}},
	year = {2014},
	note = {Publication Title: Enisa
Issue: November
ISBN: 9789292041076},
	keywords = {pinned},
	pages = {1--79},
}

@misc{mirai_tracker,
	title = {Mirai {Tracker}},
	url = {https://mirai.security.gives/},
	urldate = {2021-03-12},
	author = {{Anonym}},
	year = {2019},
	keywords = {pinned},
}

@misc{ACM_artifacts,
	title = {Artifact {Review} and {Badging} v1.1},
	url = {https://www.acm.org/publications/policies/artifact-review-and-badging-current},
	abstract = {Result and Artifact Review documentation and badges - V.1.1},
	language = {en},
	urldate = {2022-08-17},
	author = {{ACM}},
	month = aug,
	year = {2020},
	keywords = {pinned},
}

@misc{ds2os_dataset,
	title = {ds2ostraffictraces - {Kaggle}},
	url = {https://www.kaggle.com/francoisxa/ds2ostraffictraces},
	publisher = {Kaggle},
	keywords = {pinned},
}

@misc{CORE,
	title = {Conference portal - {CORE}},
	url = {http://portal.core.edu.au/conf-ranks/},
	keywords = {pinned},
}

@phdthesis{perrin_specification_2016,
	title = {Spécification des objets partagés dans les systèmes répartis sans-attente},
	url = {http://www.theses.fr/2016NANT2103},
	author = {Perrin, Matthieu},
	year = {2016},
	note = {Pages: 1 vol. (203 p.)
Url: http://www.theses.fr/2016NANT2103/document},
}

@phdthesis{ludinard_caracterisation_2014,
	type = {Informatique},
	title = {Caractérisation locale de fautes dans les systèmes large échelle},
	abstract = {Internet est un réseau de réseaux permettant la mise en œuvre de divers services consommés par les utilisateurs. Malheureusement, chacun des éléments présents dans le réseau ou impliqués dans ces services peut potentiellement exhiber des défaillances. Une défaillance peut être per ̧cue par un nombre variable d’utilisateurs suivant la localisation dans le système de la source de celle-ci. Cette thèse propose un ensemble
de contributions visant à déterminer du point de vue d’un utilisateur percevant une défaillance, si celle-ci est perçue par un faible nombre d’utilisateurs (défaillance isolée) ou à l’inverse par un très grand nombre d’utilisateurs (défaillance massive). Nous formalisons dans un premier temps les défaillances par leur impact sur la perception des services consommés par les utilisateurs. Nous montrons ainsi qu’il est impossible, du point de vue d’un utilisateur, de déterminer de manière certaine si une défaillance perçue est isolée ou massive. Cependant, il possible de déterminer de manière certaine pour chaque utilisateur, s’il a perçu une défaillance isolée, massive, ou s’il est impossible de le déterminer. Cette caractérisation est optimale et totalement parallelisable. Dans un second temps, nous proposons une architecture pour la caractérisation de fautes. Les entités du système s’organisent au sein d’une structure à deux niveaux permettant de regrouper ensemble les entités ayant des perceptions similaires et ainsi mener à bien l’approche proposée. Enfin, une analyse probabiliste de la résistance au dynamisme et aux comportements malveillants du second niveau de cette architecture complète ce document.},
	language = {fr},
	school = {Université Rennes 1},
	author = {Ludinard, Romaric},
	year = {2014},
	keywords = {⛔ No DOI found},
}

@phdthesis{vakilinia_collaborative_2019,
	title = {Collaborative {Analysis} of {Cybersecurity} {Information} {Sharing}},
	url = {http://hdl.handle.net/11714/5773},
	author = {Vakilinia, Iman},
	year = {2019},
	note = {Issue: May},
}

@techreport{strom_mitre_2020,
	title = {{MITRE} {ATT}{\textbackslash}\&{CK}®: {Design} and {Philosophy}},
	url = {https://attack.mitre.org/docs/ATTACK_Design_and_Philosophy_March_2020.pdf},
	abstract = {MITRE ATT{\textbackslash}\&CK is a globally-accessible knowledge base of adversary tactics and techniques
based on real-world observations. The ATT{\textbackslash}\&CK knowledge base is used as a foundation for the
development of specific threat models and methodologies in the private sector, in government,
and in the cybersecurity product and service community. ATT{\textbackslash}\&CK provides a common
taxonomy for both offense and defense, and has become a useful conceptual tool across many
cyber security disciplines to convey threat intelligence, perform testing through red teaming or
adversary emulation, and improve network and system defenses against intrusions. The process
MITRE used to create ATT{\textbackslash}\&CK, and the philosophy that has developed for curating new
content, are critical aspects of the work and are useful for other efforts that strive to create
similar adversary models and information repositories.},
	number = {10AOH08A-JC},
	urldate = {2022-07-07},
	author = {Strom, Blake E. and Applebaum, Andy and Miller, Doug P. and Nickels, Kathryn C. and Pennington, Adam G. and Thomas, Cody B.},
	month = mar,
	year = {2020},
}

@techreport{sivamohan_kho-xai_2022,
	type = {preprint},
	title = {{KHO}-{XAI}: {Krill} herd optimization and {Explainable} {Artificial} {Intelligence} framework for {Network} {Intrusion} {Detection} {Systems} in {Industry} 4.0},
	shorttitle = {{KHO}-{XAI}},
	url = {https://www.researchsquare.com/article/rs-1683748/v1},
	abstract = {Industry 4.0 enable novel business cases, such as client-specific production, real-time monitoring of process condition and progress, independent decision making and remote maintenance, to name a few. However, they are more susceptible to a broad range of cyber threats because of limited resources and heterogeneous nature. Such risks cause financial and reputational damages for businesses, well as the theft of sensitive information. The higher level of diversity in industrial network prevents the attackers from such attacks. Therefore, to efficiently detect the intrusions, a novel intrusion detection system known as Bidirectional Long Short-Term Memory based Explainable Artificial Intelligence framework (BiLSTM-XAI) is developed. Initially, the preprocessing task using normalization and standardization is performed to enhance the data quality for detecting network intrusions. Subsequently, the significant features are selected from the databases using the Krill herd optimization (KHO) algorithm. The proposed BiLSTM-XAI approach provides better security and privacy inside the industry networking system by detecting intrusions very precisely. In this, we utilized SHAP and LIME explainable AI algorithms to further improve the prediction accuracy. The experimental setup is made by MATLAB 2016 software using Honeypot and NSL-KDD datasets as input. The analysis result reveals that the proposed method achieves superior performance in detecting intrusions with a classification accuracy of 98.2\%.},
	language = {en},
	urldate = {2022-07-05},
	institution = {In Review},
	author = {Sivamohan, S and Sri, S. S.},
	month = jun,
	year = {2022},
	doi = {10.21203/rs.3.rs-1683748/v1},
}

@techreport{qi_differentially_2022,
	type = {preprint},
	title = {Differentially {Private} {Knowledge} {Transfer} for {Federated} {Learning}},
	url = {https://www.researchsquare.com/article/rs-1571398/v1},
	abstract = {Abstract
          Extracting useful knowledge from big data is important for machine learning. When data is privacy-sensitive and cannot be directly collected, federated learning is a promising option that extracts knowledge from decentralized data by learning and exchanging model parameters, rather than raw data. However, model parameters may encode not only non-private knowledge but also private information of local data, thereby transferring knowledge via model parameters is not privacy-secure. Here, we present a novel knowledge transfer method named PrivateKT, which uses actively selected small public data to transfer high-quality knowledge in federated learning with privacy guarantees. We verify PrivateKT on three different datasets, and results show that PrivateKT can maximally reduce 84\% of the performance gap between centralized learning and existing federated learning methods under strict differential privacy restrictions. PrivateKT provides a potential direction to effective and privacy-preserving knowledge transfer in machine intelligent systems.},
	language = {en},
	urldate = {2022-07-05},
	institution = {In Review},
	author = {Qi, Tao and Wu, Fangzhao and Wu, Chuhan and Huang, Yongfeng and Xie, Xing},
	month = may,
	year = {2022},
	doi = {10.21203/rs.3.rs-1571398/v1},
}

@techreport{popoola_optimizing_2022,
	type = {preprint},
	title = {Optimizing {Deep} {Learning} {Model} {Hyperparameters} for {Botnet} {Attack} {Detection} in {IoT} {Networks}},
	url = {https://www.techrxiv.org/articles/preprint/Optimizing_Deep_Learning_Model_Hyperparameters_for_Botnet_Attack_Detection_in_IoT_Networks/19501885/1},
	abstract = {Deep Learning (DL) models can be trained to automatically learn the underlying features of the traffic patterns in IoT networks to detect complex botnet attacks. However, the performance of a neural network model largely depends on the set of hyperparameters that is used for the model development. In this paper, an algorithm is proposed to determine the optimal set of hyperparameters (the numbers of hidden layers and hidden units, the learning rate, the optimiser, the activation function, the batch size, and the number of epochs) for efficient DLbased botnet detection in IoT networks. The DL models employ a Deep Neural Network (DNN) architecture for binary and multi-class classification. DNN-based botnet detection models are developed and experiments are performed with the BotIoT and N-BaIoT datasets to validate the effectiveness of the hyperparameter optimisation method. Experiment results showed that the proposed method produced DNN models that achieved high botnet attack detection rates, low false alarm rates, and near real-time computation speed.},
	language = {en},
	urldate = {2022-04-14},
	author = {Popoola, Segun and Adebisi, Bamidele and Gui, Guan and Hammoudeh, Mohammad and Gacanin,, Haris and Dancey, Darren},
	month = apr,
	year = {2022},
	doi = {10.36227/techrxiv.19501885.v1},
}

@techreport{kitchenham_guidelines_2007,
	title = {Guidelines for performing systematic literature reviews in software engineering},
	abstract = {The objective of this report is to propose comprehensive guidelines for systematic literature reviews appropriate for software engineering researchers, including PhD students. A systematic literature review is a means of evaluating and interpreting all available research relevant to a particular research question, topic area, or phenomenon of interest. Systematic reviews aim to present a fair evaluation of a research topic by using a trustworthy, rigorous, and auditable methodology.

The guidelines presented in this report were derived from three existing guidelines used by medical researchers, two books produced by researchers with social science backgrounds and discussions with researchers from other disciplines who are involved in evidence-based practice. The guidelines have been adapted to reflect the specific problems of software engineering research.

The guidelines cover three phases of a systematic literature review: planning the review, conducting the review and reporting the review. They provide a relatively high level description. They do not consider the impact of the research questions on the review procedures, nor do they specify in detail the mechanisms needed to perform meta-analysis.},
	number = {EBSE-2007-01},
	author = {Kitchenham, B. and Charters, S},
	year = {2007},
}

@phdthesis{busnel_systemes_2008,
	title = {Systèmes d'information collaboratifs et auto-organisants pour réseaux de capteurs large-échelle : "{De} la théorie à la pratique"},
	url = {https://tel.archives-ouvertes.fr/tel-00365659},
	abstract = {Les systèmes informatiques ont connu récemment de grandes avancées dans leur conception. D'une part, la démocratisation des réseaux via la croissance exponentielle de l'Internet a permis d'envisager des systèmes à l'échelle mondiale, visant de mettre en commun une multitude de ressources à travers la planète entière. D'autre part, la réduction continue de la taille des équipements informatiques a permis l'apparition de matériels miniatures. Le jumelage de ces deux évolutions est à l'origine de l'apparition des réseaux de capteurs sans fil. Le spectre des applications potentielles de ces réseaux est extrêmement large, que cela soit dans le contexte d'une infrastructure fixe autant que dans l'informatique embarquée. Cette thèse propose un ensemble de contributions pour la gestion de l'information à la fois dans le contexte mobile et statique. Édifiées autour des mêmes propriétés de collaboration et d'auto-organisation, ces propositions sont conçues selon une méthodologie de la théorie vers la pratique. Cette thèse vise ainsi, en premier lieu, une analyse théorique a priori d'une application classique des réseaux de capteurs statiques, à savoir le suivi de trajectoires d'objets mobiles non identifiés. Par la suite, nous étendons le spectre des applications visées en proposant une structure générique à toute mise en oeuvre réelle de réseaux de capteurs statiques. En second lieu, nous considérons une modélisation de la mobilité permettant d'analyser fondamentalement les impacts de celle-ci sur la convergence des protocoles dits de population. Enfin, nous établissons un parallèle entre les travaux menés théoriquement sur les réseaux de capteurs mobiles avec ceux plus pratiques et empiriques proposés dans le cadre des protocoles épidémiques sur réseaux filaires. En démontrant que ces deux domaines portent en réalité sur la même classe de protocoles -- et donc de problèmes -- nous ouvrons ainsi une voie captivante pour de futures recherches dans chacun de ces deux domaines, par l'utilisation de l'un dans l'autre.},
	school = {Université Rennes 1},
	author = {Busnel, Yann},
	month = nov,
	year = {2008},
}

@phdthesis{boubou_contribution_2007,
	title = {Contribution aux méthodes de classification non supervisée via des approches prétopologiques et d'agrégation d'opinions},
	url = {https://tel.archives-ouvertes.fr/tel-00195779},
	school = {Université Claude Bernard - Lyon I},
	author = {Boubou, Mounzer},
	month = nov,
	year = {2007},
}

@techreport{albaseer_data-driven_2022,
	type = {preprint},
	title = {Data-{Driven} {Participant} {Selection} and {Bandwidth} {Allocation} for {Heterogeneous} {Federated} {Edge} {Learning}},
	url = {https://www.techrxiv.org/articles/preprint/Data-Driven_Participant_Selection_and_Bandwidth_Allocation_for_Heterogeneous_Federated_Edge_Learning/19317671/1},
	abstract = {Federated edge learning (FEEL) is a fast-growing distributed learning technique for next-generation wireless edge systems. Smart systems in different application domains suffer from data heterogeneity, limited wireless resources, and device heterogeneity, necessitating the need for intelligent participants’ selection schemes that accelerate the convergence rate. Hence, this paper proposes joint participants selection and bandwidth allocation schemes to address these challenges. First, we formulate an optimization problem considering communication and computation latencies and imbalanced data distribution that meets a target round deadline and bandwidth constraints. To tackle participant selection combinatorial problems, we use a relaxation method followed by a proposed priority selection algorithm to select near-optimal participants. The proposed algorithm initially prioritizes participants with more data, effective channel states, and better CPU speed. To tackle data heterogeneity, we propose a randomized deadline controlling algorithm that diversifies the updates by enabling the edge server to involve various participants with small data samples into training rounds. The proposed algorithms provide near-optimal performance compared to the brute-force method. Experiments demonstrate that our proposed scheme accelerates the convergence rate by up to 55\% under extensive non-i.i.d settings compared to benchmarks. Additionally, the controlling algorithm significantly improves the performance of the high data heterogeneity levels, resulting in faster FEEL systems.},
	language = {en},
	urldate = {2022-03-23},
	author = {Albaseer, Abdullatif and Abdallah, Mohamed and Al-Fuqaha, Ala and Erbad, aiman},
	month = mar,
	year = {2022},
	doi = {10.36227/techrxiv.19317671.v1},
}

@techreport{hideya_lan-security_2018,
	type = {Whitepaper},
	title = {{LAN}-{Security} {Monitoring} {Project}},
	url = {https://lan-security.net/whitepaper.pdf},
	language = {en},
	urldate = {2021-10-22},
	author = {Hideya, Ochiai},
	year = {2018},
}

@techreport{juszczyk_proactive_2011,
	title = {Proactive {Detection} of {Network} {Security} {Incidents}},
	url = {https://www.enisa.europa.eu/activities/cert/support/proactive-detection/proactive-detection-report},
	abstract = {This document is the final report of the ‘Proactive Detection of Network Security Incidents’ study. The goal of the study was to investigate ways in which CERTs – national and governmental ones in particular – proactively detect incidents concerning their constituencies, identify good practice and recommended measures for new and already established CERTs, analyse problems they face and offer recommendations to relevant stakeholders on what can be done to further this process. It is important to note that the results of the study are largely community driven. That is, they are based not just on research and the experience of the experts who conducted the study, but to a large extent on the results of a survey carried out amongst 105 different CERTs (which resulted in 45 responses overall) and external expert group input. The outcome is thus a work by the community for the CERT community.},
	author = {Juszczyk, Lukasz and Grudziecki, T and Jacewicz, P and Kijewski, Piotr and Pawlinski, Pawel},
	year = {2011},
	note = {Publication Title: European Network and security information Agency},
	pages = {135},
}

@techreport{johnson_guide_2016,
	address = {Gaithersburg, MD},
	title = {Guide to {Cyber} {Threat} {Information} {Sharing}},
	url = {http://dx.doi.org/10.6028/NIST.SP.800-150},
	abstract = {Authority This publication has been developed by NIST in accordance with its statutory responsibilities under the Federal Information Security Modernization Act (FISMA) of 2014, 44 U.S.C. 3551 et seq., Public Law (P.L.) 113-283. NIST is responsible for developing information security standards and guidelines, including minimum requirements for federal information systems, but such standards and guidelines shall not apply to national security systems without the express approval of appropriate federal officials exercising policy authority over such systems. This guideline is consistent with the requirements of the Office of Management and Budget (OMB) Circular A-130.},
	institution = {National Institute of Standards and Technology},
	author = {Johnson, Christopher S. and Badger, Mark Lee and Waltermire, David A. and Snyder, Julie and Skorupka, Clem},
	month = oct,
	year = {2016},
	doi = {10.6028/NIST.SP.800-150},
	note = {Publication Title: NIST Special Publication},
	pages = {800--150},
}

@misc{sarhan_standardfeatureset_2021,
	title = {Towards a {Standard} {Feature} {Set} for {Network} {Intrusion} {Detection} {System} {Datasets}},
	url = {http://arxiv.org/abs/2101.11315},
	abstract = {Network Intrusion Detection Systems (NIDSs) are important tools for the protection of computer networks against increasingly frequent and sophisticated cyber attacks. Recently, a lot of research eﬀort has been dedicated to the development of Machine Learning (ML) based NIDSs. As in any ML-based application, the availability of high-quality datasets is critical for the training and evaluation of ML-based NIDS. One of the key problems with the currently available NIDS datasets is the lack of a standard feature set. The use of a unique and proprietary set of features for each of the publicly available datasets makes it virtually impossible to compare the performance of ML-based traﬃc classiﬁers on diﬀerent datasets, and hence to evaluate the ability of these systems to generalise across diﬀerent network scenarios. To address that limitation, this paper proposes and evaluates standard NIDS feature sets based on the NetFlow network meta-data collection protocol and system. We evaluate and compare two NetFlow-based feature set variants, a version with 12 features, and another one with 43 features. For our evaluation, we converted four widely used NIDS datasets (UNSW-NB15, BoT-IoT, ToN-IoT, CSE-CIC-IDS2018) into new variants with our proposed NetFlow based feature sets. Based on an Extra Tree classiﬁer, we compared the classiﬁcation performance of the NetFlow-based feature sets with the proprietary feature sets provided with the original datasets. While the smaller feature set cannot match the classiﬁcation performance of the proprietary feature sets, the larger set with 43 NetFlow features, surprisingly achieves a consistently higher classiﬁcation performance compared to the original feature set, which was tailored to each of the considered NIDS datasets. The proposed NetFlow-based standard NIDS feature set, together with four benchmark datasets, made available to the research community, allow a fair comparison of ML-based network traﬃc classiﬁers across diﬀerent NIDS datasets. We believe that having a standard feature set is critical for allowing a more rigorous and thorough evaluation of ML-based NIDSs and that it can help bridge the gap between academic research and the practical deployment of such systems.},
	language = {en},
	urldate = {2022-09-12},
	publisher = {arXiv},
	author = {Sarhan, Mohanad and Layeghy, Siamak and Portmann, Marius},
	month = may,
	year = {2021},
	note = {arXiv:2101.11315 [cs]},
	keywords = {Computer Science - Networking and Internet Architecture},
}

@misc{Xu2022,
	title = {Federated {Multi}-organ {Segmentation} with {Partially} {Labeled} {Data}},
	url = {http://arxiv.org/abs/2206.07156},
	abstract = {Federated learning is an emerging paradigm allowing large-scale decentralized learning without sharing data across different data owners, which helps address the concern of data privacy in medical image analysis. However, the requirement for label consistency across clients by the existing methods largely narrows its application scope. In practice, each clinical site may only annotate certain organs of interest with partial or no overlap with other sites. Incorporating such partially labeled data into a uniﬁed federation is an unexplored problem with clinical signiﬁcance and urgency. This work tackles the challenge by using a novel federated multi-encoding U-Net (Fed-MENU) method for multi-organ segmentation. In our method, a multi-encoding UNet (MENU-Net) is proposed to extract organ-speciﬁc features through different encoding sub-networks. Each sub-network can be seen as an expert of a speciﬁc organ and trained for that client. Moreover, to encourage the organ-speciﬁc features extracted by different sub-networks to be informative and distinctive, we regularize the training of the MENU-Net by designing an auxiliary generic decoder (AGD). Extensive experiments on four public datasets show that our Fed-MENU method can effectively obtain a federated learning model using the partially labeled datasets with superior performance to other models trained by either localized or centralized learning methods. Source code will be made publicly available at the time of paper publication.},
	language = {en},
	urldate = {2022-08-11},
	publisher = {arXiv},
	author = {Xu, Xuanang and Yan, Pingkun},
	month = jun,
	year = {2022},
	note = {arXiv:2206.07156 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@misc{Jadidi2022,
	title = {Security of {Machine} {Learning}-{Based} {Anomaly} {Detection} in {Cyber} {Physical} {Systems}},
	url = {http://arxiv.org/abs/2206.05678},
	abstract = {With the emergence of the Internet of Things (IoT) and Artiﬁcial Intelligence (AI) services and applications in the Cyber Physical Systems (CPS), the methods of protecting CPS against cyber threats is becoming more and more challenging. Various security solutions are implemented to protect CPS networks from cyber attacks. For instance, Machine Learning (ML) methods have been deployed to automate the process of anomaly detection in CPS environments. The core of ML is deep learning. However, it has been found that deep learning is vulnerable to adversarial attacks. Attackers can launch the attack by applying perturbations to input samples to mislead the model, which results in incorrect predictions and low accuracy. For example, the Fast Gradient Sign Method (FGSM) is a white-box attack that calculates gradient descent oppositely to maximize the loss and generates perturbations by adding the gradient to unpolluted data. In this study, we focus on the impact of adversarial attacks on deep learning-based anomaly detection in CPS networks and implement a mitigation approach against the attack by retraining models using adversarial samples. We use the Bot-IoT and Modbus IoT datasets to represent the two CPS networks. We train deep learning models and generate adversarial samples using these datasets. These datasets are captured from IoT and Industrial IoT (IIoT) networks. They both provide samples of normal and attack activities. The deep learning model trained with these datasets showed high accuracy in detecting attacks. An Artiﬁcial Neural Network (ANN) is adopted with one input layer, four intermediate layers, and one output layer. The output layer has two nodes representing the binary classiﬁcation results. To generate adversarial samples for the experiment, we used a function called the ‘fast gradient method’ from the Cleverhans library. The experimental result demonstrates the inﬂuence of FGSM adversarial samples on the accuracy of the predictions and proves the effectiveness of using the retrained model to defend against adversarial attacks.},
	language = {en},
	urldate = {2022-07-05},
	publisher = {arXiv},
	author = {Jadidi, Zahra and Pal, Shantanu and K, Nithesh Nayak and Selvakkumar, Arawinkumaar and Chang, Chih-Chia and Beheshti, Maedeh and Jolfaei, Alireza},
	month = jun,
	year = {2022},
	note = {arXiv:2206.05678 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
}

@misc{Novoa-Paradela2022,
	title = {Fast {Deep} {Autoencoder} for {Federated} learning},
	url = {http://arxiv.org/abs/2206.05136},
	abstract = {This paper presents a novel, fast and privacy preserving implementation of deep autoencoders. DAEF (Deep Autoencoder for Federated learning), unlike traditional neural networks, trains a deep autoencoder network in a non-iterative way, which drastically reduces its training time. Its training can be carried out in a distributed way (several partitions of the dataset in parallel) and incrementally (aggregation of partial models), and due to its mathematical formulation, the data that is exchanged does not endanger the privacy of the users. This makes DAEF a valid method for edge computing and federated learning scenarios. The method has been evaluated and compared to traditional (iterative) deep autoencoders using seven real anomaly detection datasets, and their performance have been shown to be similar despite DAEF’s faster training.},
	language = {en},
	urldate = {2022-07-05},
	publisher = {arXiv},
	author = {Novoa-Paradela, David and Romero-Fontenla, Oscar and Guijarro-Berdiñas, Bertha},
	month = jun,
	year = {2022},
	note = {arXiv:2206.05136 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{Noble2022,
	title = {Differentially {Private} {Federated} {Learning} on {Heterogeneous} {Data}},
	url = {http://arxiv.org/abs/2111.09278},
	abstract = {Federated Learning (FL) is a paradigm for large-scale distributed learning which faces two key challenges: (i) training eﬃciently from highly heterogeneous user data, and (ii) protecting the privacy of participating users. In this work, we propose a novel FL approach (DP-SCAFFOLD) to tackle these two challenges together by incorporating Diﬀerential Privacy (DP) constraints into the popular SCAFFOLD algorithm. We focus on the challenging setting where users communicate with a “honest-but-curious” server without any trusted intermediary, which requires to ensure privacy not only towards a third party observing the ﬁnal model but also towards the server itself. Using advanced results from DP theory and optimization, we establish the convergence of our algorithm for convex and non-convex objectives. Our paper clearly highlights the trade-oﬀ between utility and privacy and demonstrates the superiority of DP-SCAFFOLD over the state-ofthe-art algorithm DP-FedAvg when the number of local updates and the level of heterogeneity grows. Our numerical results conﬁrm our analysis and show that DP-SCAFFOLD provides signiﬁcant gains in practice.},
	language = {en},
	urldate = {2022-07-05},
	publisher = {arXiv},
	author = {Noble, Maxence and Bellet, Aurélien and Dieuleveut, Aymeric},
	month = feb,
	year = {2022},
	note = {arXiv:2111.09278 [cs, math, stat]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Mathematics - Statistics Theory},
}

@misc{Ongun2022,
	title = {{CELEST}: {Federated} {Learning} for {Globally} {Coordinated} {Threat} {Detection}},
	shorttitle = {{CELEST}},
	url = {http://arxiv.org/abs/2205.11459},
	abstract = {The cyber-threat landscape has evolved tremendously in recent years, with new threat variants emerging daily, and large-scale coordinated campaigns becoming more prevalent. In this study, we propose CELEST (CollaborativE LEarning for Scalable Threat detection), a federated machine learning framework for global threat detection over HTTP, which is one of the most commonly used protocols for malware dissemination and communication. CELEST leverages federated learning in order to collaboratively train a global model across multiple clients who keep their data locally, thus providing increased privacy and conﬁdentiality assurances. Through a novel active learning component integrated with the federated learning technique, our system continuously discovers and learns the behavior of new, evolving, and globally-coordinated cyber threats. We show that CELEST is able to expose attacks that are largely invisible to individual organizations. For instance, in one challenging attack scenario with data exﬁltration malware, the global model achieves a three-fold increase in Precision-Recall AUC compared to the local model. We deploy CELEST on two university networks and show that it is able to detect the malicious HTTP communication with high precision and low false positive rates. Furthermore, during its deployment, CELEST detected a set of previously unknown 42 malicious URLs and 20 malicious domains in one day, which were conﬁrmed to be malicious by VirusTotal.},
	language = {en},
	urldate = {2022-07-05},
	publisher = {arXiv},
	author = {Ongun, Talha and Boboila, Simona and Oprea, Alina and Eliassi-Rad, Tina and Hiser, Jason and Davidson, Jack},
	month = may,
	year = {2022},
	note = {arXiv:2205.11459 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, \_read\_urgently},
}

@misc{Halimi2022,
	title = {Federated {Unlearning}: {How} to {Efficiently} {Erase} a {Client} in {FL}?},
	shorttitle = {Federated {Unlearning}},
	url = {http://arxiv.org/abs/2207.05521},
	abstract = {With privacy legislation empowering users with the right to be forgotten, it has become essential to make a model forget about some of its training data. We explore the problem of removing any client’s contribution in federated learning (FL). During FL rounds, each client performs local training to learn a model that minimizes the empirical loss on their private data. We propose to perform unlearning at the client (to be erased) by reversing the learning process, i.e., training a model to maximize the local empirical loss. In particular, we formulate the unlearning problem as a constrained maximization problem by restricting to an 2-norm ball around a suitably chosen reference model to help retain some knowledge learnt from the other clients’ data. This allows the client to use projected gradient descent to perform unlearning. The method does neither require global access to the data used for training nor the history of the parameter updates to be stored by the aggregator (server) or any of the clients. Experiments on the MNIST dataset show that the proposed unlearning method is efﬁcient and effective.},
	language = {en},
	urldate = {2022-08-11},
	publisher = {arXiv},
	author = {Halimi, Anisa and Kadhe, Swanand and Rawat, Ambrish and Baracaldo, Nathalie},
	month = jul,
	year = {2022},
	note = {arXiv:2207.05521 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@misc{Daga2021,
	title = {Canoe : {A} {System} for {Collaborative} {Learning} for {Neural} {Nets}},
	shorttitle = {Canoe},
	url = {http://arxiv.org/abs/2108.12124},
	doi = {10.48550/arXiv.2108.12124},
	abstract = {For highly distributed environments such as edge computing, collaborative learning approaches eschew the dependence on a global, shared model, in favor of models tailored for each location. Creating tailored models for individual learning contexts reduces the amount of data transfer, while collaboration among peers provides acceptable model performance. Collaboration assumes, however, the availability of knowledge transfer mechanisms, which are not trivial for deep learning models where knowledge isn't easily attributed to precise model slices. We present Canoe - a framework that facilitates knowledge transfer for neural networks. Canoe provides new system support for dynamically extracting significant parameters from a helper node's neural network and uses this with a multi-model boosting-based approach to improve the predictive performance of the target node. The evaluation of Canoe with different PyTorch and TensorFlow neural network models demonstrates that the knowledge transfer mechanism improves the model's adaptiveness to changes up to 3.5X compared to learning in isolation, while affording several magnitudes reduction in data movement costs compared to federated learning.},
	urldate = {2022-08-11},
	publisher = {arXiv},
	author = {Daga, Harshit and Chen, Yiwen and Agrawal, Aastha and Gavrilovska, Ada},
	month = aug,
	year = {2021},
	note = {arXiv:2108.12124 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
}

@misc{Elgabli2022,
	title = {{FedNew}: {A} {Communication}-{Efficient} and {Privacy}-{Preserving} {Newton}-{Type} {Method} for {Federated} {Learning}},
	shorttitle = {{FedNew}},
	url = {http://arxiv.org/abs/2206.08829},
	abstract = {Newton-type methods are popular in federated learning due to their fast convergence. Still, they suﬀer from two main issues, namely: low communication eﬃciency and low privacy due to the requirement of sending Hessian information from clients to parameter server (PS). In this work, we introduced a novel framework called FedNew in which there is no need to transmit Hessian information from clients to PS, hence resolving the bottleneck to improve communication eﬃciency. In addition, FedNew hides the gradient information and results in a privacy-preserving approach compared to the existing state-of-the-art. The core novel idea in FedNew is to introduce a two level framework, and alternate between updating the inverse Hessian-gradient product using only one alternating direction method of multipliers (ADMM) step and then performing the global model update using Newton’s method. Though only one ADMM pass is used to approximate the inverse Hessian-gradient product at each iteration, we develop a novel theoretical approach to show the converging behavior of FedNew for convex problems. Additionally, a signiﬁcant reduction in communication overhead is achieved by utilizing stochastic quantization. Numerical results using real datasets show the superiority of FedNew compared to existing methods in terms of communication costs.},
	language = {en},
	urldate = {2022-07-06},
	publisher = {arXiv},
	author = {Elgabli, Anis and Issaid, Chaouki Ben and Bedi, Amrit S. and Rajawat, Ketan and Bennis, Mehdi and Aggarwal, Vaneet},
	month = jun,
	year = {2022},
	note = {arXiv:2206.08829 [cs, stat]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{Chen2022a,
	title = {Dap-{FL}: {Federated} {Learning} flourishes by adaptive tuning and secure aggregation},
	shorttitle = {Dap-{FL}},
	url = {http://arxiv.org/abs/2206.03623},
	abstract = {Federated learning (FL), an attractive and promising distributed machine learning paradigm, has sparked extensive interest in exploiting tremendous data stored on ubiquitous mobile devices. However, conventional FL suffers severely from resource heterogeneity, as clients with weak computational and communication capability may be unable to complete local training using the same local training hyper-parameters. In this paper, we propose Dap-FL, a deep deterministic policy gradient (DDPG)-assisted adaptive FL system, in which local learning rates and local training epochs are adaptively adjusted by all resource-heterogeneous clients through locally deployed DDPGassisted adaptive hyper-parameter selection schemes. Particularly, the rationality of the proposed hyper-parameter selection scheme is conﬁrmed through rigorous mathematical proof. Besides, due to the thoughtlessness of security consideration of adaptive FL systems in previous studies, we introduce the Paillier cryptosystem to aggregate local models in a secure and privacypreserving manner. Rigorous analyses show that the proposed Dap-FL system could guarantee the security of clients’ private local models against chosen-plaintext attacks and chosen-message attacks in a widely used honest-but-curious participants and active adversaries security model. In addition, through ingenious and extensive experiments, the proposed Dap-FL achieves higher global model prediction accuracy and faster convergence rates than conventional FL, and the comprehensiveness of the adjusted local training hyper-parameters is validated. More importantly, experimental results also show that the proposed Dap-FL achieves higher model prediction accuracy than two state-of-the-art RLassisted FL methods, i.e., 6.03\% higher than DDPG-based FL and 7.85\% higher than DQN-based FL.},
	language = {en},
	urldate = {2022-07-05},
	publisher = {arXiv},
	author = {Chen, Qian and Wang, Zilong and Chen, Jiawei and Yan, Haonan and Lin, Xiaodong},
	month = jun,
	year = {2022},
	note = {arXiv:2206.03623 [cs]},
	keywords = {Computer Science - Cryptography and Security},
}

@misc{Hejazinia2022,
	title = {{FEL}: {High} {Capacity} {Learning} for {Recommendation} and {Ranking} via {Federated} {Ensemble} {Learning}},
	shorttitle = {{FEL}},
	url = {http://arxiv.org/abs/2206.03852},
	abstract = {Federated learning (FL) has emerged as an effective approach to address consumer privacy needs. FL has been successfully applied to certain machine learning tasks, such as training smart keyboard models and keyword spotting. Despite FL’s initial success, many important deep learning use cases, such as ranking and recommendation tasks, have been limited from on-device learning. One of the key challenges faced by practical FL adoption for DL-based ranking and recommendation is the prohibitive resource requirements that cannot be satisﬁed by modern mobile systems. We propose Federated Ensemble Learning (FEL) as a solution to tackle the large memory requirement of deep learning ranking and recommendation tasks. FEL enables large-scale ranking and recommendation model training on-device by simultaneously training multiple model versions on disjoint clusters of client devices. FEL integrates the trained sub-models via an over-arch layer into an ensemble model that is hosted on the server. Our experiments demonstrate that FEL leads to 0.43–2.31\% model quality improvement over traditional on-device federated learning — a signiﬁcant improvement for ranking and recommendation system use cases.},
	language = {en},
	urldate = {2022-07-05},
	publisher = {arXiv},
	author = {Hejazinia, Meisam and Huba, Dzmitry and Leontiadis, Ilias and Maeng, Kiwan and Malek, Mani and Melis, Luca and Mironov, Ilya and Nasr, Milad and Wang, Kaikai and Wu, Carole-Jean},
	month = jun,
	year = {2022},
	note = {arXiv:2206.03852 [cs]},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, \_read\_urgently},
}

@article{zhu_resilient_2022,
	title = {Resilient and {Communication} {Efﬁcient} {Learning} for {Heterogeneous} {Federated} {Systems}},
	abstract = {The rise of Federated Learning (FL) is bringing machine learning to edge computing by utilizing data scattered across edge devices. However, the heterogeneity of edge network topologies and the uncertainty of wireless transmission are two major obstructions of FL’s wide application in edge computing, leading to prohibitive convergence time and high communication cost. In this work, we propose an FL scheme to address both challenges simultaneously. Speciﬁcally, we enable edge devices to learn self-distilled neural networks that are readily prunable to arbitrary sizes, which capture the knowledge of the learning domain in a nested and progressive manner. Not only does our approach tackle system heterogeneity by serving edge devices with varying model architectures, but it also alleviates the issue of connection uncertainty by allowing transmitting part of the model parameters under faulty network connections, without wasting the contributing knowledge of the transmitted parameters. Extensive empirical studies show that under system heterogeneity and network instability, our approach demonstrates signiﬁcant resilience and higher communication efﬁciency compared to the state-of-the-art.},
	language = {en},
	author = {Zhu, Zhuangdi and Hong, Junyuan and Drew, Steve and Zhou, Jiayu},
	year = {2022},
	keywords = {\_read\_urgently, ⛔ No DOI found},
	pages = {23},
}

@misc{Bars2022,
	title = {Refined {Convergence} and {Topology} {Learning} for {Decentralized} {Optimization} with {Heterogeneous} {Data}},
	url = {http://arxiv.org/abs/2204.04452},
	doi = {10.48550/arXiv.2204.04452},
	abstract = {One of the key challenges in decentralized and federated learning is to design algorithms that efficiently deal with highly heterogeneous data distributions across agents. In this paper, we revisit the analysis of Decentralized Stochastic Gradient Descent algorithm (D-SGD) under data heterogeneity. We exhibit the key role played by a new quantity, called {\textbackslash}emph\{neighborhood heterogeneity\}, on the convergence rate of D-SGD. By coupling the communication topology and the heterogeneity, our analysis sheds light on the poorly understood interplay between these two concepts in decentralized learning. We then argue that neighborhood heterogeneity provides a natural criterion to learn data-dependent topologies that reduce (and can even eliminate) the otherwise detrimental effect of data heterogeneity on the convergence time of D-SGD. For the important case of classification with label skew, we formulate the problem of learning such a good topology as a tractable optimization problem that we solve with a Frank-Wolfe algorithm. As illustrated over a set of simulated and real-world experiments, our approach provides a principled way to design a sparse topology that balances the convergence speed and the per-iteration communication costs of D-SGD under data heterogeneity.},
	urldate = {2022-07-05},
	publisher = {arXiv},
	author = {Bars, B. Le and Bellet, A. and Tommasi, M. and Lavoie, E. and Kermarrec, A. M.},
	month = jun,
	year = {2022},
	note = {arXiv:2204.04452 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
}

@article{zhuo_federated_2020,
	title = {Federated {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1901.08277},
	abstract = {In deep reinforcement learning, building policies of high-quality is challenging when the feature space of states is small and the training data is limited. Despite the success of previous transfer learning approaches in deep reinforcement learning, directly transferring data or models from an agent to another agent is often not allowed due to the privacy of data and/or models in many privacy-aware applications. In this paper, we propose a novel deep reinforcement learning framework to federatively build models of high-quality for agents with consideration of their privacies, namely Federated deep Reinforcement Learning (FedRL). To protect the privacy of data and models, we exploit Gausian differentials on the information shared with each other when updating their local models. In the experiment, we evaluate our FedRL framework in two diverse domains, Grid-world and Text2Action domains, by comparing to various baselines.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:1901.08277 [cs]},
	author = {Zhuo, Hankz Hankui and Feng, Wenfeng and Lin, Yufeng and Xu, Qian and Yang, Qiang},
	month = feb,
	year = {2020},
	note = {arXiv: 1901.08277},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, ⛔ No DOI found},
}

@article{schwab_fourth_2016,
	title = {The {Fourth} {Industrial} {Revolution}},
	issn = {0015-7120},
	url = {https://www.foreignaffairs.com/articles/2015-12-12/fourth-industrial-revolution},
	abstract = {We stand on the brink of a technological revolution that will fundamentally alter the way we live, work, and relate to one another. In its scale, scope, and complexity, the transformation will be unlike anything humankind has experienced before.},
	language = {en-US},
	urldate = {2021-05-26},
	author = {Schwab, Klaus},
	month = jan,
	year = {2016},
}

@article{zuo_overview_2018,
	title = {An {Overview} of {Recent} {Advances} in {Fixed}-{Time} {Cooperative} {Control} of {Multiagent} {Systems}},
	volume = {14},
	issn = {1551-3203},
	url = {https://ieeexplore.ieee.org/document/8322314/},
	doi = {10.1109/TII.2018.2817248},
	abstract = {Fixed-time cooperative control is currently a hot research topic in multiagent systems since it can provide a guaranteed settling time, which does not depend on initial conditions. Compared with asymptotic cooperative control algorithms, fixed-time cooperative control algorithms can achieve better closed-loop performance and disturbance rejection properties. Different from finite-time control, fixed-time cooperative control produces the faster rate of convergence and provides an explicit estimation of the settling time independent of initial conditions, which is desirable for multiagent systems. This paper aims at presenting an overview of recent advances in fixed-time cooperative control of multiagent systems. Some fundamental concepts about finite- and fixed-time stability and stabilization are first recalled with insight understanding. Then, recent results in finite- and fixed-time cooperative control are reviewed in detail and categorized according to different agent dynamics. Finally, this paper raises several challenging issues that need to be addressed in the near future.},
	number = {6},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Zuo, Zongyu and Han, Qing-Long and Ning, Boda and Ge, Xiaohua and Zhang, Xian-Ming},
	month = jun,
	year = {2018},
	note = {Publisher: IEEE},
	pages = {2322--2334},
}

@article{guichard_detection_2020,
	title = {Détection d'anomalies par {ACP}},
	volume = {111},
	url = {https://connect.ed-diamond.com/MISC/MISC-111/Detection-d-anomalies-par-ACP},
	abstract = {Retour de vacances. L’analyse du SIEM après un mois d’absence montre que dix incidents ont été déclenchés sur la base des alertes automatiques et ont pu être gérés convenablement par la chaîne de traitement d’incidents. Tout est-il sous contrôle ? Un analyste aimerait rapidement s’en assurer en complétant cette supervision par sa propre analyse du mois écoulé. Mais par où commencer ? Il est inenvisageable de regarder un mois de logs « rapidement » et d’autant plus quand on ne sait pas précisément ce que l’on cherche… Une solution possible est de recourir à des outils statistiques qui permettent d’identifier des périodes d’activité atypiques sur lesquelles concentrer son analyse. L’analyse en composantes principales (ACP ou PCA en anglais) est une méthode statistique qui peut répondre relativement efficacement à cette problématique. L’article présente cette méthode et son apport dans la détection d’anomalies, en prenant comme exemple l’analyse de flux réseaux.},
	journal = {MISC : Le magazine de la cybersécurité offensive et défensive},
	author = {Guichard, Jean-Philip and Johnson, Jack and Parrat, Pierre and Perez, Christian},
	month = sep,
	year = {2020},
}

@article{zhou_survey_2010,
	title = {A survey of coordinated attacks and collaborative intrusion detection},
	volume = {29},
	issn = {01674048},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016740480900073X},
	doi = {10.1016/j.cose.2009.06.008},
	abstract = {Coordinated attacks, such as large-scale stealthy scans, worm outbreaks and distributed denial-of-service (DDoS) attacks, occur in multiple networks simultaneously. Such attacks are extremely difﬁcult to detect using isolated intrusion detection systems (IDSs) that monitor only a limited portion of the Internet. In this paper, we summarize the current research directions in detecting such attacks using collaborative intrusion detection systems (CIDSs). In particular, we highlight two main challenges in CIDS research: CIDS architectures and alert correlation algorithms. We review the current CIDS approaches in terms of these two challenges. We conclude by highlighting opportunities for an integrated solution to large-scale collaborative intrusion detection.},
	language = {en},
	number = {1},
	urldate = {2021-07-21},
	journal = {Computers \& Security},
	author = {Zhou, Chenfeng Vincent and Leckie, Christopher and Karunasekera, Shanika},
	month = feb,
	year = {2010},
	keywords = {+survey, \_read},
	pages = {124--140},
}

@article{zhao_personalized_2022,
	title = {Personalized {Federated} {Few}-{Shot} {Learning}},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2022.3190359},
	abstract = {Personalized federated learning (PFL) learns a personalized model for each client in a decentralized manner, where each client owns private data that are not shared and data among clients are non-independent and identically distributed (i.i.d.) However, existing PFL solutions assume that clients have sufficient training samples to jointly induce personalized models. Thus, existing PFL solutions cannot perform well in a few-shot scenario, where most or all clients only have a handful of samples for training. Furthermore, existing few-shot learning (FSL) approaches typically need centralized training data; as such, these FSL methods are not applicable in decentralized scenarios. How to enable PFL with limited training samples per client is a practical but understudied problem. In this article, we propose a solution called personalized federated few-shot learning (pFedFSL) to tackle this problem. Specifically, pFedFSL learns a personalized and discriminative feature space for each client by identifying which models perform well on which clients, without exposing local data of clients to the server and other clients, and which clients should be selected for collaboration with the target client. In the learned feature spaces, each sample is made closer to samples of the same category and farther away from samples of different categories. Experimental results on four benchmark datasets demonstrate that pFedFSL outperforms competitive baselines across different settings.},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Zhao, Yunfeng and Yu, Guoxian and Wang, Jun and Domeniconi, Carlotta and Guo, Maozu and Zhang, Xiangliang and Cui, Lizhen},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {Collaboration, Collaborative work, Computational modeling, Data models, Distributed databases, Servers, Training, Training data, \_read\_urgently, feature space learning, few-shot learning (FSL), non-independent and identically distributed (i.i.d.) data, personalized federated learning (PFL)},
	pages = {1--11},
}

@article{zhou_pflf_2022,
	title = {{PFLF}: {Privacy}-{Preserving} {Federated} {Learning} {Framework} for {Edge} {Computing}},
	volume = {17},
	issn = {1556-6021},
	shorttitle = {{PFLF}},
	doi = {10.1109/TIFS.2022.3174394},
	abstract = {Federated learning (FL) can protect clients’ privacy from leakage in distributed machine learning. Applying federated learning to edge computing can protect the privacy of edge clients and benefit edge computing. Nevertheless, eavesdroppers can analyze the parameter information to specify clients’ private information and model features. And it is difficult to achieve a high privacy level, convergence, and low communication overhead during the entire process in the FL framework. In this paper, we propose a novel privacy-preserving federated learning framework for edge computing (PFLF). In PFLF, each client and the application server add noise before sending the data. To protect the privacy of clients, we design a flexible arrangement mechanism to count the optimal training times for clients. We prove that PFLF guarantees the privacy of clients and servers during the entire training process. Then, we theoretically prove that PFLF has three main properties: 1) For a given privacy level and model aggregation times, there is an optimal number of participating times for clients; 2) There is an upper and lower bound of convergence; 3) PFLF achieves low communication overhead by designing a flexible participation training mechanism. Simulation experiments confirm the correctness of our theoretical analysis. Therefore, PFLF helps design a framework to balance privacy levels and convergence and achieve low communication overhead when there is a part of clients dropping out of training.},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Zhou, Hao and Yang, Geng and Dai, Hua and Liu, Guoxiu},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Collaborative work, Computational modeling, Convergence, Edge computing, Federated learning, Privacy, Servers, Training, convergence performance, differential privacy, edge computing, information leakage},
	pages = {1905--1918},
}

@article{zhou_defta_2022,
	title = {{DeFTA}: {A} {Plug}-and-{Play} {Decentralized} {Replacement} for {FedAvg}},
	shorttitle = {{DeFTA}},
	url = {http://arxiv.org/abs/2204.02632},
	abstract = {Federated learning (FL) is identiﬁed as a crucial enabler for large-scale distributed machine learning (ML) without the need for local raw dataset sharing, substantially reducing privacy concerns and alleviating the isolated data problem. In reality, the prosperity of FL is largely due to a centralized framework called FedAvg [1], in which workers are in charge of model training and servers are in control of model aggregation. However, FedAvg’s centralized worker-server architecture has raised new concerns, be it the low scalability of the cluster, the risk of data leakage, and the failure or even defection of the central server. To overcome these problems, we propose Decentralized Federated Trusted Averaging (DeFTA), a decentralized FL framework that serves as a plug-and-play replacement for FedAvg, instantly bringing better security, scalability, and fault-tolerance to the federated learning process after installation. In principle, it fundamentally resolves the above-mentioned issues from an architectural perspective without compromises or tradeoffs, primarily consisting of a new model aggregating formula with theoretical performance analysis, and a decentralized trust system (DTS) to greatly improve system robustness. Note that since DeFTA is an alternative to FedAvg at the framework level, prevalent algorithms published for FedAvg can be also utilized in DeFTA with ease. Extensive experiments on six datasets and six basic models suggest that DeFTA not only has comparable performance with FedAvg in a more realistic setting, but also achieves great resilience even when 66\% of workers are malicious. Furthermore, we also present an asynchronous variant of DeFTA to endow it with more powerful usability.},
	language = {en},
	urldate = {2022-04-13},
	journal = {arXiv:2204.02632 [cs]},
	author = {Zhou, Yuhao and Shi, Minjia and Tian, Yuxin and Ye, Qing and Lv, Jiancheng},
	month = apr,
	year = {2022},
	note = {arXiv: 2204.02632},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Distributed, Parallel, and Cluster Computing, ⛔ No DOI found},
}

@article{zhong_efficient_2020,
	title = {Efficient dynamic multi-keyword fuzzy search over encrypted cloud data},
	volume = {149},
	issn = {10848045},
	url = {https://doi.org/10.1016/j.jnca.2019.102469},
	doi = {10.1016/j.jnca.2019.102469},
	abstract = {Multi-keyword search of encrypted cloud data has attracted extensive attention worldwide in the recent years due to the increasing concern for data security and privacy in Cloud Computing. Fault-tolerance is important for multi-keyword fuzzy search which can provide accurate results even with the presence of minor spelling and typographical errors in the search keywords. But, existing fuzzy search schemes lack efficiency due to their high computational overhead and do not support file dynamic updates. This paper proposes an efficient dynamic multi-keyword fuzzy search scheme for encrypted cloud data to support dynamic file updates. Locality sensitive hashing (LSH) and Bloom filters are employed to generate index vectors and query vectors. Based on the generated vectors, a balanced binary tree is constructed as the index for the entire file set, and a Top-k search algorithm is developed to search k files that are most relevant to a given query with the help of the index tree. Extensive experiments conducted on real-world datasets demonstrate that our scheme is more efficient than existing similar schemes.},
	number = {October 2019},
	journal = {Journal of Network and Computer Applications},
	author = {Zhong, Hong and Li, Zhanfei and Cui, Jie and Sun, Yue and Liu, Lu},
	month = jan,
	year = {2020},
	note = {Publisher: Elsevier Ltd},
	pages = {102469},
}

@article{zhang_adaptive_2022,
	title = {Adaptive {Memory} {Networks} with {Self}-supervised {Learning} for {Unsupervised} {Anomaly} {Detection}},
	url = {http://arxiv.org/abs/2201.00464},
	abstract = {Unsupervised anomaly detection aims to build models to effectively detect unseen anomalies by only training on the normal data. Although previous reconstruction-based methods have made fruitful progress, their generalization ability is limited due to two critical challenges. First, the training dataset only contains normal patterns, which limits the model generalization ability. Second, the feature representations learned by existing models often lack representativeness which hampers the ability to preserve the diversity of normal patterns. In this paper, we propose a novel approach called Adaptive Memory Network with Self-supervised Learning (AMSL) to address these challenges and enhance the generalization ability in unsupervised anomaly detection. Based on the convolutional autoencoder structure, AMSL incorporates a self-supervised learning module to learn general normal patterns and an adaptive memory fusion module to learn rich feature representations. Experiments on four public multivariate time series datasets demonstrate that AMSL signiﬁcantly improves the performance compared to other state-of-the-art methods. Speciﬁcally, on the largest CAP sleep stage detection dataset with 900 million samples, AMSL outperforms the second-best baseline by 4\%+ in both accuracy and F1 score. Apart from the enhanced generalization ability, AMSL is also more robust against input noise.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:2201.00464 [cs]},
	author = {Zhang, Yuxin and Wang, Jindong and Chen, Yiqiang and Yu, Han and Qin, Tao},
	month = jan,
	year = {2022},
	note = {arXiv: 2201.00464},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, ⛔ No DOI found},
}

@article{zhang_training_2021,
	title = {Training {Federated} {GANs} with {Theoretical} {Guarantees}: {A} {Universal} {Aggregation} {Approach}},
	shorttitle = {Training {Federated} {GANs} with {Theoretical} {Guarantees}},
	url = {http://arxiv.org/abs/2102.04655},
	abstract = {Recently, Generative Adversarial Networks (GANs) have demonstrated their potential in federated learning, i.e., learning a centralized model from data privately hosted by multiple sites. A federatedGAN jointly trains a centralized generator and multiple private discriminators hosted at different sites. A major theoretical challenge for the federated GAN is the heterogeneity of the local data distributions. Traditional approaches cannot guarantee to learn the target distribution, which isa mixture of the highly different local distributions. This paper tackles this theoretical challenge, and for the first time, provides a provably correct framework for federated GAN. We propose a new approach called Universal Aggregation, which simulates a centralized discriminator via carefully aggregating the mixture of all private discriminators. We prove that a generator trained with this simulated centralized discriminator can learn the desired target distribution. Through synthetic and real datasets, we show that our method can learn the mixture of largely different distributions where existing federated GAN methods fail.},
	language = {en},
	urldate = {2021-10-06},
	journal = {arXiv:2102.04655 [cs]},
	author = {Zhang, Yikai and Qu, Hui and Chang, Qi and Liu, Huidong and Metaxas, Dimitris and Chen, Chao},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.04655},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, I.2.11, I.2.6, \_read, ⛔ No DOI found},
}

@article{zhang_dynamic_2020,
	title = {Dynamic {Fusion} based {Federated} {Learning} for {COVID}-19 {Detection}},
	volume = {14},
	issn = {23318422},
	url = {http://arxiv.org/abs/2009.10401},
	abstract = {Medical diagnostic image analysis (e.g., CT scan or X-Ray) using machine learning is an efficient and accurate way to detect COVID-19 infections. However, sharing diagnostic images across medical institutions is usually not allowed due to the concern of patients' privacy. This causes the issue of insufficient datasets for training the image classification model. Federated learning is an emerging privacy-preserving machine learning paradigm that produces an unbiased global model based on the received updates of local models trained by clients without exchanging clients' local data. Nevertheless, the default setting of federated learning introduces huge communication cost of transferring model updates and can hardly ensure model performance when data heterogeneity of clients heavily exists. To improve communication efficiency and model performance, in this paper, we propose a novel dynamic fusion-based federated learning approach for medical diagnostic image analysis to detect COVID-19 infections. First, we design an architecture for dynamic fusion-based federated learning systems to analyse medical diagnostic images. Further, we present a dynamic fusion method to dynamically decide the participating clients according to their local model performance and schedule the model fusion-based on participating clients' training time. In addition, we summarise a category of medical diagnostic image datasets for COVID-19 detection, which can be used by the machine learning community for image analysis. The evaluation results show that the proposed approach is feasible and performs better than the default setting of federated learning in terms of model performance, communication efficiency and fault tolerance.},
	number = {8},
	journal = {arXiv},
	author = {Zhang, Weishan and Zhou, Tao and Lu, Qinghua and Wang, Xiao and Zhu, Chunsheng and Sun, Haoyun and Wang, Zhipeng and Lo, Sin Kit and Wang, Fei-Yue},
	month = sep,
	year = {2020},
	keywords = {⛔ No DOI found},
	pages = {1--9},
}

@article{zhang_federated_2022,
	title = {Federated {Markov} {Logic} {Network} for indoor activity recognition in {Internet} of {Things}},
	volume = {253},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S095070512200781X},
	doi = {10.1016/j.knosys.2022.109553},
	abstract = {Indoor activity recognition is essential in numerous Internet of Things (IoT) applications. As one of the widely used methods in this domain, Markov Logic Network (MLN) can simultaneously use activity knowledge and data by unifying probability and logic. The “cloud computing” model has recently been adopted to concentrate the activity data and activity knowledge in a central node for processing in indoor activity recognition by using MLN, which may lead to the data leakage of the clients. Therefore, to further alleviate client data privacy issues when building an indoor activity recognition model by training MLN, this paper proposes a Federated Markov Logic Network (FMLN) framework for indoor activity recognition. We designed different scenarios to investigate the FMLN framework, including statistical heterogeneity, the number ofvarious clients, and various network environments. The experimental results show that the FMLN framework effectively detects indoor activity.},
	language = {en},
	urldate = {2022-08-11},
	journal = {Knowledge-Based Systems},
	author = {Zhang, Chang and Ren, Xiaorui and Zhu, Tao and Zhou, Fang and Liu, Hong and Lu, Qinghua and Ning, Huansheng},
	month = oct,
	year = {2022},
	keywords = {Federated learning, Indoor activity recognition, Internet of Things, Markov Logic Network},
	pages = {109553},
}

@article{zhang_physical_2021,
	title = {Physical {Safety} and {Cyber} {Security} {Analysis} of {Multi}-{Agent} {Systems}: {A} {Survey} of {Recent} {Advances}},
	volume = {8},
	issn = {2329-9266},
	url = {https://ieeexplore.ieee.org/document/9317716/},
	doi = {10.1109/JAS.2021.1003820},
	abstract = {Multi-agent systems (MASs) are typically composed of multiple smart entities with independent sensing, communication, computing, and decision-making capabilities. Nowadays, MASs have a wide range of applications in smart grids, smart manufacturing, sensor networks, and intelligent transportation systems. Control of the MASs are often coordinated through information interaction among agents, which is one of the most important factors affecting coordination and cooperation performance. However, unexpected physical faults and cyber attacks on a single agent may spread to other agents via information interaction very quickly, and thus could lead to severe degradation of the whole system performance and even destruction of MASs. This paper is concerned with the safety/security analysis and synthesis of MASs arising from physical faults and cyber attacks, and our goal is to present a comprehensive survey on recent results on fault estimation, detection, diagnosis and fault-tolerant control of MASs, and cyber attack detection and secure control of MASs subject to two typical cyber attacks. Finally, the paper concludes with some potential future research topics on the security issues of MASs.},
	number = {2},
	journal = {IEEE/CAA Journal of Automatica Sinica},
	author = {Zhang, Dan and Feng, Gang and Shi, Yang and Srinivasan, Dipti},
	month = feb,
	year = {2021},
	pages = {319--333},
}

@article{zhang_network_2019,
	title = {Network attack prediction method based on threat intelligence for {IoT}},
	volume = {78},
	issn = {1380-7501},
	url = {http://link.springer.com/10.1007/s11042-018-7005-2},
	doi = {10.1007/s11042-018-7005-2},
	abstract = {The Social Internet of Things (SIoT) is a combination of the Internet of Things (IoT) and social networks, which enables better service discovery and improves the user experience. The threat posed by the malicious behavior of social network accounts also affects the SIoT, this paper studies the analysis and prediction of malicious behavior for SIoT accounts, proposed a method for predicting malicious behavior of SIoT accounts based on threat intelligence. The method uses support vector machine (SVM) to obtain threat intelligence related to malicious behavior of target accounts, analyze contextual data in threat intelligence to predict the behavior of malicious accounts. By collecting and analyzing the data in a SIoT environment, verifies the malicious behavior prediction method of SIoT account proposed in this paper.},
	number = {21},
	journal = {Multimedia Tools and Applications},
	author = {Zhang, Hongbin and Yi, Yuzi and Wang, Junshe and Cao, Ning and Duan, Qiang},
	month = nov,
	year = {2019},
	note = {Publisher: Multimedia Tools and Applications},
	pages = {30257--30270},
}

@article{yu_intrusion_2020,
	title = {An {Intrusion} {Detection} {Method} {Using} {Few}-{Shot} {Learning}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.2980136},
	abstract = {Network intrusion detection is an essential means to ensure the security of the network information system. In the real network, abnormal behaviors occur much less frequently than normal behaviors, resulting in scarcity of abnormal samples. We proposed an intrusion detection method based on Few-Shot Learning (FSL), which only used less than 1\% of NSL-KDD KDDTrain+ dataset for training, and achieved high accuracy of 92.34\% for KDD-Test+ and 85.75\% for KDD-Test-21, while other methods, such as J48, Naive Bayes(NB), Random Forest(RF), Support Vector Machine(SVM), recurrent neural network(RNN) and Channel boosted and residual learning based deep convolutional neural network (CBR-CNN), used 20\% of KDDTrain+ dataset for training, and achieved relatively low accuracy (less than 89.41\% for KDD-Test+ and less than 80.36\% for KDD-Test-21). The experiment on dataset of UNSW- NB15 showed a similar result. The detection rates for Dos, U2R, R2L and U2R are improved by our method too, especially for U2R and R2L, which only take up a small proportion of the dataset, the detection rates are increased from 13\% to 81.50\% and 44.41\% to 75.93\%, respectively.},
	journal = {IEEE Access},
	author = {Yu, Yingwei and Bian, Naizheng},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Feature extraction, Few-shot learning, Intrusion detection, Machine learning, Measurement, Neural networks, Testing, Training, data scarcity, deep learning, intrusion detection},
	pages = {49730--49740},
}

@article{yu_fed_2021,
	title = {Fed+: {A} {Unified} {Approach} to {Robust} {Personalized} {Federated} {Learning}},
	shorttitle = {Fed+},
	url = {http://arxiv.org/abs/2009.06303},
	abstract = {We present a class of methods for robust, personalized federated learning, called Fed+, that uniﬁes many federated learning algorithms. The principal advantage of this class of methods is to better accommodate the real-world characteristics found in federated training, such as the lack of IID data across parties, the need for robustness to outliers or stragglers, and the requirement to perform well on party-speciﬁc datasets. We achieve this through a problem formulation that allows the central server to employ robust ways of aggregating the local models while keeping the structure of local computation intact. Without making any statistical assumption on the degree of heterogeneity of local data across parties, we provide convergence guarantees for Fed+ for convex and non-convex loss functions and robust aggregation. The Fed+ theory is also equipped to handle heterogeneous computing environments including stragglers without additional assumptions; speciﬁcally, the convergence results cover the general setting where the number of local update steps across parties can vary. We demonstrate the beneﬁts of Fed+ through extensive experiments across standard benchmark datasets as well as on a challenging real-world problem in ﬁnancial portfolio management where the heterogeneity of party-level data can lead to training failure in standard federated learning approaches.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:2009.06303 [cs, math, stat]},
	author = {Yu, Pengqian and Kundu, Achintya and Wynter, Laura and Lim, Shiau Hong},
	month = jun,
	year = {2021},
	note = {arXiv: 2009.06303},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning, \_read\_urgently, ⛔ No DOI found},
}

@article{yang_federated_2019,
	title = {Federated {Machine} {Learning}: {Concept} and {Applications}},
	volume = {10},
	issn = {2157-6904},
	url = {https://dl.acm.org/doi/10.1145/3298981},
	doi = {10.1145/3298981},
	abstract = {Today's artificial intelligence still faces two major challenges. One is that, in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security.We propose a possible solution to these challenges: Secure federated learning. Beyond the federated-learning framework first proposed by Google in 2016, we introduce a comprehensive secure federated-learning framework, which includes horizontal federated learning, vertical federated learning, and federated transfer learning.We provide definitions, architectures, and applications for the federated-learning framework, and provide a comprehensive survey of existing works on this subject. In addition, we propose building data networks among organizations based on federated mechanisms as an effective solution to allowing knowledge to be shared without compromising user privacy.},
	number = {2},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	author = {Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
	month = feb,
	year = {2019},
	keywords = {+survey, \_processed},
	pages = {1--19},
}

@article{yang_cloud_2016,
	title = {Cloud based data sharing with fine-grained proxy re-encryption},
	volume = {28},
	issn = {15741192},
	url = {http://dx.doi.org/10.1016/j.pmcj.2015.06.017},
	doi = {10.1016/j.pmcj.2015.06.017},
	abstract = {Conditional proxy re-encryption (CPRE) enables fine-grained delegation of decryption rights, and has many real-world applications. In this paper, we present a ciphertext-policy attribute based CPRE scheme, together with a formalization of the primitive and its security analysis. We demonstrate the utility of the scheme in a cloud deployment, which achieves fine-grained data sharing. This application implements cloud server-enabled user revocation, offering an alternative yet more efficient solution to the user revocation problem in the context of fine-grained encryption of cloud data. High user-side efficiency is another prominent feature of the application, which makes it possible for users to use resource constrained devices, e.g., mobile phones, to access cloud data. Our evaluations show promising results on the performance of the proposed scheme.},
	journal = {Pervasive and Mobile Computing},
	author = {Yang, Yanjiang and Zhu, Haiyan and Lu, Haibing and Weng, Jian and Zhang, Youcheng and Choo, Kim-Kwang Raymond},
	month = jun,
	year = {2016},
	note = {Publisher: Elsevier B.V.},
	pages = {122--134},
}

@article{wijethilaka_federated_2022,
	title = {A {Federated} {Learning} {Approach} for {Improving} {Security} in {Network} {Slicing}},
	abstract = {Network Slicing (NS) is a predominant technology in future telecommunication networks, including Fifth Generation (5G), which supports the realization of heterogeneous applications and services. It allows the allocation of a dedicated logical network slice of the physical network to each application. Security is one of the paramount challenges in an NS ecosystem. Several technologies, including Machine Learning (ML), have been proposed to mitigate security challenges in 5G networks. However, the use of ML for NS security is not properly implemented. Especially, the scarcity of coordination and the difficulties of privacy-protected information sharing between slices cause failures and performance degradation of these ML based NS security solutions. To address this issue, this paper proposes a novel Federated Learning (FL) based coordinated security orchestration architecture named Federated Learning enabled Security Orchestrator (FLeSO) to centrally perform security operations in a slicing ecosystem while preserving the privacy of the data. In addition, the proposed FLeSO architecture enables features such as proactive security deployment and steady security level maintenance independent of the slicing strategy. The proposed architecture is implemented in a realworld slicing testbed, and a comprehensive set of experiments are performed to evaluate the effectiveness of the proposed FLeSO architecture. The test results illustrate the significant advantage of the proposed approach over the legacy system in terms of improving the security of an NS ecosystem.},
	language = {en},
	author = {Wijethilaka, Shalitha and Liyanage, Madhusanka},
	month = dec,
	year = {2022},
	keywords = {⛔ No DOI found},
	pages = {7},
}

@article{wu_mars-fl_2022,
	title = {{MarS}-{FL}: {Enabling} {Competitors} to {Collaborate} in {Federated} {Learning}},
	issn = {2332-7790},
	shorttitle = {{MarS}-{FL}},
	doi = {10.1109/TBDATA.2022.3186991},
	abstract = {Federated learning (FL) is rapidly gaining popularity and enables multiple data owners (a.k.a. FL participants) to collaboratively train machine learning models in a privacy-preserving way. A key unaddressed scenario is that these FL participants are in a competitive market, where market shares represent their competitiveness. Although they are interested to enhance the performance of their respective models through FL, market leaders (who are often data owners who can contribute significantly to building high performance FL models) want to avoid losing their market shares by enhancing their competitors’ models. Currently, there is no modeling tool to analyze such scenarios and support informed decision-making. In this paper, we bridge this gap by proposing the market share-based decision support framework for participation in FL (MarS-FL). We introduce two notions of δ-stable market and friendliness to measure the viability of FL and the market acceptability of FL. The FL participants’ behaviours can then be predicted using game theoretic tools (i.e., their optimal strategies concerning participation in FL). If the market δ-stability is achievable, the final model performance improvement of each FL-PT shall be bounded, which relates to the market conditions of FL applications. We provide tight bounds and quantify the friendliness, κ, of given market conditions to FL. Experimental results show the viability of FL in a wide range of market conditions. Our results are useful for identifying the market conditions under which collaborative FL model training is viable among competitors, and the requirements that have to be imposed while applying FL under these conditions.},
	journal = {IEEE Transactions on Big Data},
	author = {Wu, Xiaohu and Yu, Han},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Big Data},
	keywords = {Biological system modeling, Computational modeling, Data models, Federated learning, Load modeling, Predictive models, Servers, Training, competitive market, game theory, performance allocation},
	pages = {1--11},
}

@article{wu_rtids_2022,
	title = {{RTIDS}: {A} {Robust} {Transformer}-{Based} {Approach} for {Intrusion} {Detection} {System}},
	volume = {10},
	issn = {2169-3536},
	shorttitle = {{RTIDS}},
	doi = {10.1109/ACCESS.2022.3182333},
	abstract = {Due to the rapid growth in network traffic and increasing security threats, Intrusion Detection Systems (IDS) have become increasingly critical in the field of cyber security for providing secure communications against cyber adversaries. However, there exist many challenges for designing a robust, efficient and accurate IDS, especially when dealing with high-dimensional anomaly data with unforeseen and unpredictable attacks. In this paper, we propose a Robust Transformer-based Intrusion Detection System (RTIDS) reconstructing feature representations to make a trade-off between dimensionality reduction and feature retention in imbalanced datasets. The proposed method utilizes positional embedding technique to associate sequential information between features, then a variant stacked encoder-decoder neural network is used to learn low-dimensional feature representations from high-dimensional raw data. Furthermore, we apply self-attention mechanism to facilitate network traffic type classifications. Extensive experiments reveal the effectiveness of the proposed RTIDS on two publicly available real traffic intrusion detection datasets named CICIDS2017 and CIC-DDoS2019 with F1-Score of 99.17\% and 98.48\% respectively. A comparative study with classical machine learning algorithm support vector machine (SVM) and deep learning algorithms that include recurrent neural network (RNN), fuzzy neural network (FNN), and long short-term memory network (LSTM) is conducted to demonstrate the validity of the proposed method.},
	journal = {IEEE Access},
	author = {Wu, Zihan and Zhang, Hong and Wang, Penghai and Sun, Zhibo},
	year = {2022},
	note = {Conference Name: IEEE Access},
	keywords = {Data models, Decoding, Feature extraction, Hidden Markov models, Intrusion detection, Telecommunication traffic, Transformers, \_read\_urgently, feature representation, self-attention mechanism, transformer},
	pages = {64375--64387},
}

@article{xiao_sca_2022,
	title = {{SCA}: {Sybil}-based {Collusion} {Attacks} of {IIoT} {Data} {Poisoning} in {Federated} {Learning}},
	issn = {1941-0050},
	shorttitle = {{SCA}},
	doi = {10.1109/TII.2022.3172310},
	abstract = {With the massive amounts of data generated by Industrial Internet of Things (IIoT) devices at all moments, federated learning (FL) enables these distributed distrusted devices to collaborate to build machine learning model while maintaining data privacy. However, malicious participants still launch malicious attacks against the security vulnerabilities during model aggregation. This paper is the first to propose sybil-based collusion attacks (SCA) in the IIoT-FL system for the vulnerabilities mentioned above. The malicious participants use label flipping attacks to complete local poisoning training. Meanwhile, they can virtualize multiple sybil nodes to make the local poisoning models aggregated with the greatest possibility during aggregation. They focus on making the joint model misclassify the selected attack class samples during the testing phase, while other non-attack classes kept the main task accuracy similar to the non-poisoned state. Exhaustive experimental analysis demonstrates that our SCA has superior performance on multiple aspects than the state-of-the-art.},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Xiao, Xiong and Tang, Zhuo and Li, Chuanying and Xiao, Bin and Li, Kenli},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Industrial Informatics},
	keywords = {Collaborative work, Collusion attacks, Data models, Distributed databases, Federated learning, IIoT, Industrial Internet of Things, Label flipping attacks, Performance evaluation, Servers, Sybil, Training},
	pages = {1--1},
}

@article{wei_redactable_2022,
	title = {A {Redactable} {Blockchain} {Framework} for {Secure} {Federated} {Learning} in {Industrial} {Internet}-of-{Things}},
	issn = {2327-4662, 2372-2541},
	url = {https://ieeexplore.ieee.org/document/9743331/},
	doi = {10.1109/JIOT.2022.3162499},
	abstract = {Industrial Internet-of-Things (IIoT) facilitate private data collecting via(a broad range of) sensors, and the analysis of such data can inform decision-making at different levels. Federated learning can be used to analyze the collected data, in privacy preserving manner by transmitting model updates instead of private data in IIoT networks. The federated learning framework is, however, vulnerable because model updates are easily tampered with by malicious agents. Motivated by this observation, we propose a novel chameleon hash scheme with changeable trapdoor (CHCT) for secure federated learning in IIoT settings. Our scheme imposes various constraints on the use of trapdoor. We give a rigorous security analysis on our CHCT scheme. We also instantiate the CHCT scheme as a redactable medical blockchain. Experimental evaluations demonstrate the practical utility of CHCT in terms of accuracy and efﬁciency.},
	language = {en},
	urldate = {2022-07-05},
	journal = {IEEE Internet of Things Journal},
	author = {Wei, Jiannan and Zhu, Qinchuan and Li, Qianmu and Nie, Laisen and Shen, Zhangyi and Choo, Kim-Kwang Raymond and Yu, Keping},
	year = {2022},
	pages = {1--1},
}

@article{wu_transfer_2019,
	title = {A {Transfer} {Learning} {Approach} for {Network} {Intrusion} {Detection}},
	url = {http://arxiv.org/abs/1909.02352},
	doi = {10.1109/ICBDA.2019.8713213},
	abstract = {Convolution Neural Network (ConvNet) offers a high potential to generalize input data. It has been widely used in many application areas, such as visual imagery, where comprehensive learning datasets are available and a ConvNet model can be well trained and perform the required function effectively. ConvNet can also be applied to network intrusion detection. However, the currently available datasets related to the network intrusion are often inadequate, which makes the ConvNet learning deﬁcient, hence the trained model is not competent in detecting unknown intrusions. In this paper, we propose a ConvNet model using transfer learning for the network intrusion detection. The model consists of two concatenated ConvNets and is built on a two-stage learning process: learning a base dataset and transferring the learned knowledge to the learning of the target dataset. Our experiments on the NSLKDD dataset show that the proposed model can improve the detection accuracy not only on the test dataset containing mostly known attacks (KDDTest+) but also on the test dataset featuring many novel attacks (KDDTest-21) – about 2.68\% improvement on KDDTest+ and 22.02\% on KDDTest-21 can be achieved, as compared to the traditional ConvNet model.},
	language = {en},
	urldate = {2021-10-04},
	journal = {arXiv:1909.02352 [cs]},
	author = {Wu, Peilun and Guo, Hui and Buckland, Richard},
	month = dec,
	year = {2019},
	note = {arXiv: 1909.02352},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Networking and Internet Architecture, \_read},
}

@article{wood_ethereum_2014,
	title = {Ethereum: a secure decentralised generalised transaction ledger},
	volume = {151},
	abstract = {The blockchain paradigm when coupled with cryptographically-secured transactions has demonstrated its utility through a number of projects, not least Bitcoin. Each such project can be seen as a simple application on a decentralised, but singleton, compute resource. We can call this paradigm a transactional singleton machine with shared-state. Ethereum implements this paradigm in a generalised manner. Furthermore it provides a plurality of such resources, each with a distinct state and operating code but able to interact through a message-passing framework with others. We discuss its design, implementation issues, the opportunities it provides and the future hurdles we envisage.},
	journal = {Ethereum Project Yellow Paper},
	author = {Wood, Gavin},
	month = nov,
	year = {2014},
	keywords = {⛔ No DOI found},
	pages = {1--32},
}

@article{vasilomanolakis_taxonomy_2015,
	title = {Taxonomy and {Survey} of {Collaborative} {Intrusion} {Detection}},
	volume = {47},
	doi = {10.1145/2716260},
	language = {en},
	number = {4},
	journal = {ACM Computing Surveys},
	author = {Vasilomanolakis, Emmanouil and Karuppayah, Shankar and Fischer, Mathias},
	month = may,
	year = {2015},
	keywords = {+survey, \_processed},
	pages = {33},
}

@article{wang_dimension_2022,
	title = {Dimension {Reduction} {Technique} {Based} on {Supervised} {Autoencoder} for {Intrusion} {Detection} of {Industrial} {Control} {Systems}},
	volume = {2022},
	issn = {1939-0122, 1939-0114},
	url = {https://www.hindawi.com/journals/scn/2022/5713074/},
	doi = {10.1155/2022/5713074},
	abstract = {Industrial control systems (ICSs) are closely related to human life. In recent years, many ICSs have been connected to the Internet rather than being physically isolated, which has improved business efficiency while also increasing the risks of being attacked. The security issues of ICSs have gotten a lot of interest in the research community because attack events that aim at ICSs can cause catastrophic damage. An intrusion detection system (IDS) serves as an important tool for providing protection. Many IDS studies using machine learning and deep learning have been proposed. However, high-dimensional data may cause overfitting, resulting in inferior performance. To improve the classification performance, we suggest a dimension reduction technique based on the supervised autoencoder (SupervisedAE) and principal components analysis (PCA) in this study. To obtain more discriminative latent representations, compared with the conventional autoencoder, the SupervisedAE absorbs the label information during the training process. In this way, the improved autoencoder model is trained with reconstruction error and classification error simultaneously. Based on the latent representations extracted from the SupervisedAE, we add the PCA algorithm. The additional PCA algorithm reduces the dimension of features further. We conduct a series of experiments utilizing the suggested technique on a public power system data set to evaluate the performance. Compared with various dimension reduction methods, including autoencoder variants, the technique proposed in this study shows higher performance. In the meanwhile, it outperforms some existing detection methods in terms of accuracy and F1 score.},
	language = {en},
	urldate = {2022-07-05},
	journal = {Security and Communication Networks},
	author = {Wang, Chao and Liu, Hongri and Sun, Yunxiao and Wei, Yuliang and Wang, Kai and Wang, Bailing},
	editor = {Zhaoquan, Gu},
	month = jun,
	year = {2022},
	pages = {1--12},
}

@article{wang_safeguarding_2021,
	title = {Safeguarding cross-silo federated learning with local differential privacy},
	issn = {23528648},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352864821000961},
	doi = {10/gpbg2m},
	abstract = {Federated Learning (FL) is a new computing paradigm in privacy-preserving Machine Learning (ML), where the ML model is trained in a decentralized manner by the clients, preventing the server from directly accessing privacy-sensitive data from the clients. Unfortunately, recent advances have shown potential risks for user-level privacy breaches under the cross-silo FL framework. In this paper, we propose addressing the issue by using a three-plane framework to secure the cross-silo FL, taking advantage of the Local Diﬀerential Privacy (LDP) mechanism. The key insight here is that LDP can provide strong data privacy protection, while still retaining user data statistics to preserve its high utility. Experimental results on three real-world datasets demonstrate the eﬀectiveness of our framework.},
	language = {en},
	urldate = {2022-01-31},
	journal = {Digital Communications and Networks},
	author = {Wang, Chen and Wu, Xinkui and Liu, Gaoyang and Deng, Tianping and Peng, Kai and Wan, Shaohua},
	month = nov,
	year = {2021},
	pages = {S2352864821000961},
}

@article{wagner_novel_2018,
	title = {A {Novel} {Trust} {Taxonomy} for {Shared} {Cyber} {Threat} {Intelligence}},
	volume = {2018},
	issn = {1939-0114, 1939-0122},
	url = {https://www.hindawi.com/journals/scn/2018/9634507/},
	doi = {10.1155/2018/9634507},
	abstract = {Cyber threat intelligence sharing has become a focal point for many organizations to improve resilience against cyberattacks. The objective lies in sharing relevant information achieved through automating as many processes as possible without losing control or compromising security. The intelligence may be crowdsourced from decentralized stakeholders to collect and enrich existing information. Trust is an attribute of actionable cyber threat intelligence that has to be established between stakeholders. Sharing information about vulnerabilities requires a high level of trust because of the sensitive information. Some threat intelligence platforms/providers support trust establishment through internal vetting processes; others rely on stakeholders to manually build up trust. The latter may reduce the amount of intelligence sources. This work presents a novel trust taxonomy to establish a trusted threat sharing environment. 30 popular threat intelligence platforms/providers were analyzed and compared regarding trust functionalities. Trust taxonomies were analyzed and compared. Illustrative case studies were developed and analyzed applying our trust taxonomy.},
	language = {en},
	urldate = {2021-06-01},
	journal = {Security and Communication Networks},
	author = {Wagner, Thomas D. and Palomar, Esther and Mahbub, Khaled and Abdallah, Ali E.},
	month = jun,
	year = {2018},
	pages = {1--11},
}

@article{wan_blockchain-based_2019,
	title = {A {Blockchain}-{Based} {Solution} for {Enhancing} {Security} and {Privacy} in {Smart} {Factory}},
	volume = {15},
	issn = {1551-3203},
	url = {https://ieeexplore.ieee.org/document/8621042/},
	doi = {10.1109/TII.2019.2894573},
	abstract = {Through the Industrial Internet of Things (IIoT), a smart factory has entered the booming period. However, as the number of nodes and network size become larger, the traditional IIoT architecture can no longer provide effective support for such enormous system. Therefore, we introduce the Blockchain architecture, which is an emerging scheme for constructing the distributed networks, to reshape the traditional IIoT architecture. First, the major problems of the traditional IIoT architecture are analyzed, and the existing improvements are summarized. Second, we introduce a security and privacy model to help design the Blockchain-based architecture. On this basis, we decompose and reorganize the original IIoT architecture to form a new multicenter partially decentralized architecture. Then, we introduce some relative security technologies to improve and optimize the new architecture. After that we design the data interaction process and the algorithms of the architecture. Finally, we use an automatic production platform to discuss the specific implementation. The experimental results show that the proposed architecture provides better security and privacy protection than the traditional architecture. Thus, the proposed architecture represents a significant improvement of the original architecture, which provides a new direction for the IIoT development.},
	number = {6},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Wan, Jiafu and Li, Jiapeng and Imran, Muhammad and Li, Di and {Fazal-e-Amin}},
	month = jun,
	year = {2019},
	pages = {3652--3660},
}

@article{wang_blockchain_2020,
	title = {Blockchain for the {IoT} and industrial {IoT}: {A} review},
	volume = {10},
	issn = {25426605},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S254266051930085X},
	doi = {10.1016/j.iot.2019.100081},
	abstract = {The Internet of Things (IoT), especially the industrial IoT (IIoT), has rapidly developed and is receiving a lot of attention in academic areas and industry, but IoT privacy risks and security vulnerabilities are emerging from lack of fundamental security technology. The blockchain technique, due to its decentralization and information disclosure, was proposed as a decentralized and distributed approach to guarantee security requirements and motivate the development of the IoT and IIoT. In this paper, we first introduce the basic structure and main features of blockchain and summarize the security requirements to develop IoT and Industry 4.0. Then, we explore how blockchain can be applied to the IoT for Industry 4.0 using its security tools and technology. We describe the most relevant blockchain-based IoT applications to promote the functions and advantages of the blockchain technique on IoT and IIoT platforms. Finally, some recommendations are proposed to guide future blockchain researchers and developers.},
	number = {66},
	journal = {Internet of Things},
	author = {Wang, Qin and Zhu, Xinqi and Ni, Yiyang and Gu, Li and Zhu, Hongbo},
	month = jun,
	year = {2020},
	pages = {100081},
}

@article{tounsi_survey_2018,
	title = {A survey on technical threat intelligence in the age of sophisticated cyber attacks},
	volume = {72},
	issn = {01674048},
	url = {https://doi.org/10.1016/j.cose.2017.09.001},
	doi = {10.1016/j.cose.2017.09.001},
	abstract = {Today's cyber attacks require a new line of security defenses. The static approach of traditional security based on heuristic and signature does not match the dynamic nature of new generation of threats that are known to be evasive, resilient and complex. Organizations need to gather and share real-time cyber threat information and to transform it to threat intelligence in order to prevent attacks or at least execute timely disaster recovery. Threat Intelligence (TI) means evidence-based knowledge representing threats that can inform decisions. There is a general awareness for the need of threat intelligence while vendors today are rushing to provide a diverse array of threat intelligence products, specifically focusing on Technical Threat Intelligence (TTI). Although threat intelligence is being increasingly adopted, there is little consensus on what it actually is, or how to use it. Without any real understanding of this need, organizations risk investing large amounts of time and money without solving existing security problems. Our paper aims to classify and make distinction among existing threat intelligence types. We focus particularly on the TTI issues, emerging researches, trends and standards. Our paper also explains why there is a reluctance among organizations to share threat intelligence. We provide sharing strategies based on trust and anonymity, so participating organizations can do away with the risks of business leak. We also show in this paper why having a standardized representation of threat information can improve the quality of TTI, thus providing better automated analytics solutions on large volumes of TTI which are often non-uniform and redundant. Finally, we evaluate most popular open source/free threat intelligence tools, and compare their features with those of a new AlliaCERT TI tool.},
	journal = {Computers \& Security},
	author = {Tounsi, Wiem and Rais, Helmi},
	month = jan,
	year = {2018},
	note = {Publisher: Elsevier Ltd},
	pages = {212--233},
}

@article{teixeira_vote-based_2022,
	title = {A {Vote}-{Based} {Architecture} to {Generate} {Classified} {Datasets} and {Improve} {Performance} of {Intrusion} {Detection} {Systems} {Based} on {Supervised} {Learning}},
	volume = {14},
	issn = {1999-5903},
	url = {https://www.mdpi.com/1999-5903/14/3/72},
	doi = {10.3390/fi14030072},
	abstract = {An intrusion detection system (IDS) is an important tool to prevent potential threats to systems and data. Anomaly-based IDSs may deploy machine learning algorithms to classify events either as normal or anomalous and trigger the adequate response. When using supervised learning, these algorithms require classiﬁed, rich, and recent datasets. Thus, to foster the performance of these machine learning models, datasets can be generated from different sources in a collaborative approach, and trained with multiple algorithms. This paper proposes a vote-based architecture to generate classiﬁed datasets and improve the performance of supervised learning-based IDSs. On a regular basis, multiple IDSs in different locations send their logs to a central system that combines and classiﬁes them using different machine learning models and a majority vote system. Then, it generates a new and classiﬁed dataset, which is trained to obtain the best updated model to be integrated into the IDS of the companies involved. The proposed architecture trains multiple times with several algorithms. To shorten the overall runtimes, the proposed architecture was deployed in Fed4FIRE+ with Ray to distribute the tasks by the available resources. A set of machine learning algorithms and the proposed architecture were assessed. When compared with a baseline scenario, the proposed architecture enabled to increase the accuracy by 11.5\% and the precision by 11.2\%.},
	language = {en},
	number = {3},
	urldate = {2022-07-05},
	journal = {Future Internet},
	author = {Teixeira, Diogo and Malta, Silvestre and Pinto, Pedro},
	month = feb,
	year = {2022},
	keywords = {\_read\_urgently},
	pages = {72},
}

@article{tan_reputation-aware_2022,
	title = {Reputation-{Aware} {Federated} {Learning} {Client} {Selection} based on {Stochastic} {Integer} {Programming}},
	issn = {2332-7790},
	doi = {10.1109/TBDATA.2022.3191332},
	abstract = {Federated Learning(FL) has attracted wide research interest due to its potential in building machine learning models while preserving users' data privacy. However, due to the distributive nature of FL, it is vulnerable to misbehavior from participating worker nodes. Thus, it is important to select clients to participate in FL. Recent studies on FL client selection focus on the perspective of improving model training efficiency and performance, without holistically considering potential misbehavior and the cost of hiring. To bridge this gap, we propose a first-of-its-kind reputation-aware Stochastic integer programming-based FL Client Selection method (SCS). It can optimally select and compensate clients with different reputation profiles. Extensive experiments show that SCS achieves the most advantageous performance-cost trade-off compared to other existing state-of-the-art approaches.},
	journal = {IEEE Transactions on Big Data},
	author = {Tan, Xavier and Ng, Wei Chong and Lim, Wei Yang Bryan and Xiong, Zehui and Niyato, Dusit and Yu, Han},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Big Data},
	keywords = {Biological system modeling, Computational modeling, Costs, Data models, Federated learning, Stochastic processes, Training, Uncertainty, client selection, reputation, stochastic integer programming},
	pages = {1--12},
}

@article{tarasov_generating_2021,
	title = {Generating {Realistic} {Datasets} for {Deduplication} {Analysis}},
	abstract = {Deduplication is a popular component of modern storage systems, with a wide variety of approaches. Unlike traditional storage systems, deduplication performance depends on data content as well as access patterns and meta-data characteristics. Most datasets that have been used to evaluate deduplication systems are either unrepresentative, or unavailable due to privacy issues, preventing easy comparison of competing algorithms. Understanding how both content and meta-data evolve is critical to the realistic evaluation of deduplication systems.},
	language = {en},
	author = {Tarasov, Vasily and Mudrankit, Amar},
	year = {2021},
	keywords = {⛔ No DOI found},
	pages = {12},
}

@article{tsukada_neural_2020,
	title = {A {Neural} {Network}-{Based} {On}-device {Learning} {Anomaly} {Detector} for {Edge} {Devices}},
	issn = {0018-9340, 1557-9956, 2326-3814},
	url = {https://ieeexplore.ieee.org/document/9000710/},
	doi = {10.1109/TC.2020.2973631},
	abstract = {Semi-supervised anomaly detection is an approach to identify anomalies by learning the distribution of normal data. Backpropagation neural networks (i.e., BP-NNs) based approaches have recently drawn attention because of their good generalization capability. In a typical situation, BP-NN-based models are iteratively optimized in server machines with input data gathered from the edge devices. However, (1) the iterative optimization often requires signiﬁcant efforts to follow changes in the distribution of normal data (i.e., concept drift), and (2) data transfers between edge and server impose additional latency and energy consumption. To address these issues, we propose ONLAD and its IP core, named ONLAD Core. ONLAD is highly optimized to perform fast sequential learning to follow concept drift in less than one millisecond. ONLAD Core realizes on-device learning for edge devices at low power consumption, which realizes standalone execution where data transfers between edge and server are not required. Experiments show that ONLAD has favorable anomaly detection capability in an environment that simulates concept drift. Evaluations of ONLAD Core conﬁrm that the training latency is 1.95x\$6.58x faster than the other software implementations. Also, the runtime power consumption of ONLAD Core implemented on PYNQ-Z1 board, a small FPGA/CPU SoC platform, is 5.0x\$25.4x lower than them.},
	language = {en},
	urldate = {2021-10-23},
	journal = {IEEE Transactions on Computers},
	author = {Tsukada, Mineto and Kondo, Masaaki and Matsutani, Hiroki},
	year = {2020},
	pages = {1--1},
}

@article{trifonov_artificial_2019,
	title = {Artificial intelligence in cyber threats intelligence},
	doi = {10.1109/ICONIC.2018.8601235},
	abstract = {In the field of Cyber Security there has been a transition from the stage of Cyber Criminality to the stage of Cyber War over the last few years. According to the new challenges, the expert community has two main approaches: to adopt the philosophy and methods of Military Intelligence, and to use Artificial Intelligence methods for counteraction of Cyber Attacks. This paper describes some of the results obtained at Technical University of Sofia in the implementation of project related to the application of intelligent methods for increasing the security in computer networks. The analysis of the feasibility of various Artificial Intelligence methods has shown that a method that is equally effective for all stages of the Cyber Intelligence cannot be identified. While for Tactical Cyber Threats Intelligence has been selected and experimented a Multi-Agent System, the Recurrent Neural Networks are offered for the needs of Operational Cyber Threats Intelligence.},
	journal = {2018 International Conference on Intelligent and Innovative Computing Applications, ICONIC 2018},
	author = {Trifonov, Roumen and Nakov, Ognyan and Mladenov, Valeri},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781538664773},
	pages = {2018--2021},
}

@article{ulltveit-moe_secure_2016,
	title = {Secure {Information} {Sharing} in an {Industrial} {Internet} of {Things}},
	url = {http://arxiv.org/abs/1601.04301},
	abstract = {This paper investigates how secure information sharing with external vendors can be achieved in an Industrial Internet of Things (IIoT). It also identifies necessary security requirements for secure information sharing based on identified security challenges stated by the industry. The paper then proposes a roadmap for improving security in IIoT which investigates both short-term and long-term solutions for protecting IIoT devices. The short-term solution is mainly based on integrating existing good practices. The paper also outlines a long term solution for protecting IIoT devices with fine-grained access control for sharing data between external entities that would support cloud-based data storage.},
	author = {Ulltveit-Moe, Nils and Nergaard, Henrik and Erdödi, László and Gjøsæter, Terje and Kolstad, Erland and Berg, Pål},
	month = jan,
	year = {2016},
	pages = {1--12},
}

@article{staudemeyer_applying_2015,
	title = {Applying long short-term memory recurrent neural networks to intrusion detection},
	volume = {56},
	issn = {2313-7835, 1015-7999},
	url = {https://sacj.cs.uct.ac.za/index.php/sacj/article/view/248},
	doi = {10.18489/sacj.v56i1.248},
	abstract = {We claim that modelling network traﬃc as a time series with a supervised learning approach, using known genuine and malicious behaviour, improves intrusion detection. To substantiate this, we trained long short-term memory (LSTM) recurrent neural networks with the training data provided by the DARPA / KDD Cup ’99 challenge. To identify suitable LSTM-RNN network parameters and structure we experimented with various network topologies. We found networks with four memory blocks containing two cells each oﬀer a good compromise between computational cost and detection performance. We applied forget gates and shortcut connections respectively. A learning rate of 0.1 and up to 1,000 epochs showed good results.},
	language = {en},
	urldate = {2021-10-13},
	journal = {South African Computer Journal},
	author = {Staudemeyer, Ralf C.},
	month = jul,
	year = {2015},
}

@article{sun_adaptive_2020,
	title = {Adaptive {Federated} {Learning} and {Digital} {Twin} for {Industrial} {Internet} of {Things}},
	url = {http://arxiv.org/abs/2010.13058},
	abstract = {Industrial Internet of Things (IoT) enables distributed intelligent services varying with the dynamic and realtime industrial environment to achieve Industry 4.0 beneﬁts. In this paper, we consider a new architecture of digital twin empowered Industrial IoT where digital twins capture the characteristics of industrial devices to assist federated learning. Noticing that digital twins may bring estimation deviations from the actual value of device state, a trusted based aggregation is proposed in federated learning to alleviate the effects of such deviation. We adaptively adjust the aggregation frequency of federated learning based on Lyapunov dynamic deﬁcit queue and deep reinforcement learning, to improve the learning performance under the resource constraints. To further adapt to the heterogeneity of Industrial IoT, a clustering-based asynchronous federated learning framework is proposed. Numerical results show that the proposed framework is superior to the benchmark in terms of learning accuracy, convergence, and energy saving.},
	language = {en},
	urldate = {2021-10-04},
	journal = {arXiv:2010.13058 [cs]},
	author = {Sun, Wen and Lei, Shiyu and Wang, Lu and Liu, Zhiqiang and Zhang, Yan},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.13058},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, \_processed, ⛔ No DOI found},
}

@article{singh_dew-cloud-based_2022,
	title = {Dew-{Cloud}-{Based} {Hierarchical} {Federated} {Learning} for {Intrusion} {Detection} in {IoMT}},
	volume = {PP},
	issn = {2168-2208},
	doi = {10.1109/JBHI.2022.3186250},
	abstract = {The coronavirus pandemic has overburdened medical institutions, forcing physicians to diagnose and treat their patients remotely. Moreover, COVID-19 has made humans more conscious about their health, resulting in the extensive purchase of IoT-enabled medical devices. The rapid boom in the market worth of the internet of medical things (IoMT) captured cyber attackers' attention. Like health, medical data is also sensitive and worth a lot on the dark web. Despite the fact that the patient's health details have not been protected appropriately, letting the trespassers exploit them. The system administrator is unable to fortify security measures due to the limited storage capacity and computation power of the resource-constrained network devices'. Although various supervised and unsupervised machine learning algorithms have been developed to identify anomalies, the primary undertaking is to explore the swift progressing malicious attacks before they deteriorate the wellness system's integrity. In this paper, a Dew-Cloud based model is designed to enable hierarchical federated learning (HFL). The proposed Dew-Cloud model provides a higher level of data privacy with greater availability of IoMT critical application(s). The hierarchical long-term memory (HLSTM) model is deployed at distributed Dew servers with a backend supported by cloud computing. Data pre-processing feature helps the proposed model achieve high training accuracy ( 99.31 \%) with minimum training loss (0.034). The experiment results demonstrate that the proposed HFL-HLSTM model is superior to existing schemes in terms of performance metrics such as accuracy, precision, recall, and f-score.},
	language = {eng},
	journal = {IEEE journal of biomedical and health informatics},
	author = {Singh, Parminder and Gaba, Gurjot Singh and Kaur, Avinash and Hedabou, Mustapha and Gurtov, Andrei},
	month = jul,
	year = {2022},
	pmid = {35816521},
}

@article{siriwardhana_robust_2022,
	title = {Robust and {Resilient} {Federated} {Learning} for {Securing} {Future} {Networks}},
	abstract = {Machine Learning (ML) and Artificial Intelligence (AI) techniques are widely adopted in the telecommunication industry, especially to automate beyond 5G networks. Federated Learning (FL) recently emerged as a distributed ML approach that enables localized model training to keep data decentralized to ensure data privacy. In this paper, we identify the applicability of FL for securing future networks and its limitations due to the vulnerability to poisoning attacks. First, we investigate the shortcomings of state-of-the-art security algorithms for FL and perform an attack to circumvent FoolsGold algorithm, which is known as one of the most promising defense techniques currently available. The attack is launched with the addition of intelligent noise at the poisonous model updates. Then we propose a more sophisticated defense strategy, a threshold-based clustering mechanism to complement FoolsGold. Moreover, we provide a comprehensive analysis of the impact of the attack scenario and the performance of the defense mechanism.},
	language = {en},
	author = {Siriwardhana, Yushan and Porambage, Pawani and Liyanage, Madhusanka and Ylianttila, Mika},
	month = jun,
	year = {2022},
	keywords = {⛔ No DOI found},
	pages = {7},
}

@article{singh_detection_2020,
	title = {Detection and mitigation of {DDoS} attacks in {SDN}: {A} comprehensive review, research challenges and future directions},
	volume = {37},
	issn = {15740137},
	shorttitle = {Detection and mitigation of {DDoS} attacks in {SDN}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1574013720301647},
	doi = {10.1016/j.cosrev.2020.100279},
	abstract = {Many security solutions have been proposed in the past to protect Internet architecture from a diversity of malware. However, the security of the Internet and its applications is still an open research challenge. Researchers continuously working on novel network architectures such as HTTP as the narrow waist, Named Data Networking (NDN), programmable networks and Software-Defined Networking (SDN) for designing a more reliable network. Among these, SDN has emerged as a more robust and secure solution to combat against such malicious activities. In SDN, bifurcation of control plane and data plane provides more manageability, control, dynamic updating of rules, analysis, and global view of the network using a centralized controller. Though SDN seems a secured network architecture as compared to the conventional IP-based networks, still, SDN itself is vulnerable to many types of network intrusions and facing severe deployment challenges. This paper systematically reviews around 70 prominent DDoS detection and mitigation mechanisms in SDN networks. These mechanisms are characterized into four categories, viz: Information theory-based methods, Machine learning-based methods, Artificial Neural Networks (ANN) based methods and other miscellaneous methods. The paper also dowries and deliberates on various open research issues, gaps and challenges in the deployment of a secure SDN-based DDoS defence solution. Such an exhaustive review will surely help the researcher community to provide more robust and reliable DDoS solutions in SDN networks. © 2020 Elsevier Inc. All rights reserved.},
	language = {en},
	urldate = {2022-04-09},
	journal = {Computer Science Review},
	author = {Singh, Jagdeep and Behal, Sunny},
	month = aug,
	year = {2020},
	pages = {100279},
}

@article{si-ahmed_survey_2022,
	title = {Survey of {Machine} {Learning} {Based} {Intrusion} {Detection} {Methods} for {Internet} of {Medical} {Things}},
	url = {http://arxiv.org/abs/2202.09657},
	abstract = {Internet of Medical Things (IoMT) represents an application of the Internet of Things, where health professionals perform remote analysis of physiological data collected using sensors that are associated with patients, allowing real-time and permanent monitoring of the patient’s health condition and the detection of possible diseases at an early stage. However, the use of wireless communication for data transfer exposes this data to cyberattacks, and the sensitive and private nature of this data may represent a prime interest for attackers. The use of traditional security methods on equipment that is limited in terms of storage and computing capacity is ineﬀective. In this context, we have performed a comprehensive survey to investigate the use of the intrusion detection system based on machine learning (ML) for IoMT security. We presented the generic three-layer architecture of IoMT, the security requirement of IoMT security. We review the various threats that can aﬀect IoMT security and identify the advantage, disadvantages, methods, and datasets used in each solution based on ML. Then we provide some challenges and limitations of applying ML on each layer of IoMT, which can serve as direction for future study.},
	language = {en},
	urldate = {2022-03-01},
	journal = {arXiv:2202.09657 [cs]},
	author = {Si-Ahmed, Ayoub and Al-Garadi, Mohammed Ali and Boustia, Narhimene},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.09657},
	keywords = {+survey, Computer Science - Cryptography and Security, Computer Science - Machine Learning, ⛔ No DOI found},
}

@article{sivanathan_classifying_2019,
	title = {Classifying {IoT} {Devices} in {Smart} {Environments} {Using} {Network} {Traffic} {Characteristics}},
	volume = {18},
	issn = {1536-1233, 1558-0660, 2161-9875},
	url = {https://ieeexplore.ieee.org/document/8440758/},
	doi = {10.1109/TMC.2018.2866249},
	abstract = {The Internet of Things (IoT) is being hailed as the next wave revolutionizing our society, and smart homes, enterprises, and cities are increasingly being equipped with a plethora of IoT devices. Yet, operators of such smart environments may not even be fully aware of their IoTassets, let alone whether each IoT device is functioning properly safe from cyber-attacks. In this paper, we address this challenge by developing a robust framework for IoT device classiﬁcation using trafﬁc characteristics obtained at the network level. Our contributions are fourfold. First, we instrument a smart environment with 28 different IoT devices spanning cameras, lights, plugs, motion sensors, appliances, and health-monitors. We collect and synthesize trafﬁc traces from this infrastructure for a period of six months, a subset of which we release as open data for the community to use. Second, we present insights into the underlying network trafﬁc characteristics using statistical attributes such as activity cycles, port numbers, signalling patterns, and cipher suites. Third, we develop a multi-stage machine learning based classiﬁcation algorithm and demonstrate its ability to identify speciﬁc IoT devices with over 99 percent accuracy based on their network activity. Finally, we discuss the trade-offs between cost, speed, and performance involved in deploying the classiﬁcation framework in real-time. Our study paves the way for operators of smart environments to monitor their IoT assets for presence, functionality, and cyber-security without requiring any specialized devices or protocols.},
	language = {en},
	number = {8},
	urldate = {2021-05-21},
	journal = {IEEE Transactions on Mobile Computing},
	author = {Sivanathan, Arunan and Gharakheili, Hassan Habibi and Loi, Franco and Radford, Adam and Wijenayake, Chamith and Vishwanath, Arun and Sivaraman, Vijay},
	month = aug,
	year = {2019},
	pages = {1745--1759},
}

@article{sivanathan_managing_2020,
	title = {Managing {IoT} {Cyber}-{Security} {Using} {Programmable} {Telemetry} and {Machine} {Learning}},
	volume = {17},
	issn = {1932-4537},
	url = {https://ieeexplore.ieee.org/document/8981946/},
	doi = {10.1109/TNSM.2020.2971213},
	abstract = {Cyber-security risks for Internet of Things (IoT) devices sourced from a diversity of vendors and deployed in large numbers, are growing rapidly. Therefore, management of these devices is becoming increasingly important to network operators. Existing network monitoring technologies perform traffic analysis using specialized acceleration on network switches, or full inspection of packets in software, which can be complex, expensive, inflexible, and unscalable. In this paper, we use SDN paradigm combined with machine learning to leverage the benefits of programmable flow-based telemetry with flexible data-driven models to manage IoT devices based on their network activity. Our contributions are three-fold: (1) We analyze traffic traces of 17 real consumer IoT devices collected in our lab over a six-month period and identify a set of traffic flows (per-device) whose time-series attributes computed at multiple timescales (from a minute to an hour) characterize the network behavior of various IoT device types, and their operating states (i.e., booting, actively interacted with user, or being idle); (2) We develop a multi-stage architecture of inference models that use flow-level attributes to automatically distinguish IoT devices from non-IoTs, classify individual types of IoT devices, and identify their states during normal operations. We train our models and validate their efficacy using real traffic traces; and (3) We quantify the trade-off between performance and cost of our solution, and demonstrate how our monitoring scheme can be used in operation for detecting behavioral changes (firmware upgrade or cyber attacks).},
	number = {1},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Sivanathan, Arunan and Habibi Gharakheili, Hassan and Sivaraman, Vijay},
	month = mar,
	year = {2020},
	note = {Publisher: IEEE},
	pages = {60--74},
}

@article{shen_distributed_2020,
	title = {From {Distributed} {Machine} {Learning} {To} {Federated} {Learning}: {In} {The} {View} {Of} {Data} {Privacy} {And} {Security}},
	issn = {1532-0626, 1532-0634},
	shorttitle = {From {Distributed} {Machine} {Learning} {To} {Federated} {Learning}},
	url = {http://arxiv.org/abs/2010.09258},
	doi = {10.1002/cpe.6002},
	abstract = {Federated learning is an improved version of distributed machine learning that further oﬄoads operations which would usually be performed by a central server. The server becomes more like an assistant coordinating clients to work together rather than micro-managing the workforce as in traditional DML. One of the greatest advantages of federated learning is the additional privacy and security guarantees it aﬀords. Federated learning architecture relies on smart devices, such as smartphones and IoT sensors, that collect and process their own data, so sensitive information never has to leave the client device. Rather, clients train a sub-model locally and send an encrypted update to the central server for aggregation into the global model. These strong privacy guarantees make federated learning an attractive choice in a world where data breaches and information theft are common and serious threats. This survey outlines the landscape and latest developments in data privacy and security for federated learning. We identify the diﬀerent mechanisms used to provide privacy and security, such as diﬀerential privacy, secure multi-party computation and secure aggregation. We also survey the current attack models, identifying the areas of vulnerability and the strategies adversaries use to penetrate federated systems. The survey concludes with a discussion on the open challenges and potential directions of future work in this increasingly popular learning paradigm.},
	language = {en},
	urldate = {2021-10-04},
	journal = {Concurrency and Computation: Practice and Experience},
	author = {Shen, Sheng and Zhu, Tianqing and Wu, Di and Wang, Wei and Zhou, Wanlei},
	month = sep,
	year = {2020},
	note = {arXiv: 2010.09258},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, \_read},
	pages = {cpe.6002},
}

@article{shamir_communication-efcient_2014,
	title = {Communication-{Efﬁcient} {Distributed} {Optimization} using an {Approximate} {Newton}-type {Method}},
	abstract = {We present a novel Newton-type method for distributed optimization, which is particularly well suited for stochastic optimization and learning problems. For quadratic objectives, the method enjoys a linear rate of convergence which provably improves with the data size, requiring an essentially constant number of iterations under reasonable assumptions. We provide theoretical and empirical evidence of the advantages of our method compared to other approaches, such as one-shot parameter averaging and ADMM.},
	language = {en},
	author = {Shamir, Ohad and Srebro, Nathan and Zhang, Tong},
	year = {2014},
	keywords = {⛔ No DOI found},
	pages = {9},
}

@article{sengupta_comprehensive_2020,
	title = {A {Comprehensive} {Survey} on {Attacks}, {Security} {Issues} and {Blockchain} {Solutions} for {IoT} and {IIoT}},
	volume = {149},
	issn = {10848045},
	url = {https://doi.org/10.1016/j.jnca.2019.102481},
	doi = {10.1016/j.jnca.2019.102481},
	abstract = {In recent years, the growing popularity of Internet of Things (IoT) is providing a promising opportunity not only for the development of various home automation systems but also for different industrial applications. By leveraging these benefits, automation is brought about in the industries giving rise to the Industrial Internet of Things (IIoT). IoT is prone to several cyberattacks and needs challenging approaches to achieve the desired security. Moreover, with the emergence of IIoT, the security vulnerabilities posed by it are even more devastating. Therefore, in order to provide a guideline to researchers, this survey primarily attempts to classify the attacks based on the objects of vulnerability. Subsequently, each of the individual attacks is mapped to one or more layers of the generalized IoT/IIoT architecture followed by a discussion on the countermeasures proposed in literature. Some relevant real-life attacks for each of these categories are also discussed. We further discuss the countermeasures proposed for the most relevant security threats in IIoT. A case study on two of the most important industrial IoT applications is also highlighted. Next, we explore the challenges brought by the centralized IoT/IIoT architecture and how blockchain can effectively be used towards addressing such challenges. In this context, we also discuss in detail one IoT specific Blockchain design known as Tangle, its merits and demerits. We further highlight the most relevant Blockchain-based solutions provided in recent times to counter the challenges posed by the traditional cloud-centered applications. The blockchain-related solutions provided in the context of two of the most relevant applications for each of IoT and IIoT is also discussed. Subsequently, we design a taxonomy of the security research areas in IoT/IIoT along with their corresponding solutions. Finally, several open research directions relevant to the focus of this survey are identified.},
	number = {April 2019},
	journal = {Journal of Network and Computer Applications},
	author = {Sengupta, Jayasree and Ruj, Sushmita and Das Bit, Sipra},
	month = jan,
	year = {2020},
	note = {Publisher: Elsevier Ltd},
	pages = {102481},
}

@article{sha_survey_2020,
	title = {A survey of edge computing-based designs for {IoT} security},
	volume = {6},
	issn = {23528648},
	url = {https://doi.org/10.1016/j.dcan.2019.08.006},
	doi = {10.1016/j.dcan.2019.08.006},
	abstract = {Pervasive IoT applications enable us to perceive, analyze, control, and optimize the traditional physical systems. Recently, security breaches in many IoT applications have indicated that IoT applications may put the physical systems at risk. Severe resource constraints and insufficient security design are two major causes of many security problems in IoT applications. As an extension of the cloud, the emerging edge computing with rich resources provides us a new venue to design and deploy novel security solutions for IoT applications. Although there are some research efforts in this area, edge-based security designs for IoT applications are still in its infancy. This paper aims to present a comprehensive survey of existing IoT security solutions at the edge layer as well as to inspire more edge-based IoT security designs. We first present an edge-centric IoT architecture. Then, we extensively review the edge-based IoT security research efforts in the context of security architecture designs, firewalls, intrusion detection systems, authentication and authorization protocols, and privacy-preserving mechanisms. Finally, we propose our insight into future research directions and open research issues.},
	number = {2},
	journal = {Digital Communications and Networks},
	author = {Sha, Kewei and Yang, T. Andrew and Wei, Wei and Davari, Sadegh},
	month = may,
	year = {2020},
	note = {Publisher: Elsevier Ltd},
	pages = {195--202},
}

@article{schwartz_automating_2017,
	title = {Automating {Threat} {Sharing} : {How} {Companies} {Can} {Best} {Ensure} {Liability} {Protection} {When} {Sharing} {Cyber} {Threat} {Information} {With} {Other} {Companies} or {Organizations}},
	volume = {50},
	author = {Schwartz, Ari and Mackenzie, Matthew H},
	year = {2017},
}

@article{settanni_collaborative_2017,
	title = {A collaborative cyber incident management system for {European} interconnected critical infrastructures},
	volume = {34},
	issn = {22142126},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2214212616300576},
	doi = {10.1016/j.jisa.2016.05.005},
	abstract = {Today's Industrial Control Systems (ICSs) operating in critical infrastructures (CIs) are becoming increasingly complex; moreover, they are extensively interconnected with corporate information systems for cost-efficient monitoring, management and maintenance. This exposes ICSs to modern advanced cyber threats. Existing security solutions try to prevent, detect, and react to cyber threats by employing security measures that typically do not cross the organization's boundaries. However, novel targeted multi-stage attacks such as Advanced Persistent Threats (APTs) take advantage of the interdependency between organizations. By exploiting vulnerabilities of various systems, APT campaigns intrude several organizations using them as stepping stones to reach the target infrastructure. A coordinated effort to timely reveal such attacks, and promptly deploy mitigation measures is therefore required. Organizations need to cooperatively exchange security-relevant information to obtain a broader knowledge on the current cyber threat landscape and subsequently obtain new insight into their infrastructures and timely react if necessary. Cyber security operation centers (SOCs), as proposed by the European NIS directive, are being established worldwide to achieve this goal. CI providers are asked to report to the responsible SOCs about security issues revealed in their networks. National SOCs correlate all the gathered data, analyze it and eventually provide support and mitigation strategies to the affiliated organizations. Although many of these tasks can be automated, human involvement is still necessary to enable SOCs to adequately take decisions on occurring incidents and quickly implement counteractions. In this paper we present a collaborative approach to cyber incident information management for gaining situational awareness on interconnected European CIs. We provide a scenario and an illustrative use-case for our approach; we propose a system architecture for a National SOC, defining the functional components and interfaces it comprises. We further describe the functionalities provided by the different system components to support SOC operators in performing incident management tasks.},
	journal = {Journal of Information Security and Applications},
	author = {Settanni, Giuseppe and Skopik, Florian and Shovgenya, Yegor and Fiedler, Roman and Carolan, Mark and Conroy, Damien and Boettinger, Konstantin and Gall, Mark and Brost, Gerd and Ponchel, Christophe and Haustein, Mirko and Kaufmann, Helmut and Theuerkauf, Klaus and Olli, Pia},
	month = jun,
	year = {2017},
	note = {Publisher: Elsevier Ltd},
	pages = {166--182},
}

@article{ruby_anti-jamming_2022,
	title = {Anti-{Jamming} {Strategies} for {Federated} {Learning} {Internet} of {Medical} {Things}: {A} {Game} {Approach}},
	issn = {2168-2208},
	shorttitle = {Anti-{Jamming} {Strategies} for {Federated} {Learning} {Internet} of {Medical} {Things}},
	doi = {10.1109/JBHI.2022.3183644},
	abstract = {Federated learning (FL) is a new dawn of artificial intelligence (AI), in which machine learning models are constructed in a distributed manner while communicating only model parameters between a centralized aggregator and client internet-of-medical-things (IoMT) nodes. The performance of such a learning technique can be seriously hampered by the activities of a malicious jammer robot. In this paper, we study client selection and channel allocation along with the power control problem of the uplink FL process in IoMT domain under the presence of a jammer from the perspective of long-term learning duration. We map the interaction between the FL network and the jammer in each learning iteration as a Stackelberg game, in which the jammer acts as the leader and the FL network serves as the follower. We consider the client and channel selection as well as the power control jointly as the strategy of this game. Upon formulating the game, we find the joint best response strategy for both types of players by leveraging the difference of convex (DC) programming approach and the dual decomposition technique. Beside the availability of the complete information to both the players, we also study the problem from the perspective that the FL network knows the partial information of the other player. Extensive simulations have been conducted to verify the effectiveness of the proposed algorithms in the jamming game.},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Ruby, Rukhsana and Yang, Hailiang and Wu, Kaishun},
	year = {2022},
	note = {Conference Name: IEEE Journal of Biomedical and Health Informatics},
	keywords = {Anti-Jamming Strategy, Bit rate, Channel Selection, Data models, Federated Learning (FL), Games, Jamming, Medical diagnostic imaging, Power Control, Resource management, Stackelber Game, Training},
	pages = {1--12},
}

@article{saha_federated_2021,
	title = {Federated {Transfer} {Learning}: concept and applications},
	shorttitle = {Federated {Transfer} {Learning}},
	url = {http://arxiv.org/abs/2010.15561},
	abstract = {Development of Artiﬁcial Intelligence (AI) is inherently tied to the development of data. However, in most industries data exists in form of isolated islands, with limited scope of sharing between different organizations. This is an hindrance to the further development of AI. Federated learning has emerged as a possible solution to this problem in the last few years without compromising user privacy. Among different variants of the federated learning, noteworthy is federated transfer learning (FTL) that allows knowledge to be transferred across domains that do not have many overlapping features and users. In this work we provide a comprehensive survey of the existing works on this topic. In more details, we study the background of FTL and its different existing applications. We further analyze FTL from privacy and machine learning perspective.},
	language = {en},
	urldate = {2021-10-04},
	journal = {arXiv:2010.15561 [cs]},
	author = {Saha, Sudipan and Ahmad, Tahir},
	month = mar,
	year = {2021},
	note = {arXiv: 2010.15561},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, \_processed, ⛔ No DOI found},
}

@article{safaei_pour_comprehending_2019,
	title = {Comprehending the {IoT} cyber threat landscape: {A} data dimensionality reduction technique to infer and characterize {Internet}-scale {IoT} probing campaigns},
	volume = {28},
	issn = {17422876},
	url = {https://doi.org/10.1016/j.diin.2019.01.014},
	doi = {10.1016/j.diin.2019.01.014},
	abstract = {The resource-constrained and heterogeneous nature of Internet-of-Things (IoT)devices coupled with the placement of such devices in publicly accessible venues complicate efforts to secure these devices and the networks they are connected to. The Internet-wide deployment of IoT devices also makes it challenging to operate security solutions at strategic locations within the network or to identify orchestrated activities from seemingly independent malicious events from such devices. Therefore, in this paper, we initially seek to determine the magnitude of IoT exploitations by examining more than 1 TB of passive measurement data collected from a/8 network telescope and by correlating it with 400 GB of information from the Shodan service. In the second phase of the study, we conduct in-depth discussions with Internet Service Providers (ISPs)and backbone network operators, as well as leverage geolocation databases to not only attribute such exploitations to their hosting environment (ISPs, countries, etc.)but also to classify such inferred IoT devices based on their hosting sector type (financial, education, manufacturing, etc.)and most abused IoT manufacturers. In the third phase, we automate the task of alerting realms that are determined to be hosting exploited IoT devices. Additionally, to address the problem of inferring orchestrated IoT campaigns by solely observing their activities targeting the network telescope, we further introduce a theoretically sound technique based on L1-norm PCA, and validate the utility of the proposed data dimensionality reduction technique against the conventional L2-norm PCA. Specifically, we identify “in the wild” IoT coordinated probing campaigns that are targeting generic ports and campaigns specifically searching for open resolvers (for amplification purposes). The results reveal more than 120,000 Internet-scale exploited IoT devices, some of which are operating in critical infrastructure sectors such as health and manufacturing. We also infer 140 large-scale IoT-centric probing campaigns; a sample of which includes a worldwide distributed campaign where close to 40\% of its population includes video surveillance cameras from a single manufacturer, and another very large inferred coordinated campaign consisting of more than 50,000 IoT devices. The reported findings highlight the insecurity of the IoT paradigm at large and thus demonstrate the importance of understanding such evolving threat landscape.},
	journal = {Digital Investigation},
	author = {Safaei Pour, Morteza and Bou-Harb, Elias and Varma, Kavita and Neshenko, Nataliia and Pados, Dimitris A. and Choo, Kim-Kwang Raymond},
	month = apr,
	year = {2019},
	note = {Publisher: Elsevier Ltd},
	pages = {S40--S49},
}

@article{rjoub_one-shot_2022,
	title = {One-{Shot} {Federated} {Learning}-based {Model}-{Free} {Reinforcement} {Learning}},
	abstract = {The Federated Learning (FL) paradigm is emerging as a way to train machine learning (ML) models in distributed systems. A large population of interconnected devices (i.e. Internet of Things (IoT)) acting as local learners optimize the model parameters collectively (e.g., neural networks’ weights), rather than sharing and disclosing the training data set with the server. FL approaches assume each participant has enough training data for the tasks of interest. Realistically, data collected by IoT devices may be insufficient and often unlabeled. In particular, each IoT device may only contain one or a few samples of every relevant data category, and may not have the time or interest to label them. In realistic applications, this severely limits FL’s practicality and usability. In this paper, we propose a One-Shot Federated Learning (OSFL) framework considering a FL scenario wherein the local training is carried out on IoT devices and the global aggregation is done at the level of an edge server. Moreover, we combine model-free reinforcement learning with OSFL to design a more intelligent IoT device to infer whether to label a sample automatically or request the true label for the one-shot learning set-up. We validate our system on the SODA10M dataset. Experiments show that our solution achieves better performance than DQN and RS benchmark approaches.},
	language = {en},
	author = {Rjoub, Gaith and Bentahar, Jamal and Wahab, Omar Abdel and Drawel, Nagat},
	year = {2022},
	keywords = {\_read\_urgently, ⛔ No DOI found},
	pages = {15},
}

@article{rjoub_trust-augmented_2022,
	title = {Trust-augmented {Deep} {Reinforcement} {Learning} for {Federated} {Learning} {Client} {Selection}},
	language = {en},
	author = {Rjoub, Gaith and Wahab, Omar Abdel and Cohen, Robin and Bataineh, Ahmed Saleh},
	month = jul,
	year = {2022},
	keywords = {⛔ No DOI found},
	pages = {33},
}

@article{rodriguez-barroso_backdoor_2022,
	title = {Backdoor attacks-resilient aggregation based on {Robust} {Filtering} of {Outliers} in federated learning for image classification},
	volume = {245},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705122002635},
	doi = {10.1016/j.knosys.2022.108588},
	abstract = {Federated Learning is a distributed machine learning paradigm vulnerable to different kind of adversarial attacks, since its distributed nature and the inaccessibility of the data by the central server. In this work, we focus on model-poisoning backdoor attacks, because they are characterized by their stealth and effectiveness. We claim that the model updates of the clients of a federated learning setting follow a Gaussian distribution, and those ones with an outlier behavior in that distribution are likely to be adversarial clients. We propose a new federated aggregation operator called Robust Filtering of one-dimensional Outliers (RFOut-1d), which works as a resilient defensive mechanism to modelpoisoning backdoor attacks. RFOut-1d is based on an univariate outlier detection method that filters out the model updates of the adversarial clients. The results on three federated image classification dataset show that RFOut-1d dissipates the impact of the backdoor attacks to almost nullifying them throughout all the learning rounds, as well as it keeps the performance of the federated learning model and it outperforms that state-of-the-art defenses against backdoor attacks.},
	language = {en},
	urldate = {2022-07-05},
	journal = {Knowledge-Based Systems},
	author = {Rodríguez-Barroso, Nuria and Martínez-Cámara, Eugenio and Luzón, M. Victoria and Herrera, Francisco},
	month = jun,
	year = {2022},
	pages = {108588},
}

@article{ring_flow-based_2017,
	title = {Flow-based benchmark data sets for intrusion detection},
	issn = {20488610},
	abstract = {Anomaly based intrusion detection systems suffer from a lack of appropriate evaluation data sets. Often, existing data sets may not be published due to privacy concerns or do not reflect actual and current attack scenarios. In order to overcome these problems, we identify characteristics of good data sets and develop an appropriate concept for the generation of labelled flow-based data sets that satisfy these criteria. The concept is implemented based on OpenStack, thus demonstrating the suitability of virtual environments. Virtual environments offer advantages compared to static data sets by easily creating up-to-date data sets with recent trends in user behaviour and new attack scenarios. In particular, we emulate a small business environment which includes several clients and typical servers. Network traffic is generated by scripts which emulate typical user activities like surfing the web, writing emails, or printing documents on the clients. These scripts follow some guidelines to ensure that the user behaviour is as realistic as possible, also with respect to working hours and lunch breaks. The generated network traffic is recorded in unidirectional NetFlow format. For generating malicious traffic, attacks like Denial of Service, Brute Force, and Port Scans are executed within the network. Since origins, targets, and timestamps of executed attacks are known, labelling of recorded NetFlow data is easily possible. For inclusion of actual traffic, which has its origin outside the OpenStack environment, an external server with two services is deployed. This server has a public IP address and is exposed to real and up-to-date attacks from the internet. We captured approximately 32 million flows over a period of four weeks and categorized them into five classes. Further, the chronological sequence of the flows is analysed and the distribution of normal and malicious traffic is discussed in detail. The main contribution of this paper is the demonstration of a novel approach to use OpenStack as a basis for generating realistic data sets that can be used for the evaluation of network intrusion detection systems.},
	journal = {Proceedings of the 16th European Conference on Cyber Warfare and Security (ECCWS)},
	author = {Ring, Markus and Wunderlich, Sarah and Grüdl, Dominik and Landes, Dieter and Hotho, Andreas},
	year = {2017},
	note = {Publisher: ACPI
ISBN: 9781911218432},
	keywords = {⛔ No DOI found},
	pages = {361--369},
}

@article{reddi_adaptive_2021,
	title = {Adaptive {Federated} {Optimization}},
	url = {http://arxiv.org/abs/2003.00295},
	abstract = {Federated learning is a distributed machine learning paradigm in which a large number of clients coordinate with a central server to learn a model without sharing their own training data. Standard federated optimization methods such as Federated Averaging (FEDAVG) are often difﬁcult to tune and exhibit unfavorable convergence behavior. In non-federated settings, adaptive optimization methods have had notable success in combating such issues. In this work, we propose federated versions of adaptive optimizers, including ADAGRAD, ADAM, and YOGI, and analyze their convergence in the presence of heterogeneous data for general nonconvex settings. Our results highlight the interplay between client heterogeneity and communication efﬁciency. We also perform extensive experiments on these methods and show that the use of adaptive optimizers can signiﬁcantly improve the performance of federated learning.},
	language = {en},
	urldate = {2022-01-28},
	journal = {arXiv:2003.00295 [cs, math, stat]},
	author = {Reddi, Sashank and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Konečný, Jakub and Kumar, Sanjiv and McMahan, H. Brendan},
	month = sep,
	year = {2021},
	note = {arXiv: 2003.00295},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning, ⛔ No DOI found},
}

@article{ren_federated_2019,
	title = {Federated {Learning}-{Based} {Computation} {Offloading} {Optimization} in {Edge} {Computing}-{Supported} {Internet} of {Things}},
	volume = {7},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8728285/},
	doi = {10.1109/ACCESS.2019.2919736},
	abstract = {Recently, smart cities, smart homes, and smart medical systems have challenged the functionality and connectivity of the large-scale Internet of Things (IoT) devices. Thus, with the idea of offloading intensive computing tasks from them to edge nodes (ENs), edge computing emerged to supplement these limited devices. Benefit from this advantage, IoT devices can save more energy and still maintain the quality of the services they should provide. However, computational offload decisions involve federation and complex resource management and should be determined in the real-time face to dynamic workloads and radio environments. Therefore, in this work, we use multiple deep reinforcement learning (DRL) agents deployed on multiple edge nodes to indicate the decisions of the IoT devices. On the other hand, with the aim of making DRL-based decisions feasible and further reducing the transmission costs between the IoT devices and edge nodes, federated learning (FL) is used to train DRL agents in a distributed fashion. The experimental results demonstrate the effectiveness of the decision scheme and federated learning in the dynamic IoT system.},
	journal = {IEEE Access},
	author = {Ren, Jianji and Wang, Haichao and Hou, Tingting and Zheng, Shuai and Tang, Chaosheng},
	year = {2019},
	pages = {69194--69201},
}

@article{rauf_taxonomy_2018,
	title = {A {Taxonomy} of {Bio}-{Inspired} {Cyber} {Security} {Approaches}: {Existing} {Techniques} and {Future} {Directions}},
	volume = {43},
	issn = {21914281},
	url = {https://doi.org/10.1007/s13369-018-3117-2},
	doi = {10.1007/s13369-018-3117-2},
	abstract = {After decades of deploying cyber security systems, it is a well-known fact that the existing cyber infrastructure has numerous inherent limitations that make the maintenance of the current network security devices un-scalable and provide the adversary with asymmetric advantages. These limitations include: (1) difficulty in obtaining the global knowledge due to the lack of mutual interactions among network devices, (2) no sense of self-awareness, (3) absence of self-correcting/organizing mechanisms; for instance, error-prone and time-consuming manual configuration, which is not effective in real-time attack mitigation, (4) disability to diagnose mis-configuration and conflict resolution due to multiparty management of security infrastructure. Biological systems, on the other hand, have intrinsic appealing characteristics as a result of billions of years of evolution, such as adaptivity to varying environmental conditions, inherent resiliency to failures and damages, successful and collaborative operation on the basis of a limited set of rules with global intelligence (which is larger than superposition of individuals). The aim of this survey is to review the existing bio-inspired approaches that have been used toward addressing the aforementioned issues and evaluate them accordingly. We also aim to provide information about the intrinsic potential of existing bio-inspired techniques which has not been explored yet, for improving cyber security.},
	number = {12},
	journal = {Arabian Journal for Science and Engineering},
	author = {Rauf, Usman},
	year = {2018},
	note = {Publisher: Springer Berlin Heidelberg},
	pages = {6693--6708},
}

@article{riahi_game_2019,
	title = {Game theory for resource sharing in large distributed systems},
	volume = {9},
	issn = {2088-8708},
	url = {http://ijece.iaescore.com/index.php/IJECE/article/view/10176},
	doi = {10.11591/ijece.v9i2.pp1249-1257},
	abstract = {In game theory, cooperative and non-cooperative approaches are distinguished in terms of two elements. The first refers to the player's ability to engage: in a non-cooperative context, they are entirely free to make decisions when they make their choices; However, in a cooperative context, they have the opportunity to engage contractually the strategies that should be adopted during the game, that during a phase of discussions held before the game and during combinations which may be formed.In this context, the problem is not so much to predict the outcome of the game between players to leave the benefit of cooperation. To achieve this, and this is the second major difference with the non-cooperative approach, it adopts an axiomatic approach (or normative) by which we set upstream properties a priori reasonable (or desirable) on the outcome of the game. The purpose of this paper is to present briefly the main types of non-cooperative games and the tools that allow them to be analyzed in a complete information context where all aspects of the game are well known to decision makers.{\textless}/span{\textgreater}},
	number = {2},
	journal = {International Journal of Electrical and Computer Engineering (IJECE)},
	author = {Riahi, Sara and Riahi, Azzeddine},
	month = apr,
	year = {2019},
	pages = {1249},
}

@article{ring_creation_2017,
	title = {Creation of {Flow}-{Based} {Data} {Sets} for {Intrusion} {Detection}},
	volume = {16},
	issn = {14453312, 14453347},
	url = {https://www.jstor.org/stable/26504117},
	abstract = {Publicly available labelled data sets are necessary for evaluating anomaly-based Intrusion Detection Systems (IDSs). However, existing data sets are often not up-to-date or not yet published because of privacy concerns. This paper identifies requirements for good data sets and proposes an approach for their generation. The key idea is to use a test environment and emulate realistic user behaviour with parameterised scripts on the clients. Comprehensive logging mechanisms provide additional information which may be used for a better understanding of the inner dynamics of an IDS. Finally, the proposed approach is used to generate the flow-based CIDDS-002 data set.},
	number = {4},
	journal = {Journal of Information Warfare},
	author = {Ring, Markus and Wunderlich, Sarah and Grüdl, Dominik and Landes, Dieter and Hotho, Andreas},
	year = {2017},
	note = {Publisher: Peregrine Technical Solutions},
	keywords = {⛔ No DOI found},
	pages = {41--54},
}

@article{ramirez_poisoning_2016,
	title = {Poisoning {Attacks} and {Defenses} on {Artiﬁcial} {Intelligence}: {A} {Survey}},
	volume = {4},
	abstract = {Machine learning models have been widely adopted in several ﬁelds. However, most recent studies have shown several vulnerabilities from attacks with a potential to jeopardize the integrity of the model, presenting a new window of research opportunity in terms of cyber-security. This survey is conducted with a main intention of highlighting the most relevant information related to security vulnerabilities in the context of machine learning (ML) classiﬁers; more speciﬁcally, directed towards training procedures against data poisoning attacks, representing a type of attack that consists of tampering the data samples fed to the model during the training phase, leading to a degradation in the model’s overall accuracy during the inference phase. This work compiles the most relevant insights and ﬁndings found in the latest existing literatures addressing this type of attacks. Moreover, this paper also covers several defense techniques that promise feasible detection and mitigation mechanisms, capable of conferring a certain level of robustness to a target model against an attacker. A thorough assessment is performed on the reviewed works, comparing the effects of data poisoning on a wide range of ML models in real-world conditions, performing quantitative and qualitative analyses. This paper analyzes the main characteristics for each approach including performance success metrics, required hyperparameters, and deployment complexity. Moreover, this paper emphasizes the underlying assumptions and limitations considered by both attackers and defenders along with their intrinsic properties such as: availability, reliability, privacy, accountability, interpretability, etc. Finally, this paper concludes by making references of some of main existing research trends that provide pathways towards future research directions in the ﬁeld of cyber-security.},
	language = {en},
	author = {Ramirez, Miguel A and Kim, Song-Kyoo and Hamadi, Hussam Al and Damiani, Ernesto and Kim, Tae-Yeon and Cho, Chung-Suk and Yeun, Chan Yeob},
	year = {2016},
	pages = {16},
}

@article{rahman_blockchain_2022,
	title = {Blockchain based {AI}-enabled {Industry} 4.0 {CPS} {Protection} against {Advanced} {Persistent} {Threat}},
	issn = {2327-4662, 2372-2541},
	url = {https://ieeexplore.ieee.org/document/9695986/},
	doi = {10/gpch65},
	abstract = {Industry 4.0 is all about doing things in a concurrent, secure, and fine-grained manner. IoT edge-sensors and their associated data play a predominant role in today’s industry ecosystem. Breaching data or forging source devices after injecting advanced persistent threats (APT) damages the industry owners’ money and loss of operators’ lives. The existing challenges include APT injection attacks targeting vulnerable edge devices, insecure data transportation, trust inconsistencies among stakeholders, incompliant data storing mechanisms, etc. Edgeservers often suffer because of their lightweight computation capacity to stamp out unauthorized data or instructions, which in essence, makes them exposed to attackers. When attackers target edge servers while transporting data using traditional PKI-rendered trusts, consortium blockchain (CBC) offers proven techniques to transfer and maintain those sensitive data securely. With the recent improvement of edge machine learning, edge devices can filter malicious data at their end which largely motivates us to institute a Blockchain and AI aligned APT detection system. The unique contributions of the paper include efficient APT detection at the edge and transparent recording of the detection history in an immutable blockchain ledger. In line with that, the certificateless data transfer mechanism boost trust among collaborators and ensure an economical and sustainable mechanism after eliminating existing certificate authority. Finally, the edge-compliant storage technique facilitates efficient predictive maintenance. The respective experimental outcomes reveal that the proposed technique outperforms the other competing systems and models.},
	language = {en},
	urldate = {2022-02-04},
	journal = {IEEE Internet of Things Journal},
	author = {Rahman, Ziaur and Yi, Xun and Khalil, Ibrahim},
	year = {2022},
	pages = {1--1},
}

@article{radulescu_multi-objective_2019,
	title = {Multi-{Objective} {Multi}-{Agent} {Decision} {Making}: {A} {Utility}-based {Analysis} and {Survey}},
	volume = {34},
	issn = {1387-2532},
	url = {http://link.springer.com/10.1007/s10458-019-09433-x},
	doi = {10.1007/s10458-019-09433-x},
	abstract = {The majority of multi-agent system (MAS) implementations aim to optimise agents' policies with respect to a single objective, despite the fact that many real-world problem domains are inherently multi-objective in nature. Multi-objective multi-agent systems (MOMAS) explicitly consider the possible trade-offs between conflicting objective functions. We argue that, in MOMAS, such compromises should be analysed on the basis of the utility that these compromises have for the users of a system. As is standard in multi-objective optimisation, we model the user utility using utility functions that map value or return vectors to scalar values. This approach naturally leads to two different optimisation criteria: expected scalarised returns (ESR) and scalarised expected returns (SER). We develop a new taxonomy which classifies multi-objective multi-agent decision making settings, on the basis of the reward structures, and which and how utility functions are applied. This allows us to offer a structured view of the field, to clearly delineate the current state-of-the-art in multi-objective multi-agent decision making approaches and to identify promising directions for future research. Starting from the execution phase, in which the selected policies are applied and the utility for the users is attained, we analyse which solution concepts apply to the different settings in our taxonomy. Furthermore, we define and discuss these solution concepts under both ESR and SER optimisation criteria. We conclude with a summary of our main findings and a discussion of many promising future research directions in multi-objective multi-agent systems.},
	number = {1},
	journal = {Autonomous Agents and Multi-Agent Systems},
	author = {Rădulescu, Roxana and Mannion, Patrick and Roijers, Diederik M. and Nowé, Ann},
	month = sep,
	year = {2019},
	note = {ISBN: 1045801909},
	pages = {10},
}

@article{pala_information_2019,
	title = {Information {Sharing} in {Cybersecurity}: {A} {Review}},
	volume = {16},
	issn = {1545-8490},
	url = {http://pubsonline.informs.org/doi/10.1287/deca.2018.0387},
	doi = {10.1287/deca.2018.0387},
	abstract = {In this survey, we review the cybersecurity information-sharing literature, categorizing the identified papers based on their main focus and methodological approaches implemented to the cybersecurity information-sharing problem. We constitute our research framework on the major considerations of firms, governments, citizens, and adversaries. This includes actors involved, types of information to be shared, current legal baseline, information-sharing organizations/policies/architectures, benefits of sharing, and concerns/costs/barriers of sharing. We observe that both qualitative and quantitative approaches are implemented in the literature. In general, quantitative approaches have been dedicated to discuss the challenges and barriers of public/private collaboration in information sharing, such as privacy and liability, and to propose secure and effective sharing mechanisms. On the other hand, quantitative approaches have been more interested in developing models that balance cybersecurity investment and information sharing as well as provide effective incentive mechanisms. This review summarizes the academic efforts in cybersecurity information sharing by analyzing 82 identified papers with their methodological approaches. The papers using game-theoretical models are dominant in the literature as we spend more time summarizing those efforts. We conclude the review by providing potential research gaps and future research directions.},
	number = {3},
	journal = {Decision Analysis},
	author = {Pala, Ali and Zhuang, Jun},
	month = sep,
	year = {2019},
	pages = {172--196},
}

@article{pei_personalized_2022,
	title = {Personalized federated learning framework for network traffic anomaly detection},
	volume = {209},
	issn = {13891286},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1389128622001001},
	doi = {10.1016/j.comnet.2022.108906},
	abstract = {With the widespread use of real-time sensors in various fields, such as IoT systems, it is important to improve the performance of most network traffic anomaly detection methods, which have low accuracy and high false alarm rates. However, there are two key challenges to address. In this study, we proposed a personalized federated anomaly detection framework for network traffic anomaly detection, in which data are aggregated under the premise of privacy protection and relatively personalized models are constructed by fine-tuning. Subsequently, a network traffic anomaly detection method based on the self-coding of long- and short-term memory networks was proposed. Real network traffic was tested to analyze the effects of the model structure and external noise on the detection performance, and the experimental results verified the correctness of the proposed method. Compared with other data-reconstruction-based detection methods, the proposed method has higher detection accuracy and better detection performance.},
	language = {en},
	urldate = {2022-04-01},
	journal = {Computer Networks},
	author = {Pei, Jiaming and Zhong, Kaiyang and Jan, Mian Ahmad and Li, Jinhai},
	month = may,
	year = {2022},
	pages = {108906},
}

@article{phan_deepair_2022,
	title = {{DeepAir}: {Deep} {Reinforcement} {Learning} for {Adaptive} {Intrusion} {Response} in {Software}-{Defined} {Networks}},
	issn = {1932-4537, 2373-7379},
	shorttitle = {{DeepAir}},
	url = {https://ieeexplore.ieee.org/document/9732448/},
	doi = {10.1109/TNSM.2022.3158468},
	abstract = {In this paper, we propose an adaptive intrusion response solution based on deep reinforcement learning, namely DeepAir, to effectively defend against cyber-attacks in SoftwareDeﬁned Networks (SDN). Speciﬁcally, we ﬁrst study an intrusion response system (IRS) that operates at the SDN control plane. Next, we propose a dynamic intrusion response solution to maximize the attack defense performance while minimizing the negative impact on benign trafﬁc forwarding and the policy deployment cost in the SDN data plane. Then, we model the intrusion response system based on a Markov decision process (MDP) approach and formulate the related optimization problem. Afterward, we develop a Double Deep Q-Network based intrusion response control algorithm to assist the intrusion response system to quickly obtain the optimal intrusion response policy. In our case study, we consider denial-of-service (DoS) attacks—the performance evaluation results demonstrate that DeepAir can effectively prevent malicious packets from arriving at the victim in all considered DoS attack scenarios, i.e., approximately 85\% of attack packets are dropped. Moreover, by applying the optimal intrusion response policy, DeepAir can signiﬁcantly reduce the ratio of Quality-of-Service violated trafﬁc ﬂows compared to a Qlearning based approach (by 70\%), and to two existing solutions, i.e., GATE (by 75\%) and GTAC-IRS (by 80\%), respectively.},
	language = {en},
	urldate = {2022-03-23},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Phan, Trung V. and Bauschert, Thomas},
	year = {2022},
	keywords = {\_read},
	pages = {1--1},
}

@article{pahl_mixed-interaction_2020,
	title = {A {Mixed}-{Interaction} {Critical} {Infrastructure} {Honeypot}},
	abstract = {Operational Technology (OT) plays an essential role in modern societies. It is pivotal for applications such as water or power supply, healthcare, or transportation. At the same time, OT is often connected to the Internet for enabling remote-control and collaboration. Its societal impact makes OT an attractive attack target. Its connectivity to the Internet significantly increases the attack probability. For protecting against attacks, it is important to identify and study them. Honeypots enable such studies. However, realistic honeypots are difficult and expensive to setup. They are also inflexible as their setting is typically static. In collaboration with Airbus Cybersecurity, the chaire Cy- ber CNI currently develops a mixed-interaction honeypot for critical infrastructures. The targeted setup combines physical and virtualized elements that can flexibly be reconfigured. This allows running diverse settings distributed in time or space. The virtualized part allows scaling the experiments. The goal of the Cyber CNI honeypot is enabling the closer study of Information and Operational Technology (IT \& OT).},
	journal = {European Cyber Week (ECW), C\&ESAR Conferences},
	author = {Pahl, Marc-Oliver and Kabil, Alexandre and Bourget, Edwin and Gay, Matthieu and Brun, Paul-emmanuel},
	year = {2020},
	keywords = {⛔ No DOI found},
}

@article{onyema_design_2022,
	title = {Design of {Intrusion} {Detection} {System} based on {Cyborg} intelligence for security of {Cloud} {Network} {Traffic} of {Smart} {Cities}},
	volume = {11},
	copyright = {2022 The Author(s)},
	issn = {2192-113X},
	url = {https://journalofcloudcomputing.springeropen.com/articles/10.1186/s13677-022-00305-6},
	doi = {10.1186/s13677-022-00305-6},
	abstract = {The Internet of things (IoT) is an important technology that is highly beneficial in establishing smart items, connections and cities. However, there are worries regarding security and privacy vulnerabilities in IoT in which some emerge from numerous sources, including cyberattacks, unsecured networks, data, connections or communication. This paper provides an ensemble intrusion strategy based on Cyborg Intelligence (machine learning and biological intelligence) framework to boost security of IoT enabled networks utilized for network traffic of smart cities. To do this, multiple algorithms such Random Forest, Bayesian network (BN), C5.0, CART and Artificial Neural Network were investigated to determine their usefulness in identifying threats and attacks-botnets in IoT networks based on cyborg intelligence using the KDDcup99 dataset. The results reveal that the AdaBoost ensemble learning based on Cyborg Intelligence Intrusion Detection framework facilitates dissimilar network characteristics with the capacity to swiftly identify different botnet assaults efficiently. The suggested framework has obtained good accuracy, detection rate and a decreased false positive rate in comparison to other standard methodologies. The conclusion of this study would be a valuable complement to the efforts toward protecting IoT-powered networks and the accomplishment of safer smart cities.},
	language = {en},
	number = {1},
	urldate = {2022-08-18},
	journal = {Journal of Cloud Computing},
	author = {Onyema, Edeh Michael and Dalal, Surjeet and Romero, Carlos Andrés Tavera and Seth, Bijeta and Young, Praise and Wajid, Mohd Anas},
	month = dec,
	year = {2022},
	note = {Number: 1
Publisher: SpringerOpen},
	pages = {1--20},
}

@article{oseni_explainable_2022,
	title = {An {Explainable} {Deep} {Learning} {Framework} for {Resilient} {Intrusion} {Detection} in {IoT}-{Enabled} {Transportation} {Networks}},
	issn = {1558-0016},
	doi = {10.1109/TITS.2022.3188671},
	abstract = {The security of safety-critical IoT systems, such as the Internet of Vehicles (IoV), has a great interest, focusing on using Intrusion Detection Systems (IDS) to recognise cyber-attacks in IoT networks. Deep learning methods are commonly used for the anomaly detection engines of many IDSs because of their ability to learn from heterogeneous data. However, while this type of machine learning model produces high false-positive rates and the reasons behind its predictions are not easily understood, even by experts. The ability to understand or comprehend the reasoning behind the decision of an IDS to block a particular packet helps cybersecurity experts validate the system’s effectiveness and develop more cyber-resilient systems. This paper proposes an explainable deep learning-based intrusion detection framework that helps improve the transparency and resiliency of DL-based IDS in IoT networks. The framework employs a SHapley Additive exPlanations (SHAP) mechanism to interpret decisions made by deep learning-based IDS to experts who rely on the decisions to ensure IoT networks’ security and design more cyber-resilient systems. The proposed framework was validated using the ToN\_IoT dataset and compared with other compelling techniques. The experimental results have revealed the high performance of the proposed framework with a 99.15\% accuracy and a 98.83\% F1 score, illustrating its capability to protect IoV networks against sophisticated cyber-attacks.},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Oseni, Ayodeji and Moustafa, Nour and Creech, Gideon and Sohrabi, Nasrin and Strelzoff, Andrew and Tari, Zahir and Linkov, Igor},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Intelligent Transportation Systems},
	keywords = {Computer architecture, Deep learning, Explainable AI, Internet of Things, Internet of Vehicles (IoV), Intrusion detection, IoT, Protocols, Safety, Security, deep learning, network intrusion detection, security},
	pages = {1--15},
}

@article{nguyen_realguard_2022,
	title = {Realguard: {A} {Lightweight} {Network} {Intrusion} {Detection} {System} for {IoT} {Gateways}},
	volume = {22},
	issn = {1424-8220},
	shorttitle = {Realguard},
	url = {https://www.mdpi.com/1424-8220/22/2/432},
	doi = {10/gpbg37},
	abstract = {Cyber security has become increasingly challenging due to the proliferation of the Internet of things (IoT), where a massive number of tiny, smart devices push trillion bytes of data to the Internet. However, these devices possess various security ﬂaws resulting from the lack of defense mechanisms and hardware security support, therefore making them vulnerable to cyber attacks. In addition, IoT gateways provide very limited security features to detect such threats, especially the absence of intrusion detection methods powered by deep learning. Indeed, deep learning models require high computational power that exceeds the capacity of these gateways. In this paper, we introduce Realguard, an DNN-based network intrusion detection system (NIDS) directly operated on local gateways to protect IoT devices within the network. The superiority of our proposal is that it can accurately detect multiple cyber attacks in real time with a small computational footprint. This is achieved by a lightweight feature extraction mechanism and an efﬁcient attack detection model powered by deep neural networks. Our evaluations on practical datasets indicate that Realguard could detect ten types of attacks (e.g., port scan, Botnet, and FTP-Patator) in real time with an average accuracy of 99.57\%, whereas the best of our competitors is 98.85\%. Furthermore, our proposal effectively operates on resource-constraint gateways (Raspberry PI) at a high packet processing rate reported about 10.600 packets per second.},
	language = {en},
	number = {2},
	urldate = {2022-01-31},
	journal = {Sensors},
	author = {Nguyen, Xuan-Ha and Nguyen, Xuan-Duong and Huynh, Hoang-Hai and Le, Kim-Hung},
	month = jan,
	year = {2022},
	pages = {432},
}

@article{nguyen_flguard_2021,
	title = {{FLGUARD}: {Secure} and {Private} {Federated} {Learning}},
	shorttitle = {{FLGUARD}},
	url = {http://arxiv.org/abs/2101.02281},
	abstract = {Recently, a number of backdoor attacks against Federated Learning (FL) have been proposed. In such attacks, an adversary injects poisoned model updates into the federated model aggregation process with the goal of manipulating the aggregated model to provide false predictions on speciﬁc adversary-chosen inputs. A number of defenses have been proposed but none of them can effectively protect the FL process also against so-called multi-backdoor attacks in which multiple different backdoors are injected by the adversary simultaneously without severely impacting the benign performance of the aggregated model. To overcome this challenge, we introduce FLGUARD, a poisoning defense framework that is able to defend FL against state-ofthe-art backdoor attacks while simultaneously maintaining the benign performance of the aggregated model. Moreover, FL is also vulnerable to inference attacks, in which a malicious aggregator can infer information about clients’ training data from their model updates. To thwart such attacks, we augment FLGUARD with state-of-the-art secure computation techniques that securely evaluate the FLGUARD algorithm. We provide formal argumentation for the effectiveness of our FLGUARD and extensively evaluate it against known backdoor attacks on several datasets and applications (including image classiﬁcation, word prediction, and IoT intrusion detection) demonstrating that FLGUARD can entirely remove backdoors with a negligible effect on accuracy. We also show that private FLGUARD achieves practical runtimes.},
	language = {en},
	urldate = {2021-05-18},
	journal = {arXiv:2101.02281 [cs]},
	author = {Nguyen, Thien Duc and Rieger, Phillip and Yalame, Hossein and Möllering, Helen and Fereidooni, Hossein and Marchal, Samuel and Miettinen, Markus and Mirhoseini, Azalia and Sadeghi, Ahmad-Reza and Schneider, Thomas and Zeitouni, Shaza},
	month = jan,
	year = {2021},
	note = {arXiv: 2101.02281},
	keywords = {\_processed, ⛔ No DOI found},
}

@article{pa_iotpot_2016,
	title = {{IoTPOT}: {A} {Novel} {Honeypot} for {Revealing} {Current} {IoT} {Threats}},
	volume = {24},
	issn = {1882-6652},
	url = {https://www.jstage.jst.go.jp/article/ipsjjip/24/3/24_522/_article},
	doi = {10.2197/ipsjjip.24.522},
	abstract = {We analyze the increasing threats against IoT devices. We show that Telnet-based attacks that target IoT devices have rocketed since 2014. Based on this observation, we propose an IoT honeypot and sandbox, which attracts and analyzes Telnet-based attacks against various IoT devices running on different CPU architectures such as ARM, MIPS, and PPC. By analyzing the observation results of our honeypot and captured malware samples, we show that there are currently at least 5 distinct DDoS malware families targeting Telnet-enabled IoT devices and one of the families has quickly evolved to target more devices with as many as 9 different CPU architectures.},
	number = {3},
	journal = {Journal of Information Processing},
	author = {Pa, Yin Minn Pa and Suzuki, Shogo and Yoshioka, Katsunari and Matsumoto, Tsutomu and Kasama, Takahiro and Rossow, Christian},
	year = {2016},
	pages = {522--533},
}

@article{naeem_cache_2022,
	title = {Cache in fog computing design, concepts, contributions, and security issues in machine learning prospective},
	issn = {2352-8648},
	url = {https://www.sciencedirect.com/science/article/pii/S2352864822001651},
	doi = {10.1016/j.dcan.2022.08.004},
	abstract = {The massive growth of diversified smart devices and continuous data generation poses a challenge to communication architectures. To deal with this problem, communication networks consider fog computing as one of promising technologies that can improve overall communication performance. It brings on-demand services proximate to the end devices and delivers the requested data in a short time. Fog computing faces several issues such as latency, bandwidth, and link utilization due to limited resources and the high processing demands of end devices. To this end, fog caching plays an imperative role in addressing data dissemination issues. This study provides a comprehensive discussion of fog computing, Internet of Things (IoTs) and the critical issues related to data security and dissemination in fog computing. Moreover, we determine the fog-based caching schemes and contribute to deal with the existing issues of fog computing. Besides, this paper presents a number of caching schemes with their contributions, benefits, and challenges to overcome the problems and limitations of fog computing. We also identify machine learning-based approaches for cache security and management in fog computing, as well as several prospective future research directions in caching, fog computing, and machine learning.},
	language = {en},
	urldate = {2022-08-16},
	journal = {Digital Communications and Networks},
	author = {Naeem, Muhammad Ali and Zikria, Yousaf Bin and Ali, Rashid and Tariq, Usman and Meng, Yahui and Bashir, Ali Kashif},
	month = aug,
	year = {2022},
	keywords = {Caching, Cloud computing, Fog computing, Internet of things, Latency},
}

@article{naz_ensemble_2022,
	title = {Ensemble learning-based {IDS} for sensors telemetry data in {IoT} networks},
	volume = {19},
	issn = {1551-0018},
	url = {http://www.aimspress.com/article/doi/10.3934/mbe.2022493},
	doi = {10.3934/mbe.2022493},
	abstract = {The Internet of Things (IoT) is a paradigm that connects a range of physical smart devices to provide ubiquitous services to individuals and automate their daily tasks. IoT devices collect data from the surrounding environment and communicate with other devices using diﬀerent communication protocols such as CoAP, MQTT, DDS, etc. Study shows that these protocols are vulnerable to attack and prove a signiﬁcant threat to IoT telemetry data. Within a network, IoT devices are interdependent, and the behaviour of one device depends on the data coming from another device. An intruder exploits vulnerabilities of a device’s interdependent feature and can alter the telemetry data to indirectly control the behaviour of other dependent devices in a network. Therefore, securing IoT devices have become a signiﬁcant concern in IoT networks. The research community often proposes intrusion Detection Systems (IDS) using diﬀerent techniques. One of the most adopted techniques is machine learning (ML) based intrusion detection. This study suggests a stacking-based ensemble model makes IoT devices more intelligent for detecting unusual behaviour in IoT networks. The TON-IoT (2020) dataset is used to assess the eﬀectiveness of the proposed model. The proposed model achieves signiﬁcant improvements in accuracy and other evaluation measures in binary and multi-class classiﬁcation scenarios for most of the sensors compared to traditional ML algorithms and other ensemble techniques.},
	language = {en},
	number = {10},
	urldate = {2022-08-11},
	journal = {Mathematical Biosciences and Engineering},
	author = {Naz, Naila and Khan, Muazzam A and Alsuhibany, Suliman A. and Diyan, Muhammad and Tan, Zhiyuan and Khan, Muhammad Almas and Ahmad, Jawad},
	year = {2022},
	pages = {10550--10580},
}

@article{nguyen_fast-convergent_2021,
	title = {Fast-{Convergent} {Federated} {Learning}},
	volume = {39},
	issn = {0733-8716, 1558-0008},
	url = {https://ieeexplore.ieee.org/document/9252927/},
	doi = {10.1109/JSAC.2020.3036952},
	abstract = {Federated learning has emerged recently as a promising solution for distributing machine learning tasks through modern networks of mobile devices. Recent studies have obtained lower bounds on the expected decrease in model loss that is achieved through each round of federated learning. However, convergence generally requires a large number of communication rounds, which induces delay in model training and is costly in terms of network resources. In this paper, we propose a fast-convergent federated learning algorithm, called FOLB, which performs intelligent sampling of devices in each round of model training to optimize the expected convergence speed. We ﬁrst theoretically characterize a lower bound on improvement that can be obtained in each round if devices are selected according to the expected improvement their local models will provide to the current global model. Then, we show that FOLB obtains this bound through uniform sampling by weighting device updates according to their gradient information. FOLB is able to handle both communication and computation heterogeneity of devices by adapting the aggregations according to estimates of device’s capabilities of contributing to the updates. We evaluate FOLB in comparison with existing federated learning algorithms and experimentally show its improvement in trained model accuracy, convergence speed, and/or model stability across various machine learning tasks and datasets.},
	language = {en},
	number = {1},
	urldate = {2022-05-25},
	journal = {IEEE Journal on Selected Areas in Communications},
	author = {Nguyen, Hung T. and Sehwag, Vikash and Hosseinalipour, Seyyedali and Brinton, Christopher G. and Chiang, Mung and Vincent Poor, H.},
	month = jan,
	year = {2021},
	pages = {201--218},
}

@article{navas_mtd_2020,
	title = {{MTD}, {Where} {Art} {Thou}? {A} {Systematic} {Review} of {Moving} {Target} {Defense} {Techniques} for {IoT}},
	volume = {V},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/document/9270287/},
	doi = {10.1109/JIOT.2020.3040358},
	abstract = {Context: Internet of Things (IoT) systems are increasingly deployed in the real world, but their security lags behind the state of the art of non-IoT systems. Moving Target Defense (MTD) is a cyberdefense paradigm, successfully implemented in conventional systems, that could improve IoT security. Objective: Identify and synthesize existing MTD techniques for IoT and validate the feasibility of MTD as a cybersecurity paradigm suitable for IoT systems. Method: We use a systematic literature review method to search and analyze existing MTD for IoT techniques up to July 2020. We evaluated the existing techniques in terms of security foundations and real-world deployability using the evidence they provide. We define and use entropy-related metrics to categorize them. This is the first MTD survey to use Shannon\&\#x2019;s entropy metric empirically. Results: Thirty-two distinct MTD for IoT techniques exist: 54\% are Network-layer-based, 50\% present strong evidence about their real-world deployment, and 64\% have weak security foundations. Conclusion: MTD for IoT is a feasible cyberdefense approach. A variety of proposals exist, with evidence about their implementation and evaluation. Nevertheless, the MTD for IoT state of the art is still immature: the security foundations of most existing proposals are weak. Novel techniques should prioritize providing convincing security foundations and real-world deployment evidence.},
	number = {c},
	journal = {IEEE Internet of Things Journal},
	author = {Navas, Renzo E. and Cuppens, Frederic and Cuppens, Nora Boulahia and Toutain, Laurent and Papadopoulos, Georgios Z.},
	year = {2020},
	pages = {1--1},
}

@article{neshenko_demystifying_2019,
	title = {Demystifying {IoT} {Security}: {An} {Exhaustive} {Survey} on {IoT} {Vulnerabilities} and a {First} {Empirical} {Look} on {Internet}-{Scale} {IoT} {Exploitations}},
	volume = {21},
	issn = {1553-877X},
	url = {https://ieeexplore.ieee.org/document/8688434/},
	doi = {10.1109/COMST.2019.2910750},
	abstract = {The security issue impacting the Internet-of-Things (IoT) paradigm has recently attracted significant attention from the research community. To this end, several surveys were put forward addressing various IoT-centric topics, including intrusion detection systems, threat modeling, and emerging technologies. In contrast, in this paper, we exclusively focus on the ever-evolving IoT vulnerabilities. In this context, we initially provide a comprehensive classification of state-of-the-art surveys, which address various dimensions of the IoT paradigm. This aims at facilitating IoT research endeavors by amalgamating, comparing, and contrasting dispersed research contributions. Subsequently, we provide a unique taxonomy, which sheds the light on IoT vulnerabilities, their attack vectors, impacts on numerous security objectives, attacks which exploit such vulnerabilities, corresponding remediation methodologies and currently offered operational cyber security capabilities to infer and monitor such weaknesses. This aims at providing the reader with a multidimensional research perspective related to IoT vulnerabilities, including their technical details and consequences, which is postulated to be leveraged for remediation objectives. Additionally, motivated by the lack of empirical (and malicious) data related to the IoT paradigm, this paper also presents a first look on Internet-scale IoT exploitations by drawing upon more than 1.2 GB of macroscopic, passive measurements' data. This aims at practically highlighting the severity of the IoT problem, while providing operational situational awareness capabilities, which undoubtedly would aid in the mitigation task, at large. Insightful findings, inferences and outcomes in addition to open challenges and research problems are also disclosed in this paper, which we hope would pave the way for future research endeavors addressing theoretical and empirical aspects related to the imperative topic of IoT security.},
	number = {3},
	journal = {IEEE Communications Surveys \& Tutorials},
	author = {Neshenko, Nataliia and Bou-Harb, Elias and Crichigno, Jorge and Kaddoum, Georges and Ghani, Nasir},
	year = {2019},
	note = {Publisher: IEEE},
	keywords = {+survey},
	pages = {2702--2733},
}

@article{mothukuri_survey_2021,
	title = {A survey on security and privacy of federated learning},
	volume = {115},
	issn = {0167739X},
	url = {https://doi.org/10.1016/j.future.2020.10.007},
	doi = {10.1016/j.future.2020.10.007},
	abstract = {Federated learning (FL) is a new breed of Artificial Intelligence (AI) that builds upon decentralized data and training that brings learning to the edge or directly on-device. FL is a new research area often referred to as a new dawn in AI, is in its infancy, and has not yet gained much trust in the community, mainly because of its (unknown) security and privacy implications. To advance the state of the research in this area and to realize extensive utilization of the FL approach and its mass adoption, its security and privacy concerns must be first identified, evaluated, and documented. FL is preferred in use-cases where security and privacy are the key concerns and having a clear view and understanding of risk factors enable an implementer/adopter of FL to successfully build a secure environment and gives researchers a clear vision on possible research areas. This paper aims to provide a comprehensive study concerning FL's security and privacy aspects that can help bridge the gap between the current state of federated AI and a future in which mass adoption is possible. We present an illustrative description of approaches and various implementation styles with an examination of the current challenges in FL and establish a detailed review of security and privacy concerns that need to be considered in a thorough and clear context. Findings from our study suggest that overall there are fewer privacy-specific threats associated with FL compared to security threats. The most specific security threats currently are communication bottlenecks, poisoning, and backdoor attacks while inference-based attacks are the most critical to the privacy of FL. We conclude the paper with much needed future research directions to make FL adaptable in realistic scenarios.},
	journal = {Future Generation Computer Systems},
	author = {Mothukuri, Viraaji and Parizi, Reza M. and Pouriyeh, Seyedamin and Huang, Yan and Dehghantanha, Ali and Srivastava, Gautam},
	month = feb,
	year = {2021},
	note = {Publisher: Elsevier B.V.},
	pages = {619--640},
}

@article{mun_internet_2020,
	title = {Internet {Traffic} {Classification} with {Federated} {Learning}},
	volume = {10},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/10/1/27},
	doi = {10/gmhhmv},
	abstract = {As Internet trafﬁc classiﬁcation is a typical problem for ISPs or mobile carriers, there have been a lot of studies based on statistical packet header information, deep packet inspection, or machine learning. Due to recent advances in end-to-end encryption and dynamic port policies, machine or deep learning has been an essential key to improve the accuracy of packet classiﬁcation. In addition, ISPs or mobile carriers should carefully deal with the privacy issue while collecting user packets for accounting or security. The recent development of distributed machine learning, called federated learning, collaboratively carries out machine learning jobs on the clients without uploading data to a central server. Although federated learning provides an on-device learning framework towards user privacy protection, its feasibility and performance of Internet trafﬁc classiﬁcation have not been fully examined. In this paper, we propose a federated-learning trafﬁc classiﬁcation protocol (FLIC), which can achieve an accuracy comparable to centralized deep learning for Internet application identiﬁcation without privacy leakage. FLIC can classify new applications on-the-ﬂy when a participant joins in learning with a new application, which has not been done in previous works. By implementing the prototype of FLIC clients and a server with TensorFlow, the clients gather packets, perform the on-device training job and exchange the training results with the FLIC server. In addition, we demonstrate that federated learning-based packet classiﬁcation achieves an accuracy of 88\% under non-independent and identically distributed (non-IID) trafﬁc across clients. When a new application that can be classiﬁed dynamically as a client participates in learning was added, an accuracy of 92\% was achieved.},
	language = {en},
	number = {1},
	urldate = {2022-02-08},
	journal = {Electronics},
	author = {Mun, Hyunsu and Lee, Youngseok},
	month = dec,
	year = {2020},
	pages = {27},
}

@article{mothukuri_federated_2021,
	title = {Federated {Learning}-based {Anomaly} {Detection} for {IoT} {Security} {Attacks}},
	issn = {2327-4662},
	doi = {10/gmhhmw},
	abstract = {The Internet of Things (IoT) is made up of billions of physical devices connected to the Internet via networks that perform tasks independently with less human intervention. Such brilliant automation of mundane tasks requires a considerable amount of user data in digital format, which in turn makes IoT networks an open-source of Personally Identifiable Information data for malicious attackers to steal, manipulate and perform nefarious activities. Huge interest has developed over the past years in applying machine learning (ML)-assisted approaches in the IoT security space. However, the assumption in many current works is that big training data is widely available and transferable to the main server because data is born at the edge and is generated continuously by IoT devices. This is to say that classic ML works on the legacy set of entire data located on a central server, which makes it the least preferred option for domains with privacy concerns on user data. To address this issue, we propose federated learning (FL)-based anomaly detection approach to proactively recognize intrusion in IoT networks using decentralized on-device data. Our approach uses federated training rounds on Gated Recurrent Units (GRUs) models and keeps the data intact on local IoT devices by sharing only the learned weights with the central server of the FL. Also, the approach’s ensembler part aggregates the updates from multiple sources to optimize the global ML model’s accuracy. Our experimental results demonstrate that our approach outperforms the classic/centralized machine learning (non-FL) versions in securing the privacy of user data and provides an optimal accuracy rate in attack detection.},
	journal = {IEEE Internet of Things Journal},
	author = {Mothukuri, Viraaji and Khare, Prachi and Parizi, Reza M. and Pouriyeh, Seyedamin and Dehghantanha, Ali and Srivastava, Gautam},
	year = {2021},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Anomaly detection, Computer architecture, Data models, Federated Learning, Gated Recurrent Units., Internet of Things, Logic gates, Recurrent neural networks, Security, Servers, Training, \_read},
	pages = {1--1},
}

@article{moustafa_new_2018,
	title = {A {New} {Threat} {Intelligence} {Scheme} for {Safeguarding} {Industry} 4.0 {Systems}},
	volume = {6},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8374422/},
	doi = {10.1109/ACCESS.2018.2844794},
	abstract = {Industry 4.0 represents the fourth phase of industry and manufacturing revolution, unique in that it provides Internet-connected smart systems, including automated factories, organizations, development on demand, and 'just-in-time' development. Industry 4.0 includes the integration of cyber-physical systems (CPSs), Internet of Things (IoT), cloud and fog computing paradigms for developing smart systems, smart homes, and smart cities. Given Industry 4.0 is comprised sensor fields, actuators, fog and cloud processing paradigms, and network systems, designing a secure architecture faces two major challenges: handling heterogeneous sources at scale and maintaining security over a large, disparate, data-driven system that interacts with the physical environment. This paper addresses these challenges by proposing a new threat intelligence scheme that models the dynamic interactions of industry 4.0 components including physical and network systems. The scheme consists of two components: a smart management module and a threat intelligence module. The smart data management module handles heterogeneous data sources, one of the foundational requirements for interacting with an Industry 4.0 system. This includes data to and from sensors, actuators, in addition to other forms of network traffic. The proposed threat intelligence technique is designed based on beta mixture-hidden Markov models (MHMMs) for discovering anomalous activities against both physical and network systems. The scheme is evaluated on two well-known datasets: the CPS dataset of sensors and actuators and the UNSW-NB15 dataset of network traffic. The results reveal that the proposed technique outperforms five peer mechanisms, suggesting its effectiveness as a viable deployment methodology in real-Industry 4.0 systems.},
	journal = {IEEE Access},
	author = {Moustafa, Nour and Adi, Erwin and Turnbull, Benjamin and Hu, Jiankun},
	year = {2018},
	note = {Publisher: IEEE},
	pages = {32910--32924},
}

@article{mirzaee_fids_2021,
	title = {{FIDS}: {A} {Federated} {Intrusion} {Detection} {System} for {5G} {Smart} {Metering} {Network}},
	abstract = {In a critical infrastructure such as Smart Grid (SG), providing security of the system and privacy of consumers are signiﬁcant challenges to be considered. The SG developers adopt Machine Learning (ML) algorithms within the Intrusion Detection System (IDS) to monitor trafﬁc data and network performance. This visibility safeguards the SG from possible intrusions or attacks that may trigger the system. However, it requires access to residents’ consumption information which is a severe threat to their privacy. In this paper, we present a novel method to detect abnormalities on a large scale SG while preserving the privacy of users. We design a Federated IDS (FIDS) architecture using Federated Learning (FL) in a 5G environment for the SG metering network. In this way, we design Federated Deep Neural Network (FDNN) model that protects customers’ information and provides supervisory management for the whole energy distribution network. Simulation results for a real-time dataset demonstrate the reasonable improvement of the proposed FDNN model compared with the state-of-the-art algorithms. The FDNN achieves approximately 99.5\% accuracy, 99.5\% precision/recall, and 99.5\% f1-score when comparing with classiﬁcation algorithms.},
	language = {en},
	author = {Mirzaee, Parya Haji and Shojafar, Mohammad and Pooranian, Zahra and Asef, Pedram and Cruickshank, Haitham and Tafazolli, Rahim},
	year = {2021},
	keywords = {⛔ No DOI found},
	pages = {8},
}

@article{mohanty_efficient_2020,
	title = {An efficient {Lightweight} integrated {Blockchain} ({ELIB}) model for {IoT} security and privacy},
	volume = {102},
	issn = {0167739X},
	url = {https://doi.org/10.1016/j.future.2019.09.050},
	doi = {10.1016/j.future.2019.09.050},
	abstract = {Presently, BlockChain (BC) gained significant interest because of its undeniable nature and related advantages of security and privacy, BC has the power to resolve the limitations of Internet of Things (IoT) such as data protection and privacy. At the same time, BC has high computation complexity, restricted scalability, high bandwidth overhead and latency that is unsuitable to IoT. In this paper, efficient Lightweight integrated Blockchain (ELIB) model is developed to meet necessitates of IoT. The presented model is deployed in a smart home environment as an important illustration to verify its applicability in various IoT scenarios. The resource constrained resources in a smart home takes the advantages from a centralized manager which generates shared keys to transmit data, process every incoming and outgoing requests. The presented ELIB model generates an overlay network where highly equipped resources can merges to a public BC which verifies dedicated security and privacy. A set of three optimizations are carried out in the presented ELIB model include lightweight consensus algorithm, certificateless (CC) cryptography and Distributed Throughput Management (DTM) scheme. A detailed simulation takes place under different scenarios in terms of processing time, energy usage and overhead. The ELIB attains a total of 50\% saving in processing time on comparing to baseline method with the minimum energy consumption of 0.07mJ. The obtained experimental outcome indicated that the ELIB shows maximum performance under several evaluation parameters.},
	journal = {Future Generation Computer Systems},
	author = {Mohanty, Sachi Nandan and Ramya, K.C. and Rani, S. Sheeba and Gupta, Deepak and Shankar, K. and Lakshmanaprabu, S.K. and Khanna, Ashish},
	month = jan,
	year = {2020},
	note = {Publisher: Elsevier B.V.},
	pages = {1027--1037},
}

@article{mohanta_survey_2020,
	title = {Survey on {IoT} security: {Challenges} and solution using machine learning, artificial intelligence and blockchain technology},
	volume = {11},
	issn = {25426605},
	url = {https://doi.org/10.1016/j.iot.2020.100227},
	doi = {10.1016/j.iot.2020.100227},
	abstract = {Internet of Things (IoT) is one of the most rapidly used technologies in the last decade in various applications. The smart things are connected in wireless or wired for communication, processing, computing, and monitoring different real-time scenarios. The things are heterogeneous and have low memory, less processing power. The implementation of the IoT system comes with security and privacy challenges because traditional based existing security protocols do not suitable for IoT devices. In this survey, the authors initially described an overview of the IoT technology and the area of its application. The primary security issue CIA (confidentially, Integrity, Availability) and layer-wise issues are identified. Then the authors systematically study the three primary technology Machine learning(ML), Artificial intelligence(AI), and Blockchain for addressing the security issue in IoT. In the end, an analysis of this survey, security issues solved by the ML, AI, and Blockchain with research challenges are mention.},
	journal = {Internet of Things},
	author = {Mohanta, Bhabendu Kumar and Jena, Debasish and Satapathy, Utkalika and Patnaik, Srikanta},
	month = sep,
	year = {2020},
	note = {Publisher: Elsevier B.V.},
	pages = {100227},
}

@article{meng_when_2018,
	title = {When {Intrusion} {Detection} {Meets} {Blockchain} {Technology}: {A} {Review}},
	volume = {6},
	issn = {2169-3536},
	url = {http://ieeexplore.ieee.org/document/8274922/},
	doi = {10.1109/ACCESS.2018.2799854},
	abstract = {With the purpose of identifying cyber threats and possible incidents, intrusion detection systems (IDSs) are widely deployed in various computer networks. In order to enhance the detection capability of a single IDS, collaborative intrusion detection networks (or collaborative IDSs) have been developed, which allow IDS nodes to exchange data with each other. However, data and trust management still remain two challenges for current detection architectures, which may degrade the effectiveness of such detection systems. In recent years, blockchain technology has shown its adaptability in many fields, such as supply chain management, international payment, interbanking, and so on. As blockchain can protect the integrity of data storage and ensure process transparency, it has a potential to be applied to intrusion detection domain. Motivated by this, this paper provides a review regarding the intersection of IDSs and blockchains. In particular, we introduce the background of intrusion detection and blockchain, discuss the applicability of blockchain to intrusion detection, and identify open challenges in this direction.},
	journal = {IEEE Access},
	author = {Meng, Weizhi and Tischhauser, Elmar Wolfgang and Wang, Qingju and Wang, Yu and Han, Jinguang},
	year = {2018},
	note = {Publisher: IEEE},
	pages = {10179--10188},
}

@article{ma_shieldfl_2022,
	title = {{ShieldFL}: {Mitigating} {Model} {Poisoning} {Attacks} in {Privacy}-{Preserving} {Federated} {Learning}},
	volume = {17},
	issn = {1556-6013, 1556-6021},
	shorttitle = {{ShieldFL}},
	url = {https://ieeexplore.ieee.org/document/9762272/},
	doi = {10.1109/TIFS.2022.3169918},
	abstract = {Privacy-Preserving Federated Learning (PPFL) is an emerging secure distributed learning paradigm that aggregates user-trained local gradients into a federated model through a cryptographic protocol. Unfortunately, PPFL is vulnerable to model poisoning attacks launched by a Byzantine adversary, who crafts malicious local gradients to harm the accuracy of the federated model. To resist model poisoning attacks, existing defense strategies focus on identifying suspicious local gradients over plaintexts. However, the Byzantine adversary submits encrypted poisonous gradients to circumvent existing defense strategies in PPFL, resulting in encrypted model poisoning. To address the issue, in this paper we design a privacy-preserving defense strategy using two-trapdoor homomorphic encryption (referred to as ShieldFL), which can resist encrypted model poisoning without compromising privacy in PPFL. Specially, we ﬁrst present the secure cosine similarity method aiming to measure the distance between two encrypted gradients. Then, we propose the Byzantine-tolerance aggregation using cosine similarity, which can achieve robustness for both Independently Identically Distribution (IID) and non-IID data. Extensive evaluations on three benchmark datasets (i.e., MNIST, KDDCup99, and Amazon) show that ShieldFL outperforms existing defense strategies. Especially, ShieldFL can achieve 30\%−80\% accuracy improvement to defend two state-of-the-art model poisoning attacks in both non-IID and IID settings.},
	language = {en},
	urldate = {2022-07-05},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Ma, Zhuoran and Ma, Jianfeng and Miao, Yinbin and Li, Yingjiu and Deng, Robert H.},
	year = {2022},
	pages = {1639--1654},
}

@article{martins_host-based_2022,
	title = {Host-based {IDS}: {A} review and open issues of an anomaly detection system in {IoT}},
	volume = {133},
	issn = {0167739X},
	shorttitle = {Host-based {IDS}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X22000760},
	doi = {10.1016/j.future.2022.03.001},
	abstract = {The Internet of Things (IoT) envisions a smart environment powered by connectivity and heterogeneity where ensuring reliable services and communications across multiple industries, from financial fields to healthcare and fault detection systems, is a top priority. In such fields, data is being collected and broadcast at high speed on a continuous and real-time scale, including IoT in the streaming processing paradigm. Intrusion Detection Systems (IDS) rely on manually defined security policies and signatures that fail to design a real-time solution or prevent zero-day attacks. Therefore, anomaly detection appears as a prominent solution capable of recognizing patterns, learning from experience, and detecting abnormal behavior. However, most approaches do not fit the urged requirements, often evaluated on deprecated datasets not representative of the working environment. As a result, our contributions address an overview of cybersecurity threats in IoT, important recommendations for a real-time IDS, and a real-time dataset setting to evaluate a security system covering multiple cyber threats. The dataset used to evaluate current host-based IDS approaches is publicly available and can be used as a benchmark by the community.},
	language = {en},
	urldate = {2022-03-23},
	journal = {Future Generation Computer Systems},
	author = {Martins, Inês and Resende, João S. and Sousa, Patrícia R. and Silva, Simão and Antunes, Luís and Gama, João},
	month = aug,
	year = {2022},
	keywords = {+survey, \_read},
	pages = {95--113},
}

@article{meidan_n-baiot_2018,
	title = {N-{BaIoT}: {Network}-based {Detection} of {IoT} {Botnet} {Attacks} {Using} {Deep} {Autoencoders}},
	volume = {17},
	issn = {1536-1268, 1558-2590},
	shorttitle = {N-{BaIoT}},
	url = {http://arxiv.org/abs/1805.03409},
	doi = {10.1109/MPRV.2018.03367731},
	abstract = {The proliferation of IoT devices which can be more easily compromised than desktop computers has led to an increase in the occurrence of IoT-based botnet attacks. In order to mitigate this new threat there is a need to develop new methods for detecting attacks launched from compromised IoT devices and differentiate between hour and millisecond long IoT-based attacks. In this paper we propose and empirically evaluate a novel network-based anomaly detection method which extracts behavior snapshots of the network and uses deep autoencoders to detect anomalous network trafﬁc emanating from compromised IoT devices. To evaluate our method, we infected nine commercial IoT devices in our lab with two of the most widely known IoT-based botnets, Mirai and BASHLITE. Our evaluation results demonstrated our proposed method’s ability to accurately and instantly detect the attacks as they were being launched from the compromised IoT devices which were part of a botnet.},
	language = {en},
	number = {3},
	urldate = {2021-10-23},
	journal = {IEEE Pervasive Computing},
	author = {Meidan, Yair and Bohadana, Michael and Mathov, Yael and Mirsky, Yisroel and Breitenbacher, Dominik and Shabtai, Asaf and Elovici, Yuval},
	month = jul,
	year = {2018},
	note = {arXiv: 1805.03409},
	keywords = {68U35, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
	pages = {12--22},
}

@article{marchal_audi_2019,
	title = {{AuDI}: {Toward} {Autonomous} {IoT} {Device}-{Type} {Identification} {Using} {Periodic} {Communication}},
	volume = {37},
	issn = {0733-8716, 1558-0008},
	shorttitle = {{AuDI}},
	url = {https://ieeexplore.ieee.org/document/8664655/},
	doi = {10.1109/JSAC.2019.2904364},
	abstract = {IoT devices are being widely deployed. But the huge variance among them in the level of security and requirements for network resources makes it unfeasible to manage IoT networks using a common generic policy. One solution to this challenge is to deﬁne policies for classes of devices based on device type. In this paper, we present AUDI, a system for quickly and effectively identifying the type of a device in an IoT network by analyzing their network communications. AUDI models the periodic communication trafﬁc of IoT devices using an unsupervised learning method to perform identiﬁcation. In contrast to prior work, AUDI operates autonomously after initial setup, learning, without human intervention nor labeled data, to identify previously unseen device types. AUDI can identify the type of a device in any mode of operation or stage of lifecycle of the device. Via systematic experiments using 33 off-the-shelf IoT devices, we show that AUDI is effective (98.2\% accuracy).},
	language = {en},
	number = {6},
	urldate = {2021-06-04},
	journal = {IEEE Journal on Selected Areas in Communications},
	author = {Marchal, Samuel and Miettinen, Markus and Nguyen, Thien Duc and Sadeghi, Ahmad-Reza and Asokan, N.},
	month = jun,
	year = {2019},
	pages = {1402--1412},
}

@article{lyu_threats_2020,
	title = {Threats to {Federated} {Learning}: {A} {Survey}},
	url = {http://arxiv.org/abs/2003.02133},
	abstract = {With the emergence of data silos and popular privacy awareness, the traditional centralized approach of training artificial intelligence (AI) models is facing strong challenges. Federated learning (FL) has recently emerged as a promising solution under this new reality. Existing FL protocol design has been shown to exhibit vulnerabilities which can be exploited by adversaries both within and without the system to compromise data privacy. It is thus of paramount importance to make FL system designers to be aware of the implications of future FL algorithm design on privacy-preservation. Currently, there is no survey on this topic. In this paper, we bridge this important gap in FL literature. By providing a concise introduction to the concept of FL, and a unique taxonomy covering threat models and two major attacks on FL: 1) poisoning attacks and 2) inference attacks, this paper provides an accessible review of this important topic. We highlight the intuitions, key techniques as well as fundamental assumptions adopted by various attacks, and discuss promising future research directions towards more robust privacy preservation in FL.},
	journal = {arXiv},
	author = {Lyu, Lingjuan and Yu, Han and Yang, Qiang},
	month = mar,
	year = {2020},
	keywords = {⛔ No DOI found},
}

@article{lu_defense_2022,
	title = {Defense against backdoor attack in federated learning},
	issn = {01674048},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167404822002139},
	doi = {10.1016/j.cose.2022.102819},
	abstract = {As a new distributed machine learning framework, Federated Learning (FL) effectively solves the problems of data silo and privacy protection in the field of artificial intelligence. However, for its independent devices, heterogeneous data and unbalanced data distribution, it is more vulnerable to adversarial attack, especially backdoor attack. In this paper, we investigate typical backdoor attacks in FL, containing model replacement attack and adaptive backdoor attack. Based on attack initiating round, we divide backdoor attack into convergence-round attack and early-round attack. In addition, we respectively design a defense scheme with model pre-aggregation and similarity measurement to detect and remove backdoor model under convergence-round attack and a defense scheme with backdoor neuron activation to remove backdoor under early-round attack. Experiments and performance analysis show that compared to benchmark schemes, our defense scheme with similarity measurement obtains the highest backdoor detection accuracy under model replacement attack (25\% increase) and adaptive backdoor attack (67\% increase) at the convergence round. Moreover, detection effect is the most stable. Compared to defense of participant-level differential privacy and adversarial training, our defense scheme with backdoor neuron activation can rapidly remove malicious effects of backdoor without reducing the main task accuracy under early-round attack. Thus, the robustness of FL can be improved greatly with our defense schemes. We make our key codes public at Github https://github.com/lsw3130104597/Backdoor\_detection.},
	language = {en},
	urldate = {2022-07-04},
	journal = {Computers \& Security},
	author = {Lu, Shiwei and Li, Ruihu and Liu, Wenbin and Chen, Xuan},
	month = jun,
	year = {2022},
	pages = {102819},
}

@article{ma_applying_2022,
	title = {Applying {Federated} {Learning} in {Software}-{Defined} {Networks}: {A} {Survey}},
	volume = {14},
	issn = {2073-8994},
	shorttitle = {Applying {Federated} {Learning} in {Software}-{Defined} {Networks}},
	url = {https://www.mdpi.com/2073-8994/14/2/195},
	doi = {10/gpbg4s},
	abstract = {Federated learning (FL) is a type of distributed machine learning approacs that trains global models through the collaboration of participants. It protects data privacy as participants only contribute local models instead of sharing private local data. However, the performance of FL highly relies on the number of participants and their contributions. When applying FL over conventional computer networks, attracting more participants, encouraging participants to contribute more local resources, and enabling efﬁcient and effective collaboration among participants become very challenging. As software-deﬁned networks (SDNs) enable open and ﬂexible networking architecture with separate control and data planes, SDNs provide standardized protocols and speciﬁcations to enable ﬁne-grained collaborations among devices. Applying FL approaches over SDNs can take use such advantages to address challenges. A SDN control plane can have multiple controllers organized in layers; the controllers in the lower layer can be placed in the network edge to deal with the asymmetries in the attached switches and hosts, and the controller in the upper layer can supervise the whole network centrally and globally. Applying FL in SDNs with a layered-distributed control plane may be able to protect the data privacy of each participant while improving collaboration among participants to produce higher-quality models over asymmetric networks. Accordingly, this paper aims to make a comprehensive survey on the related mechanisms and solutions that enable FL in SDNs. It highlights three major challenges, an incentive mechanism, privacy and security, and model aggregation, which affect the quality and quantity of participants, the security and privacy in model transferring, and the performance of the global model, respectively. The state of the art in mechanisms and solutions that can be applied to address such challenges in the current literature are categorized based on the challenges they face, followed by suggestions of future research directions. To the best of our knowledge, this work is the ﬁrst effort in surveying the state of the art in combining FL with SDNs.},
	language = {en},
	number = {2},
	urldate = {2022-01-31},
	journal = {Symmetry},
	author = {Ma, Xiaohang and Liao, Lingxia and Li, Zhi and Lai, Roy Xiaorong and Zhang, Miao},
	month = jan,
	year = {2022},
	keywords = {+survey},
	pages = {195},
}

@article{lo_systematic_2021,
	title = {A {Systematic} {Literature} {Review} on {Federated} {Machine} {Learning}: {From} {A} {Software} {Engineering} {Perspective}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	shorttitle = {A {Systematic} {Literature} {Review} on {Federated} {Machine} {Learning}},
	url = {http://arxiv.org/abs/2007.11354},
	doi = {10.1145/3450288},
	abstract = {Federated learning is an emerging machine learning paradigm where clients train models locally and formulate a global model based on the local model updates. To identify the state-of-the-art in federated learning and explore how to develop federated learning systems, we perform a systematic literature review from a software engineering perspective, based on 231 primary studies. Our data synthesis covers the lifecycle of federated learning system development that includes background understanding, requirement analysis, architecture design, implementation, and evaluation. We highlight and summarise the findings from the results, and identify future trends to encourage researchers to advance their current work.},
	language = {en},
	number = {5},
	urldate = {2021-10-04},
	journal = {ACM Computing Surveys},
	author = {Lo, Sin Kit and Lu, Qinghua and Wang, Chen and Paik, Hye-Young and Zhu, Liming},
	month = jun,
	year = {2021},
	note = {arXiv: 2007.11354},
	keywords = {+survey, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Computer Science - Software Engineering, \_read},
	pages = {1--39},
}

@article{liu_hierarchical_2022,
	title = {Hierarchical {Federated} {Learning} with {Quantization}: {Convergence} {Analysis} and {System} {Design}},
	issn = {1558-2248},
	shorttitle = {Hierarchical {Federated} {Learning} with {Quantization}},
	doi = {10.1109/TWC.2022.3190512},
	abstract = {Federated learning (FL) is a powerful distributed machine learning framework where a server aggregates models trained by different clients without accessing their private data. Hierarchical FL, with a client-edge-cloud aggregation hierarchy, can effectively leverage both the cloud server’s access to many clients’ data and the edge servers’ closeness to the clients to achieve a high communication efficiency. Neural network quantization can further reduce the communication overhead during model uploading. To fully exploit the advantages of hierarchical FL, an accurate convergence analysis with respect to the key system parameters is needed. Unfortunately, existing analysis is loose and does not consider model quantization. In this paper, we derive a tighter convergence bound for hierarchical FL with quantization. The convergence result leads to practical guidelines for important design problems such as the client-edge aggregation and edge-client association strategies. Based on the obtained analytical results, we optimize the two aggregation intervals and show that the client-edge aggregation interval should slowly decay while the edge-cloud aggregation interval needs to adapt to the ratio of the client-edge and edge-cloud propagation delay. Simulation results shall verify the design guidelines and demonstrate the effectiveness of the proposed aggregation strategy.},
	journal = {IEEE Transactions on Wireless Communications},
	author = {Liu, Lumin and Zhang, Jun and Song, Shenghui and Letaief, Khaled B.},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Wireless Communications},
	keywords = {Convergence, Convergence Analysis, Edge Learning, Federated Learning, Guidelines, Optimization, Quantization (signal), Servers, System analysis and design, Training},
	pages = {1--1},
}

@article{lin_multi-datasource_2022,
	title = {Multi-datasource machine learning in intrusion detection: {Packet} flows, system logs and host statistics},
	volume = {68},
	issn = {2214-2126},
	shorttitle = {Multi-datasource machine learning in intrusion detection},
	url = {https://www.sciencedirect.com/science/article/pii/S2214212622001168},
	doi = {10.1016/j.jisa.2022.103248},
	abstract = {This work compares the performance of different combinations of data sources for intrusion detection in depth. To learn and distinguish between normal and malicious behavior, we use machine learning algorithms and train three typical models on three kinds of datasets: system logs, packet flows and host statistics. Unlike other studies, our study captures and monitors the behavior from multiple data sources in order to catch security attacks. Our aim is to figure out how to build the most effective dataset for machine learning with a combination of multiple sources. However, since there are no such datasets which have been generated from multiple sources for given attacks, we show how to build and generate a dataset with three data sources. We then compare the F1 score of the detection by applying machine learning algorithms for various combinations of the data sources. Our evaluation results show that the dataset of host statistics results in better performance (0.91) than traffic flows (0.63) and system logs (0.44) because it has the highest average F1-score in the three stages of attacks, while the other datasets may have poor F1-scores in some of the stages, particularly in the stage of impact. However, in the initial access stage of attacks, the dataset of logs performs the best (0.94), and the packet flows are suitable for detecting network DoS attacks (0.82). Furthermore, running this detection with all three data sources results in minor overheads of at most 2.1\% CPU utilization. Finally, we analyze the important features of each model, such as the number of logs generated by apache-access, in.telnetd and postfix in the dataset of logs, SrcBytes and TotBytes in the dataset of flows, and MINFLT, VSTEXT and RSIZE in the dataset of statistics.},
	language = {en},
	urldate = {2022-08-11},
	journal = {Journal of Information Security and Applications},
	author = {Lin, Ying-Dar and Wang, Ze-Yu and Lin, Po-Ching and Nguyen, Van-Linh and Hwang, Ren-Hung and Lai, Yuan-Cheng},
	month = aug,
	year = {2022},
	keywords = {Feature engineering, Host statistics, Intrusion detection, Machine learning, System log, Traffic flow},
	pages = {103248},
}

@article{liu_machine_2019,
	title = {Machine {Learning} and {Deep} {Learning} {Methods} for {Intrusion} {Detection} {Systems}: {A} {Survey}},
	volume = {9},
	issn = {2076-3417},
	shorttitle = {Machine {Learning} and {Deep} {Learning} {Methods} for {Intrusion} {Detection} {Systems}},
	url = {https://www.mdpi.com/2076-3417/9/20/4396},
	doi = {10.3390/app9204396},
	abstract = {Networks play important roles in modern life, and cyber security has become a vital research area. An intrusion detection system (IDS) which is an important cyber security technique, monitors the state of software and hardware running in the network. Despite decades of development, existing IDSs still face challenges in improving the detection accuracy, reducing the false alarm rate and detecting unknown attacks. To solve the above problems, many researchers have focused on developing IDSs that capitalize on machine learning methods. Machine learning methods can automatically discover the essential differences between normal data and abnormal data with high accuracy. In addition, machine learning methods have strong generalizability, so they are also able to detect unknown attacks. Deep learning is a branch of machine learning, whose performance is remarkable and has become a research hotspot. This survey proposes a taxonomy of IDS that takes data objects as the main dimension to classify and summarize machine learning-based and deep learning-based IDS literature. We believe that this type of taxonomy framework is ﬁt for cyber security researchers. The survey ﬁrst clariﬁes the concept and taxonomy of IDSs. Then, the machine learning algorithms frequently used in IDSs, metrics, and benchmark datasets are introduced. Next, combined with the representative literature, we take the proposed taxonomic system as a baseline and explain how to solve key IDS issues with machine learning and deep learning techniques. Finally, challenges and future developments are discussed by reviewing recent representative studies.},
	language = {en},
	number = {20},
	urldate = {2022-03-11},
	journal = {Applied Sciences},
	author = {Liu, Hongyu and Lang, Bo},
	month = oct,
	year = {2019},
	keywords = {+survey},
	pages = {4396},
}

@article{li_federated_2022,
	title = {Federated learning with workload-aware client scheduling in heterogeneous systems},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608022002957},
	doi = {10.1016/j.neunet.2022.07.030},
	abstract = {Federated Learning (FL) is a novel distributed machine learning, which allows thousands of edge devices to train models locally without uploading data to the central server. Since devices in real federated settings are resource-constrained, FL encounters systems heterogeneity, which causes considerable stragglers and incurs significant accuracy degradation. To tackle the challenges of systems heterogeneity and improve the robustness of the global model, we propose a novel adaptive federated framework in this paper. Specifically, we propose FedSAE that leverages the workload completion history of clients to adaptively predict the affordable training workload for each device. Consequently, FedSAE can significantly reduce stragglers in highly heterogeneous systems. We incorporate Active Learning into FedSAE to dynamically schedule participants. The server evaluates the devices’ training value based on their training loss in each round, and larger-value clients are selected with a higher probability. As a result, the model convergence is accelerated. Furthermore, we propose q-FedSAE that combines FedSAE and q-FFL to improve global fairness in highly heterogeneous systems. The evaluations conducted in a highly heterogeneous system demonstrate that both FedSAE and q-FedSAE converge faster than FedAvg. In particular, FedSAE outperforms FedAvg across multiple federated datasets — FedSAE improves testing accuracy by 22.19\% and reduces stragglers by 90.69\% on average. Moreover, holding the same accuracy as FedSAE, q-FedSAE allows for more robust convergence and fairer model performance than q-FedAvg, FedSAE.},
	language = {en},
	urldate = {2022-08-16},
	journal = {Neural Networks},
	author = {Li, Li and Liu, Duo and Duan, Moming and Zhang, Yu and Ren, Ao and Chen, Xianzhang and Tan, Yujuan and Wang, Chengliang},
	month = aug,
	year = {2022},
	keywords = {Distributed machine learning, Federated learning, Neural Networks},
}

@article{li_transfer_2021,
	title = {Transfer learning based intrusion detection scheme for {Internet} of vehicles},
	volume = {547},
	issn = {00200255},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025520305569},
	doi = {10.1016/j.ins.2020.05.130},
	abstract = {As a new type of network, the types of attack in the Internet of Vehicles (IoV) are constantly emerging and changing. Consequently, the machine learning based intrusion detection model has to update to cope with new attacks. However, existing machine learning based IoV intrusion detection schemes require large amounts of labeled data to complete model updates. For new attacks, the IoV cloud is also difﬁcult to identify in time, which requires a lot of labor and time cost in IoV. To solve above issue, this paper employs transfer learning and proposes two model update schemes based on whether the IoV cloud can timely provide a small amount of labeled data for a new attack. The ﬁrst one is the cloud-assisted update scheme where the IoV cloud can provide a small amount of data. And the second one is the local update scheme where the IoV cloud cannot provide any labeled data timely. In this paper, the local update scheme obtains pseudo label of the unlabeled data in new attacks via pre-classiﬁes and uses the pseudo-labeled data for multiple rounds of transfer learning. Then the vehicle can complete the update without obtaining any labeled data through the IoV cloud. The experimental results show that compared with the existing method, our two schemes have improved the detection accuracy by at least 23\%.},
	language = {en},
	urldate = {2021-10-04},
	journal = {Information Sciences},
	author = {Li, Xinghua and Hu, Zhongyuan and Xu, Mengfan and Wang, Yunwei and Ma, Jianfeng},
	month = feb,
	year = {2021},
	keywords = {\_read},
	pages = {119--135},
}

@article{li_inspecting_2021,
	title = {Inspecting the {Running} {Process} of {Horizontal} {Federated} {Learning} via {Visual} {Analytics}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {https://ieeexplore.ieee.org/document/9408377/},
	doi = {10.1109/TVCG.2021.3074010},
	abstract = {As a decentralized training approach, horizontal federated learning (HFL) enables distributed clients to collaboratively learn a machine learning model while keeping personal/private information on local devices. Despite the enhanced performance and efﬁciency of HFL over local training, clues for inspecting the behaviors of the participating clients and the federated model are usually lacking due to the privacy-preserving nature of HFL. Consequently, the users can only conduct a shallow-level analysis of potential abnormal behaviors and have limited means to assess the contributions of individual clients and implement the necessary intervention. Visualization techniques have been introduced to facilitate the HFL process inspection, usually by providing model metrics and evaluation results as a dashboard representation. Although the existing visualization methods allow a simple examination of the HFL model performance, they cannot support the intensive exploration of the HFL process. In this study, strictly following the HFL privacy-preserving protocol, we design an exploratory visual analytics system for the HFL process termed HFLens, which supports comparative visual interpretation at the overview, communication round, and client instance levels. Speciﬁcally, the proposed system facilitates the investigation of the overall process involving all clients, the correlation analysis of clients’ information in one or different communication round(s), the identiﬁcation of potential anomalies, and the contribution assessment of each HFL client. Two case studies conﬁrm the efﬁcacy of our system. Experts’ feedback suggests that our approach indeed helps in understanding and diagnosing the HFL process better.},
	language = {en},
	urldate = {2021-09-21},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Li, Quan and Wei, Xiguang and Lin, Huanbin and Liu, Yang and Chen, Tianjian and Ma, Xiaojuan},
	year = {2021},
	pages = {1--1},
}

@article{li_federated_2020,
	title = {Federated {Optimization} in {Heterogeneous} {Networks}},
	shorttitle = {fedprox},
	url = {http://arxiv.org/abs/1812.06127},
	abstract = {Federated Learning is a distributed learning paradigm with two key challenges that differentiate it from traditional distributed optimization: (1) signiﬁcant variability in terms of the systems characteristics on each device in the network (systems heterogeneity), and (2) non-identically distributed data across the network (statistical heterogeneity). In this work, we introduce a framework, FedProx, to tackle heterogeneity in federated networks. FedProx can be viewed as a generalization and re-parametrization of FedAvg, the current state-of-the-art method for federated learning. While this re-parameterization makes only minor modiﬁcations to the method itself, these modiﬁcations have important ramiﬁcations both in theory and in practice. Theoretically, we provide convergence guarantees for our framework when learning over data from non-identical distributions (statistical heterogeneity), and while adhering to device-level systems constraints by allowing each participating device to perform a variable amount of work (systems heterogeneity). Practically, we demonstrate that FedProx allows for more robust convergence than FedAvg across a suite of realistic federated datasets. In particular, in highly heterogeneous settings, FedProx demonstrates signiﬁcantly more stable and accurate convergence behavior relative to FedAvg—improving absolute test accuracy by 22\% on average.},
	language = {en},
	urldate = {2021-09-20},
	journal = {arXiv:1812.06127 [cs, stat]},
	author = {Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
	month = apr,
	year = {2020},
	note = {arXiv: 1812.06127},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, \_read, ⛔ No DOI found},
}

@article{lin_survey_2017,
	title = {A {Survey} on {Internet} of {Things}: {Architecture}, {Enabling} {Technologies}, {Security} and {Privacy}, and {Applications}},
	volume = {4},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/document/7879243/},
	doi = {10.1109/JIOT.2017.2683200},
	abstract = {Fog/edge computing has been proposed to be integrated with Internet of Things (IoT) to enable computing services devices deployed at network edge, aiming to improve the user’s experience and resilience of the services in case of fail- ures. With the advantage of distributed architecture and close to end-users, fog/edge computing can provide faster response and greateome-imt-cer quality of service for IoT applications. Thus, fog/edge computing-based IoT becomes future infrastructure on IoT devel- opment. To develop fog/edge computing-based IoT infrastructure, the architecture, enabling techniques, and issues related to IoT should be investigated first, and then the integration of fog/edge computing and IoT should be explored. To this end, this paper conducts a comprehensive overview of IoT with respect to system architecture, enabling technologies, security and privacy issues, and present the integration of fog/edge computing and IoT, and applications. Particularly, this paper first explores the relation- ship between cyber-physical systems and IoT, both of which play important roles in realizing an intelligent cyber-physical world. Then, existing architectures, enabling technologies, and security and privacy issues in IoT are presented to enhance the under- standing of the state of the art IoT development. To investigate the fog/edge computing-based IoT, this paper also investigate the rela- tionship between IoT and fog/edge computing, and discuss issues in fog/edge computing-based IoT. Finally, several applications, including the smart grid, smart transportation, and smart cities, are presented to demonstrate how fog/edge computing-based IoT to be implemented in real-world applications.},
	number = {5},
	journal = {IEEE Internet of Things Journal},
	author = {Lin, Jie and Yu, Wei and Zhang, Nan and Yang, Xinyu and Zhang, Hanlin and Zhao, Wei},
	month = oct,
	year = {2017},
	note = {Publisher: IEEE
ISBN: 978-1-5386-1442-6},
	pages = {1125--1142},
}

@article{li_federated_2022-1,
	title = {Federated {Anomaly} {Detection} on {System} {Logs} for the {Internet} of {Things}: {A} {Customizable} and {Communication}-{Efficient} {Approach}},
	issn = {1932-4537, 2373-7379},
	shorttitle = {Federated {Anomaly} {Detection} on {System} {Logs} for the {Internet} of {Things}},
	url = {https://ieeexplore.ieee.org/document/9716881/},
	doi = {10.1109/TNSM.2022.3152620},
	abstract = {Runtime log-based anomaly detection is one of several key building blocks in ensuring system security, as well as post-incident forensic investigations. However, existing logbased anomaly detection approaches that are implemented on large-scale Internet of Things (IoT) systems generally upload the local data from the edge devices to a centralized (cloud) server for processing and analysis. Such a workﬂow incurs signiﬁcant communication and computation overheads, with potential privacy implications. Hence, in this paper, we propose a customizable and communication-efﬁcient federated anomaly detection scheme (hereafter referred to as FedLog), designed to facilitate the identiﬁcation of abnormal log patterns in large-scale IoT systems. Speciﬁcally, we ﬁrst craft a Temporal Convolutional Network-Attention Mechanism-based Convolutional Neural Network (TCN-ACNN) model, to effectively extract ﬁne-grained features from system logs. Second, we develop a new federated learning framework to support IoT devices in establishing a comprehensive anomaly detection model in a collaborative and privacy-preserving manner. Third, a lottery ticket hypothesis based masking strategy is designed to achieve customizable and communication-efﬁcient federated learning in handling nonIndependent and Identically Distributed (non-IID) log datasets. We then evaluate the performance of our proposed scheme with those of DeepLog (published in CCS, 2017) and Loganomaly (published in IJCAI, 2019) in both centralized learning and federated learning settings, using two publicly available and widely used real-world datasets (i.e., HDFS and BGL). The ﬁndings demonstrate the utility of the proposed FedLog scheme, in terms of log-based anomaly detection.},
	language = {en},
	urldate = {2022-02-25},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Li, Beibei and Ma, Shang and Deng, Ruilong and Choo, Kim-Kwang Raymond and Yang, Jin},
	year = {2022},
	pages = {1--1},
}

@article{lefoane_unsupervised_2022,
	title = {Unsupervised {Learning} for {Feature} {Selection}: {A} proposed {Solution} for {Botnet} {Detection} in {5G} {Networks}},
	issn = {1941-0050},
	shorttitle = {Unsupervised {Learning} for {Feature} {Selection}},
	doi = {10.1109/TII.2022.3192044},
	abstract = {The world has seen exponential growth in deploying Internet of Things (IoT) devices. In recent years, connected IoT devices have surpassed the number of connected non-IoT devices. The number of IoT devices continues to grow and they are becoming a critical component of the national infrastructure. IoT devices' characteristics and inherent limitations make them attractive targets for hackers and cyber criminals. Botnet attack is one of the serious threats on the Internet today. This article proposes pattern-based feature selection methods as part of a machine learning (ML) based botnet detection system. Specifically, two methods are proposed: the first is based on the most dominant pattern feature values and the second is based on Maximal Frequent Itemset (MFI) mining. The proposed feature selection method uses Gini Impurity (GI) and an unsupervised clustering method to select the most influential features automatically. The evaluation results show that the proposed methods have improved the performance of the detection system. The developed system has a True Positive Rate (TPR) of 100\% and a False Positive Rate (FPR) of 0\% for best performing models. In addition, the proposed methods reduce the computational cost of the system as evidenced by the detection speed of the system.},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Lefoane, Moemedi and Ghafir, Ibrahim and Kabir, Sohag and Awan, Irfan-Ullah},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Industrial Informatics},
	keywords = {5G mobile communication, Botnet, Botnet attack, Feature extraction, Informatics, Internet of Things, Security, Telecommunication traffic, feature selection, intrusion detection system, machine learning, network security},
	pages = {1--9},
}

@article{li_multi-tentacle_2022,
	title = {Multi-{Tentacle} {Federated} {Learning} over {Software}-{Defined} {Industrial} {Internet} of {Things} {Against} {Adaptive} {Poisoning} {Attacks}},
	issn = {1941-0050},
	doi = {10.1109/TII.2022.3173996},
	abstract = {Software-defined industrial Internet of things (SD-IIoT) exploits federated learning to process the sensitive data at edges, while adaptive poisoning attacks threat the security of SD-IIoT. To address this problem, this paper proposes a multi-tentacle federated learning (MTFL) framework, which is essential to guarantee the trustness of training data in SD-IIoT. In MTFL, participants with similar learning tasks are assigned to the same tentacle group. To identify adaptive poisoning attacks, a tentacle distribution-based efficient poisoning attack detection (TD-EPAD) algorithm is presented. And also, to minimize the impact of adaptive poisoning data, a stochastic tentacle data exchanging (STDE) protocol is also proposed. Simultaneously, to protect the tentacle's privacy in STDE, all exchanged data will be processed by differential privacy technology. A MTFL prototype system is implemented, which provides extensive ablation experiments and comparison experiments, demonstrating that the accuracy of the global model under attack scenario can be improved with 40\%.},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Li, Gaolei and Wu, Jun and Li, Shenghong and Yang, Wu and Li, Changlian},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Industrial Informatics},
	keywords = {Adaptation models, Collaborative work, Data models, Differential Privacy, Industrial Internet of Things, Informatics, Multi-Tentacle Federated Learning, Poisoning Attacks, Protocols, Software-Defined Industrial Internet of Things (SD-IIoT), Training},
	pages = {1--1},
}

@article{li_fedmd_2019,
	title = {{FedMD}: {Heterogenous} {Federated} {Learning} via {Model} {Distillation}},
	shorttitle = {{FedMD}},
	url = {http://arxiv.org/abs/1910.03581},
	abstract = {Federated learning enables the creation of a powerful centralized model without compromising the data privacy of multiple participants. While successful, it does not incorporate the case where each participant independently designs its own model. Due to intellectual property concerns and heterogeneous nature of tasks and data, this is a widespread requirement in applications of federated learning to areas such as health care and AI as a service. In this work, we use transfer learning and knowledge distillation to develop a universal framework that enables federated learning when each agent owns not only their private data, but also uniquely designed models. We test our framework on the MNIST/FEMNIST dataset and the CIFAR10/CIFAR100 dataset and observe fast improvement across all participating models. With 10 distinct participants, the ﬁnal test accuracy of each model on average receives a 20\% gain on top of what’s possible without collaboration and is only a few percent lower than the performance each model would have obtained if all private datasets were pooled and made directly available for all participants.},
	language = {en},
	urldate = {2022-02-25},
	journal = {arXiv:1910.03581 [cs, stat]},
	author = {Li, Daliang and Wang, Junpu},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.03581},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, ⛔ No DOI found},
}

@article{le_xgboost_2022,
	title = {{XGBoost} for {Imbalanced} {Multiclass} {Classification}-{Based} {Industrial} {Internet} of {Things} {Intrusion} {Detection} {Systems}},
	volume = {14},
	issn = {2071-1050},
	url = {https://www.mdpi.com/2071-1050/14/14/8707},
	doi = {10.3390/su14148707},
	abstract = {The Industrial Internet of Things (IIoT) has advanced digital technology and the fastest interconnection, which creates opportunities to substantially grow industrial businesses today. Although IIoT provides promising opportunities for growth, the massive sensor IoT data collected are easily attacked by cyber criminals. Hence, IIoT requires different high security levels to protect the network. An Intrusion Detection System (IDS) is one of the crucial security solutions, which aims to detect the network’s abnormal behavior and monitor safe network trafﬁc to avoid attacks. In particular, the effectiveness of the Machine Learning (ML)-based IDS approach to building a secure IDS application is attracting the security research community in both the general cyber network and the speciﬁc IIoT network. However, most available IIoT datasets contain multiclass output data with imbalanced distributions. This is the main reason for the reduction in the detection accuracy of attacks of the ML-based IDS model. This research proposes an IDS for IIoT imbalanced datasets by applying the eXtremely Gradient Boosting (XGBoost) model to overcome this issue. Two modern IIoT imbalanced datasets were used to assess our proposed method’s effectiveness and robustness, X-IIoTDS and TON\_IoT. The XGBoost model achieved excellent attack detection with F1 scores of 99.9\% and 99.87\% on the two datasets. This result demonstrated that the proposed approach improved the detection attack performance in imbalanced multiclass IIoT datasets and was superior to existing IDS frameworks.},
	language = {en},
	number = {14},
	urldate = {2022-08-11},
	journal = {Sustainability},
	author = {Le, Thi-Thu-Huong and Oktian, Yustus Eko and Kim, Howon},
	month = jul,
	year = {2022},
	pages = {8707},
}

@article{kundu_detection_2022,
	title = {Detection and {Classification} of {Botnet} {Traffic} using {Deep} {Learning} with {Model} {Explanation}},
	issn = {1941-0018},
	doi = {10.1109/TDSC.2022.3183361},
	abstract = {Distributed denial-of-service attacks are a kind of malicious attempts among many others that make target services unavailable to legitimate users by using a large number of bots, which send many service requests exceeding the processing capacity of the services. Detection of botnet traffic is therefore critical to maintaining the availability and quality of the services. In contrast, identifying the type of botnet attacks helps system administrators quickly determine which part of the computer and network system is under attack. Current works focus on rule-based detection, which sets rules in the network firewall to drop suspicious traffic that matches the rules. With the emergence of machine learning and deep learning (ML/DL), several preliminary works have been developed to learn botnet traffic behavior and perform detection. However, the performance of existing ML/DL models can be further improved and their decision/prediction are not transparent, making it hard for users to interpret and trust the results. In this work, we develop a novel deep learning model for botnet detection and classification combined with its ability of explaining the decision of the model. We first leverage latent representation of traffic features generated using convolutional neural networks to detect whether a traffic record is generated by a bot then determine the type of bots. We adopt an existing explainable framework to interpret the prediction of the developed deep learning model. We perform extensive experiments with real network traffic as well as synthetic traffic generated by IXIA BreakingPoint System. We compare the developed model with existing models on various performance metrics. The experimental results show that the developed model outperforms the existing machine learning models with an improvement of up to {\textless}inline-formula{\textgreater}{\textless}tex-math notation="LaTeX"{\textgreater}\$15\%\${\textless}/tex-math{\textgreater}{\textless}/inline-formula{\textgreater} for all performance metrics while providing a clear explanation of the model decision.},
	journal = {IEEE Transactions on Dependable and Secure Computing},
	author = {Kundu, Partha Pratim and Truong-Huu, Tram and Chen, Ling and Zhou, Luying and Teo, Sin G.},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Dependable and Secure Computing},
	keywords = {Behavioral sciences, Botnet, Botnet Detection and Classification, Convolutional neural networks, Deep Learning, Deep learning, Explainable AI, Feature extraction, Monitoring, Network Security, Servers},
	pages = {1--15},
}

@article{kurt_online_2022,
	title = {Online {Privacy}-{Preserving} {Data}-{Driven} {Network} {Anomaly} {Detection}},
	issn = {0733-8716, 1558-0008},
	url = {https://ieeexplore.ieee.org/document/9690092/},
	doi = {10/gpbg4r},
	abstract = {We study online privacy-preserving anomaly detection in a setting in which the data are distributed over a network and locally sensitive to each node, and a probabilistic data model is unknown. We design and analyze a data-driven solution scheme where each node observes a high-dimensional data stream for which it computes a local outlierness score. This score is then perturbed, encrypted, and sent to a network operator. The network operator then decrypts an aggregate statistic over the network and performs online network anomaly detection via the proposed generalized cumulative sum (CUSUM) algorithm. We derive an asymptotic lower bound and an asymptotic approximation for the average false alarm period of the proposed algorithm. Additionally, we derive an asymptotic upper bound and asymptotic approximation for the average detection delay of the proposed algorithm under a certain anomaly. We show the analytical tradeoff between the anomaly detection performance and the differential privacy level, controlled via the local perturbation noise. Experiments illustrate that the proposed algorithm offers a good tradeoff between privacy and quick anomaly detection against the UDP ﬂooding and spam attacks in a real Internet of Things (IoT) network.},
	language = {en},
	urldate = {2022-01-31},
	journal = {IEEE Journal on Selected Areas in Communications},
	author = {Kurt, Mehmet Necip and Yilmaz, Yasin and Wang, Xiaodong and Mosterman, Pieter J.},
	year = {2022},
	pages = {1--1},
}

@article{lavaur_evolution_2022,
	series = {Special {Issue} on {Network} {Security} {Management}},
	title = {The {Evolution} of {Federated} {Learning}-based {Intrusion} {Detection} and {Mitigation}: a {Survey}},
	copyright = {All rights reserved},
	abstract = {In 2016, Google introduced the concept of Federated Learning (FL), enabling collaborative Machine Learning (ML). FL does not share local data but ML models, offering applications in diverse domains. This paper focuses on the application of FL to Intrusion Detection Systems (IDSs). There, common criteria to compare existing solutions are missing. In particular, this survey shows: (i) how FL-based IDSs are used in different domains; (ii) what differences exist between architectures; (iii) the state of the art of FL-based IDS.
With a structured literature survey, this work identifies the relevant state of the art in FL–based intrusion detection from its creation in 2016 until 2021. It provides a reference architecture and a taxonomy to serve as guidelines to compare and design FL- based IDSs. Both are validated with the existing works. Finally, it identifies research directions for the application of FL to intrusion detection systems.},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Lavaur, Leo and Pahl, Marc-Oliver and Busnel, Yann and Autrel, Fabien},
	month = jun,
	year = {2022},
	keywords = {+survey},
}

@article{langner_stuxnet_2011,
	title = {Stuxnet: {Dissecting} a {Cyberwarfare} {Weapon}},
	volume = {9},
	issn = {1540-7993},
	url = {http://ieeexplore.ieee.org/document/5772960/},
	doi = {10.1109/MSP.2011.67},
	abstract = {Ralph Langner, an expert in industrial control system security, explores the technical side of Stuxnet, dangerous malware that attacks SCADA systems. © 2011 IEEE.},
	number = {3},
	journal = {IEEE Security \& Privacy Magazine},
	author = {Langner, Ralph},
	month = may,
	year = {2011},
	pages = {49--51},
}

@article{kumar_distributed_2022,
	title = {A {Distributed} {Intrusion} {Detection} {System} to {Detect} {DDoS} {Attacks} in {Blockchain}-enabled {IoT} {Network}},
	issn = {07437315},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0743731522000351},
	doi = {10.1016/j.jpdc.2022.01.030},
	abstract = {The Internet of Things (IoT) is emerging as a new technology for the development of various critical applications. However, these applications are still working on centralized storage architecture and have various key challenges like privacy, security, and single point of failure. Recently, the blockchain technology has emerged as a backbone for the IoT-based application development. The blockchain can be leveraged to solve privacy, security, and single point of failure (third-part dependency) issues of IoT applications. The integration of blockchain with IoT can beneﬁt both individual and society. However, 2017 Distributed Denial of Service (DDoS) attack on mining pool exposed the critical fault-lines among blockchain-enabled IoT network. Moreover, these application generates huge amount of data. Machine Learning (ML) gives complete autonomy in big data analysis, capabilities of decision making and therefore is used as an analytical tool. Thus, in order to address above challenges, this paper proposes a novel distributed Intrusion Detection System (IDS) using fog computing to detect DDoS attacks against mining pool in blockchain-enabled IoT Network. The performance is evaluated by training Random Forest (RF) and an optimized gradient tree boosting system (XGBoost) on distributed fog nodes. The proposed model e↵ectiveness is assessed using an actual IoT-based dataset i.e., BoT-IoT, which includes most recent attacks found in blockchain-enabled IoT network. The results indicate, for binary attack-detection XGBoost outperforms whereas for multi-attack detection Random Forest outperforms. Overall on distributed fog nodes RF takes less time for training and testing compared to XGBoost.},
	language = {en},
	urldate = {2022-02-25},
	journal = {Journal of Parallel and Distributed Computing},
	author = {Kumar, Randhir and Kumar, Prabhat and Tripathi, Rakesh and Gupta, Govind P. and Garg, Sahil and Hassan, Mohammad Mehedi},
	month = feb,
	year = {2022},
	pages = {S0743731522000351},
}

@article{kumar_blockchain_2022,
	title = {Blockchain and {Deep} {Learning} for {Secure} {Communication} in {Digital} {Twin} {Empowered} {Industrial} {IoT} {Network}},
	issn = {2327-4697},
	doi = {10.1109/TNSE.2022.3191601},
	abstract = {The rapid expansion of the Industrial Internet of Things (IIoT) necessitates the digitization of industrial processes in order to increase network efficiency. The integration of Digital Twin (DT) with IIoT digitizes physical objects into virtual representations to improve data analytics performance. Nevertheless, DT empowered IIoT generates a massive amount of data that is mostly sent to the cloud or edge servers for real-time analysis. However, unreliable public communication channels and lack of trust among participating entities causes various types of threats and attacks on the ongoing communication. Motivated from the aforementioned discussion, we present a blockchain and Deep Learning (DL) integrated framework for delivering decentralized data processing and learning in IIoT network. The framework first present a new DT model that facilitates construction of a virtual environment to simulate and replicate security-critical processes of IIoT. Second, we propose a blockchain-based data transmission scheme that uses smart contracts to ensure integrity and authenticity of data. Finally, the DL scheme is designed to apply the Intrusion Detection System (IDS) against valid data retrieved from blockchain. In DL scheme, a Long Short Term Memory-Sparse AutoEncoder (LSTMSAE) technique is proposed to learn the spatial-temporal representation. The extracted characteristics are further used by the proposed Multi-Head Self-Attention (MHSA)-based Bidirectional Gated Recurrent Unit (BiGRU) algorithm to learn long-distance features and accurately detect attacks. The practical implementation of our proposed framework proves considerable enhancement of communication security and data privacy in DT empowered IIoT network.},
	journal = {IEEE Transactions on Network Science and Engineering},
	author = {Kumar, Prabhat and Kumar, Randhir and Kumar, Abhinav and Franklin, A. Antony and Garg, Sahil and Singh, Satinder},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Network Science and Engineering},
	keywords = {Blockchain, Blockchains, Computational modeling, Data models, Deep Learning (DL), Digital Twin (DT), Digital twins, Industrial Internet of Things, Industrial Internet of Things (IIoT), Security, Smart Contract, Virtual environments},
	pages = {1--13},
}

@article{kumar_fedclean_2022,
	title = {{FedClean}: {A} {Defense} {Mechanism} against {Parameter} {Poisoning} {Attacks} in {Federated} {Learning}},
	abstract = {In Federated learning (FL) systems, a centralized entity (server), instead of access to the training data, has access to model parameter updates computed by each participant independently and based solely on their samples. Unfortunately, FL is susceptible to model poisoning attacks, in which malicious or malfunctioning entities share polluted updates that can compromise the model’s accuracy. In this study, we propose FedClean, an FL mechanism that is robust to model poisoning attacks. The accuracy of the models trained with the assistance of FedClean is close to the one where malicious entities do not participate.},
	language = {en},
	author = {Kumar, Abhishek and Khimani, Vivek and Chatzopoulos, Dimitris and Hui, Pan},
	month = apr,
	year = {2022},
	keywords = {⛔ No DOI found},
	pages = {5},
}

@article{koroniotis_towards_2019,
	title = {Towards the development of realistic botnet dataset in the {Internet} of {Things} for network forensic analytics: {Bot}-{IoT} dataset},
	volume = {100},
	issn = {0167739X},
	shorttitle = {Towards the development of realistic botnet dataset in the {Internet} of {Things} for network forensic analytics},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X18327687},
	doi = {10.1016/j.future.2019.05.041},
	abstract = {The proliferation of IoT systems, has seen them targeted by malicious third parties. To address this challenge, realistic protection and investigation countermeasures, such as network intrusion detection and network forensic systems, need to be effectively developed. For this purpose, a well-structured and representative dataset is paramount for training and validating the credibility of the systems. Although there are several network datasets, in most cases, not much information is given about the Botnet scenarios that were used. This paper proposes a new dataset, so-called Bot-IoT, which incorporates legitimate and simulated IoT network traffic, along with various types of attacks. We also present a realistic testbed environment for addressing the existing dataset drawbacks of capturing complete network information, accurate labeling, as well as recent and complex attack diversity. Finally, we evaluate the reliability of the BoT-IoT dataset using different statistical and machine learning methods for forensics purposes compared with the benchmark datasets. This work provides the baseline for allowing botnet identification across IoT-specific networks. The Bot-IoT dataset can be accessed at Bot-iot (2018) [1].},
	language = {en},
	urldate = {2021-10-23},
	journal = {Future Generation Computer Systems},
	author = {Koroniotis, Nickolaos and Moustafa, Nour and Sitnikova, Elena and Turnbull, Benjamin},
	month = nov,
	year = {2019},
	pages = {779--796},
}

@article{konecny_federated_2016,
	title = {Federated {Optimization}: {Distributed} {Machine} {Learning} for {On}-{Device} {Intelligence}},
	url = {http://arxiv.org/abs/1610.02527},
	abstract = {We introduce a new and increasingly relevant setting for distributed optimization in machine learning, where the data defining the optimization are unevenly distributed over an extremely large number of nodes. The goal is to train a high-quality centralized model. We refer to this setting as Federated Optimization. In this setting, communication efficiency is of the utmost importance and minimizing the number of rounds of communication is the principal goal. A motivating example arises when we keep the training data locally on users' mobile devices instead of logging it to a data center for training. In federated optimziation, the devices are used as compute nodes performing computation on their local data in order to update a global model. We suppose that we have extremely large number of devices in the network --- as many as the number of users of a given service, each of which has only a tiny fraction of the total data available. In particular, we expect the number of data points available locally to be much smaller than the number of devices. Additionally, since different users generate data with different patterns, it is reasonable to assume that no device has a representative sample of the overall distribution. We show that existing algorithms are not suitable for this setting, and propose a new algorithm which shows encouraging experimental results for sparse convex problems. This work also sets a path for future research needed in the context of {\textbackslash}federated optimization.},
	author = {Konečný, Jakub and McMahan, H. Brendan and Ramage, Daniel and Richtárik, Peter},
	month = oct,
	year = {2016},
	pages = {1--38},
}

@article{konecny_federated_2016-1,
	title = {Federated {Learning}: {Strategies} for {Improving} {Communication} {Efficiency}},
	url = {http://arxiv.org/abs/1610.05492},
	abstract = {Federated Learning is a machine learning setting where the goal is to train a high-quality centralized model while training data remains distributed over a large number of clients each with unreliable and relatively slow network connections. We consider learning algorithms for this setting where on each round, each client independently computes an update to the current model based on its local data, and communicates this update to a central server, where the client-side updates are aggregated to compute a new global model. The typical clients in this setting are mobile phones, and communication efficiency is of the utmost importance. In this paper, we propose two ways to reduce the uplink communication costs: structured updates, where we directly learn an update from a restricted space parametrized using a smaller number of variables, e.g. either low-rank or a random mask; and sketched updates, where we learn a full model update and then compress it using a combination of quantization, random rotations, and subsampling before sending it to the server. Experiments on both convolutional and recurrent networks show that the proposed methods can reduce the communication cost by two orders of magnitude.},
	author = {Konečný, Jakub and McMahan, H. Brendan and Yu, Felix X. and Richtárik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
	month = oct,
	year = {2016},
	pages = {1--10},
}

@article{kilincer_machine_2021,
	title = {Machine learning methods for cyber security intrusion detection: {Datasets} and comparative study},
	volume = {188},
	issn = {1389-1286},
	shorttitle = {Machine learning methods for cyber security intrusion detection},
	url = {https://www.sciencedirect.com/science/article/pii/S1389128621000141},
	doi = {10.1016/j.comnet.2021.107840},
	abstract = {The increase in internet usage brings security problems with it. Malicious software can affect the operation of the systems and disrupt data confidentiality due to the security gaps in the systems. Intrusion Detection Systems (IDS) have been developed to detect and report attacks. In order to develop IDS systems, artificial intelligence-based approaches have been used more frequently. In this study, literature studies using CSE-CIC IDS-2018, UNSW-NB15, ISCX-2012, NSL-KDD and CIDDS-001 data sets, which are widely used to develop IDS systems, are reviewed in detail. In addition, max-min normalization was performed on these data sets and classification was made with support vector machine (SVM), K-Nearest neighbor (KNN), Decision Tree (DT) algorithms, which are among the classical machine learning approaches. As a result, more successful results have been obtained in some of the studies given in the literature. The study is thought to be useful for developing IDS systems on the basis of artificial intelligence with approaches such as machine learning.},
	language = {en},
	urldate = {2022-08-18},
	journal = {Computer Networks},
	author = {Kilincer, Ilhan Firat and Ertam, Fatih and Sengur, Abdulkadir},
	month = apr,
	year = {2021},
	keywords = {Cyber security, DT, IDS, KNN, Machine learning, SVM},
	pages = {107840},
}

@article{kiss_kharon_2016,
	title = {Kharon dataset: {Android} malware under a microscope},
	abstract = {Background – This study is related to the understanding of Android malware that now populate smartphone’s markets. Aim – Our main objective is to help other malware researchers to better understand how malware works. Additionally, we aim at supporting the reproducibility of experiments analyzing malware samples: such a collection should improve the comparison of new detection or analysis methods. Methodology – In order to achieve these goals, we describe here an Android malware collection called Kharon. This collection gives as much as possible a representation of the diversity of malware types. With such a dataset, we manually dissected each malware by reversing their code. We run them in a controlled and monitored real smartphone in order to extract their precise behavior. We also summarized their behavior using a graph representations of the information ﬂows induced by an execution. With such a process, we obtained a precise knowledge of their malicious code and actions. Results and conclusions – Researchers can ﬁgure out the engineering efforts of malware developers and understand their programming patterns. Another important result of this study is that most of malware now include triggering techniques that delay and hide their malicious activities. We also think that this collection can initiate a reference test set for future research works.},
	language = {en},
	author = {Kiss, N and Lalande, J.-F. and Leslous, M. and Viet Triem Tong, V.},
	year = {2016},
	keywords = {⛔ No DOI found},
	pages = {12},
}

@article{kolias_intrusion_2016,
	title = {Intrusion {Detection} in 802.11 {Networks}: {Empirical} {Evaluation} of {Threats} and a {Public} {Dataset}},
	volume = {18},
	issn = {1553-877X},
	url = {http://ieeexplore.ieee.org/document/7041170/},
	doi = {10.1109/COMST.2015.2402161},
	abstract = {WiFi has become the de facto wireless technology for achieving short- to medium-range device connectivity. While early attempts to secure this technology have been proved inadequate in several respects, the current more robust security amendments will inevitably get outperformed in the future, too. In any case, several security vulnerabilities have been spotted in virtually any version of the protocol rendering the integration of external protection mechanisms a necessity. In this context, the contribution of this paper is multifold. First, it gathers, categorizes, thoroughly evaluates the most popular attacks on 802.11 and analyzes their signatures. Second, it offers a publicly available dataset containing a rich blend of normal and attack traffic against 802.11 networks. A quite extensive first-hand evaluation of this dataset using several machine learning algorithms and data features is also provided. Given that to the best of our knowledge the literature lacks such a rich and well-tailored dataset, it is anticipated that the results of the work at hand will offer a solid basis for intrusion detection in the current as well as next-generation wireless networks.},
	number = {1},
	journal = {IEEE Communications Surveys \& Tutorials},
	author = {Kolias, Constantinos and Kambourakis, Georgios and Stavrou, Angelos and Gritzalis, Stefanos},
	year = {2016},
	note = {Publisher: IEEE},
	keywords = {+survey},
	pages = {184--208},
}

@article{kim_federated_2021,
	title = {Federated {Learning} with {Local} {Differential} {Privacy}: {Trade}-offs between {Privacy}, {Utility}, and {Communication}},
	author = {Kim, Muah and Gunlu, Onur and Schaefer, Rafael F},
	year = {2021},
	note = {Medium: Cryptology ePrint Archive, Report 2021/142},
	keywords = {⛔ No DOI found},
}

@article{kolias_ddos_2017,
	title = {{DDoS} in the {IoT}: {Mirai} and {Other} {Botnets}},
	volume = {50},
	issn = {0018-9162},
	url = {http://ieeexplore.ieee.org/document/7971869/},
	doi = {10.1109/MC.2017.201},
	abstract = {The Mirai botnet and its variants and imitators are a wake-up call to the industry to better secure Internet of Things devices or risk exposing the Internet infrastructure to increasingly disruptive distributed denial-of-service attacks.},
	number = {7},
	journal = {Computer},
	author = {Kolias, Constantinos and Kambourakis, Georgios and Stavrou, Angelos and Voas, Jeffrey},
	year = {2017},
	note = {Publisher: IEEE
ISBN: 978-1-5090-4862-5},
	pages = {80--84},
}

@article{khoa_deep_2021,
	title = {Deep {Transfer} {Learning}: {A} {Novel} {Collaborative} {Learning} {Model} for {Cyberattack} {Detection} {Systems} in {IoT} {Networks}},
	shorttitle = {Deep {Transfer} {Learning}},
	url = {http://arxiv.org/abs/2112.00988},
	abstract = {Federated Learning (FL) has recently become an effective approach for cyberattack detection systems, especially in Internet-of-Things (IoT) networks. By distributing the learning process across IoT gateways, FL can improve learning efﬁciency, reduce communication overheads and enhance privacy for cyberattack detection systems. Challenges in implementation of FL in such systems include unavailability of labeled data and dissimilarity of data features in different IoT networks. In this paper, we propose a novel collaborative learning framework that leverages Transfer Learning (TL) to overcome these challenges. Particularly, we develop a novel collaborative learning approach that enables a target network with unlabeled data to effectively and quickly learn “knowledge” from a source network that possesses abundant labeled data. It is important that the stateof-the-art studies require the participated datasets of networks to have the same features, thus limiting the efﬁciency, ﬂexibility as well as scalability of intrusion detection systems. However, our proposed framework can address these problems by exchanging the learning “knowledge” among various deep learning models, even when their datasets have different features. Extensive experiments on recent real-world cybersecurity datasets show that the proposed framework can improve more than 40\% as compared to the state-of-the-art deep learning based approaches.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:2112.00988 [cs]},
	author = {Khoa, Tran Viet and Hoang, Dinh Thai and Trung, Nguyen Linh and Nguyen, Cong T. and Quynh, Tran Thi Thuy and Nguyen, Diep N. and Ha, Nguyen Viet and Dutkiewicz, Eryk},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.00988},
	keywords = {Computer Science - Machine Learning, ⛔ No DOI found},
}

@article{khraisat_critical_2021,
	title = {A critical review of intrusion detection systems in the internet of things: techniques, deployment strategy, validation strategy, attacks, public datasets and challenges},
	volume = {4},
	copyright = {2021 The Author(s)},
	issn = {2523-3246},
	shorttitle = {A critical review of intrusion detection systems in the internet of things},
	url = {https://cybersecurity.springeropen.com/articles/10.1186/s42400-021-00077-7},
	doi = {10.1186/s42400-021-00077-7},
	abstract = {The Internet of Things (IoT) has been rapidly evolving towards making a greater impact on everyday life to large industrial systems. Unfortunately, this has attracted the attention of cybercriminals who made IoT a target of malicious activities, opening the door to a possible attack on the end nodes. To this end, Numerous IoT intrusion detection Systems (IDS) have been proposed in the literature to tackle attacks on the IoT ecosystem, which can be broadly classified based on detection technique, validation strategy, and deployment strategy. This survey paper presents a comprehensive review of contemporary IoT IDS and an overview of techniques, deployment Strategy, validation strategy and datasets that are commonly applied for building IDS. We also review how existing IoT IDS detect intrusive attacks and secure communications on the IoT. It also presents the classification of IoT attacks and discusses future research challenges to counter such IoT attacks to make IoT more secure. These purposes help IoT security researchers by uniting, contrasting, and compiling scattered research efforts. Consequently, we provide a unique IoT IDS taxonomy, which sheds light on IoT IDS techniques, their advantages and disadvantages, IoT attacks that exploit IoT communication systems, corresponding advanced IDS and detection capabilities to detect IoT attacks.},
	language = {en},
	number = {1},
	urldate = {2022-08-18},
	journal = {Cybersecurity},
	author = {Khraisat, Ansam and Alazab, Ammar},
	month = dec,
	year = {2021},
	note = {Number: 1
Publisher: SpringerOpen},
	keywords = {+survey},
	pages = {1--27},
}

@article{khraisat_survey_2019,
	title = {Survey of intrusion detection systems: techniques, datasets and challenges},
	volume = {2},
	issn = {2523-3246},
	shorttitle = {Survey of intrusion detection systems},
	url = {https://cybersecurity.springeropen.com/articles/10.1186/s42400-019-0038-7},
	doi = {10.1186/s42400-019-0038-7},
	abstract = {Cyber-attacks are becoming more sophisticated and thereby presenting increasing challenges in accurately detecting intrusions. Failure to prevent the intrusions could degrade the credibility of security services, e.g. data confidentiality, integrity, and availability. Numerous intrusion detection methods have been proposed in the literature to tackle computer security threats, which can be broadly classified into Signature-based Intrusion Detection Systems (SIDS) and Anomaly-based Intrusion Detection Systems (AIDS). This survey paper presents a taxonomy of contemporary IDS, a comprehensive review of notable recent works, and an overview of the datasets commonly used for evaluation purposes. It also presents evasion techniques used by attackers to avoid detection and discusses future research challenges to counter such techniques so as to make computer systems more secure.},
	language = {en},
	number = {1},
	urldate = {2022-03-11},
	journal = {Cybersecurity},
	author = {Khraisat, Ansam and Gondal, Iqbal and Vamplew, Peter and Kamruzzaman, Joarder},
	month = dec,
	year = {2019},
	keywords = {+survey},
	pages = {20},
}

@article{keshav_how_2007,
	title = {How to read a paper},
	volume = {37},
	number = {3},
	journal = {acm special interest group on data communication},
	author = {Keshav, S.},
	year = {2007},
	keywords = {⛔ No DOI found},
	pages = {83--84},
}

@article{kashani_deep_2021,
	title = {{DEEP} {LEARNING} {INTERVIEWS}},
	language = {en},
	author = {Kashani, Shlomo},
	month = oct,
	year = {2021},
	keywords = {⛔ No DOI found},
	pages = {401},
}

@article{karantzas_empirical_2021,
	title = {An {Empirical} {Assessment} of {Endpoint} {Detection} and {Response} {Systems} against {Advanced} {Persistent} {Threats} {Attack} {Vectors}},
	volume = {1},
	issn = {2624-800X},
	url = {https://www.mdpi.com/2624-800X/1/3/21},
	doi = {10.3390/jcp1030021},
	abstract = {Advanced persistent threats pose a signiﬁcant challenge for blue teams as they apply various attacks over prolonged periods, impeding event correlation and their detection. In this work, we leverage various diverse attack scenarios to assess the efﬁcacy of EDRs against detecting and preventing APTs. Our results indicate that there is still a lot of room for improvement as state-of-theart EDRs fail to prevent and log the bulk of the attacks that are reported in this work. Additionally, we discuss methods to tamper with the telemetry providers of EDRs, allowing an adversary to perform a more stealth attack.},
	language = {en},
	number = {3},
	urldate = {2021-07-20},
	journal = {Journal of Cybersecurity and Privacy},
	author = {Karantzas, George and Patsakis, Constantinos},
	month = jul,
	year = {2021},
	pages = {387--421},
}

@article{kephart_vision_2003,
	title = {The vision of autonomic computing},
	volume = {36},
	issn = {0018-9162},
	url = {http://ieeexplore.ieee.org/document/1160055/},
	doi = {10.1109/MC.2003.1160055},
	abstract = {A 2001 IBM manifesto observed that a looming software complexity crisis - caused by applications and environments that number into the tens of millions of lines of code - threatened to halt progress in computing. The manifesto noted the almost impossible difficulty of managing current and planned computing systems, which require integrating several heterogeneous environments into corporate-wide computing systems that extend into the Internet. Autonomic computing, perhaps the most attractive approach to solving this problem, creates systems that can manage themselves when given high-level objectives from administrators. Systems manage themselves according to an administrator's goals. New components integrate as effortlessly as a new cell establishes itself in the human body. These ideas are not science fiction, but elements of the grand challenge to create self-managing computing systems.},
	number = {1},
	journal = {Computer},
	author = {Kephart, J.O. and Chess, D.M.},
	month = jan,
	year = {2003},
	pages = {41--50},
}

@article{katevas_policy-based_2020,
	title = {Policy-{Based} {Federated} {Learning}},
	url = {http://arxiv.org/abs/2003.06612},
	abstract = {In this paper we present PoliFL, a decentralized, edge-based framework that supports heterogeneous privacy policies for federated learning. We evaluate our system on three use cases that train models with sensitive user data collected by mobile phones - predictive text, image classification, and notification engagement prediction - on a Raspberry Pi edge device. We find that PoliFL is able to perform accurate model training and inference within reasonable resource and time budgets while also enforcing heterogeneous privacy policies.},
	author = {Katevas, Kleomenis and Bagdasaryan, Eugene and Waterman, Jason and Safadieh, Mohamad Mounir and Birrell, Eleanor and Haddadi, Hamed and Estrin, Deborah},
	month = mar,
	year = {2020},
	keywords = {⛔ No DOI found},
}

@article{kang_incentive_2019,
	title = {Incentive {Mechanism} for {Reliable} {Federated} {Learning}: {A} {Joint} {Optimization} {Approach} to {Combining} {Reputation} and {Contract} {Theory}},
	volume = {6},
	issn = {2327-4662},
	shorttitle = {Incentive {Mechanism} for {Reliable} {Federated} {Learning}},
	doi = {10.1109/JIOT.2019.2940820},
	abstract = {Federated learning is an emerging machine learning technique that enables distributed model training using local datasets from large-scale nodes, e.g., mobile devices, but shares only model updates without uploading the raw training data. This technique provides a promising privacy preservation for mobile devices while simultaneously ensuring high learning performance. The majority of existing work has focused on designing advanced learning algorithms with an aim to achieve better learning performance. However, the challenges, such as incentive mechanisms for participating in training and worker (i.e., mobile devices) selection schemes for reliable federated learning, have not been explored yet. These challenges have hindered the widespread adoption of federated learning. To address the above challenges, in this article, we first introduce reputation as the metric to measure the reliability and trustworthiness of the mobile devices. We then design a reputation-based worker selection scheme for reliable federated learning by using a multiweight subjective logic model. We also leverage the blockchain to achieve secure reputation management for workers with nonrepudiation and tamper-resistance properties in a decentralized manner. Moreover, we propose an effective incentive mechanism combining reputation with contract theory to motivate high-reputation mobile devices with high-quality data to participate in model learning. Numerical results clearly indicate that the proposed schemes are efficient for reliable federated learning in terms of significantly improving the learning accuracy.},
	number = {6},
	journal = {IEEE Internet of Things Journal},
	author = {Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Xie, Shengli and Zhang, Junshan},
	month = dec,
	year = {2019},
	keywords = {Blockchain, Contracts, Data models, Mobile handsets, Reliability, Task analysis, Training, contract theory, federated learning, mobile networks, reputation, security and privacy},
	pages = {10700--10714},
}

@article{kaloroumakis_toward_2021,
	title = {Toward a {Knowledge} {Graph} of {Cybersecurity} {Countermeasures}},
	abstract = {This paper describes our research and development toward a precise, unambiguous, and information-dense knowledge graph of cybersecurity countermeasures. In project work for our sponsors we have repeatedly encountered the need for a model that can identify and precisely specify cybersecurity countermeasure components and capabilities. Furthermore, it is necessary that practitioners know not only what threats a capability claims to address, but, speciﬁcally how those threats are addressed from an engineering perspective, and under what circumstances the solution would work. This knowledge is essential to estimate operational applicability, vulnerabilities, and develop enterprise solutions comprising multiple capabilities. To address this recurring need in the near-term, we created D3FEND, a framework in which we encode a countermeasure knowledge base, but more speciﬁcally, a knowledge graph. The graph contains semantically rigorous types and relations that deﬁne both the key concepts in the cybersecurity countermeasure domain and the relations necessary to link those concepts to each other. We ground each of the concepts and relations to particular references in the cybersecurity literature. Numerous sources of research and development literature were analyzed, including a targeted sample of over 500 countermeasure patents drawn from the U.S. Patent Ofﬁce corpus over the years 2001 to 2018. To demonstrate the value of this approach in practice, we describe how the graph supports queries that can inferentially map cybersecurity countermeasures to offensive TTPs. As part of a larger vision, we outline future D3FEND work to leverage the linked open data available on research literature and apply machine learning, in particular semi-supervised methods, to assist in maintaining the D3FEND knowledge graph over time. Finally, we welcome community feedback on D3FEND.},
	language = {en},
	author = {Kaloroumakis, Peter E and Smith, Michael J},
	year = {2021},
	keywords = {⛔ No DOI found},
	pages = {11},
}

@article{kairouz_advances_2021,
	title = {Advances and {Open} {Problems} in {Federated} {Learning}},
	url = {http://arxiv.org/abs/1912.04977},
	abstract = {Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in FL research, this paper discusses recent advances and presents an extensive collection of open problems and challenges.},
	language = {en},
	urldate = {2022-04-01},
	journal = {arXiv:1912.04977 [cs, stat]},
	author = {Kairouz, Peter and McMahan, H. Brendan and Avent, Brendan and Bellet, Aurélien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and D'Oliveira, Rafael G. L. and Eichner, Hubert and Rouayheb, Salim El and Evans, David and Gardner, Josh and Garrett, Zachary and Gascón, Adrià and Ghazi, Badih and Gibbons, Phillip B. and Gruteser, Marco and Harchaoui, Zaid and He, Chaoyang and He, Lie and Huo, Zhouyuan and Hutchinson, Ben and Hsu, Justin and Jaggi, Martin and Javidi, Tara and Joshi, Gauri and Khodak, Mikhail and Konečný, Jakub and Korolova, Aleksandra and Koushanfar, Farinaz and Koyejo, Sanmi and Lepoint, Tancrède and Liu, Yang and Mittal, Prateek and Mohri, Mehryar and Nock, Richard and Özgür, Ayfer and Pagh, Rasmus and Raykova, Mariana and Qi, Hang and Ramage, Daniel and Raskar, Ramesh and Song, Dawn and Song, Weikang and Stich, Sebastian U. and Sun, Ziteng and Suresh, Ananda Theertha and Tramèr, Florian and Vepakomma, Praneeth and Wang, Jianyu and Xiong, Li and Xu, Zheng and Yang, Qiang and Yu, Felix X. and Yu, Han and Zhao, Sen},
	month = mar,
	year = {2021},
	note = {arXiv: 1912.04977},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning, ⛔ No DOI found},
}

@article{kang_blockchain_2019,
	title = {Blockchain for {Secure} and {Efficient} {Data} {Sharing} in {Vehicular} {Edge} {Computing} and {Networks}},
	volume = {6},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/document/8489897/},
	doi = {10.1109/JIOT.2018.2875542},
	abstract = {The drastically increasing volume and the growing trend on the types of data have brought in the possibility of realizing advanced applications such as enhanced driving safety, and have enriched existing vehicular services through data sharing among vehicles and data analysis. Due to limited resources with vehicles, vehicular edge computing and networks (VECONs) i.e., the integration of mobile edge computing and vehicular networks, can provide powerful computing and massive storage resources. However, road side units that primarily presume the role of vehicular edge computing servers cannot be fully trusted, which may lead to serious security and privacy challenges for such integrated platforms despite their promising potential and benefits. We exploit consortium blockchain and smart contract technologies to achieve secure data storage and sharing in vehicular edge networks. These technologies efficiently prevent data sharing without authorization. In addition, we propose a reputation-based data sharing scheme to ensure high-quality data sharing among vehicles. A three-weight subjective logic model is utilized for precisely managing reputation of the vehicles. Numerical results based on a real dataset show that our schemes achieve reasonable efficiency and high-level of security for data sharing in VECONs.},
	number = {3},
	journal = {IEEE Internet of Things Journal},
	author = {Kang, Jiawen and Yu, Rong and Huang, Xumin and Wu, Maoqiang and Maharjan, Sabita and Xie, Shengli and Zhang, Yan},
	month = jun,
	year = {2019},
	note = {Publisher: IEEE},
	pages = {4660--4670},
}

@article{jiang_fedhgcdroid_2022,
	title = {{FedHGCDroid}: {An} {Adaptive} {Multi}-{Dimensional} {Federated} {Learning} for {Privacy}-{Preserving} {Android} {Malware} {Classification}},
	volume = {24},
	issn = {1099-4300},
	shorttitle = {{FedHGCDroid}},
	url = {https://www.mdpi.com/1099-4300/24/7/919},
	doi = {10.3390/e24070919},
	abstract = {With the popularity of Android and its open source, the Android platform has become an attractive target for hackers, and the detection and classiﬁcation of malware has become a research hotspot. Existing malware classiﬁcation methods rely on complex manual operation or large-volume high-quality training data. However, malware data collected by security providers contains user privacy information, such as user identity and behavior habit information. The increasing concern for user privacy poses a challenge to the current malware classiﬁcation scheme. Based on this problem, we propose a new android malware classiﬁcation scheme based on Federated learning, named FedHGCDroid, which classiﬁes malware on Android clients in a privacy-protected manner. Firstly, we use a convolutional neural network and graph neural network to design a novel multi-dimensional malware classiﬁcation model HGCDroid, which can effectively extract malicious behavior features to classify the malware accurately. Secondly, we introduce an FL framework to enable distributed Android clients to collaboratively train a comprehensive Android malware classiﬁcation model in a privacy-preserving way. Finally, to adapt to the non-IID distribution of malware on Android clients, we propose a contribution degree-based adaptive classiﬁer training mechanism FedAdapt to improve the adaptability of the malware classiﬁer based on Federated learning. Comprehensive experimental studies on the Androzoo dataset (under different non-IID data settings) show that the FedHGCDroid achieves more adaptability and higher accuracy than the other state-of-the-art methods.},
	language = {en},
	number = {7},
	urldate = {2022-08-11},
	journal = {Entropy},
	author = {Jiang, Changnan and Yin, Kanglong and Xia, Chunhe and Huang, Weidong},
	month = jul,
	year = {2022},
	pages = {919},
}

@article{jiang_doll_2022,
	title = {{DOLL}: {Distributed} {OnLine} {Learning} {Using} {Preemptible} {Cloud} {Instances} - {Technical} {Report}},
	abstract = {Many companies are increasingly making machine learning integral to their businesses. To defray the resulting compute costs, much work has proposed using preemptible cloud instances, a discount tier of virtual machine rentals that may be interrupted at the cloud provider’s discretion, to run machine learning jobs. However, processing data streams on preemptible instances presents new challenges: processing data points as they arrive may lead to bottlenecks when scaling the system to handle higher throughput, particularly if the instances are frequently interrupted. Ours is the first work to design, analyze, and optimize a system that trains a machine learning model on a set of data streams with online stochastic gradient descent (SGD) on preemptible instances. Our system, DOLL, uses queueing and batching to parallelize and scale SGD to large numbers of workers and incoming data streams, as well as heterogeneous data arrival rates across streams. An expected error convergence guarantee is then derived for DOLL’s training process. We use this guarantee to optimize the cost of requisitioning preemptible and on-demand instances in the face of a performance target and wall-clock time deadline; this optimization is validated on experiments demonstrating substantial cost savings with little impact on model error, compared to on-demand instances.},
	language = {en},
	author = {Jiang, Harry and Zhang, Xiaoxi and Joe-Wong, Carlee},
	year = {2022},
	keywords = {⛔ No DOI found},
	pages = {12},
}

@article{johnson_mimic-iii_2016,
	title = {{MIMIC}-{III}, a freely accessible critical care database},
	volume = {3},
	issn = {2052-4463},
	url = {https://doi.org/10.1038/sdata.2016.35},
	doi = {10.1038/sdata.2016.35},
	abstract = {MIMIC-III (‘Medical Information Mart for Intensive Care’) is a large, single-center database comprising information relating to patients admitted to critical care units at a large tertiary care hospital. Data includes vital signs, medications, laboratory measurements, observations and notes charted by care providers, fluid balance, procedure codes, diagnostic codes, imaging reports, hospital length of stay, survival data, and more. The database supports applications including academic and industrial research, quality improvement initiatives, and higher education coursework.},
	number = {1},
	journal = {Scientific Data},
	author = {Johnson, Alistair E.W. and Pollard, Tom J. and Shen, Lu and Lehman, Li-wei H. and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Anthony Celi, Leo and Mark, Roger G.},
	year = {2016},
	pages = {160035},
}

@article{johnson_intrinsic_2021,
	title = {Intrinsic {Propensity} for {Vulnerability} in {Computers}? {Arbitrary} {Code} {Execution} in the {Universal} {Turing} {Machine}},
	shorttitle = {Intrinsic {Propensity} for {Vulnerability} in {Computers}?},
	url = {http://arxiv.org/abs/2105.02124},
	abstract = {The universal Turing machine is generally considered to be the simplest, most abstract model of a computer. This paper reports on the discovery of an accidental arbitrary code execution vulnerability in Marvin Minsky’s 1967 implementation of the universal Turing machine. By submitting crafted data, the machine may be coerced into executing user-provided code. The article presents the discovered vulnerability in detail and discusses its potential implications. To the best of our knowledge, an arbitrary code execution vulnerability has not previously been reported for such a simple system.},
	language = {en},
	urldate = {2021-06-01},
	journal = {arXiv:2105.02124 [cs]},
	author = {Johnson, Pontus},
	month = apr,
	year = {2021},
	note = {arXiv: 2105.02124},
	keywords = {⛔ No DOI found},
}

@article{hou_network_2022,
	title = {Network intrusion detection based on {DNA} spatial information},
	issn = {1389-1286},
	url = {https://www.sciencedirect.com/science/article/pii/S1389128622003620},
	doi = {10.1016/j.comnet.2022.109318},
	abstract = {There is an ever-increasing risk of illegal access-induced Network Intrusion (NI), which calls for prompt detection of illegal network behavior through profound Network Traffic (NT) analyses. However, current intrusion detection methods are limited in accuracy due to insufficient data standardization. This paper puts forward a deoxyribonucleic acid (DNA)-Spatial Information (SI) method to overcome these limitations. A DNA encoding model is formed, which defines a mapping relationship between NT attributes and nucleobases to reconstruct NT samples expressed as DNA sequences. Then, a feature extraction algorithm is constructed that deduces a Spatial Information Feature Matrix (SIFM) to represent sequence statistical features. A Random Forest (RF) algorithm is adopted as a matching process to determine NI behaviors considering the detection efficiency. Following experiments evaluate its method performance on two datasets, NSL-KDD and UNSW-NB15. Results demonstrate that DNA-SI obtains better results than state-of-the-art works, where the accuracy, F1-score, recall, far are 95.75\%, 94.41\%, 94.12\%, 3.26\% and 92.30\%, 92.78\%, 89.82\%, 4.66\% respectively. The fact that it is insusceptible to minority intrusion samples is another point worth attention. In sum, this quick and accurate network intrusion detection points to a new orientation for safeguarding network security.},
	language = {en},
	urldate = {2022-08-31},
	journal = {Computer Networks},
	author = {Hou, Tianhao and Xing, Hongyan and Liang, Xinyi and Su, Xin and Wang, Zenghui},
	month = aug,
	year = {2022},
	keywords = {Cybersecurity, DNA encoding, IDS, Intrusion detection},
	pages = {109318},
}

@article{hou_federated_2022,
	title = {A {Federated} {Learning}-{Based} {Fault} {Detection} {Algorithm} for {Power} {Terminals}},
	volume = {2022},
	issn = {1024-123X},
	url = {https://www.hindawi.com/journals/mpe/2022/9031701/},
	doi = {10.1155/2022/9031701},
	abstract = {Power terminal is an important part of the power grid, and fault detection of power terminals is essential for the safety of the power grid. Existing fault detection of power terminals is usually based on artificial intelligent or deep learning models in the cloud or edge servers to achieve high accuracy and low latency. However, these methods cannot protect the privacy of the terminals and update the detection model incrementally. A terminal-edge-server collaborative fault detection model based on federated learning is proposed in this study to improve the accuracy of fault detection, reduce the data transmission and protect the privacy of the terminals. The fault detection model is initially trained in the server using historical data and updated using the parameters of local models from edge servers according to different updating strategies, then the parameters will be sent to each edge server and further to all terminals. Each edge server updates the local model via the compressed system log from terminals in its coverage region, and each terminal uses the model to detect fault according to the system behavior in the log. Experiment results show that this fault detection algorithm has high accuracy and low latency, and the accuracy increases with more model updating.},
	language = {en},
	urldate = {2022-08-11},
	journal = {Mathematical Problems in Engineering},
	author = {Hou, Shuai and Lu, Jizhe and Zhu, Enguo and Zhang, Hailong and Ye, Aliaosha},
	month = jul,
	year = {2022},
	note = {Publisher: Hindawi},
	pages = {e9031701},
}

@article{jayasinghe_federated_2022,
	title = {Federated {Learning} based {Anomaly} {Detection} as an {Enabler} for {Securing} {Network} and {Service} {Management} {Automation} in {Beyond} {5G} {Networks}},
	abstract = {Network automation is a necessity in order to meet the unprecedented demand in the future networks and zero touch network architecture is proposed to cater such requirements. Closed-loop and artificial intelligence are key enablers in this proposed architecture in critical elements such as security. Apart from the arising privacy concerns, machine learning models can also face resource limitations. Federated learning is a machine learning based techniques which address both privacy and communication efficiency issues. Therefore, we propose a federated learning based model incorporating ZSM architecture for network automation. The paper also contains the simulations and its results of the proposed multi-stage federated learning based which use UNSW-NB15 Dataset.},
	language = {en},
	author = {Jayasinghe, Suwani and Siriwardhana, Yushan and Porambage, Pawani and Liyanage, Madhusanka and Ylianttila, Mika},
	month = jun,
	year = {2022},
	keywords = {⛔ No DOI found},
	pages = {7},
}

@article{huang_efmvfl_2022,
	title = {{EFMVFL}: {An} {Efficient} and {Flexible} {Multi}-party {Vertical} {Federated} {Learning} without a {Third} {Party}},
	shorttitle = {{EFMVFL}},
	url = {http://arxiv.org/abs/2201.06244},
	abstract = {Federated learning allows multiple participants to conduct joint modeling without disclosing their local data. Vertical federated learning (VFL) handles the situation where participants share the same ID space and different feature spaces. In most VFL frameworks, to protect the security and privacy of the participants’ local data, a third party is needed to generate homomorphic encryption key pairs and perform decryption operations. In this way, the third party is granted the right to decrypt information related to model parameters. However, it isn’t easy to ﬁnd such a credible entity in the real world. Existing methods for solving this problem are either communication-intensive or unsuitable for multi-party scenarios. By combining secret sharing and homomorphic encryption, we propose a novel VFL framework without a third party called EFMVFL, which supports ﬂexible expansion to multiple participants with low communication overhead and is applicable to generalized linear models. We give instantiations of our framework under logistic regression and Poisson regression. Theoretical analysis and experiments show that our framework is secure, more efﬁcient, and easy to be extended to multiple participants.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:2201.06244 [cs]},
	author = {Huang, Yimin and Feng, Xinyu and Wang, Wanwan and He, Hao and Wang, Yukun and Yao, Ming},
	month = jan,
	year = {2022},
	note = {arXiv: 2201.06244},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, ⛔ No DOI found},
}

@article{hossain_adversarial_2022,
	title = {Adversarial {Analysis} of the {Differentially}-{Private} {Federated} {Learning} in {Cyber}-{Physical} {Critical} {Infrastructures}},
	url = {http://arxiv.org/abs/2204.02654},
	abstract = {Differential privacy (DP) is considered to be an effective privacy-preservation method to secure the promising distributed machine learning (ML) paradigm- federated learning (FL) from privacy attacks (e.g., membership inference attack). Nevertheless, while the DP mechanism greatly alleviates the privacy concerns, recent studies have shown that it can be exploited to conduct security attacks (e.g., false data injection attacks). To address such attacks on FL-based applications in critical infrastructures, in this paper, we perform the ﬁrst systematic study on the DP-exploited poisoning attacks from an adversarial point of view. We demonstrate that the DP method, despite providing a level of privacy guarantee, can effectively open a new poisoning attack vector for the adversary. Our theoretical analysis and empirical evaluation on a smart grid dataset show the FL performance degradation (sub-optimal model generation) scenario due to the differential noise-exploited selective model poisoning attacks. As a countermeasure, we propose a reinforcement learning-based differential privacy level selection (rDP) process. The rDP process utilizes the differential privacy parameters (privacy loss, information leakage probability, etc.) and the losses to intelligently generate an optimal privacy level for the nodes. The evaluation shows the accumulated reward and errors of the proposed technique converge to an optimal privacy policy.},
	language = {en},
	urldate = {2022-04-13},
	journal = {arXiv:2204.02654 [cs]},
	author = {Hossain, Md Tamjid and Badsha, Shahriar and Hung and La and Shen, Haoting and Islam, Shafkat and Khalil, Ibrahim and Yi, Xun},
	month = apr,
	year = {2022},
	note = {arXiv: 2204.02654},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Distributed, Parallel, and Cluster Computing, ⛔ No DOI found},
}

@article{hernandez_wifederated_2021,
	title = {{WiFederated}: {Scalable} {WiFi} {Sensing} using {Edge} {Based} {Federated} {Learning}},
	issn = {2327-4662, 2372-2541},
	shorttitle = {{WiFederated}},
	url = {https://ieeexplore.ieee.org/document/9659826/},
	doi = {10/gpbg3t},
	abstract = {WiFi sensing using Channel State Information (CSI) offers a device-free and non-intrusive method for human activity monitoring. However, the data-hungry and location-specific training process hinders its scalable deployment at large sizes. In this work, we propose WiFederated, a federated learning (FL) approach to train machine learning models for WiFi sensing tasks. Using WiFederated, client devices can not only perform training in parallel at the edge instead of sequentially at a central server but can also collaboratively learn and share generalizable location-independent traits about physical actions being monitored. We demonstrate that an FL model trained on as few as 2-3 locations can provide high prediction accuracy in new locations even without any data available from them. We also demonstrate how new locations can achieve higher prediction accuracy even with a small number of available samples when using the pretrained FL model rather than training from scratch. The results show that the FL model can save local training epochs and reduce the need for large data collection at each new location. Thus, the proposed WiFederated system scales as more locations are added. We show that WiFederated provides a more accurate and time efficient solution compared to existing transfer learning and adversarial learning solutions thanks to the parallel training ability at multiple clients. By introducing new client selection methods during the FL process, we also show that accuracy can further increase. Finally, we evaluate the feasibility of training models at the edge and introduce continuous annotation to allow for continuous learning over time.},
	language = {en},
	urldate = {2022-01-31},
	journal = {IEEE Internet of Things Journal},
	author = {Hernandez, Steven M. and Bulut, Eyuphan},
	year = {2021},
	pages = {1--1},
}

@article{hoffmann_souza_survey_2020,
	title = {A survey on decision-making based on system reliability in the context of {Industry} 4.0},
	volume = {56},
	issn = {02786125},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0278612520300807},
	doi = {10.1016/j.jmsy.2020.05.016},
	abstract = {The business world is continually changing. Dynamic environments, full of uncertainties, complexities, and ambiguities, demand faster and more confident decisions. To compete in this environment, Industry 4.0 emerges as an essential alternative. In this context, the reliability of manufacturing is an essential aspect for companies to make successful decisions. In the literature, several technologies associated with Industry 4.0 have been applied to improve the availability of equipment, including the Internet of Things (IoT), Cyber-Physical Systems (CPS), blockchain, and data mining. Nevertheless, there is still no survey study that seeks to show how reliability has collaborated to support decision-making in organizations, in the context of Industry 4.0. In general, most applications still focus on the productivity and health of individual equipment. However, in today's volatile and complex businesses, local decisions are no longer sufficient; it is necessary to analyze the organization entirely. Thus, being aware of the impacts that a local failure can impose on the entire company has significant weight in the decision-making process. In this context, this article presents a survey to identify how researches on systems reliability has contributed to and supported the development of decision-making in Industry 4.0. The main contribution of this article is to highlight how reliability can be used to support different types of strategic decisions in the context of Industry 4.0. Finally, it highlights the need for research associating management decisions with the technologies of Industry 4.0.},
	number = {May},
	journal = {Journal of Manufacturing Systems},
	author = {Hoffmann Souza, Marcos Leandro and da Costa, Cristiano André and de Oliveira Ramos, Gabriel and da Rosa Righi, Rodrigo},
	month = jul,
	year = {2020},
	pages = {133--156},
}

@article{hajimirzaee_chfl_nodate,
	title = {{CHFL}: {A} {Collaborative} {Hierarchical} {Federated} {Intrusion} {Detection} {System} for {Vehicular} {Networks}},
	abstract = {Wireless interfaces, remote control schemes, and increased autonomy have raised the attacks surface of vehicular networks. As powerful monitoring entities, intrusion detection systems (IDS) must be updated and customised to respond to emerging networks’ requirements. As server-based monitoring schemes were prone to signiﬁcant privacy concerns, new privacy constrained learning methods such as federated learning (FL) have received considerable attention in designing IDS. However, to alleviate the efﬁciency and enhance the scalability of the original FL, this paper proposes a novel collaborative hierarchical federated IDS, named CHFL for the vehicular network. In the CHFL model, a group of vehicles assisted by vehicle-to-everything (V2X) communication technologies can exchange intrusion detection information collaboratively in a private format. Each group nominates a leader, and the leading vehicle serves as the intermediate in the second level detection system of the hierarchical federated model. The leader communicates directly with the server to transmit and receive model updates of its nearby end vehicles. By reducing the number of direct communications to the server, our proposed system reduces network uplink trafﬁc and queuing-processing latency. In addition, CHFL improved the prediction loss and the accuracy of the whole system. We are achieving an accuracy of 99.10\% compared with 97.01\% accuracy of the original FL.},
	language = {en},
	author = {Hajimirzaee, Parya and Shojafar, Mohammad and Cruickshank, Haitham and Tafazolli, Rahim},
	keywords = {\_unpublished, ⛔ No DOI found},
	pages = {7},
}

@article{haines_1999_2001,
	title = {1999 {DARPA} {Intrusion} {Detection} {Evaluation}: {Design} and {Procedures}},
	language = {en},
	author = {Haines, J W and Lippmann, R P and Fried, DJ and Zissman, M A and Tran, E and Boswell, S B},
	year = {2001},
	keywords = {⛔ No DOI found},
	pages = {188},
}

@article{hand_note_2018,
	title = {A note on using the {F}-measure for evaluating record linkage algorithms},
	volume = {28},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-017-9746-6},
	doi = {10/gfw6dw},
	language = {en},
	number = {3},
	urldate = {2021-11-10},
	journal = {Statistics and Computing},
	author = {Hand, David and Christen, Peter},
	month = may,
	year = {2018},
	pages = {539--547},
}

@article{hardy_private_2017,
	title = {Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption},
	url = {http://arxiv.org/abs/1711.10677},
	abstract = {Consider two data providers, each maintaining private records of different feature sets about common entities. They aim to learn a linear model jointly in a federated setting, namely, data is local and a shared model is trained from locally computed updates. In contrast with most work on distributed learning, in this scenario (i) data is split vertically, i.e. by features, (ii) only one data provider knows the target variable and (iii) entities are not linked across the data providers. Hence, to the challenge of private learning, we add the potentially negative consequences of mistakes in entity resolution. Our contribution is twofold. First, we describe a three-party end-to-end solution in two phases—privacy-preserving entity resolution and federated logistic regression over messages encrypted with an additively homomorphic scheme—, secure against a honest-but-curious adversary. The system allows learning without either exposing data in the clear or sharing which entities the data providers have in common. Our implementation is as accurate as a naive non-private solution that brings all data in one place, and scales to problems with millions of entities with hundreds of features. Second, we provide what is to our knowledge the ﬁrst formal analysis of the impact of entity resolution’s mistakes on learning, with results on how optimal classiﬁers, empirical losses, margins and generalisation abilities are affected. Our results bring a clear and strong support for federated learning: under reasonable assumptions on the number and magnitude of entity resolution’s mistakes, it can be extremely beneﬁcial to carry out federated learning in the setting where each peer’s data provides a signiﬁcant uplift to the other.},
	language = {en},
	urldate = {2021-10-04},
	journal = {arXiv:1711.10677 [cs]},
	author = {Hardy, Stephen and Henecka, Wilko and Ivey-Law, Hamish and Nock, Richard and Patrini, Giorgio and Smith, Guillaume and Thorne, Brian},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.10677},
	keywords = {Computer Science - Machine Learning, \_read, ⛔ No DOI found},
}

@article{hamad_bin-iot_nodate,
	title = {{BIN}-{IoT} : {Behavioural} {Network} {Traffic} {Identification}},
	journal = {EEE Transactions on Network and Service Management},
	author = {Hamad, Salma Abdalla and Sheng, Quan Z. and Tran, Dai Hoang and Zhang, Wei Emma and Nepal, Surya},
	keywords = {\_unpublished, ⛔ No DOI found},
}

@article{habeeb_network_2022,
	title = {Network intrusion detection system: {A} survey on artificial intelligence-based techniques},
	volume = {n/a},
	issn = {1468-0394},
	shorttitle = {Network intrusion detection system},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13066},
	doi = {10.1111/exsy.13066},
	abstract = {High data rate requirements in recent years have resulted in the massive expansion of communication systems, network size and the amount of data generated and processed. This has eventually caused many threats to the communication networks as well due to a more frequent generation of security attacks that are either novel or the mutation of the existing attacks. To secure the networks against such threats, an intrusion detection system (IDS) is considered as one of the promising solutions. The main problem with the IDS is its increased false alarm rate (FAR) in detecting the zero-day attacks. To improve the detection accuracy and minimizing the FAR, the researchers proposed IDS solutions using artificial intelligence (AI) approaches. In this research, we have systematically reviewed the recent AI-based network IDS (NIDS) solutions proposed during the period 2016–2021 by the research community. We systematically analysed the proposed NIDS solutions based on their strengths, shortcomings, AI methodology adopted, datasets, and the evaluation metrics used for evaluation purposes. From the review, we observed that the hybrid approach is mostly adopted by the researchers to propose AI-based NIDS solutions, with a trend shifting to deep learning-based approaches over the last 2 years. Also, most of the proposed solutions are evaluated using a very old dataset with only a few studies opting for the latest datasets. Finally based on our observations, we highlighted the research challenges and the future research directions to help young researchers to contribute to this field.},
	language = {en},
	number = {n/a},
	urldate = {2022-08-11},
	journal = {Expert Systems},
	author = {Habeeb, Mohammed Sayeeduddin and Babu, T. Ranga},
	month = jul,
	year = {2022},
	keywords = {+survey, deep learning, machine learning, network attacks, network intrusion detection system, network security},
	pages = {e13066},
}

@article{ha_explainable_2022,
	title = {Explainable {Anomaly} {Detection} for {Industrial} {Control} {System} {Cybersecurity}},
	abstract = {Industrial Control Systems (ICSs) are becoming more and more important in managing the operation of many important systems in smart manufacturing, such as power stations, water supply systems, and manufacturing sites. While massive digital data can be a driving force for system performance, data security has raised serious concerns. Anomaly detection, therefore, is essential for preventing network security intrusions and system attacks. Many AI-based anomaly detection methods have been proposed and achieved high detection performance, however, are still a ”black box” that is hard to be interpreted. In this study, we suggest using Explainable Artificial Intelligence to enhance the perspective and reliable results of an LSTMbased Autoencoder-OCSVM learning model for anomaly detection in ICS. We demonstrate the performance of our proposed method based on a well-known SCADA dataset.},
	language = {en},
	author = {Ha, Do Thu and Hoang, Nguyen Xuan and Hoang, Nguyen Viet and Du, Nguyen Huu and Huong, Truong Thu and Tran, Kim Phuc},
	month = apr,
	year = {2022},
	keywords = {\_read, ⛔ No DOI found},
	pages = {7},
}

@article{gupta_hierarchical_2021,
	title = {Hierarchical {Federated} {Learning} based {Anomaly} {Detection} using {Digital} {Twins} for {Smart} {Healthcare}},
	url = {http://arxiv.org/abs/2111.12241},
	abstract = {Internet of Medical Things (IoMT) is becoming ubiquitous with a proliferation of smart medical devices and applications used in smart hospitals, smart-home based care, and nursing homes. It utilizes smart medical devices and cloud computing services along with core Internet of Things (IoT) technologies to sense patients’ vital body parameters, monitor health conditions and generate multivariate data to support justin-time health services. Mostly, this large amount of data is analyzed in centralized servers. Anomaly Detection (AD) in a centralized healthcare ecosystem is often plagued by signiﬁcant delays in response time with high performance overhead. Moreover, there are inherent privacy issues associated with sending patients’ personal health data to a centralized server, which may also introduce several security threats to the AD model, such as possibility of data poisoning. To overcome these issues with centralized AD models, here we propose a Federated Learning (FL) based AD model which utilizes edge cloudlets to run AD models locally without sharing patients’ data. Since existing FL approaches perform aggregation on a single server which restricts the scope of FL, in this paper, we introduce a hierarchical FL that allows aggregation at different levels enabling multiparty collaboration. We introduce a novel disease-based grouping mechanism where different AD models are grouped based on speciﬁc types of diseases. Furthermore, we develop a new Federated Time Distributed (FEDTIMEDIS) Long Short-Term Memory (LSTM) approach to train the AD model. We present a Remote Patient Monitoring (RPM) use case to demonstrate our model, and illustrate a proof-of-concept implementation using Digital Twin (DT) and edge cloudlets.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:2111.12241 [cs]},
	author = {Gupta, Deepti and Kayode, Olumide and Bhatt, Smriti and Gupta, Maanak and Tosun, Ali Saman},
	month = nov,
	year = {2021},
	note = {arXiv: 2111.12241},
	keywords = {Computer Science - Cryptography and Security, \_read\_urgently, ⛔ No DOI found},
}

@article{hafeez_toward_2017,
	title = {Toward {Secure} {Edge} {Networks} {Taming} {Device} to {Device} ({D2D}) {Communication} in {IoT}},
	url = {http://arxiv.org/abs/1712.05958},
	abstract = {The growing popularity of Internet-of-Things (IoT) has created the need for network-based traffic anomaly detection systems that could identify misbehaving devices. In this work, we propose a lightweight technique, IoT-guard, for identifying malicious traffic flows. IoT-guard uses semi-supervised learning to distinguish between malicious and benign device behaviours using the network traffic generated by devices. In order to achieve this, we extracted 39 features from network logs and discard any features containing redundant information. After feature selection, fuzzy C-Mean (FCM) algorithm was trained to obtain clusters discriminating benign traffic from malicious traffic. We studied the feature scores in these clusters and use this information to predict the type of new traffic flows. IoT-guard was evaluated using a real-world testbed with more than 30 devices. The results show that IoTguard achieves high accuracy (98\%), in differentiating various types of malicious and benign traffic, with low false positive rates. Furthermore, it has low resource footprint and can operate on OpenWRT enabled access points and COTS computing boards.},
	author = {Hafeez, Ibbad and Ding, Aaron Yi and Antikainen, Markku and Tarkoma, Sasu},
	month = dec,
	year = {2017},
	pages = {1--15},
}

@article{haddadpajouh_ai4safe-iot_2020,
	title = {{AI4SAFE}-{IoT}: an {AI}-powered secure architecture for edge layer of {Internet} of things},
	volume = {32},
	issn = {0941-0643},
	url = {https://doi.org/10.1007/s00521-020-04772-3},
	doi = {10.1007/s00521-020-04772-3},
	abstract = {With the increasing use of the Internet of things (IoT) in diverse domains, security concerns and IoT threats are constantly rising. The computational and memory limitations of IoT devices have resulted in emerging vulnerabilities in most IoT-run environments. Due to the low processing ability, IoT devices are often not capable of running complex defensive mechanisms. Lack of an architecture for a safer IoT environment is referred to as the most important barrier in developing a secure IoT system. In this paper, we propose a secure architecture for IoT edge layer infrastructure, called AI4SAFE-IoT. This architecture is built upon AI-powered security modules at the edge layer for protecting IoT infrastructure. Cyber threat attribution, intelligent web application firewall, cyber threat hunting, and cyber threat intelligence are the main modules proposed in our architecture. The proposed modules detect, attribute, and further identify the stage of an attack life cycle based on the Cyber Kill Chain model. In the proposed architecture, we define each security module and show its functionality against different threats in real-world applications. Moreover, due to the integration of AI security modules in a different layer of AI4SAFE-IoT, each threat in the edge layer will be handled by its corresponding security module delivered by a service. We compared the proposed architecture with the existing models and discussed our architecture independence of the underlying IoT layer and its comparatively low overhead according to delivering security as service for the edge layer of IoT architecture instead of embed implementation. Overall, we evaluated our proposed architecture based on the IoT service management score. The proposed architecture obtained 84.7 out of 100 which is the highest score among peer IoT edge layer security architectures.},
	number = {20},
	journal = {Neural Computing and Applications},
	author = {HaddadPajouh, Hamed and Khayami, Raouf and Dehghantanha, Ali and Choo, Kim-Kwang Raymond and Parizi, Reza M.},
	month = oct,
	year = {2020},
	note = {Publisher: Springer London
ISBN: 0123456789},
	pages = {16119--16133},
}

@article{guo_gld-net_2022,
	title = {{GLD}-{Net}: {Deep} {Learning} to {Detect} {DDoS} {Attack} via {Topological} and {Traffic} {Feature} {Fusion}},
	volume = {2022},
	issn = {1687-5265},
	shorttitle = {{GLD}-{Net}},
	url = {https://www.hindawi.com/journals/cin/2022/4611331/},
	doi = {10.1155/2022/4611331},
	abstract = {Distributed denial of service (DDoS) attacks are the most common means of cyberattacks against infrastructure, and detection is the first step in combating them. The current DDoS detection mainly uses the improvement or fusion of machine learning and deep learning methods to improve classification performance. However, most classifiers are trained with statistical flow features as input, ignoring topological connection changes. This one-sidedness affects the detection accuracy and cannot provide a basis for the distribution of attack sources for defense deployment. In this study, we propose a topological and flow feature-based deep learning method (GLD-Net), which simultaneously extracts flow and topological features from time-series flow data and exploits graph attention network (GAT) to mine correlations between non-Euclidean features to fuse flow and topological features. The long short-term memory (LSTM) network connected behind GAT obtains the node neighborhood relationship, and the fully connected layer is utilized to achieve feature dimension reduction and traffic type mapping. Experiments on the NSL-KDD2009 and CIC-IDS2017 datasets show that the detection accuracy of the GLD-Net method for two classifications (normal and DDoS flow) and three classifications (normal, fast DDoS flow, and slow DDoS flow) reaches 0.993 and 0.942, respectively. Compared with the existing DDoS attack detection methods, its average improvement is 0.11 and 0.081, respectively. In addition, the correlation coefficient between the detection accuracy of attack flow and the four source distribution indicators ranges from 0.7 to 0.83, which lays a foundation for the inference of attack source distribution. Notably, we are the first to fuse topology and flow features and achieve high-performance DDoS attack intrusion detection through graph-style neural networks. This study has important implications for related research and development of network security systems in other fields.},
	language = {en},
	urldate = {2022-08-23},
	journal = {Computational Intelligence and Neuroscience},
	author = {Guo, Wei and Qiu, Han and Liu, Zimian and Zhu, Junhu and Wang, Qingxian},
	month = aug,
	year = {2022},
	note = {Publisher: Hindawi},
	keywords = {\_read\_urgently},
	pages = {e4611331},
}

@article{fung_dirichlet-based_2011,
	title = {Dirichlet-{Based} {Trust} {Management} for {Effective} {Collaborative} {Intrusion} {Detection} {Networks}},
	volume = {8},
	issn = {1932-4537},
	doi = {10.1109/TNSM.2011.050311.100028},
	abstract = {The accuracy of detecting intrusions within a Collaborative Intrusion Detection Network (CIDN) depends on the efficiency of collaboration between peer Intrusion Detection Systems (IDSes) as well as the security itself of the CIDN. In this paper, we propose Dirichlet-based trust management to measure the level of trust among IDSes according to their mutual experience. An acquaintance management algorithm is also proposed to allow each IDS to manage its acquaintances according to their trustworthiness. Our approach achieves strong scalability properties and is robust against common insider threats, resulting in an effective CIDN. We evaluate our approach based on a simulated CIDN, demonstrating its improved robustness, efficiency and scalability for collaborative intrusion detection in comparison with other existing models.},
	number = {2},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Fung, Carol J and Zhang, Jie and Aib, Issam and Boutaba, Raouf},
	month = jun,
	year = {2011},
	note = {Conference Name: IEEE Transactions on Network and Service Management},
	keywords = {Collaboration, Collaborative intrusion detection system, Equations, Intrusion detection, Mathematical model, Peer to peer computing, Robustness, Scalability, admission control, computer security, security management, trust management},
	pages = {79--91},
}

@article{ghosh_self-healing_2007,
	title = {Self-healing systems — survey and synthesis},
	volume = {42},
	issn = {01679236},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167923606000807},
	doi = {10.1016/j.dss.2006.06.011},
	abstract = {As modern software-based systems and applications gain in versatility and functionality, the ability to manage inconsistent resources and service disparate user requirements becomes increasingly imperative. Furthermore, as systems increase in complexity, rectification of system faults and recovery from malicious attacks become more difficult, labor-intensive, expensive, and error-prone. These factors have actuated research dealing with the concept of self-healing systems. Self-healing systems attempt to “heal” themselves in the sense of recovering from faults and regaining normative performance levels independently the concept derives from the manner in which a biological system heals a wound. Such systems employ models, whether external or internal, to monitor system behavior and use inputs obtaining therefore to adapt themselves to the run-time environment. Researchers have approached this concept from several different angles this paper surveys research in this field and proposes a strategy of synthesis and classification. © 2006 Elsevier B.V. All rights reserved.},
	language = {en},
	number = {4},
	urldate = {2022-03-31},
	journal = {Decision Support Systems},
	author = {Ghosh, Debanjan and Sharman, Raj and Raghav Rao, H. and Upadhyaya, Shambhu},
	month = jan,
	year = {2007},
	keywords = {+survey},
	pages = {2164--2185},
}

@article{guo_robust_2021,
	title = {Robust and {Privacy}-{Preserving} {Collaborative} {Learning}: {A} {Comprehensive} {Survey}},
	shorttitle = {Robust and {Privacy}-{Preserving} {Collaborative} {Learning}},
	url = {http://arxiv.org/abs/2112.10183},
	abstract = {With the rapid demand of data and computational resources in deep learning systems, a growing number of algorithms to utilize collaborative machine learning techniques, for example, federated learning, to train a shared deep model across multiple participants. It could effectively take advantage of resource of each participant and obtain a more powerful learning system. However, integrity and privacy threats in such systems have greatly obstructed the applications of collaborative learning. And a large amount of works have been proposed to maintain the model integrity and mitigate the privacy leakage of training data during the training phase for different collaborate learning systems. Compared with existing surveys that mainly focus on one speciﬁc collaborate learning system, this survey aims to provide a systematic and comprehensive review of security and privacy researches in collaborative learning. Our survey ﬁrst provides the system overview of collaborative learning, followed by an brief introduction of integrity and privacy threats. In an organized way, we then detail the existing integrity and privacy attacks as well as their defenses. We also list some open problems in this area and opensource the related papers on GitHub: https://github.com/csl-cqu/awesome-secure-collebrativelearning-papers.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:2112.10183 [cs]},
	author = {Guo, Shangwei and Zhang, Xu and Yang, Fei and Zhang, Tianwei and Gan, Yan and Xiang, Tao and Liu, Yang},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.10183},
	keywords = {Computer Science - Cryptography and Security, ⛔ No DOI found},
}

@article{fung_mitigating_2018,
	title = {Mitigating {Sybils} in {Federated} {Learning} {Poisoning}},
	issn = {23318422},
	url = {http://arxiv.org/abs/1808.04866},
	abstract = {Machine learning (ML) over distributed multi-party data is required for a variety of domains. Existing approaches, such as federated learning, collect the outputs computed by a group of devices at a central aggregator and run iterative algorithms to train a globally shared model. Unfortunately, such approaches are susceptible to a variety of attacks, including model poisoning, which is made substantially worse in the presence of sybils. In this paper we first evaluate the vulnerability of federated learning to sybil-based poisoning attacks. We then describe {\textbackslash}emph\{FoolsGold\}, a novel defense to this problem that identifies poisoning sybils based on the diversity of client updates in the distributed learning process. Unlike prior work, our system does not bound the expected number of attackers, requires no auxiliary information outside of the learning process, and makes fewer assumptions about clients and their data. In our evaluation we show that FoolsGold exceeds the capabilities of existing state of the art approaches to countering sybil-based label-flipping and backdoor poisoning attacks. Our results hold for different distributions of client data, varying poisoning targets, and various sybil strategies. Code can be found at: https://github.com/DistributedML/FoolsGold},
	journal = {arXiv},
	author = {Fung, Clement and Yoon, Chris J. M. and Beschastnikh, Ivan},
	month = aug,
	year = {2018},
	keywords = {⛔ No DOI found},
}

@article{garcia-teodoro_anomaly-based_2009,
	title = {Anomaly-based network intrusion detection: {Techniques}, systems and challenges},
	volume = {28},
	issn = {01674048},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167404808000692},
	doi = {10.1016/j.cose.2008.08.003},
	abstract = {The Internet and computer networks are exposed to an increasing number of security threats. With new types of attacks appearing continually, developing flexible and adaptive security oriented approaches is a severe challenge. In this context, anomaly-based network intrusion detection techniques are a valuable technology to protect target systems and networks against malicious activities. However, despite the variety of such methods described in the literature in recent years, security tools incorporating anomaly detection functionalities are just starting to appear, and several important problems remain to be solved. This paper begins with a review of the most well-known anomaly-based intrusion detection techniques. Then, available platforms, systems under development and research projects in the area are presented. Finally, we outline the main challenges to be dealt with for the wide scale deployment of anomaly-based intrusion detectors, with special emphasis on assessment issues. © 2008 Elsevier Ltd. All rights reserved.},
	number = {1-2},
	journal = {Computers \& Security},
	author = {García-Teodoro, P. and Díaz-Verdejo, J. and Maciá-Fernández, G. and Vázquez, E.},
	month = feb,
	year = {2009},
	pages = {18--28},
}

@article{gong_blocis_2020,
	title = {{BLOCIS}: {Blockchain}-{Based} {Cyber} {Threat} {Intelligence} {Sharing} {Framework} for {Sybil}-{Resistance}},
	volume = {9},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/9/3/521},
	doi = {10.3390/electronics9030521},
	abstract = {The convergence of fifth-generation (5G) communication and the Internet-of-Things (IoT) has dramatically increased the diversity and complexity of the network. This change diversifies the attacker’s attack vectors, increasing the impact and damage of cyber threats. Cyber threat intelligence (CTI) technology is a proof-based security system which responds to these advanced cyber threats proactively by analyzing and sharing security-related data. However, the performance of CTI systems can be significantly compromised by creating and disseminating improper security policies if an attacker intentionally injects malicious data into the system. In this paper, we propose a blockchain-based CTI framework that improves confidence in the source and content of the data and can quickly detect and eliminate inaccurate data for resistance to a Sybil attack. The proposed framework collects CTI by a procedure validated through smart contracts and stores information about the metainformation of data in a blockchain network. The proposed system ensures the validity and reliability of CTI data by ensuring traceability to the data source and proposes a system model that can efficiently operate and manage CTI data in compliance with the de facto standard. We present the simulation results to prove the effectiveness and Sybil-resistance of the proposed framework in terms of reliability and cost to attackers.},
	number = {3},
	journal = {Electronics},
	author = {Gong, Seonghyeon and Lee, Changhoon},
	month = mar,
	year = {2020},
	pages = {521},
}

@article{ferrag_edge-iiotset_2022,
	title = {Edge-{IIoTset}: {A} {New} {Comprehensive} {Realistic} {Cyber} {Security} {Dataset} of {IoT} and {IIoT} {Applications} for {Centralized} and {Federated} {Learning}},
	volume = {10},
	issn = {2169-3536},
	shorttitle = {Edge-{IIoTset}},
	url = {https://ieeexplore.ieee.org/document/9751703/},
	doi = {10.1109/ACCESS.2022.3165809},
	abstract = {In this paper, we propose a new comprehensive realistic cyber security dataset of IoT and IIoT applications, called Edge-IIoTset, which can be used by machine learning-based intrusion detection systems in two different modes, namely, centralized and federated learning. Speciﬁcally, the dataset has been generated using a purpose-built IoT/IIoT testbed with a large representative set of devices, sensors, protocols and cloud/edge conﬁgurations. The IoT data are generated from various IoT devices (more than 10 types) such as Low-cost digital sensors for sensing temperature and humidity, Ultrasonic sensor, Water level detection sensor, pH Sensor Meter, Soil Moisture sensor, Heart Rate Sensor, Flame Sensor, etc.). Furthermore, we identify and analyze fourteen attacks related to IoT and IIoT connectivity protocols, which are categorized into ﬁve threats, including, DoS/DDoS attacks, Information gathering, Man in the middle attacks, Injection attacks, and Malware attacks. In addition, we extract features obtained from different sources, including alerts, system resources, logs, network trafﬁc, and propose new 61 features with high correlations from 1176 found features. After processing and analyzing the proposed realistic cyber security dataset, we provide a primary exploratory data analysis and evaluate the performance of machine learning approaches (i.e., traditional machine learning as well as deep learning) in both centralized and federated learning modes. The Edge-IIoTset dataset can be publicly accessed from http://ieee-dataport.org/8939.},
	language = {en},
	urldate = {2022-08-31},
	journal = {IEEE Access},
	author = {Ferrag, Mohamed Amine and Friha, Othmane and Hamouda, Djallel and Maglaras, Leandros and Janicke, Helge},
	year = {2022},
	pages = {40281--40306},
}

@article{feng_vertical_2022,
	title = {Vertical federated learning-based feature selection with non-overlapping sample utilization},
	volume = {208},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S095741742201291X},
	doi = {10.1016/j.eswa.2022.118097},
	abstract = {Vertical federated learning (VFL) is a privacy preserving collaborative machine learning technique designed for distributed learning scenarios in which data from different parties have overlap in the sample space. In this paper, a VFL method for feature selection, which is an effective dimensionality reduction technique that selects a subset of informative features from high-dimensional data by eliminating irrelevant and redundant features, is proposed. Because of the potential insufficiency of useful information for learning informative features and the difficulty in sharing raw data among parties due to the increasing awareness of data privacy protection, it is desirable to exploit information from multiple parties without raw data sharing. In this paper, we propose a VFL-based feature selection method that leverages deep learning models as well as complementary information from features in the same samples at multiple parties without data disclosure. In order to further improve feature selection performance, information of samples that do not have features appearing in all parties are also utilized. Promising results in extensive experiments show the effectiveness of the proposed approach in terms of collaborative feature selection without data sharing.},
	language = {en},
	urldate = {2022-08-11},
	journal = {Expert Systems with Applications},
	author = {Feng, Siwei},
	month = dec,
	year = {2022},
	keywords = {Deep learning, Feature selection, Privacy protection, Vertical federated learning},
	pages = {118097},
}

@article{feng_semi-supervised_2022,
	title = {Semi-{Supervised} {Federated} {Heterogeneous} {Transfer} {Learning}},
	volume = {252},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705122006943},
	doi = {10.1016/j.knosys.2022.109384},
	abstract = {Federated learning (FL) is a privacy-preserving paradigm that collaboratively train machine learning models with distributed data stored in different silos without exposing sensitive information. Different from most existing FL approaches requiring data from different parties share either the same feature space or sample ID space, federated transfer learning (FTL), which is a recently proposed FL concept, is designed for situations where data from different parties differ not only in samples but also in feature space. However, like most traditional FL approaches, FTL methods also suffer from issues caused by insufficiency of overlapping data. In this paper, we propose a novel FTL framework referred to as Semi-Supervised Federated Heterogeneous Transfer Learning (SFHTL) to leverage on the unlabeled non-overlapping samples to reduce model overfitting as a result of insufficient overlapping training samples in FL scenarios. Unlike existing FTL approaches, SFHTL makes use of non-overlapping samples from all parties to expand the training set for each party to improve local model performance. Through extensive experimental evaluation based on real-world datasets, we demonstrate significant advantages of SFHTL over state-of-the-art approaches.},
	language = {en},
	urldate = {2022-08-11},
	journal = {Knowledge-Based Systems},
	author = {Feng, Siwei and Li, Boyang and Yu, Han and Liu, Yang and Yang, Qiang},
	month = sep,
	year = {2022},
	keywords = {Data privacy preservation, Federated transfer learning, Non-overlapping data utilization, Training set expansion, \_read\_urgently},
	pages = {109384},
}

@article{frideh_parastar_-device_2022,
	title = {On-device {ML} {For} the {Current} and the {Emerging} {Networks}: {A} {Survey} on {Current} {Approaches} and {Challenges}},
	shorttitle = {On-device {ML} {For} the {Current} and the {Emerging} {Networks}},
	url = {https://rgdoi.net/10.13140/RG.2.2.15410.89288},
	doi = {10.13140/RG.2.2.15410.89288},
	abstract = {MU-MIMO Data-Driven Optimization on Downlink Commodity Wi-Fi View project All content following this page was uploaded by Mohammad Sepahi on 19 April 2022. The user has requested enhancement of the downloaded file.},
	language = {en},
	urldate = {2022-07-05},
	author = {Frideh Parastar and Sepahi, Mohammad},
	year = {2022},
	note = {Publisher: Unpublished},
	keywords = {+survey},
}

@article{fereidooni_safelearn_2021,
	title = {{SAFELearn}: {Secure} {Aggregation} for private {FEderated} {Learning}},
	abstract = {Federated learning (FL) is an emerging distributed machine learning paradigm which addresses critical data privacy issues in machine learning by enabling clients, using an aggregation server (aggregator), to jointly train a global model without revealing their training data. Thereby, it improves not only privacy but is also efﬁcient as it uses the computation power and data of potentially millions of clients for training in parallel. However, FL is vulnerable to so-called inference attacks by malicious aggregators which can infer information about clients’ data from their model updates. Secure aggregation restricts the central aggregator to only learn the summation or average of the updates of clients. Unfortunately, existing protocols for secure aggregation for FL suffer from high communication, computation, and many communication rounds.},
	language = {en},
	author = {Fereidooni, Hossein and Marchal, Samuel and Miettinen, Markus and Mirhoseini, Azalia and Möllering, Helen and Nguyen, Thien Duc and Rieger, Phillip and Sadeghi, Ahmad-Reza and Schneider, Thomas and Yalame, Hossein and Zeitouni, Shaza},
	year = {2021},
	keywords = {⛔ No DOI found},
	pages = {8},
}

@article{foglietta_detecting_2019,
	title = {From {Detecting} {Cyber}-{Attacks} to {Mitigating} {Risk} {Within} a {Hybrid} {Environment}},
	volume = {13},
	issn = {1932-8184, 1937-9234, 2373-7816},
	url = {https://ieeexplore.ieee.org/document/8352138/},
	doi = {10.1109/JSYST.2018.2824252},
	abstract = {Telecommunication networks based on commonplace technologies (such as Ethernet) often constitute a vulnerable attack vector against modern critical infrastructures (CIs), particularly for supervisory control and data acquisition (SCADA) systems, which rely on them for monitoring and controlling physical components. This paper presents a unique platform that encompasses a range of capabilities, from cyber-attack detection to mitigation strategies, through interdependency and risk evaluation. The platform is made of two main components: a cyber-attack detection subsystem and a risk assessment framework. Both blocks are innovative from research point of view and they have been developed and customized to ﬁt the CIs’ features, that are completely different from telecommunication networks. This platform has been tested on a hybrid environment testbed, made of virtual and real components, within the scope of the EU FP7 CockpitCI and EU H2020 ATENA projects. The case study corresponds to a medium voltage power grid controlled by a SCADA control center, where the platform has been validated with optimal results in terms of detection capabilities and time response.},
	language = {en},
	number = {1},
	urldate = {2021-05-19},
	journal = {IEEE Systems Journal},
	author = {Foglietta, Chiara and Masucci, Dario and Palazzo, Cosimo and Santini, Riccardo and Panzieri, Stefano and Rosa, Luis and Cruz, Tiago and Lev, Leonid},
	month = mar,
	year = {2019},
	keywords = {\_read},
	pages = {424--435},
}

@article{elgamal_public_1985,
	title = {A public key cryptosystem and a signature scheme based on discrete logarithms},
	volume = {31},
	issn = {0018-9448},
	url = {http://ieeexplore.ieee.org/document/1057074/},
	doi = {10.1109/TIT.1985.1057074},
	abstract = {A new signature scheme is proposed, together with an imple- Hence both A and B are able to compute K,,. But, for an mentation of the Diffie-Hellman key distribution scheme that achieves a intruder, computing KA B appears to be difficult. It is not public key cryptosystem. The security of both systems relies on the yet proved that breaking the system is equivalent to comdifficulty of computing discrete logarithms over finite fields.},
	language = {en},
	number = {4},
	urldate = {2021-05-20},
	journal = {IEEE Transactions on Information Theory},
	author = {Elgamal, T.},
	month = jul,
	year = {1985},
	pages = {469--472},
}

@article{edwards_hajime_2016,
	title = {Hajime: {Analysis} of a decentralized internet worm for {IoT} devices},
	abstract = {This paper chronicles the discovery and analysis of a malicious internet worm, dubbed ​ Hajime ​ , which targets embedded/Internet of Things (" IoT ") devices and spreads by scanning the public internet for devices running Telnet servers with insecure default credentials. Though worms which target IoT devices are not new, they are rising in prominence lately due to the generally weak security such devices have. What makes ​ Hajime ​ unique is that it does not rely on centralized malware distribution server(s), but instead communicates over a distributed/decentralized overlay network to receive configuration and software updates. Background},
	journal = {Cs.Umd.Edu},
	author = {Edwards, Sam and Profetis, Ioannis},
	year = {2016},
	keywords = {⛔ No DOI found},
	pages = {1--18},
}

@article{etesami_dynamic_2019,
	title = {Dynamic {Games} in {Cyber}-{Physical} {Security}: {An} {Overview}},
	volume = {9},
	issn = {21530793},
	doi = {10.1007/s13235-018-00291-y},
	abstract = {Due to complex dependencies between multiple layers and components of emerging cyber-physical systems, security and vulnerability of such systems have become a major challenge in recent years. In this regard, game theory, a powerful tool for modeling strategic interactions between multiple decision makers with conflicting objectives, offers a natural paradigm to address the security-related issues arising in these systems. While there exists substantial amount of work in modeling and analyzing security problems using game-theoretic techniques, most of the existing literature in this area focuses on static game models, ignoring the dynamic nature of interactions between the main players (defenders vs. attackers). In this paper, we focus only on dynamic game analysis of cyber-physical security problems and provide a general overview of the existing results and recent advances based on application domains. We also discuss several limitations of the existing models and identify several hitherto unaddressed directions for future research.},
	number = {4},
	journal = {Dynamic Games and Applications},
	author = {Etesami, S. Rasoul and Başar, Tamer},
	year = {2019},
	note = {ISBN: 1323501800},
	pages = {884--913},
}

@article{farwell_stuxnet_2011,
	title = {Stuxnet and the {Future} of {Cyber} {War}},
	volume = {53},
	issn = {0039-6338},
	url = {https://www.tandfonline.com/doi/full/10.1080/00396338.2011.555586},
	doi = {10.1080/00396338.2011.555586},
	number = {1},
	journal = {Survival},
	author = {Farwell, James P. and Rohozinski, Rafal},
	month = feb,
	year = {2011},
	pages = {23--40},
}

@article{doshi_machine_2018,
	title = {Machine {Learning} {DDoS} {Detection} for {Consumer} {Internet} of {Things} {Devices}},
	url = {https://ieeexplore.ieee.org/document/8424629/},
	doi = {10.1109/SPW.2018.00013},
	abstract = {An increasing number of Internet of Things (IoT) devices are connecting to the Internet, yet many of these devices are fundamentally insecure, exposing the Internet to a variety of attacks. Botnets such as Mirai have used insecure consumer IoT devices to conduct distributed denial of service (DDoS) attacks on critical Internet infrastructure. This motivates the development of new techniques to automatically detect consumer IoT attack traffic. In this paper, we demonstrate that using IoT-specific network behaviors (e.g. limited number of endpoints and regular time intervals between packets) to inform feature selection can result in high accuracy DDoS detection in IoT network traffic with a variety of machine learning algorithms, including neural networks. These results indicate that home gateway routers or other network middleboxes could automatically detect local IoT device sources of DDoS attacks using low-cost machine learning algorithms and traffic data that is flow-based and protocol-agnostic.},
	number = {Ml},
	journal = {2018 IEEE Security and Privacy Workshops (SPW)},
	author = {Doshi, Rohan and Apthorpe, Noah and Feamster, Nick},
	month = apr,
	year = {2018},
	note = {Publisher: IEEE
ISBN: 978-1-5386-8276-0},
	pages = {29--35},
}

@article{dong_interpretable_2022,
	title = {An {Interpretable} {Federated} {Learning}-based {Network} {Intrusion} {Detection} {Framework}},
	url = {http://arxiv.org/abs/2201.03134},
	abstract = {Learning-based Network Intrusion Detection Systems (NIDSs) are widely deployed for defending various cyberattacks. Existing learning-based NIDS mainly uses Neural Network (NN) as a classiﬁer that relies on the quality and quantity of cyberattack data. Such NN-based approaches are also hard to interpret for improving efﬁciency and scalability. In this paper, we design a new local-global computation paradigm, FEDFOREST, a novel learning-based NIDS by combining the interpretable Gradient Boosting Decision Tree (GBDT) and Federated Learning (FL) framework. Speciﬁcally, FEDFOREST is composed of multiple clients that extract local cyberattack data features for the server to train models and detect intrusions. A privacy-enhanced technology is also proposed in FEDFOREST to further defeat the privacy of the FL systems. Extensive experiments on 4 cyberattack datasets of different tasks demonstrate that FEDFOREST is effective, efﬁcient, interpretable, and extendable. FEDFOREST ranks ﬁrst in the collaborative learning and cybersecurity competition 2021 for Chinese college students.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:2201.03134 [cs]},
	author = {Dong, Tian and Li, Song and Qiu, Han and Lu, Jialiang},
	month = jan,
	year = {2022},
	note = {arXiv: 2201.03134},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, \_read, ⛔ No DOI found},
}

@article{deng_improving_2022,
	title = {Improving {Federated} {Learning} {With} {Quality}-{Aware} {User} {Incentive} and {Auto}-{Weighted} {Model} {Aggregation}},
	issn = {1558-2183},
	doi = {10.1109/TPDS.2022.3195207},
	abstract = {Federated learning enables distributed model training over various computing nodes, e.g., mobile devices, where instead of sharing raw user data, computing nodes can solely commit model updates without compromising data privacy. The quality of federated learning relies on the model updates contributed by computing nodes training with their local data. However, with various factors (e.g., training data size, mislabeled data samples, skewed data distributions), the model update qualities of computing nodes can vary dramatically, while inclusively aggregating low-quality model updates can deteriorate the global model quality. To achieve efficient federated learning, in this paper, we propose a novel framework named FAIR, i.e., Federated leArning with qualIty awaReness. Particularly, FAIR integrates three major components: 1) learning quality estimation: we adopt the model aggregation weight (learned in the third component) to reversely quantify the individual learning quality of nodes in a privacy-preserving manner, and leverage the historical learning records to infer the next-round learning quality; 2) quality-aware incentive mechanism: within the recruiting budget, we model a reverse auction problem to stimulate the participation of high-quality and low-cost computing nodes, and the method is proved to be truthful, individually rational, and computationally efficient; and 3) auto-weighted model aggregation: based on the gradient descent method, we devise an auto-weighted model aggregation algorithm to automatically learn the optimal aggregation weights to further enhance the global model quality. Based on real-world datasets and learning tasks, extensive experiments are conducted to demonstrate the efficacy of FAIR.},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Deng, Yongheng and Lyu, Feng and Ren, Ju and Chen, Yi-Chao and Yang, Peng and Zhou, Yuezhi and Zhang, Yaoxue},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Parallel and Distributed Systems},
	keywords = {Collaborative work, Computational modeling, Data models, Edge computing, Resource management, Task analysis, Training, Training data, \_read\_urgently, federated learning, incentive mechanism, learning quality, mobile computing, model aggregation},
	pages = {1--15},
}

@article{dietz_comparing_nodate,
	title = {Comparing {Traditional} and {GAN}-based {Approaches} for the {Synthesis} of {Wide} {Area} {Network} {Topologies}},
	abstract = {Wide Area Network (WAN) research beneﬁts from the availability of realistic network topologies, e. g., as input to simulations, emulators, or testbeds. With the rise of Machine Learning (ML) and particularly Deep Learning (DL) methods, this demand for topologies, which can be used as training data, is greater than ever. However, public datasets are limited, thus, it is promising to generate synthetic graphs with realistic properties based on real topologies for the augmentation of existing data sets. As the generation of synthetic graphs has been in the focus of researchers of various applications ﬁelds since several decades, we have a variety of traditional model-dependent and modelindependent graph generators at hand, as well as DL-based approaches, such as Generative Adversarial Networks (GANs). In this work, we adapt and evaluate these existing generators for the WAN use case, i. e., for generating synthetic WAN networks with realistic geographical distances between nodes. Moreover, we investigate a hierarchical graph synthesis approach, which divides the synthesis into local clusters. Finally, we compare the similarity of synthetic and real WAN topologies and discuss the suitability of the generators for data augmentation in the WAN use case.},
	language = {en},
	author = {Dietz, Katharina and Seufert, Michael and Hoßfeld, Tobias},
	keywords = {\_unpublished, ⛔ No DOI found},
	pages = {9},
}

@article{demertzis_blockchained_nodate,
	title = {Blockchained {Federated} {Learning} for {Threat} {Defense}},
	abstract = {Given the increasing complexity of threats in smart cities, the changing environment and the weakness of traditional security systems, which in most cases fail to detect serious threats such as zero-day attacks, the need for alternative more active and more effective security methods keeps increasing. Such approaches are the adoption of intelligent solutions to prevent, detect and deal with threats or anomalies under the conditions and the operating parameters of the infrastructure in question. Intelligent systems are capable, of displaying logical, empirical, and non-human decision-making, since they are trained appropriately by historical data representative of the problem they are trying to solve. In most cases, it is either not possible or it is inappropriate to centrally store all smart cities data. Thus, we should perform real-time knowledge mining and we should obtain a subset of a data flow containing a small but recent percentage of observations. This fact raises serious objections to the accuracy and reliability of the employed intelligent system classifiers, who have been tame over time and they become incapable of detecting serious threats. This research paper introduces the development of an intelligent Threat Defense system, employing Blockchain Federated Learning, which seeks to fully upgrade the way passive intelligent systems operate, aiming at implementing an Advanced Adaptive Cooperative Learning (AACL) mechanism for smart cities networks. The AACL is based on the most advanced methods of computational intelligence, while ensuring privacy and anonymity for participants and stakeholders. The proposed framework combines Federated Learning for the distributed and continuously validated learning of the tracing algorithms. Learning is achieved through encrypted smart contracts within the blockchain technology, for unambiguous validation and control of the process. The aim of the proposed Framework is to intelligently classify smart cities networks traffic derived from Industrial IoT (IIoT) by Deep Content Inspection (DCI) methods, in order to identify anomalies that are usually due to Advanced Persistent Threat (APT) attacks.},
	language = {en},
	author = {Demertzis, Konstantinos},
	keywords = {⛔ No DOI found},
	pages = {12},
}

@article{dong_eastfly_2020,
	title = {{EaSTFLy}: {Efficient} and secure ternary federated learning},
	volume = {94},
	issn = {01674048},
	shorttitle = {{EaSTFLy}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167404820300985},
	doi = {10.1016/j.cose.2020.101824},
	language = {en},
	urldate = {2021-05-18},
	journal = {Computers \& Security},
	author = {Dong, Ye and Chen, Xiaojun and Shen, Liyan and Wang, Dakui},
	month = jul,
	year = {2020},
	pages = {101824},
}

@article{da_costa_internet_2019,
	title = {Internet of {Things}: {A} survey on machine learning-based intrusion detection approaches},
	volume = {151},
	issn = {13891286},
	url = {https://doi.org/10.1016/j.comnet.2019.01.023},
	doi = {10.1016/j.comnet.2019.01.023},
	abstract = {In the world scenario, concerns with security and privacy regarding computer networks are always increasing. Computer security has become a necessity due to the proliferation of information technologies in everyday life. The increase in the number of Internet accesses and the emergence of new technologies, such as the Internet of Things (IoT paradigm, are accompanied by new and modern attempts to invade computer systems and networks. Companies are increasingly investing in studies to optimize the detection of these attacks. Institutions are selecting intelligent techniques to test and verify by comparing the best rates of accuracy. This research, therefore, focuses on rigorous state-of-the-art literature on Machine Learning Techniques applied in Internet-of-Things and Intrusion Detection for computer network security. The work aims, therefore, recent and in-depth research of relevant works that deal with several intelligent techniques and their applied intrusion detection architectures in computer networks with emphasis on the Internet of Things and machine learning. More than 95 works on the subject were surveyed, spanning across different themes related to security issues in IoT environments.},
	journal = {Computer Networks},
	author = {da Costa, Kelton A.P. and Papa, João P. and Lisboa, Celso O. and Munoz, Roberto and de Albuquerque, Victor Hugo C.},
	month = mar,
	year = {2019},
	note = {Publisher: Elsevier B.V.},
	keywords = {+survey},
	pages = {147--157},
}

@article{darley_machine_2022,
	title = {Machine {Learning} {Intrusion} {Detection} as a {Solution} to {Security} and {Privacy} {Issues} in {IoT}: {A} {Systematic} {Review}},
	volume = {7},
	issn = {2579-0625, 2579-0617},
	shorttitle = {Machine {Learning} {Intrusion} {Detection} as a {Solution} to {Security} and {Privacy} {Issues} in {IoT}},
	url = {https://journal.engineering.fuoye.edu.ng/index.php/engineer/article/view/802},
	doi = {10.46792/fuoyejet.v7i2.802},
	abstract = {Billions of IoT devices are in use worldwide and generate a humongous amount of data for the IoT system. This continuous stream of data is open to attack during its collection, transportation, processing, dissemination and storage cycle. Also, IoT devices themselves are points of system vulnerability through which the system can be attacked. Machine learning (ML), due to its ability to identify inherent patterns and behaviour in data, has been applied by many researchers to IoT data such that strange patterns or intrusions into IoT systems can be speedily detected and real-time decisions on security and privacy (S\&P) protection implemented in a timely manner. Different ML techniques with their different algorithms have provided solutions in various scenarios such that security and privacy requirements for the IoT system can be met. In particular, ML has been successfully applied in intrusion detection and has been shown to perform better than traditional means in flagging new trends of attacks. This paper presents a systematic literature review on ML intrusion detection in IoT. Academic journals from 2011 to 2021 from two databases (IEEE and ProQuest) were explored using the Preferred Reporting Items for Systematic Reviews and MetaAnalyses (PRISMA) framework. A review of the final selected papers revealed that data preprocessing, feature extraction, model training and deployment of ML-based Intrusion Detection Systems (IDS) increase computational complexity resulting in greater resource requirement (CPU, memory, and energy); enable ML to be used in the execution of adversarial attacks on IoT devices and networks (as seen with emerging attacks); give rise to scalability issues especially due to the heterogeneous nature of IoT networks; require trade-offs between detection accuracy and false-positive events; and highlight the superior performance of deep learning methods over traditional ML ones in anomaly detection. Generally, the changing nature of attacks makes it difficult for any particular IDS to be able to detect all attack types thus making the development of IDS a continuing project.},
	language = {en},
	number = {2},
	urldate = {2022-08-11},
	journal = {FUOYE Journal of Engineering and Technology},
	author = {Darley, Olufunke G. and Adenowo, Adetokunbo A. and Yussuff, Abayomi I. O.},
	month = jun,
	year = {2022},
	keywords = {+survey},
	pages = {148--156},
}

@article{damiani_open_2004,
	title = {An {Open} {Digest}-based {Technique} for {Spam} {Detection}},
	abstract = {A promising anti-spam technique consists in collecting users opinions that given email messages are spam and using this collective judgment to block message propagation to other users. To be eﬀective, this strategy requires a way to identify similarity among email messages, even if the program used by the spammer to generate the messages may try to obfuscate their common origin.},
	language = {en},
	author = {Damiani, E},
	year = {2004},
	keywords = {⛔ No DOI found},
	pages = {6},
}

@article{data_data_2021,
	title = {Data {Encoding} for {Byzantine}-{Resilient} {Distributed} {Optimization}},
	volume = {67},
	issn = {15579654},
	doi = {10.1109/TIT.2020.3035868},
	abstract = {We study distributed optimization in the presence of Byzantine adversaries, where both data and computation are distributed among m worker machines, t of which may be corrupt. The compromised nodes may collaboratively and arbitrarily deviate from their pre-specified programs, and a designated (master) node iteratively computes the model/parameter vector for generalized linear models. In this work, we primarily focus on two iterative algorithms: Proximal Gradient Descent (PGD) and Coordinate Descent (CD). Gradient descent (GD) is a special case of these algorithms. PGD is typically used in the data-parallel setting, where data is partitioned across different samples, whereas, CD is used in the model-parallelism setting, where data is partitioned across the parameter space. At the core of our solutions to both these algorithms is a method for Byzantine-resilient matrix-vector (MV) multiplication; and for that, we propose a method based on data encoding and error correction over real numbers to combat adversarial attacks. We can tolerate up to t≤ m-12rfloor corrupt worker nodes, which is information-theoretically optimal. We give deterministic guarantees, and our method does not assume any probability distribution on the data. We develop a sparse encoding scheme which enables computationally efficient data encoding and decoding. We demonstrate a trade-off between the corruption threshold and the resource requirements (storage, computational, and communication complexity). As an example, for t≤q m 3 , our scheme incurs only a constant overhead on these resources, over that required by the plain distributed PGD/CD algorithms which provide no adversarial protection. To the best of our knowledge, ours is the first paper that connects MV multiplication with CD and designs a specific encoding matrix for MV multiplication whose structure we can leverage to make CD secure against adversarial attacks. Our encoding scheme extends efficiently to (i) the data streaming model, in which data samples come in an online fashion and are encoded as they arrive, and (ii) making stochastic gradient descent (SGD) Byzantine-resilient. In the end, we give experimental results to show the efficacy of our proposed schemes.},
	number = {2},
	journal = {IEEE Transactions on Information Theory},
	author = {Data, Deepesh and Song, Linqi and Diggavi, Suhas N.},
	year = {2021},
	pages = {1117--1140},
}

@article{decker_distributed_1987,
	title = {Distributed problem-solving techniques: {A} survey},
	volume = {17},
	issn = {0018-9472},
	url = {https://ieeexplore.ieee.org/document/6499280/},
	doi = {10.1109/TSMC.1987.6499280},
	abstract = {Distributed problem-solving is defined as a subfield of artificial intelligence that deals with the interaction of groups of intelligent agents attempting to cooperate to solve problems. A taxonomy of distributed artificial intelligence systems is presented, based on the communication and control methodologies used by their constituent agents, along with the theoretical foundations which underly them. Control in distributed problem-solvers is characterized by cooperation, organization, and dynamics. Communications are specified through paradigms, content, and protocols. Several prototypical systems in areas such as natural language processing and medical diagnosis are briefly discussed, along with more mature systems in applications such as air-traffic control, vehicle monitoring, and manufacturing systems.},
	number = {5},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics},
	author = {Decker, Keith S.},
	month = sep,
	year = {1987},
	note = {Publisher: IEEE},
	pages = {729--740},
}

@article{de_fuentes_pracis_2017,
	title = {{PRACIS}: {Privacy}-preserving and aggregatable cybersecurity information sharing},
	volume = {69},
	issn = {01674048},
	url = {http://dx.doi.org/10.1016/j.cose.2016.12.011},
	doi = {10.1016/j.cose.2016.12.011},
	abstract = {Cooperative cyberdefense has been recognized as an essential strategy to fight against cyberattacks. Cybersecurity Information Sharing (CIS), especially about threats and incidents, is a key aspect in this regard. CIS provides members with an improved situational awareness to prepare for and respond to future cyberthreats. Privacy preservation is critical in this context, since organizations can be reluctant to share information otherwise. This is particularly critical when CIS is facilitated through an untrusted infrastructure provided by a third party (e.g., the cloud). Despite this, current data formats and protocols for CIS do not guarantee any form of privacy preservation to participants. In this paper we introduce PRACIS, a scheme for CIS networks that guarantees private data forwarding and aggregation. PRACIS leverages the well-known Structured Threat Information Expression (STIX) standard data format. Remarkably, PRACIS can be seamlessly integrated with existing STIX-based message brokering middleware such as publish-subscribe architectures. PRACIS achieves these goals by combining standard format-preserving and homomorphic encryption primitives. We discuss experimental results obtained with a prototype implementation developed for a subset of STIX. Results show that entities may create up to 689 incidents per minute, far beyond the estimated average of 81. Moreover, aggregation of 104 incidents can be carried out in just 2.1 s, and the transmission overhead is just 13.5 kbps. Overall, these results suggest that the costs incurred by PRACIS are easily affordable in real-world scenarios.},
	journal = {Computers \& Security},
	author = {de Fuentes, José M. and González-Manzano, Lorena and Tapiador, Juan and Peris-Lopez, Pedro},
	month = aug,
	year = {2017},
	note = {Publisher: Elsevier Ltd},
	pages = {127--141},
}

@article{chicco_advantages_2020,
	title = {The advantages of the {Matthews} correlation coefficient ({MCC}) over {F1} score and accuracy in binary classification evaluation},
	volume = {21},
	issn = {1471-2164},
	url = {https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7},
	doi = {10.1186/s12864-019-6413-7},
	abstract = {Background: To evaluate binary classifications and their confusion matrices, scientific researchers can employ several statistical rates, accordingly to the goal of the experiment they are investigating. Despite being a crucial issue in machine learning, no widespread consensus has been reached on a unified elective chosen measure yet. Accuracy and F1 score computed on confusion matrices have been (and still are) among the most popular adopted metrics in binary classification tasks. However, these statistical measures can dangerously show overoptimistic inflated results, especially on imbalanced datasets.
Results: The Matthews correlation coefficient (MCC), instead, is a more reliable statistical rate which produces a high score only if the prediction obtained good results in all of the four confusion matrix categories (true positives, false negatives, true negatives, and false positives), proportionally both to the size of positive elements and the size of negative elements in the dataset.
Conclusions: In this article, we show how MCC produces a more informative and truthful score in evaluating binary classifications than accuracy and F1 score, by first explaining the mathematical properties, and then the asset of MCC in six synthetic use cases and in a real genomics scenario. We believe that the Matthews correlation coefficient should be preferred to accuracy and F1 score in evaluating binary classification tasks by all scientific communities.},
	language = {en},
	number = {1},
	urldate = {2022-03-11},
	journal = {BMC Genomics},
	author = {Chicco, Davide and Jurman, Giuseppe},
	month = dec,
	year = {2020},
	pages = {6},
}

@article{chismon_threat_2015,
	title = {Threat {Intelligence}: {Collecting}, {Analysing}, {Evaluating}},
	abstract = {Threat intelligence is rapidly becoming an ever-higher business priority. There is a general awareness of the need to ‘do’ threat intelligence, and vendors are falling over themselves to offer a confusingly diverse array of threat intelligence products. Figure},
	journal = {Cert-Uk},
	author = {Chismon, David and Ruks, Martyn},
	year = {2015},
	keywords = {⛔ No DOI found},
	pages = {36},
}

@article{coss_cia_2014,
	title = {The {CIA} {Strikes} {Back}: {Redefining} {Confidentiality}, {Integrity} and {Availability} in {Security}.},
	volume = {10},
	url = {www.jissec.org},
	abstract = {This paper reviews the history of the CIA (Confidentiality, Integrity and Availability) triad from the perspectives of information security practitioners and scholars. Whilst the former have trusted the technical orientation of the triad as a unique point of reference in information security, the latter have questioned the triad's capacity of addressing the breadth of socio-technical issues that have emerged in security since the 2000s. Through a revisiting of the key tenets of the triad, the paper reconciles these two, seemingly fragmented, approaches. The main argument is that the CIA triad will continue to assume a major role in information security practice. However, this is not due to the fact that practitioners have discarded, or rejected the enhancements that socio-technical security scholars have proposed over the years; rather, it is because these enhancements can be accommodated by a broader re-conceptualization of the original CIA triad. The paper concludes with potential areas for future research.},
	number = {3},
	journal = {Journal of Information System Security},
	author = {Coss, David and Samonas, Spyridon},
	year = {2014},
	keywords = {⛔ No DOI found},
	pages = {21 -- 45},
}

@article{chen_privacy-preserving_2022,
	title = {Privacy-preserving knowledge transfer for intrusion detection with federated deep autoencoding gaussian mixture model},
	volume = {609},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025522007939},
	doi = {10.1016/j.ins.2022.07.104},
	abstract = {Knowledge transfer is critical in making use of data from multi-source domains, but most existing techniques are not privacy-preserving. Nowadays, data leakage, together with the advancement of big-data-driven Artificial Intelligence, has raised huge concerns over data security. The neglect of privacy makes such approaches impractical. For addressing intrusion detection tasks, the Deep Autoencoding Gaussian Mixture Model (DAGMM) concatenates and jointly optimizes a compression and an estimation network in an unsupervised manner. However, DAGMM still suffers from the lack of diversely distributed intrusion samples in real-life scenarios where organizations are neither willing nor legally allowed to engage in data sharing. Given the increasing public concern over data privacy and scandals, federated learning which only allows model parameter sharing is thus proposed to enhance model performance while preserving data privacy. Moreover, it also addresses the competitive concerns on the part of organizations when sharing data with their rivals. This study proposes a Federated Deep Autoencoding Gaussian Mixture Model (F-DAGMM) to build up privacy-preserving knowledge transfer, to further support inter-organizational cooperation and high-level decision making. A two-phase federated optimization strategy is proposed to address the performance degradation caused by the significant differences in the individual clients’ data distributions. Extensive experiments demonstrate the superiority of the proposed F-DAGMM.},
	language = {en},
	urldate = {2022-08-11},
	journal = {Information Sciences},
	author = {Chen, Yang and Zhang, Junzhe and Yeo, Chai Kiat},
	month = sep,
	year = {2022},
	keywords = {Anomaly detection, Deep autoencoding gaussian mixture model, Federated learning, Intrusion detection, Knowledge transfer, Privacy preserving},
	pages = {1204--1220},
}

@article{charles_convergence_2021,
	title = {Convergence and {Accuracy} {Trade}-{Oﬀs} in {Federated} {Learning} and {Meta}-{Learning}},
	abstract = {We study a family of algorithms, which we refer to as local update methods, generalizing many federated and meta-learning algorithms. We prove that for quadratic models, local update methods are equivalent to ﬁrst-order optimization on a surrogate loss we exactly characterize. Moreover, fundamental algorithmic choices (such as learning rates) explicitly govern a trade-oﬀ between the condition number of the surrogate loss and its alignment with the true loss. We derive novel convergence rates showcasing these trade-oﬀs and highlight their importance in communication-limited settings. Using these insights, we are able to compare local update methods based on their convergence/accuracy trade-oﬀ, not just their convergence to critical points of the empirical loss. Our results shed new light on a broad range of phenomena, including the eﬃcacy of server momentum in federated learning and the impact of proximal client updates.},
	language = {en},
	author = {Charles, Zachary and Konecny, Jakub},
	year = {2021},
	keywords = {⛔ No DOI found},
	pages = {11},
}

@article{chen_machine_2022,
	title = {Machine {Learning}-{Enabled} {IoT} {Security}: {Open} {Issues} and {Challenges} {Under} {Advanced} {Persistent} {Threats}},
	language = {en},
	author = {Chen, Zhiyan and Liu, Jinxin and Shen, Yu and Simsek, Murat and Kantarci, Burak and Mouftah, Hussein T and Djukic, Petar},
	year = {2022},
	keywords = {+survey, ⛔ No DOI found},
	pages = {35},
}

@article{chen_evfl_2022,
	title = {{EVFL}: {An} explainable vertical federated learning for data-oriented {Artificial} {Intelligence} systems},
	issn = {13837621},
	shorttitle = {{EVFL}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1383762122000583},
	doi = {10.1016/j.sysarc.2022.102474},
	abstract = {Vertical federated learning (VFL), as one of the latest advances of security in the data-oriented Artiﬁcial Intelligence (AI) systems, facilitates better keeping the AI systems converge faster with higher performance and security. Since a large amount of data from these systems is often of low quality, the training data needs to be interpreted and evaluated. While there have been some research efforts, they still have signiﬁcant shortcomings, such as high computational complexity and impracticality. Considering the characteristics of the data, the interpretation of machine learning models allows for data cleansing, which can improve data quality and help regulators understand the decision-making process. In this paper, we propose an explainable vertical federated learning (EVFL) framework, including the credibility assessment strategy, the federated counterfactual explanation and the importance rate (IR) metric. Furthermore, we initialize the knowledge-based counterfactual instance based on prior knowledge and retrain the federated counterfactual method for feasible counterfactual features. We report experimental results obtained on the Lending Club and Zhongyuan datasets for implementing our framework to show that our approach is signiﬁcantly effective. Notably, on the Lending Club dataset, our method can have a +4.9\% improvement over other selections.},
	language = {en},
	urldate = {2022-04-01},
	journal = {Journal of Systems Architecture},
	author = {Chen, Peng and Du, Xin and Lu, Zhihui and Wu, Jie and Hung, Patrick C.K.},
	month = mar,
	year = {2022},
	pages = {102474},
}

@article{chen_fedhealth_2020,
	title = {{FedHealth}: {A} {Federated} {Transfer} {Learning} {Framework} for {Wearable} {Healthcare}},
	volume = {35},
	issn = {1941-1294},
	shorttitle = {{FedHealth}},
	doi = {10.1109/MIS.2020.2988604},
	abstract = {With the rapid development of computing technology, wearable devices make it easy to get access to people's health information. Smart healthcare achieves great success by training machine learning models on a large quantity of user personal data. However, there are two critical challenges. First, user data often exist in the form of isolated islands, making it difficult to perform aggregation without compromising privacy security. Second, the models trained on the cloud fail on personalization. In this article, we propose FedHealth, the first federated transfer learning framework for wearable healthcare to tackle these challenges. FedHealth performs data aggregation through federated learning, and then builds relatively personalized models by transfer learning. Wearable activity recognition experiments and real Parkinson's disease auxiliary diagnosis application have evaluated that FedHealth is able to achieve accurate and personalized healthcare without compromising privacy and security. FedHealth is general and extensible in many healthcare applications.},
	number = {4},
	journal = {IEEE Intelligent Systems},
	author = {Chen, Yiqiang and Qin, Xin and Wang, Jindong and Yu, Chaohui and Gao, Wen},
	month = jul,
	year = {2020},
	note = {Conference Name: IEEE Intelligent Systems},
	keywords = {Biomedical monitoring, Collaborative work, Data models, Data privacy, Federated learning, Intelligent systems, Medical services, Servers, Training, Transfer learning, Wearable computing, Wearable healthcare},
	pages = {83--93},
}

@article{chen_adsim_2021,
	title = {{ADSim}: {Network} {Anomaly} {Detection} via {Similarity}-aware {Heterogeneous} {Ensemble} {Learning}},
	abstract = {The last decade has seen increasing application of machine learning to various tasks, including network anomaly detection. But anomaly detection methods using a single machine learning algorithm often fail to perform well, since network trafﬁc can have complex and changeable patterns. Therefore, many solutions based on ensemble learning have been proposed to address this problem. However, previous studies have a essential drawback that they overlook the similarity between the weak classiﬁers, which may degrade the detection ability of the model. What’s more, prior work use ofﬂine and supervised algorithms, which means a large amount of memory and reliable labels are necessary during the training period.},
	language = {en},
	author = {Chen, Wenqi and Wang, Zhiliang and Zhong, Ying and Han, Dongqi and Duan, Chenxin and Yin, Xia and Yang, Jiahai and Shi, Xingang},
	year = {2021},
	keywords = {⛔ No DOI found},
	pages = {5},
}

@article{chaabouni_network_2019,
	title = {Network {Intrusion} {Detection} for {IoT} {Security} {Based} on {Learning} {Techniques}},
	volume = {21},
	issn = {1553-877X},
	url = {https://ieeexplore.ieee.org/document/8629941/},
	doi = {10.1109/COMST.2019.2896380},
	abstract = {Pervasive growth of Internet of Things (IoT) is visible across the globe. The 2016 Dyn cyberattack exposed the critical fault-lines among smart networks. Security of IoT has become a critical concern. The danger exposed by infested Internet-connected Things not only affects the security of IoT but also threatens the complete Internet eco-system which can possibly exploit the vulnerable Things (smart devices) deployed as botnets. Mirai malware compromised the video surveillance devices and paralyzed Internet via distributed denial of service attacks. In the recent past, security attack vectors have evolved bothways, in terms of complexity and diversity. Hence, to identify and prevent or detect novel attacks, it is important to analyze techniques in IoT context. This survey classifies the IoT security threats and challenges for IoT networks by evaluating existing defense techniques. Our main focus is on network intrusion detection systems (NIDSs); hence, this paper reviews existing NIDS implementation tools and datasets as well as free and open-source network sniffing software. Then, it surveys, analyzes, and compares state-of-the-art NIDS proposals in the IoT context in terms of architecture, detection methodologies, validation strategies, treated threats, and algorithm deployments. The review deals with both traditional and machine learning (ML) NIDS techniques and discusses future directions. In this survey, our focus is on IoT NIDS deployed via ML since learning algorithms have a good success rate in security and privacy. The survey provides a comprehensive review of NIDSs deploying different aspects of learning techniques for IoT, unlike other top surveys targeting the traditional systems. We believe that, this paper will be useful for academia and industry research, first, to identify IoT threats and challenges, second, to implement their own NIDS and finally to propose new smart techniques in IoT context considering IoT limitations. Moreover, the survey will enable security individuals differentiate IoT NIDS from traditional ones.},
	number = {3},
	journal = {IEEE Communications Surveys \& Tutorials},
	author = {Chaabouni, Nadia and Mosbah, Mohamed and Zemmari, Akka and Sauvignac, Cyrille and Faruki, Parvez},
	year = {2019},
	note = {Publisher: IEEE},
	keywords = {+survey},
	pages = {2671--2701},
}

@article{chandola_anomaly_2009,
	title = {Anomaly detection: {A} survey},
	volume = {41},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Anomaly detection},
	url = {https://dl.acm.org/doi/10.1145/1541880.1541882},
	doi = {10.1145/1541880.1541882},
	abstract = {Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.},
	language = {en},
	number = {3},
	urldate = {2022-03-20},
	journal = {ACM Computing Surveys},
	author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
	month = jul,
	year = {2009},
	keywords = {+survey},
	pages = {1--58},
}

@article{celdran_cyberspec_2022,
	title = {{CyberSpec}: {Intelligent} {Behavioral} {Fingerprinting} to {Detect} {Attacks} on {Crowdsensing} {Spectrum} {Sensors}},
	shorttitle = {{CyberSpec}},
	url = {http://arxiv.org/abs/2201.05410},
	abstract = {Integrated sensing and communication (ISAC) is a novel paradigm using crowdsensing spectrum sensors to help with the management of spectrum scarcity. However, well-known vulnerabilities of resource-constrained spectrum sensors and the possibility of being manipulated by users with physical access complicate their protection against spectrum sensing data falsiﬁcation (SSDF) attacks. Most recent literature suggests using behavioral ﬁngerprinting and Machine/Deep Learning (ML/DL) for improving similar cybersecurity issues. Nevertheless, the applicability of these techniques in resource-constrained devices, the impact of attacks affecting spectrum data integrity, and the performance and scalability of models suitable for heterogeneous sensors types are still open challenges. To improve limitations, this work presents seven SSDF attacks affecting spectrum sensors and introduces CyberSpec, an ML/DL-oriented framework using device behavioral ﬁngerprinting to detect anomalies produced by SSDF attacks affecting resource-constrained spectrum sensors. CyberSpec has been implemented and validated in ElectroSense, a real crowdsensing RF monitoring platform where several conﬁgurations of the proposed SSDF attacks have been executed in different sensors. A pool of experiments with different unsupervised ML/DL-based models has demonstrated the suitability of CyberSpec detecting the previous attacks within an acceptable timeframe.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:2201.05410 [cs]},
	author = {Celdrán, Alberto Huertas and Sánchez, Pedro Miguel Sánchez and Bovet, Gérôme and Pérez, Gregorio Martínez and Stiller, Burkhard},
	month = jan,
	year = {2022},
	note = {arXiv: 2201.05410},
	keywords = {Computer Science - Cryptography and Security, ⛔ No DOI found},
}

@article{chadwick_cloud-edge_2020,
	title = {A cloud-edge based data security architecture for sharing and analysing cyber threat information},
	volume = {102},
	issn = {0167739X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X19300895},
	doi = {10.1016/j.future.2019.06.026},
	abstract = {Cyber-attacks affect every aspect of our lives. These attacks have serious consequences, not only for cyber-security, but also for safety, as the cyber and physical worlds are increasingly linked. Providing effective cyber-security requires cooperation and collaboration among all the entities involved. Increasing the amount of cyber threat information (CTI) available for analysis allows better prediction, prevention and mitigation of cyber-attacks. However, organizations are deterred from sharing their CTI over concerns that sensitive and confidential information may be revealed to others. We address this concern by providing a flexible framework that allows the confidential sharing of CTI for analysis between collaborators. We propose a five-level trust model for a cloud-edge based data sharing infrastructure. The data owner can choose an appropriate trust level and CTI data sanitization approach, ranging from plain text, through anonymization/pseudonymization to homomorphic encryption, in order to manipulate the CTI data prior to sharing it for analysis. Furthermore, this sanitization can be performed by either an edge device or by the cloud service provider, depending upon the level of trust the organization has in the latter. We describe our trust model, our cloud-edge infrastructure, and its deployment model, which are designed to satisfy the broadest range of requirements for confidential CTI data sharing. Finally we briefly describe our implementation and the testing that has been carried out so far by four pilot projects that are validating our infrastructure.},
	language = {en},
	urldate = {2021-06-01},
	journal = {Future Generation Computer Systems},
	author = {Chadwick, David W and Fan, Wenjun and Costantino, Gianpiero and de Lemos, Rogerio and Di Cerbo, Francesco and Herwono, Ian and Manea, Mirko and Mori, Paolo and Sajjad, Ali and Wang, Xiao-Si},
	month = jan,
	year = {2020},
	pages = {710--722},
}

@article{castrucci_design_2012,
	title = {Design and implementation of a mediation system enabling secure communication among {Critical} {Infrastructures}},
	volume = {5},
	issn = {18745482},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1874548212000194},
	doi = {10.1016/j.ijcip.2012.04.001},
	abstract = {Nowadays, the increase of interdependencies among different Critical Infrastructures (CI) makes it more and more difficult to protect without using a systemic approach that considers a single infrastructure as part of a complex system of infrastructures. A strong collaboration among CI owners is required to avoid, or at least to limit the propagation of failures from one infrastructure to another and to put CI in safety mode. The key element enabling this required cooperation is the possibility for them to exchange relevant information related to the status of their infrastructures and to the services provided. In this paper, we present a middleware solution that allows CIs sharing real-time information, enabling the design and implementation of fault mitigation strategies and mechanisms to prevent the cascading phenomena generated by the failure propagation from one infrastructure to another.},
	language = {en},
	number = {2},
	urldate = {2021-05-19},
	journal = {International Journal of Critical Infrastructure Protection},
	author = {Castrucci, Marco and Neri, Alessandro and Caldeira, Filipe and Aubert, Jocelyn and Khadraoui, Djamel and Aubigny, Matthieu and Harpes, Carlo and Simões, Paulo and Suraci, Vincenzo and Capodieci, Paolo},
	month = jul,
	year = {2012},
	pages = {86--97},
}

@article{cha_blockchain-based_2020,
	title = {Blockchain-{Based} {Cyber} {Threat} {Intelligence} {System} {Architecture} for {Sustainable} {Computing}},
	volume = {12},
	issn = {2071-1050},
	doi = {10.3390/su12166401},
	abstract = {Nowadays, the designing of cyber-physical systems has a significant role and plays a substantial part in developing a sustainable computing ecosystem for secure and scalable network architecture. The introduction of Cyber Threat Intelligence (CTI) has emerged as a new security system to mitigate existing cyber terrorism for advanced applications. CTI demands a lot of requirements at every step. In particular, data collection is a critical source of information for analysis and sharing; it is highly dependent on the reliability of the data. Although many feeds provide information on threats recently, it is essential to collect reliable data, as the data may be of unknown origin and provide information on unverified threats. Additionally, effective resource management needs to be put in place due to the large volume and diversity of the data. In this paper, we propose a blockchain-based cyber threat intelligence system architecture for sustainable computing in order to address issues such as reliability, privacy, scalability, and sustainability. The proposed system model can cooperate with multiple feeds that collect CTI data, create a reliable dataset, reduce network load, and measure organizations’ contributions to motivate participation. To assess the proposed model’s effectiveness, we perform the experimental analysis, taking into account various measures, including reliability, privacy, scalability, and sustainability. Experimental results of evaluation using the IP of 10 open source intelligence (OSINT) CTI feeds show that the proposed model saves about 15\% of storage space compared to total network resources in a limited test environment.},
	number = {16},
	journal = {Sustainability},
	author = {Cha, Jeonghun and Singh, Sushil Kumar and Pan, Yi and Park, Jong Hyuk},
	year = {2020},
	pages = {6401},
}

@article{buczak_survey_2016,
	title = {A {Survey} of {Data} {Mining} and {Machine} {Learning} {Methods} for {Cyber} {Security} {Intrusion} {Detection}},
	volume = {18},
	issn = {1553-877X},
	doi = {10.1109/COMST.2015.2494502},
	abstract = {This survey paper describes a focused literature survey of machine learning (ML) and data mining (DM) methods for cyber analytics in support of intrusion detection. Short tutorial descriptions of each ML/DM method are provided. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in ML/DM approaches, some well-known cyber data sets used in ML/DM are described. The complexity of ML/DM algorithms is addressed, discussion of challenges for using ML/DM for cyber security is presented, and some recommendations on when to use a given method are provided.},
	number = {2},
	journal = {IEEE Communications Surveys Tutorials},
	author = {Buczak, Anna L. and Guven, Erhan},
	year = {2016},
	note = {Conference Name: IEEE Communications Surveys Tutorials},
	keywords = {+survey, Computer security, Cyber Analytics, Cyber analytics, Data Mining, Data mining, Data models, IP networks, Machine Learning, Measurement, Ports (Computers), Protocols, \_read, data mining, machine learning},
	pages = {1153--1176},
}

@article{cao_cofed_2022,
	title = {{CoFED}: {Cross}-silo {Heterogeneous} {Federated} {Multi}-task {Learning} via {Co}-training},
	shorttitle = {{CoFED}},
	url = {http://arxiv.org/abs/2202.08603},
	abstract = {Federated Learning (FL) is a machine learning technique that enables participants to train highquality models collaboratively without exchanging their private data. Participants in cross-silo FL settings are independent organizations with different task needs, and they are concerned not only with data privacy, but also with training independently their unique models due to intellectual property. Most existing FL schemes are incapability for the above scenarios. In this paper, we propose a communication-efﬁcient FL scheme, CoFED, based on pseudo-labeling unlabeled data like co-training. To the best of our knowledge, it is the ﬁrst FL scheme compatible with heterogeneous tasks, heterogeneous models, and heterogeneous training algorithms simultaneously. Experimental results show that CoFED achieves better performance with a lower communication cost. Especially for the non-IID settings and heterogeneous models, the proposed method improves the performance by 35\%.},
	language = {en},
	urldate = {2022-02-25},
	journal = {arXiv:2202.08603 [cs]},
	author = {Cao, Xingjian and Li, Zonghang and Yu, Hongfang and Sun, Gang},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.08603},
	keywords = {Computer Science - Machine Learning, ⛔ No DOI found},
}

@article{cai_hybrid_2022,
	title = {A {Hybrid} parallel deep learning model for efficient intrusion detection based on metric learning},
	issn = {0954-0091, 1360-0494},
	url = {https://www.tandfonline.com/doi/full/10.1080/09540091.2021.2024509},
	doi = {10/gpbg4f},
	abstract = {With the rapid development of network technology, a variety of new malicious attacks appear while attack methods are constantly updated. As the attackers exploit the vulnerabilities of popular thirdparty components to invade target websites, further improving the classification accuracy of malicious network traffic is the key to improving the performance of abnormal traffic detection. Existing intrusion detection systems may suffer from incomplete feature extraction and low classification accuracy. Thus, this paper proposes an efficient hybrid parallel deep learning model (HPM) for intrusion detection based on margin learning. First, HPM constructs two parallel CNN architectures and fuses the spatial features obtained through full convolution. Secondly, the temporal information of the fused features is parsed separately using two parallel LSTMs. Finally, the extracted spatial-temporal features are fed into the CosMargin classifier for classification detection after global convolution and global pooling. Besides, this paper proposes an improved traffic feature extraction method, which not only reduces redundant features but also speeds up the convergence speed of the network. In the experiment, our HPM has achieved 99\% detection accuracy of each malicious class, ranging from 5\%–10\% improvement with other models, which demonstrates the superiority of our proposed model.},
	language = {en},
	urldate = {2022-01-31},
	journal = {Connection Science},
	author = {Cai, Shaokang and Han, Dezhi and Yin, Xinming and Li, Dun and Chang, Chin-Chen},
	month = jan,
	year = {2022},
	pages = {1--27},
}

@article{caldas_leaf_2019,
	title = {{LEAF}: {A} {Benchmark} for {Federated} {Settings}},
	shorttitle = {{LEAF}},
	url = {http://arxiv.org/abs/1812.01097},
	abstract = {Modern federated networks, such as those comprised of wearable devices, mobile phones, or autonomous vehicles, generate massive amounts of data each day. This wealth of data can help to learn models that can improve the user experience on each device. However, the scale and heterogeneity of federated data presents new challenges in research areas such as federated learning, meta-learning, and multi-task learning. As the machine learning community begins to tackle these challenges, we are at a critical time to ensure that developments made in these areas are grounded with realistic benchmarks. To this end, we propose LEAF, a modular benchmarking framework for learning in federated settings. LEAF includes a suite of open-source federated datasets, a rigorous evaluation framework, and a set of reference implementations, all geared towards capturing the obstacles and intricacies of practical federated environments.},
	language = {en},
	urldate = {2021-10-18},
	journal = {arXiv:1812.01097 [cs, stat]},
	author = {Caldas, Sebastian and Duddu, Sai Meher Karthik and Wu, Peter and Li, Tian and Konečný, Jakub and McMahan, H. Brendan and Smith, Virginia and Talwalkar, Ameet},
	month = dec,
	year = {2019},
	note = {arXiv: 1812.01097},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, ⛔ No DOI found},
}

@article{cao_when_2019,
	title = {When {Internet} of {Things} {Meets} {Blockchain}: {Challenges} in {Distributed} {Consensus}},
	volume = {33},
	issn = {0890-8044},
	url = {http://arxiv.org/abs/1905.06022},
	doi = {10.1109/MNET.2019.1900002},
	abstract = {Blockchain has been regarded as a promising technology for Internet of Things (IoT), since it provides significant solutions for decentralized network which can address trust and security concerns, high maintenance cost problem, etc. The decentralization provided by blockchain can be largely attributed to the use of consensus mechanism, which enables peer-to-peer trading in a distributed manner without the involvement of any third party. This article starts from introducing the basic concept of blockchain and illustrating why consensus mechanism plays an indispensable role in a blockchain enabled IoT system. Then, we discuss the main ideas of two famous consensus mechanisms including Proof of Work (PoW) and Proof of Stake (PoS), and list their limitations in IoT. Next, two mainstream Direct Acyclic Graph (DAG) based consensus mechanisms, i.e., the Tangle and Hashgraph, are reviewed to show why DAG consensus is more suitable for IoT system than PoW and PoS. Potential issues and challenges of DAG based consensus mechanism to be addressed in the future are discussed in the last.},
	number = {6},
	journal = {IEEE Network},
	author = {Cao, Bin and Li, Yixin and Zhang, Lei and Zhang, Long and Mumtaz, Shahid and Zhou, Zhenyu and Peng, Mugen},
	month = nov,
	year = {2019},
	pages = {133--139},
}

@article{beutel_flower_2020,
	title = {Flower: {A} friendly federated learning research framework},
	journal = {arXiv preprint arXiv:2007.14390},
	author = {Beutel, Daniel J and Topal, Taner and Mathur, Akhil and Qiu, Xinchi and Parcollet, Titouan and Lane, Nicholas D},
	year = {2020},
	keywords = {⛔ No DOI found},
}

@article{bierbrauer_transfer_2022,
	title = {Transfer learning for raw network traffic detection},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417422016840},
	doi = {10.1016/j.eswa.2022.118641},
	abstract = {Traditional machine learning models used for network intrusion detection systems rely on vast amounts of network traffic data with expertly engineered features. The abundance of computational and expert resources at the enterprise level allow for the employment of such models; however, these resources quickly dwindle in edge network scenarios. As Internet of Battlefield Things (IoBT) networks become common place in tactical environments, there is a need for improved and distributed models trained without these enterprise resources. Transfer learning – which allows us to take information learned in one domain and apply it to another – provides one way to create and distribute these models towards the edge. Using neural networks, we demonstrate the feasibility of transfer learning for intrusion detection using only raw network traffic in computationally limited environments. Our results show that with a transferred one-dimensional convolutional neural network model combined with a retrained random forest model, we obtain over 96\% accuracy with only 5,000 training samples on edge devices with an edge training time of approximately 67 s.},
	language = {en},
	urldate = {2022-08-29},
	journal = {Expert Systems with Applications},
	author = {Bierbrauer, David A. and De Lucia, Michael J. and Reddy, Krishna and Maxwell, Paul and Bastian, Nathaniel D.},
	month = aug,
	year = {2022},
	keywords = {Deep learning, Feature engineering, Internet of Battlefield Things, Machine learning, Network intrusion detection, Transfer learning},
	pages = {118641},
}

@article{blackburn_truth_2016,
	title = {The {Truth}, {The} {Whole} {Truth}, and {Nothing} {But} the {Truth}: {A} {Pragmatic} {Guide} to {Assessing} {Empirical} {Evaluations}},
	volume = {38},
	issn = {0164-0925, 1558-4593},
	shorttitle = {The {Truth}, {The} {Whole} {Truth}, and {Nothing} {But} the {Truth}},
	url = {https://dl.acm.org/doi/10.1145/2983574},
	doi = {10.1145/2983574},
	abstract = {An unsound claim can misdirect a field, encouraging the pursuit of unworthy ideas and the abandonment of promising ideas. An inadequate description of a claim can make it difficult to reason about the claim, for example, to determine whether the claim is sound. Many practitioners will acknowledge the threat of unsound claims or inadequate descriptions of claims to their field. We believe that this situation is exacerbated, and even encouraged, by the lack of a systematic approach to exploring, exposing, and addressing the source of unsound claims and poor exposition.
            This article proposes a framework that identifies three sins of reasoning that lead to unsound claims and two sins of exposition that lead to poorly described claims and evaluations. Sins of exposition obfuscate the objective of determining whether or not a claim is sound, while sins of reasoning lead directly to unsound claims.
            Our framework provides practitioners with a principled way of critiquing the integrity of their own work and the work of others. We hope that this will help individuals conduct better science and encourage a cultural shift in our research community to identify and promulgate sound claims.},
	language = {en},
	number = {4},
	urldate = {2021-09-24},
	journal = {ACM Transactions on Programming Languages and Systems},
	author = {Blackburn, Stephen M. and Diwan, Amer and Hauswirth, Matthias and Sweeney, Peter F. and Amaral, José Nelson and Brecht, Tim and Bulej, Lubomír and Click, Cliff and Eeckhout, Lieven and Fischmeister, Sebastian and Frampton, Daniel and Hendren, Laurie J. and Hind, Michael and Hosking, Antony L. and Jones, Richard E. and Kalibera, Tomas and Keynes, Nathan and Nystrom, Nathaniel and Zeller, Andreas},
	month = oct,
	year = {2016},
	keywords = {\_read},
	pages = {1--20},
}

@article{berger_attacks_2020,
	title = {Attacks on the {Industrial} {Internet} of {Things} – {Development} of a multi-layer {Taxonomy}},
	volume = {93},
	issn = {01674048},
	url = {https://doi.org/10.1016/j.cose.2020.101790},
	doi = {10.1016/j.cose.2020.101790},
	abstract = {The Industrial Internet of Things (IIoT) provides new opportunities to improve process and production efficiency, which enable new business models. At the same time, the high degree of cross-linking and decentralization increases the complexity of IIoT systems and creates new vulnerabilities. Hence, organizations are not only vulnerable to conventional IT threats, but also to a multitude of new, IIoT-specific attacks. Yet, a literature-based and empirically evaluated understanding of attacks on the IIoT is still lacking. Against this backdrop, we develop a multi-layer taxonomy that helps researchers and practitioners to identify similarities and differences between attacks on the IIoT. Based on the latest literature and a sample of about 50 attacks, we deductively and inductively determine attack characteristics and dimensions. We demonstrate the usefulness and practical relevance of our taxonomy by applying it to a real-world incident affecting a German steel facility. By combining IT security, IIoT, and risk management to form an interdisciplinary approach, we contribute to the descriptive knowledge in these fields. Industry experts confirm that our taxonomy enables a detailed classification of attacks, which supports the identification, documentation, and communication of incidents within organizations and their value-creation networks. With this, our taxonomy provides a profound basis for the further development of IT security management and the derivation of mitigation measures.},
	journal = {Computers \& Security},
	author = {Berger, Stephan and Bürger, Olga and Röglinger, Maximilian},
	month = jun,
	year = {2020},
	note = {Publisher: Elsevier Ltd},
	pages = {101790},
}

@article{bonawitz_towards_2019,
	title = {Towards {Federated} {Learning} at {Scale}: {System} {Design}},
	url = {http://arxiv.org/abs/1902.01046},
	abstract = {Federated Learning is a distributed machine learning approach which enables model training on a large corpus of decentralized data. We have built a scalable production system for Federated Learning in the domain of mobile devices, based on TensorFlow. In this paper, we describe the resulting high-level design, sketch some of the challenges and their solutions, and touch upon the open problems and future directions.},
	journal = {arXiv},
	author = {Bonawitz, Keith and Eichner, Hubert and Grieskamp, Wolfgang and Huba, Dzmitry and Ingerman, Alex and Ivanov, Vladimir and Kiddon, Chloe and Konečný, Jakub and Mazzocchi, Stefano and McMahan, H. Brendan and Van Overveldt, Timon and Petrou, David and Ramage, Daniel and Roselander, Jason},
	month = feb,
	year = {2019},
	keywords = {⛔ No DOI found},
}

@article{banabilah_federated_2022,
	title = {Federated learning review: {Fundamentals}, enabling technologies, and future applications},
	volume = {59},
	issn = {0306-4573},
	shorttitle = {Federated learning review},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457322001649},
	doi = {10.1016/j.ipm.2022.103061},
	abstract = {Federated Learning (FL) has been foundational in improving the performance of a wide range of applications since it was first introduced by Google. Some of the most prominent and commonly used FL-powered applications are Android’s Gboard for predictive text and Google Assistant. FL can be defined as a setting that makes on-device, collaborative Machine Learning possible. A wide range of literature has studied FL technical considerations, frameworks, and limitations with several works presenting a survey of the prominent literature on FL. However, prior surveys have focused on technical considerations and challenges of FL, and there has been a limitation in more recent work that presents a comprehensive overview of the status and future trends of FL in applications and markets. In this survey, we introduce the basic fundamentals of FL, describing its underlying technologies, architectures, system challenges, and privacy-preserving methods. More importantly, the contribution of this work is in scoping a wide variety of FL current applications and future trends in technology and markets today. We present a classification and clustering of literature progress in FL in application to technologies including Artificial Intelligence, Internet of Things, blockchain, Natural Language Processing, autonomous vehicles, and resource allocation, as well as in application to market use cases in domains of Data Science, healthcare, education, and industry. We discuss future open directions and challenges in FL within recommendation engines, autonomous vehicles, IoT, battery management, privacy, fairness, personalization, and the role of FL for governments and public sectors. By presenting a comprehensive review of the status and prospects of FL, this work serves as a reference point for researchers and practitioners to explore FL applications under a wide range of domains.},
	language = {en},
	number = {6},
	urldate = {2022-08-30},
	journal = {Information Processing \& Management},
	author = {Banabilah, Syreen and Aloqaily, Moayad and Alsayed, Eitaa and Malik, Nida and Jararweh, Yaser},
	month = nov,
	year = {2022},
	keywords = {+survey, Data privacy, Data security, Decentralized learning, Distributed learning, Federated learning, Machine learning, Mobile edge networks},
	pages = {103061},
}

@article{bemani_aggregation_2022,
	title = {Aggregation {Strategy} on {Federated} {Machine} {Learning} {Algorithm} for {Collaborative} {Predictive} {Maintenance}},
	volume = {22},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/16/6252},
	doi = {10.3390/s22166252},
	abstract = {Industry 4.0 lets the industry build compact, precise, and connected assets and also has made modern industrial assets a massive source of data that can be used in process optimization, defining product quality, and predictive maintenance (PM). Large amounts of data are collected from machines, processed, and analyzed by different machine learning (ML) algorithms to achieve effective PM. These machines, assumed as edge devices, transmit their data readings to the cloud for processing and modeling. Transmitting massive amounts of data between edge and cloud is costly, increases latency, and causes privacy concerns. To address this issue, efforts have been made to use edge computing in PM applications., reducing data transmission costs and increasing processing speed. Federated learning (FL) has been proposed a mechanism that provides the ability to create a model from distributed data in edge, fog, and cloud layers without violating privacy and offers new opportunities for a collaborative approach to PM applications. However, FL has challenges in confronting with asset management in the industry, especially in the PM applications, which need to be considered in order to be fully compatible with these applications. This study describes distributed ML for PM applications and proposes two federated algorithms: Federated support vector machine (FedSVM) with memory for anomaly detection and federated long-short term memory (FedLSTM) for remaining useful life (RUL) estimation that enables factories at the fog level to maximize their PM models’ accuracy without compromising their privacy. A global model at the cloud level has also been generated based on these algorithms. We have evaluated the approach using the Commercial Modular Aero-Propulsion System Simulation (CMAPSS) dataset to predict engines’ RUL Experimental results demonstrate the advantage of FedSVM and FedLSTM in terms of model accuracy, model convergence time, and network usage resources.},
	language = {en},
	number = {16},
	urldate = {2022-08-25},
	journal = {Sensors},
	author = {Bemani, Ali and Björsell, Niclas},
	month = aug,
	year = {2022},
	pages = {6252},
}

@article{bajpai_dagstuhl_2019,
	title = {The {Dagstuhl} beginners guide to reproducibility for experimental networking research},
	volume = {49},
	issn = {0146-4833},
	url = {https://dl.acm.org/doi/10.1145/3314212.3314217},
	doi = {10.1145/3314212.3314217},
	abstract = {Reproducibility is one of the key characteristics of good science, but hard to achieve for experimental disciplines like Internet measurements and networked systems. This guide provides advice to researchers, particularly those new to the field, on designing experiments so that their work is more likely to be reproducible and to serve as a foundation for follow-on work by others.},
	language = {en},
	number = {1},
	urldate = {2022-08-12},
	journal = {ACM SIGCOMM Computer Communication Review},
	author = {Bajpai, Vaibhav and Brunstrom, Anna and Feldmann, Anja and Kellerer, Wolfgang and Pras, Aiko and Schulzrinne, Henning and Smaragdakis, Georgios and Wählisch, Matthias and Wehrle, Klaus},
	month = feb,
	year = {2019},
	pages = {24--30},
}

@article{apruzzese_appcon_2020,
	title = {{AppCon}: {Mitigating} {Evasion} {Attacks} to {ML} {Cyber} {Detectors}},
	volume = {12},
	issn = {2073-8994},
	shorttitle = {{AppCon}},
	url = {https://www.mdpi.com/2073-8994/12/4/653},
	doi = {10.3390/sym12040653},
	abstract = {Adversarial attacks represent a critical issue that prevents the reliable integration of machine learning methods into cyber defense systems. Past work has shown that even proﬁcient detectors are highly affected just by small perturbations to malicious samples, and that existing countermeasures are immature. We address this problem by presenting AppCon, an original approach to harden intrusion detectors against adversarial evasion attacks. Our proposal leverages the integration of ensemble learning to realistic network environments, by combining layers of detectors devoted to monitor the behavior of the applications employed by the organization. Our proposal is validated through extensive experiments performed in heterogeneous network settings simulating botnet detection scenarios, and consider detectors based on distinct machine- and deep-learning algorithms. The results demonstrate the effectiveness of AppCon in mitigating the dangerous threat of adversarial attacks in over 75\% of the considered evasion attempts, while not being affected by the limitations of existing countermeasures, such as performance degradation in non-adversarial settings. For these reasons, our proposal represents a valuable contribution to the development of more secure cyber defense platforms.},
	language = {en},
	number = {4},
	urldate = {2022-07-05},
	journal = {Symmetry},
	author = {Apruzzese, Giovanni and Andreolini, Mauro and Marchetti, Mirco and Colacino, Vincenzo Giuseppe and Russo, Giacomo},
	month = apr,
	year = {2020},
	keywords = {\_read\_urgently},
	pages = {653},
}

@article{apruzzese_cross-evaluation_2022,
	title = {The {Cross}-evaluation of {Machine} {Learning}-based {Network} {Intrusion} {Detection} {Systems}},
	issn = {1932-4537, 2373-7379},
	url = {https://ieeexplore.ieee.org/document/9729769/},
	doi = {10.1109/TNSM.2022.3157344},
	abstract = {Enhancing Network Intrusion Detection Systems (NIDS) with supervised Machine Learning (ML) is tough. MLNIDS must be trained and evaluated, operations requiring data where benign and malicious samples are clearly labelled. Such labels demand costly expert knowledge, resulting in a lack of real deployments, as well as on papers always relying on the same outdated data. The situation improved recently, as some efforts disclosed their labelled datasets. However, most past works used such datasets just as a ‘yet another’ testbed, overlooking the added potential provided by such availability.},
	language = {en},
	urldate = {2022-07-05},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Apruzzese, Giovanni and Pajola, Luca and Conti, Mauro},
	year = {2022},
	keywords = {Evaluation., Intrusion Detection Systems, Labeling, Machine Learning, Machine learning, Monitoring, Network Security, Network intrusion detection, Proposals, Reliability, Training},
	pages = {1--1},
}

@article{almomani_wsn-ds_2016,
	title = {{WSN}-{DS}: {A} {Dataset} for {Intrusion} {Detection} {Systems} in {Wireless} {Sensor} {Networks}},
	volume = {2016},
	issn = {1687-725X, 1687-7268},
	shorttitle = {{WSN}-{DS}},
	url = {https://www.hindawi.com/journals/js/2016/4731953/},
	doi = {10.1155/2016/4731953},
	abstract = {Wireless Sensor Networks (WSN) have become increasingly one of the hottest research areas in computer science due to their wide range of applications including critical military and civilian applications. Such applications have created various security threats, especially in unattended environments. To ensure the security and dependability of WSN services, an Intrusion Detection System (IDS) should be in place. This IDS has to be compatible with the characteristics of WSNs and capable of detecting the largest possible number of security threats. In this paper a specialized dataset for WSN is developed to help better detect and classify four types of Denial of Service (DoS) attacks: Blackhole, Grayhole, Flooding, and Scheduling attacks. This paper considers the use of LEACH protocol which is one of the most popular hierarchical routing protocols in WSNs. A scheme has been defined to collect data from Network Simulator 2 (NS-2) and then processed to produce 23 features. The collected dataset is called WSN-DS. Artificial Neural Network (ANN) has been trained on the dataset to detect and classify different DoS attacks. The results show that WSN-DS improved the ability of IDS to achieve higher classification accuracy rate. WEKA toolbox was used with holdout and 10-Fold Cross Validation methods. The best results were achieved with 10-Fold Cross Validation with one hidden layer. The classification accuracies of attacks were 92.8\%, 99.4\%, 92.2\%, 75.6\%, and 99.8\% for Blackhole, Flooding, Scheduling, and Grayhole attacks, in addition to the normal case (without attacks), respectively.},
	language = {en},
	urldate = {2021-10-25},
	journal = {Journal of Sensors},
	author = {Almomani, Iman and Al-Kasasbeh, Bassam and AL-Akhras, Mousa},
	year = {2016},
	pages = {1--16},
}

@article{alexander_mitre_2020,
	title = {{MITRE} {ATT}\&{CK} for {Industrial} {Control} {Systems} : {Design} and {Philosophy}},
	abstract = {This paper discusses the motivation behind the creation of MITRE ATT\&CK® for Industrial Control Systems (ICS), the unique components described within it, its design philosophy, how the project has progressed, and how it can be used. For individuals new to ATT\&CK, the MITRE ATT\&CK®: Design and Philosophy whitepaper [1] should be read before reading this paper. This document does not represent a comprehensive resource on MITRE ATT\&CK. For individuals already familiar with ATT\&CK, this document can be viewed as an extension to the MITRE ATT\&CK whitepaper that highlights unique, as well as some common, aspects of the design and philosophy of ATT\&CK for ICS.},
	author = {Alexander, Otis and Belisle, Misha and Steele, Jacob},
	year = {2020},
	keywords = {⛔ No DOI found},
}

@article{aledhari_federated_2020,
	title = {Federated {Learning}: {A} {Survey} on {Enabling} {Technologies}, {Protocols}, and {Applications}},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9153560/},
	doi = {10.1109/ACCESS.2020.3013541},
	abstract = {This paper provides a comprehensive study of Federated Learning (FL) with an emphasis on enabling software and hardware platforms, protocols, real-life applications and use-cases. FL can be applicable to multiple domains but applying it to different industries has its own set of obstacles. FL is known as collaborative learning, where algorithm(s) get trained across multiple devices or servers with decentralized data samples without having to exchange the actual data. This approach is radically different from other more established techniques such as getting the data samples uploaded to servers or having data in some form of distributed infrastructure. FL on the other hand generates more robust models without sharing data, leading to privacy-preserved solutions with higher security and access privileges to data. This paper starts by providing an overview of FL. Then, it gives an overview of technical details that pertain to FL enabling technologies, protocols, and applications. Compared to other survey papers in the field, our objective is to provide a more thorough summary of the most relevant protocols, platforms, and real-life use-cases of FL to enable data scientists to build better privacy-preserving solutions for industries in critical need of FL. We also provide an overview of key challenges presented in the recent literature and provide a summary of related research work. Moreover, we explore both the challenges and advantages of FL and present detailed service use-cases to illustrate how different architectures and protocols that use FL can fit together to deliver desired results.},
	journal = {IEEE Access},
	author = {Aledhari, Mohammed and Razzak, Rehma and Parizi, Reza M. and Saeed, Fahad},
	year = {2020},
	pages = {140699--140725},
}

@article{alazzam_federated_2022,
	title = {Federated {Deep} {Learning} {Approaches} for the {Privacy} and {Security} of {IoT} {Systems}},
	volume = {2022},
	issn = {1530-8677, 1530-8669},
	url = {https://www.hindawi.com/journals/wcmc/2022/1522179/},
	doi = {10.1155/2022/1522179},
	abstract = {Using federated learning, which is a distributed machine learning approach, a machine learning model can train on a distributed data set without having to transfer any data between computers. Instead of using a centralised server for training, the model uses data stored locally on the device itself. After that, the server uses this model to create a jointly trained model. Federated learning asserts that privacy is preserved because no data is sent. Botnet attacks are detected using on-device decentralised traffic statistics and a deep autoencoder. This proposed federated learning approach addresses privacy and security concerns about data privacy and security rather than allowing data to be transferred or relocated off the network edge. In order to get the intended results of a previously centralised machine learning technique while also increasing data security, computation will be shifted to the edge layer. Up to 98\% accuracy is achieved in anomaly detection with our proposed model using features like MAC IP and source/destination/IP for training. Our solution outperforms a standard centrally managed system in terms of attack detection accuracy, according to our comparative performance analysis.},
	language = {en},
	urldate = {2022-04-06},
	journal = {Wireless Communications and Mobile Computing},
	author = {Alazzam, Malik Bader and Alassery, Fawaz and Almulihi, Ahmed},
	editor = {Rani, Shalli},
	month = apr,
	year = {2022},
	pages = {1--7},
}

@article{alazab_federated_2021,
	title = {Federated {Learning} for {Cybersecurity}: {Concepts}, {Challenges} and {Future} {Directions}},
	issn = {1551-3203, 1941-0050},
	shorttitle = {Federated {Learning} for {Cybersecurity}},
	url = {https://ieeexplore.ieee.org/document/9566732/},
	doi = {10/gnm4dj},
	abstract = {Federated learning (FL) is a recent development in artiﬁcial intelligence which is typically based on the concept of decentralized data. As cyber-attacks are frequently happening in the various applications deployed in real-time, most industrialists are hesitating to move forward in adopting the technology of the Internet of Everything (IoE). This paper aims to provide an extensive study on how FL could be utilized for providing better cybersecurity and prevent various cyber-attacks in real-time. We present an extensive survey of the various FL models currently developed by researchers for providing authentication, privacy, trust management and attack detection. We also discuss few realtime use cases that have been deployed recently and how FL is adopted in them for preserving privacy of data and improving the performance of the system. Based on the study, we conclude the paper with some prominent challenges and future directions on which the researchers can focus for adopting FL in real-time scenarios.},
	language = {en},
	urldate = {2021-12-02},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Alazab, Mamoun and R M, Swarna Priya and M, Parimala and Reddy, Praveen and Gadekallu, Thippa Reddy and Pham, Quoc-Viet},
	year = {2021},
	keywords = {+survey, \_processed},
	pages = {1--1},
}

@article{al-yaseen_real-time_2017,
	title = {Real-time multi-agent system for an adaptive intrusion detection system},
	volume = {85},
	issn = {01678655},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167865516303415},
	doi = {10.1016/j.patrec.2016.11.018},
	language = {en},
	urldate = {2021-07-21},
	journal = {Pattern Recognition Letters},
	author = {Al-Yaseen, Wathiq Laftah and Othman, Zulaiha Ali and Nazri, Mohd Zakree Ahmad},
	month = jan,
	year = {2017},
	keywords = {\_read},
	pages = {56--64},
}

@article{agrawal_federated_2021,
	title = {Federated {Learning} for {Intrusion} {Detection} {System}: {Concepts}, {Challenges} and {Future} {Directions}},
	shorttitle = {Federated {Learning} for {Intrusion} {Detection} {System}},
	url = {http://arxiv.org/abs/2106.09527},
	abstract = {The rapid development of the Internet and smart devices trigger surge in network trafﬁc making its infrastructure more complex and heterogeneous. The predominated usage of mobile phones, wearable devices and autonomous vehicles are examples of distributed networks which generate huge amount of data each and every day. The computational power of these devices have also seen steady progression which has created the need to transmit information, store data locally and drive network computations towards edge devices. Intrusion detection systems play a signiﬁcant role in ensuring security and privacy of such devices. Machine Learning and Deep Learning with Intrusion Detection Systems have gained great momentum due to their achievement of high classiﬁcation accuracy. However the privacy and security aspects potentially gets jeopardised due to the need of storing and communicating data to centralized server. On the contrary, federated learning (FL) ﬁts in appropriately as a privacy-preserving decentralized learning technique that does not transfer data but trains models locally and transfers the parameters to the centralized server. The present paper aims to present an extensive and exhaustive review on the use of FL in intrusion detection system. In order to establish the need for FL, various types of IDS, relevant ML approaches and its associated issues are discussed. The paper presents detailed overview of the implementation of FL in various aspects of anomaly detection. The allied challenges of FL implementations are also identiﬁed which provides idea on the scope of future direction of research. The paper ﬁnally presents the plausible solutions associated with the identiﬁed challenges in FL based intrusion detection system implementation acting as a baseline for prospective research.},
	language = {en},
	urldate = {2021-12-02},
	journal = {arXiv:2106.09527 [cs]},
	author = {Agrawal, Shaashwat and Sarkar, Sagnik and Aouedi, Ons and Yenduri, Gokul and Piamrat, Kandaraj and Bhattacharya, Sweta and Maddikunta, Praveen Kumar Reddy and Gadekallu, Thippa Reddy},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.09527},
	keywords = {+survey, Computer Science - Cryptography and Security, Computer Science - Machine Learning, \_processed, ⛔ No DOI found},
}

@article{afzali_seresht_mais-ids_2014,
	title = {{MAIS}-{IDS}: {A} distributed intrusion detection system using multi-agent {AIS} approach},
	volume = {35},
	issn = {09521976},
	shorttitle = {{MAIS}-{IDS}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0952197614001444},
	doi = {10.1016/j.engappai.2014.06.022},
	abstract = {This paper proposes an agent-based approach using artiﬁcial immune system (AIS) paradigms as a successful mechanism for a distributed intrusion detection system (IDS). The AIS paradigms are negative selection, clonal selection, danger theory, and immune network. These paradigms are very successful for anomaly IDS. The AIS paradigms are inspired by the powerful human immune system (HIS) and are promising candidate for design of an IDS. The proposed AIS-based agents are capable of learning, selfadaption, platform mobility, autonomy and collaboration. The proposed system (MAIS-IDS) was designed using these powerful and collaborative agents. This system has mobile and static agents with detector agents as the main actors in MAIS-IDS. The life cycles of agents are determined using the proposed immune algorithms in speciﬁc phases. Essential characteristics of MAIS-IDS are cloning, mutation, migration, collaboration, and randomness. MAIS-IDS was evaluated using a network of virtualized hosts, a kernel-based virtual machine (KVM) hypervisor and management Orchestra.},
	language = {en},
	urldate = {2021-07-21},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Afzali Seresht, Neda and Azmi, Reza},
	month = oct,
	year = {2014},
	keywords = {\_read},
	pages = {286--298},
}

@inproceedings{yuan_towards_2021,
	address = {Madrid, Spain},
	title = {Towards {Lightweight} and {Efficient} {Distributed} {Intrusion} {Detection} {Framework}},
	isbn = {978-1-72818-104-2},
	url = {https://ieeexplore.ieee.org/document/9685953/},
	doi = {10.1109/GLOBECOM46510.2021.9685953},
	abstract = {Federated learning (FL), as a promising distributed learning paradigm, has put many efforts into distributed intrusion detection systems (IDS), for defending against various malicious attacks, such as SQL injection and DDoS attacks. Compared with traditional IDS based on centralized deep learning (DL), FL-based solutions require not to share users’ raw data while yielding better detection performance. However, state-ofthe-art FL-based methods still suffer from two key limitations: 1) insufﬁcient detection performance on non-independent and identically distributed (non-IID) data, and 2) high communication and computational overheads due to the utilization of large-scale neural network models. In this paper, we propose a lightweight collaborative intrusion detection framework, called CoLGBM, the ﬁrst of its kind in the regime of decentralized IDS, where decision tree and light gradient boosting machine (LGBM) are combined for constructing the detection scheme. The main insight is that through combining user-trained decision trees (each user’s decision tree is derived from its own data with unique distribution), our framework can perform effectively on non-IID data while working efﬁciently for handling enormous samples. Compared with the current FL-based methods, our CoLGBM achieves higher accuracy and lower overhead on both IID and non-IID data. Extensive experiment results demonstrate our scheme with high-level performance.},
	language = {en},
	urldate = {2022-02-15},
	booktitle = {2021 {IEEE} {Global} {Communications} {Conference} ({GLOBECOM})},
	publisher = {IEEE},
	author = {Yuan, Shuai and Li, Hongwei and Zhang, Rui and Hao, Meng and Li, Yiran and Lu, Rongxing},
	month = dec,
	year = {2021},
	pages = {1--6},
}

@inproceedings{zhang_dual_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Dual {Adversarial} {Federated} {Learning} on {Non}-{IID} {Data}},
	isbn = {978-3-031-10989-8},
	doi = {10.1007/978-3-031-10989-8_19},
	abstract = {Federated Learning (FL) enables multiple distributed local clients to coordinate with a central server to train a global model without sharing their private data. However, the data owned by different clients, even with the same label, may induce conflicts in the latent feature maps, especially under the non-IID FL scenarios. This would fatally impair the performance of the global model. To this end, we propose a novel approach, DAFL, for Dual Adversarial Federated Learning, to mitigate the divergence on latent feature maps among different clients on non-IID data. In particular, a local dual adversarial training is designed to identify the origins of latent feature maps, and then transforms the conflicting latent feature maps to reach a consensus between global and local models in each client. Besides, the latent feature maps of the two models become closer to each other adaptively by reducing their Kullback Leibler divergence. Extensive experiments on benchmark datasets validate the effectiveness of DAFL and also demonstrate that DAFL outperforms the state-of-the-art approaches in terms of test accuracy under different non-IID settings.},
	language = {en},
	booktitle = {Knowledge {Science}, {Engineering} and {Management}},
	publisher = {Springer International Publishing},
	author = {Zhang, Tao and Yang, Shaojing and Song, Anxiao and Li, Guangxia and Dong, Xuewen},
	editor = {Memmi, Gerard and Yang, Baijian and Kong, Linghe and Zhang, Tianwei and Qiu, Meikang},
	year = {2022},
	keywords = {Dual adversarial training, Federated learning, Kullback Leibler divergence, Latent feature map, Non-IID data},
	pages = {233--246},
}

@inproceedings{yutao_internet_2022,
	title = {Internet of {Things} {Intrusion} {Detection} {System} based on {Transfer} {Learning}},
	doi = {10.1109/ICETCI55101.2022.9832387},
	abstract = {Because of the many types of Internet of Things (IoT) attacks, as well as the lack of computing resources for some devices, the small number of anomalous datasets and the lack of updated data, resulting in insufficient training data and computational power for supervised learning-based intrusion detection models and the Internet datasets still dominate the research on IoT intrusion detection. Therefore, this paper proposes a VGG-RED approach to IoT intrusion detection based on Transfer Learning (TL), which migrates the feature weights from the training of two Internet intrusion detection datasets to the training of three IoT intrusion detection datasets respectively, and inter-migrates the three IoT datasets. The classification models are trained by model parameter migration and neural network fine-tuning. Unlike previous work on extracting manually designed features, this method retains the end-to-end learning performance of Deep Learning (DL), reduces the risk of concept migration occurring, and reduces human intervention. Experimental results demonstrate the feasibility of the VGG-RED model to migrate Internet attack classification to the IoT. The model can effectively improve the accuracy of malicious attack detection in IoT environments while reducing computational resources, and has a strong generalization capability, with an accuracy improvement of about 2\% and a time reduction of 7-13\%.},
	booktitle = {2022 {IEEE} 2nd {International} {Conference} on {Electronic} {Technology}, {Communication} and {Information} ({ICETCI})},
	author = {Yutao, Wang and Zhongtian, Li and Yi, Bu and Jie, Li and Fangzheng, Xu and Yu, Bao},
	month = may,
	year = {2022},
	keywords = {Computational modeling, Deep learning, Intrusion detection, IoT intrusion detection, Neural networks, Training, Training data, Transfer learning, anomaly detection, convolutional neural networks, deep learning, transfer learning},
	pages = {25--30},
}

@inproceedings{xue_deep_2022,
	title = {Deep {Transfer} {Learning} for {IoT} {Intrusion} {Detection}},
	doi = {10.1109/CNIOT55862.2022.00023},
	abstract = {Intrusion detection system (IDS) is crucial to security architecture of Internet of Things (IoT). In recent researches, the traditional machine learning and deep learning methods have been applied to the field of intrusion detection and achieved satisfactory performance. However, due to diverse IoT and dynamic network environment, it is difficult to use a single model for heterogeneous IoT networks and collect enough labeled data to train the new model. To solve these issues, we propose an intrusion detection approach based on heterogeneous transfer learning (HTL) for building an intrusion detection model with strong adaptability. Specifically, the approach consists of an Autoencoder architecture for aligning the heterogeneous features and lightweight Convolutional Neural Network (CNN) for unsupervised domain adaptation. Extensive experimental results on three public datasets reveal that the effectiveness of our proposed approach in the IoT environment with unlabeled and limited data.},
	booktitle = {2022 3rd {International} {Conference} on {Computing}, {Networks} and {Internet} of {Things} ({CNIOT})},
	author = {Xue, Bing and Zhao, Hai and Yao, Wei},
	month = may,
	year = {2022},
	keywords = {Adaptation models, Buildings, Computer architecture, Data models, Deep learning, Intrusion detection, IoT, Transfer learning, \_read\_urgently, domain adaptation, intrusion detection, transfer learning},
	pages = {88--94},
}

@inproceedings{yang_h-fl_2021,
	address = {Montreal, Canada},
	title = {H-{FL}: {A} {Hierarchical} {Communication}-{Efficient} and {Privacy}-{Protected} {Architecture} for {Federated} {Learning}},
	isbn = {978-0-9992411-9-6},
	shorttitle = {H-{FL}},
	url = {https://www.ijcai.org/proceedings/2021/67},
	doi = {10/gngc3r},
	abstract = {The longstanding goals of federated learning (FL) require rigorous privacy guarantees and low communication overhead while holding a relatively high model accuracy. However, simultaneously achieving all the goals is extremely challenging. In this paper, we propose a novel framework called hierarchical federated learning (H-FL) to tackle this challenge. Considering the degradation of the model performance due to the statistic heterogeneity of the training data, we devise a runtime distribution reconstruction strategy, which reallocates the clients appropriately and utilizes mediators to rearrange the local training of the clients. In addition, we design a compression-correction mechanism incorporated into H-FL to reduce the communication overhead while not sacriﬁcing the model performance. To further provide privacy guarantees, we introduce differential privacy while performing local training, which injects moderate amount of noise into only part of the complete model. Experimental results show that our H-FL framework achieves the state-of-art performance on different datasets for the real-world image recognition tasks.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {Proceedings of the {Thirtieth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Yang, He},
	month = aug,
	year = {2021},
	keywords = {\_read\_urgently},
	pages = {479--485},
}

@inproceedings{xu_robust_2021,
	address = {Chengdu, China},
	title = {Robust {Model} {Aggregation} for {Federated} {Learning} with {Heterogeneous} {Clients}},
	isbn = {978-1-66540-950-6},
	url = {https://ieeexplore.ieee.org/document/9674541/},
	doi = {10/gpbg4q},
	abstract = {This Federated learning has received extensive attention in recent years due to its potential in mitigating risks of intruding privacy. However, most of existing methods don’t provide adequate consideration to the heterogeneity of client. Therefore these parameters are treated equally and aggregated with the same weight. As a result, the overall performance may be degraded because of straggling clients. In this paper, we propose an aggregation algorithm considering the accuracy of local model of heterogeneous clients. The server evaluates the accuracy of the uploaded local model with a benchmark dataset, and then updates model parameters according to the accuracy ratio. Experimental results show the model accuracy of our proposed method performs better than existing methods. At the same time, in the presence of noisy users, it can eliminate their effect by assigning lower aggregation weights to them.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2021 7th {International} {Conference} on {Computer} and {Communications} ({ICCC})},
	publisher = {IEEE},
	author = {Xu, Ruiting and Feng, Xinxin and Zheng, Haifeng},
	month = dec,
	year = {2021},
	pages = {1606--1610},
}

@inproceedings{yosinski_how_2014,
	title = {How transferable are features in deep neural networks?},
	abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the ﬁrst layer they learn features similar to Gabor ﬁlters and color blobs. Such ﬁrst-layer features appear not to be speciﬁc to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to speciﬁc by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus speciﬁcity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difﬁculties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A ﬁnal surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after ﬁne-tuning to the target dataset.},
	language = {en},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Neural} {Information} {Processing} {Systems} - {Volume} 2},
	author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
	month = dec,
	year = {2014},
	pages = {9},
}

@inproceedings{wang_flare_2022,
	address = {Nagasaki Japan},
	title = {{FLARE}: {Defending} {Federated} {Learning} against {Model} {Poisoning} {Attacks} via {Latent} {Space} {Representations}},
	isbn = {978-1-4503-9140-5},
	shorttitle = {{FLARE}},
	url = {https://dl.acm.org/doi/10.1145/3488932.3517395},
	doi = {10.1145/3488932.3517395},
	abstract = {Federated learning (FL) has been shown vulnerable to a new class of adversarial attacks, known as model poisoning attacks (MPA), where one or more malicious clients try to poison the global model by sending carefully crafted local model updates to the central parameter server. Existing defenses that have been fixated on analyzing model parameters show limited effectiveness in detecting such carefully crafted poisonous models. In this work, we propose FLARE, a robust model aggregation mechanism for FL, which is resilient against state-of-the-art MPAs. Instead of solely depending on model parameters, FLARE leverages the penultimate layer representations (PLRs) of the model for characterizing the adversarial influence on each local model update. PLRs demonstrate a better capability to differentiate malicious models from benign ones than model parameter-based solutions. We further propose a trust evaluation method that estimates a trust score for each model update based on pairwise PLR discrepancies among all model updates. Under the assumption that honest clients make up the majority, FLARE assigns a trust score to each model update in a way that those far from the benign cluster are assigned low scores. FLARE then aggregates the model updates weighted by their trust scores and finally updates the global model. Extensive experimental results demonstrate the effectiveness of FLARE in defending FL against various MPAs, including semantic backdoor attacks, trojan backdoor attacks, and untargeted attacks, and safeguarding the accuracy of FL.},
	language = {en},
	urldate = {2022-07-05},
	booktitle = {Proceedings of the 2022 {ACM} on {Asia} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Wang, Ning and Xiao, Yang and Chen, Yimin and Hu, Yang and Lou, Wenjing and Hou, Y. Thomas},
	month = may,
	year = {2022},
	pages = {946--958},
}

@inproceedings{wustrich_towards_2020,
	title = {Towards an {Extensible} {IoT} {Security} {Taxonomy}},
	volume = {2020-July},
	isbn = {978-1-72818-086-1},
	url = {https://ieeexplore.ieee.org/document/9219584/},
	doi = {10.1109/ISCC50000.2020.9219584},
	abstract = {Security is essential in the Internet of Things (IoT). IoT threat classifications are often non-intuitive to use. Identifying relevant properties of an attack is difficult and requires reading details of the attack. We therefore propose a simple-to-use naming scheme for IoT threat classification. It is based on the affected layers and the affected security goals. We evaluate the usefulness of the chosen approach by applying it to common IoT threats.},
	booktitle = {2020 {IEEE} {Symposium} on {Computers} and {Communications} ({ISCC})},
	publisher = {IEEE},
	author = {Wustrich, Lars and Pahl, Marc-Oliver and Liebald, Stefan},
	month = jul,
	year = {2020},
	note = {ISSN: 15301346},
	pages = {1--6},
}

@inproceedings{wu_towards_2019,
	title = {Towards {Improved} {Trust} in {Threat} {Intelligence} {Sharing} using {Blockchain} and {Trusted} {Computing}},
	isbn = {978-1-72812-949-5},
	url = {https://ieeexplore.ieee.org/document/8939192/},
	doi = {10.1109/IOTSMS48152.2019.8939192},
	abstract = {Threat intelligence sharing is posited as an important aid to help counter cybersecurity attacks and a number of threat intelligence sharing communities exist. There is a general consensus that many challenges remain to be overcome to achieve fully effective sharing, including concerns about privacy, negative publicity, policy/legal issues and expense of sharing, amongst others. One recent trend undertaken to address this is the use of decentralized blockchain based sharing architectures. However while these platforms can help increase sharing effectiveness they do not fully address all of the above challenges. In particular, issues around trust are not satisfactorily solved by current approaches. In this paper, we describe a novel trust enhancement framework -TITAN- for decentralized sharing based on the use of P2P reputation systems to address open trust issues. Our design uses blockchain and Trusted Execution Environment technologies to ensure security, integrity and privacy in the operation of the threat intelligence sharing reputation system.},
	booktitle = {2019 {Sixth} {International} {Conference} on {Internet} of {Things}: {Systems}, {Management} and {Security} ({IOTSMS})},
	publisher = {IEEE},
	author = {Wu, Yichang and Qiao, Yuansong and Ye, Yuhang and Lee, Brian},
	month = oct,
	year = {2019},
	pages = {474--481},
}

@inproceedings{wang_cmfl_2019,
	address = {Dallas, TX, USA},
	title = {{CMFL}: {Mitigating} {Communication} {Overhead} for {Federated} {Learning}},
	isbn = {978-1-72812-519-0},
	shorttitle = {{CMFL}},
	url = {https://ieeexplore.ieee.org/document/8885054/},
	doi = {10/ggv8zc},
	abstract = {Federated Learning enables mobile users to collaboratively learn a global prediction model by aggregating their individual updates without sharing the privacy-sensitive data. As mobile devices usually have limited data plan and slow network connections to the central server where the global model is maintained, mitigating the communication overhead is of paramount importance. While existing works mainly focus on reducing the total bits transferred in each update via data compression, we study an orthogonal approach that identiﬁes irrelevant updates made by clients and precludes them from being uploaded for reduced network footprint. Following this idea, we propose Communication-Mitigated Federated Learning (CMFL) in this paper. CMFL provides clients with the feedback information regarding the global tendency of model updating. Each client checks if its update aligns with this global tendency and is relevant enough to model improvement. By avoiding uploading those irrelevant updates to the server, CMFL can substantially reduce the communication overhead while still guaranteeing the learning convergence. CMFL is shown to achieve general improvement in communication efﬁciency for almost all of the existing federated learning schemes. We evaluate CMFL through extensive simulations and EC2 emulations. Compared with vanilla Federated Learning, CMFL yields 13.97x communication efﬁciency in terms of the reduction of network footprint. When applied to Federated Multi-Task Learning, CMFL improves the communication efﬁciency by 5.7x with 4\% higher prediction accuracy.},
	language = {en},
	urldate = {2022-02-08},
	booktitle = {2019 {IEEE} 39th {International} {Conference} on {Distributed} {Computing} {Systems} ({ICDCS})},
	publisher = {IEEE},
	author = {Wang, Luping and Wang, Wei and Li, Bo},
	month = jul,
	year = {2019},
	pages = {954--964},
}

@inproceedings{wagner_cyber_2019,
	title = {Cyber {Threat} {Intelligence} for “{Things}”},
	isbn = {978-1-72810-232-0},
	url = {https://ieeexplore.ieee.org/document/8899384/},
	doi = {10.1109/CyberSA.2019.8899384},
	abstract = {Cyber Threat Intelligence (CTI) programs have gained momentum across the cybersecurity community. Whether they are vendor based or open source solutions, practitioners should be able to find an appropriate solution to enhance security for their IT infrastructure. The tangible world, i.e. (Industrial) Internet of Things (I)IoT products and embedded components have not been considered yet in the CTI world with few exceptions from industry-specific vendors and Information Sharing Analysis Centres (ISACs). This extended abstract presents a work in progress to establish a CTI program for “things”, especially the generation, consumption and distribution of product-specific CTI.},
	booktitle = {2019 {International} {Conference} on {Cyber} {Situational} {Awareness}, {Data} {Analytics} {And} {Assessment} ({Cyber} {SA})},
	publisher = {IEEE},
	author = {Wagner, Thomas D},
	month = jun,
	year = {2019},
	pages = {1--2},
}

@inproceedings{verma_data_2019,
	address = {London United Kingdom},
	title = {Data {Quality} for {Security} {Challenges}: {Case} {Studies} of {Phishing}, {Malware} and {Intrusion} {Detection} {Datasets}},
	isbn = {978-1-4503-6747-9},
	shorttitle = {Data {Quality} for {Security} {Challenges}},
	url = {https://dl.acm.org/doi/10.1145/3319535.3363267},
	doi = {10.1145/3319535.3363267},
	abstract = {Techniques from data science are increasingly being applied by researchers to security challenges. However, challenges unique to the security domain necessitate painstaking care for the models to be valid and robust. In this paper, we explain key dimensions of data quality relevant for security, illustrate them with several popular datasets for phishing, intrusion detection and malware, indicate operational methods for assuring data quality and seek to inspire the audience to generate high quality datasets for security challenges.},
	language = {en},
	urldate = {2022-08-12},
	booktitle = {Proceedings of the 2019 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Verma, Rakesh M. and Zeng, Victor and Faridi, Houtan},
	month = nov,
	year = {2019},
	pages = {2605--2607},
}

@inproceedings{wagner_misp_2016,
	address = {New York, New York, USA},
	title = {{MISP} - {The} design and implementation of a collaborative threat intelligence sharing platform},
	isbn = {978-1-4503-4565-1},
	url = {http://dl.acm.org/citation.cfm?doid=2994539.2994542},
	doi = {10.1145/2994539.2994542},
	abstract = {The IT community is confronted with incidents of all kinds and nature, new threats appear on a daily basis. Fighting these security incidents individually is almost impossible. Sharing information about threats among the community has become a key element in incident response to stay on top of the attackers. Reliable information resources, pro- viding credible information, are therefore essential to the IT community, or even at broader scale, to intelligence commu- nities or fraud detection groups. This paper presents the Malware Information Sharing Plat- form (MISP) and threat sharing project, a trusted platform, that allows the collection and sharing of important indica- tors of compromise (IoC) of targeted attacks, but also threat information like vulnerabilities or financial indicators used in fraud cases. The aim of MISP is to help in setting up preven- tive actions and counter-measures used against targeted at- tacks. Enable detection via collaborative-knowledge-sharing about existing malware and other threats.},
	booktitle = {Proceedings of the 2016 {ACM} on {Workshop} on {Information} {Sharing} and {Collaborative} {Security} - {WISCS}'16},
	publisher = {ACM Press},
	author = {Wagner, Cynthia and Dulaunoy, Alexandre and Wagener, Gérard and Iklody, Andras},
	year = {2016},
	pages = {49--56},
}

@inproceedings{vakilinia_privacy-preserving_2017,
	title = {Privacy-preserving cybersecurity information exchange mechanism},
	volume = {49},
	url = {http://ieeexplore.ieee.org/document/8046783/},
	doi = {10.23919/SPECTS.2017.8046783},
	abstract = {Cybersecurity information sharing is improving cyber incident detection and prevention by reducing the loss caused by attacks and eliminating the costs of duplication efforts for cyber-defense. However, privacy is one of the major concerns of organizations, while they are gathering security information to share externally. In order to preserve the privacy of organizations in the cybersecurity information sharing framework, we propose a novel mechanism which consists of four components: (i) Registration, (ii) Sharing, (iii) Dispute, (iv) Rewarding. Our mechanism enables the organizations to share their cybersecurity information without revealing their identities. Besides, in order to encourage collaboration and prevent free-riding, rewards are issued anonymously in return for contributions. For this purpose, we are proposing a new aggregatable blind signature based on BBS+ signature scheme. Security analysis and performance evaluation are conducted showing the effectiveness and efficiency of the proposed mechanism.},
	booktitle = {2017 {International} {Symposium} on {Performance} {Evaluation} of {Computer} and {Telecommunication} {Systems} ({SPECTS})},
	publisher = {IEEE},
	author = {Vakilinia, Iman and Tosh, Deepak K. and Sengupta, Shamik},
	month = jul,
	year = {2017},
	note = {Issue: 10
ISSN: 07359276},
	pages = {1--7},
}

@inproceedings{turrin_statistical_2020,
	address = {New York, NY, USA},
	series = {{CPSIOTSEC}'20},
	title = {A {Statistical} {Analysis} {Framework} for {ICS} {Process} {Datasets}},
	isbn = {978-1-4503-8087-4},
	url = {https://doi.org/10.1145/3411498.3419961},
	doi = {10.1145/3411498.3419961},
	abstract = {In recent years, several schemes have been proposed to detect anomalies and attacks on Cyber-Physical Systems (CPSs) such as Industrial Control Systems (ICSs). Based on the analysis of sensor data, unexpected or malicious behavior is detected. Those schemes often rely on (implicit) assumptions on temporally stable sensor data distributions and invariants between process values. Unfortunately, the proposed schemes often perform not optimally with Recall scores lower than 70\% (e.g., missing 3 alarms every 10 anomalies) for some ICS datasets, with unclear root issues. In this work, we propose a general framework to check whether a given ICS dataset has specific properties (stable sensor distributions in normal operations, potentially state-dependent), which then allows to determine whether certain Anomaly Detection approaches can be expected to perform well. We apply our framework to three datasets showing that the behavior of actuators and sensors are very different between Training set and Test set. In addition, we present high-level guides to consider when designing an Anomaly Detection System.},
	urldate = {2022-08-12},
	booktitle = {Proceedings of the 2020 {Joint} {Workshop} on {CPS}\&{IoT} {Security} and {Privacy}},
	publisher = {Association for Computing Machinery},
	author = {Turrin, Federico and Erba, Alessandro and Tippenhauer, Nils Ole and Conti, Mauro},
	month = nov,
	year = {2020},
	keywords = {anomaly detection, dataset, industrial control systems},
	pages = {25--30},
}

@inproceedings{ur_rehman_towards_2020,
	address = {Toronto, ON, Canada},
	title = {Towards {Blockchain}-{Based} {Reputation}-{Aware} {Federated} {Learning}},
	isbn = {978-1-72818-695-5},
	url = {https://ieeexplore.ieee.org/document/9163027/},
	doi = {10.1109/INFOCOMWKSHPS50562.2020.9163027},
	abstract = {Federated learning (FL) is the collaborative machine learning (ML) technique whereby the devices collectively train and update a shared ML model while preserving their personal datasets. FL systems solve the problems of communicationefﬁciency, bandwidth-optimization, and privacy-preservation. Despite the potential beneﬁts of FL, one centralized shared ML model across all the devices produce coarse-grained predictions which, in essence, are not required in many application areas involving personalized prediction services. In this paper, we present a novel concept of ﬁne-grained FL to decentralize the shared ML models on the edge servers. We then present a formal extended deﬁnition of ﬁne-grained FL process in mobile edge computing systems. In addition, we deﬁne the core requirements of ﬁnegrained FL systems including personalization, decentralization, ﬁne-grained FL, incentive mechanisms, trust, activity monitoring, heterogeneity and context-awareness, model synchronization, and communication and bandwidth-efﬁciency. Moreover, we present the concept of blockchain-based reputation-aware ﬁne-grained FL in order to ensure trustworthy collaborative training in mobile edge computing systems. Finally, we perform the qualitative comparison of proposed approach with state-of-the-art related work and found some promising initial results.},
	language = {en},
	urldate = {2021-10-29},
	booktitle = {{IEEE} {INFOCOM} 2020 - {IEEE} {Conference} on {Computer} {Communications} {Workshops} ({INFOCOM} {WKSHPS})},
	publisher = {IEEE},
	author = {ur Rehman, Muhammad Habib and Salah, Khaled and Damiani, Ernesto and Svetinovic, Davor},
	month = jul,
	year = {2020},
	keywords = {\_read},
	pages = {183--188},
}

@inproceedings{thanigaivelan_distributed_2016,
	title = {Distributed internal anomaly detection system for {Internet}-of-{Things}},
	isbn = {978-1-4673-9292-1},
	url = {http://ieeexplore.ieee.org/document/7444797/},
	doi = {10.1109/CCNC.2016.7444797},
	abstract = {We present overview of a distributed internal anomaly detection system for Internet-of-things. In the detection system, each node monitors its neighbors and if abnormal behavior is detected, the monitoring node will block the packets from the abnormally behaving node at the data link layer and reports to its parent node. The reporting propagates from child to parent nodes until it reaches the root. A novel control message, distress propagation object (DPO), is devised to report the anomaly to the subsequent parents and ultimately the edge-router. The DPO message is integrated to routing protocol for low-power and lossy networks (RPL). The system has configurable profile settings and it is able to learn and differentiate the nodes' normal and suspicious activities without a need for prior knowledge. It has different subsystems and operation phases at data link and network layers, which share a common repository in a node. The system uses network fingerprinting to be aware of changes in network topology and nodes' positions without any assistance from a positioning system.},
	booktitle = {2016 13th {IEEE} {Annual} {Consumer} {Communications} \& {Networking} {Conference} ({CCNC})},
	publisher = {IEEE},
	author = {Thanigaivelan, Nanda Kumar and Nigussie, Ethiopia and Kanth, Rajeev Kumar and Virtanen, Seppo and Isoaho, Jouni},
	month = jan,
	year = {2016},
	pages = {319--320},
}

@inproceedings{vakilinia_attribute_2017,
	title = {Attribute based sharing in cybersecurity information exchange framework},
	volume = {49},
	url = {http://ieeexplore.ieee.org/document/8046770/},
	doi = {10.23919/SPECTS.2017.8046770},
	abstract = {As the complexity of the cyber attacks are increasing, there is a growing demand for proactive defense against them. CYBersecurity information EXchange (CYBEX) is playing a crucial role to implement proactive defense. CYBEX conveys organizations' sensitive information which demands proper access control management. However, previous works in this area do not consider access control for CYBEX. In this work, we tackle the access control problem in CYBEX. We model the attribute based access control in CYBEX with a semi-trusted sharing server. To achieve attribute based access control in CYBEX, our mechanism is developed based on the concepts of ciphertext policy attribute based encryption (CP-ABE) [1] and STIX [2]. The mechanism's workflow is as follows, at the beginning users claim their attributes from attribute authorities, then a key generation center generates decryption keys for users based on their attributes. For the sharing, organizations embed access control to their shared data. This is conducted by encrypting sensitive information such that only users with appropriate attributes can decrypt them. Security analysis, implementation and performance evaluation indicate the effectiveness and efficiency of the mechanism.},
	booktitle = {2017 {International} {Symposium} on {Performance} {Evaluation} of {Computer} and {Telecommunication} {Systems} ({SPECTS})},
	publisher = {IEEE},
	author = {Vakilinia, Iman and Tosh, Deepak K. and Sengupta, Shamik},
	month = jul,
	year = {2017},
	note = {Issue: 10
ISSN: 07359276},
	pages = {1--6},
}

@inproceedings{vakilinia_coalitional_2017,
	title = {A coalitional game theory approach for cybersecurity information sharing},
	volume = {2017-Octob},
	isbn = {978-1-5386-0595-0},
	url = {http://ieeexplore.ieee.org/document/8170845/},
	doi = {10.1109/MILCOM.2017.8170845},
	abstract = {As the complexity and number of cybersecurity incidents are growing, the traditional security measures are not sufficient to defend against attackers. In this situation, cyber threat intelligence capability substantially improves the detection and prevention of the sophisticated attacks. Cybersecurity information sharing is a key factor of threat intelligence, allowing organizations to detect and prevent malicious behaviors proactively. However, stimulating organizations to participate and deterring free-riding in such sharing is a big challenge. To this end, the sharing system should be equipped with a rewarding and participation-fee allocation mechanisms to encourage sharing behavior. In this paper, we investigate a rewarding and participation-fee calculation based on profit sharing in coalitional game theory. In particular, we formulate a coalitional game between organizations and analyze the well-known Shapley value and Nucleolus solution concepts in cybersecurity information sharing system.},
	booktitle = {{MILCOM} 2017 - 2017 {IEEE} {Military} {Communications} {Conference} ({MILCOM})},
	publisher = {IEEE},
	author = {Vakilinia, Iman and Sengupta, Shamik},
	month = oct,
	year = {2017},
	pages = {237--242},
}

@inproceedings{thakkar_game_2020,
	address = {Las Vegas, NV, USA},
	title = {Game theoretic approach applied in cybersecurity information exchange framework},
	isbn = {978-1-72813-893-0},
	url = {https://ieeexplore.ieee.org/document/9045430/},
	doi = {10.1109/CCNC46108.2020.9045430},
	abstract = {In CYBersecurity information EXchange (CYBEX) framework, Cyber Threat Intelligence (CTI) is shared among multiple organizations with a view of creating situational awareness. But there is a possibility that malicious organizations coexist with regular ones in this framework, which can get hold of the threat data shared by other organizations and can use it for carrying out malicious activities. We formulate the aforementioned problem as an incomplete information game assuming that whenever CYBEX receives any information, it processes the information for anomaly detection. We ﬁnd the mixed strategy Nash equilibrium probabilities and corresponding Bayesian belief updates. We simulate the game to ﬁnd the best response strategies with which regular and malicious organizations can play to increase their payoffs. Based on the best response strategies of organizations, we analyze that achieving more anomaly detection rate while keeping the processing rate minimum is the best action strategy with which CYBEX can play to increase the gain of both CYBEX and regular organizations over malicious organizations. We also ﬁnd the approximate average minimum processing rate and anomaly detection rate with which CYBEX can play in order to maintain the payoff of itself and regular organizations higher than the malicious ones.},
	language = {en},
	urldate = {2022-03-17},
	booktitle = {2020 {IEEE} 17th {Annual} {Consumer} {Communications} \& {Networking} {Conference} ({CCNC})},
	publisher = {IEEE},
	author = {Thakkar, Ankita and Badsha, Shahriar and Sengupta, Shamik},
	month = jan,
	year = {2020},
	pages = {1--7},
}

@inproceedings{tao_wan_intrudetector_2001,
	address = {New Orleans, LA, USA},
	title = {{IntruDetector}: a software platform for testing network intrusion detection algorithms},
	isbn = {978-0-7695-1405-5},
	shorttitle = {{IntruDetector}},
	url = {http://ieeexplore.ieee.org/document/991516/},
	doi = {10/cwrznf},
	abstract = {An Intrusion Detection System (IDS), that monitors passively specific computing resources, and reports anomalous or intrusive activities, is becoming an important component in the security system of information infrastructure. Algorithms for detecting intrusions are under rapid development, but far from being mature. One interesting and difficult issue is how to study and test a new intrusion detection algorithm against a variety of (perhaps simulated) intrusive activities under realistic background traffic. A flexible and general-purpose platform for testing intrusion detection algorithms is clearly desirable. This paper presents such a software platform, called IntruDetector. With this platform, detection algorithms can be tested directly in a real environment with wide range of intrusive activities. The data of normal system activities are directly collected from the live environment, and are mixed with intrusive activities that are simulated by hybrid simulation. The main properties of this approach are: (1) the background traffic is realistic; (2) it allows flexible simulation of various types of intrusions; and (3) normal system operation will not be disrupted by virtually simulated destructive intrusions during testing.},
	language = {en},
	urldate = {2022-01-12},
	booktitle = {Seventeenth {Annual} {Computer} {Security} {Applications} {Conference}},
	publisher = {IEEE Comput. Soc},
	author = {{Tao Wan} and {Xue Dong Yang}},
	year = {2001},
	keywords = {\_read\_urgently},
	pages = {3--11},
}

@inproceedings{sterritt_autonomous_2009,
	title = {Autonomous and {Autonomic} {Systems}: {Paradigm} for {Engineering} {Effective} {Software}-{Based} {Systems}?},
	isbn = {978-1-4244-6863-8},
	url = {http://ieeexplore.ieee.org/document/5621784/},
	doi = {10.1109/SEW.2009.22},
	abstract = {The Autonomous and Autonomic Systems initiative has as its vision the creation of self-directed and self-managing systems to address today's concerns of complexity and total cost of ownership while meeting tomorrow's needs for pervasive and ubiquitous software-based computation and communication. The future of computing and communications is being researched under many areas, including cloud, grid, utility, pervasive, ubiquitous, invisible, world, ambient, paint and so forth. The driving force behind these future paradigms of computer-based systems is the increasing convergence between proliferation of devices, wireless networking, and mobile software. Weiser first described what has become known as ubiquitous computing as the move away from the \&amp;\#x201C;dramatic\&amp;\#x201D; machine, where hardware and software's focus was on being so exciting that we as users would not want to be without it, towards making the machine \&amp;\#x201C;invisible\&amp;\#x201D;, so embedded in our lives it is used without thinking or recognising it as computing. Behind these different terms and research areas, lie three key properties: nomadic, embedded and invisible. In effect, leading to, the creation of a single system with (potentially) billions of networked information devices and resulting in a Complexity Quagmire? As such, the case can be made that all of the next generation paradigms, in one form or another, will require an autonomic-self-managing-infrastructure to be able to provide the successful reality of this envisaged level of pervasiveness, invisibility and mobility. This keynote talk reports on research and development, with examples from Biometric Identification and Tracking Systems, Autonomic Communications, and Space Exploration Systems, utilizing the biological metaphor of the autonomic nervous system to computing and communications, in which computer-based systems self-regulate by using automatic reactions to defend, optimize and heal.},
	booktitle = {2009 33rd {Annual} {IEEE} {Software} {Engineering} {Workshop}},
	publisher = {IEEE},
	author = {Sterritt, Roy},
	month = oct,
	year = {2009},
	pages = {57--57},
}

@inproceedings{slevi_survey_2021,
	address = {Palladam, India},
	title = {A survey on {Deep} {Learning} based {Intrusion} {Detection} {Systems} on {Internet} of {Things}},
	isbn = {978-1-66542-642-8},
	url = {https://ieeexplore.ieee.org/document/9641050/},
	doi = {10/gpbg3p},
	abstract = {The integration of IDS and Internet of Things (IoT) with deep learning plays a significant role in safety. S ecurity has a strong role to play. Application of the IoT network decreases the time complexity and resources. In the traditional intrusion detection systems (IDS ), this research work implements the cutting-edge methodologies in the IoT environment. This research is based on analysis, conception, testing and execution. Detection of intrusio ns can be performed by using the advanced deep learning system and multiagent. The NS L-KDD dataset is used to test the IoT system. The IoT system is used to test the IoT system. In order to detect attacks from intruders of transport layer, efficiency result rely on advanced deep learning idea. In order to increase the system performance, multi -agent algorithms could be employed to train communications agencies and to optimize the feedback training process. Advanced deep learning techniques such as CNN will be researched to boost system performance. The testing part an IoT includes data simulator which will be used to generate in continuous of research work finding with deep learning algorithms of suitable IDS in IoT network environment of current scenario wi thout time complexity.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2021 {Fifth} {International} {Conference} on {I}-{SMAC} ({IoT} in {Social}, {Mobile}, {Analytics} and {Cloud}) ({I}-{SMAC})},
	publisher = {IEEE},
	author = {Slevi, S. Tamil and Visalakshi, P.},
	month = nov,
	year = {2021},
	keywords = {+survey},
	pages = {1488--1496},
}

@inproceedings{sivanathan_characterizing_2017,
	title = {Characterizing and classifying {IoT} traffic in smart cities and campuses},
	isbn = {978-1-5386-2784-6},
	url = {http://ieeexplore.ieee.org/document/8116438/},
	doi = {10.1109/INFCOMW.2017.8116438},
	abstract = {Campuses and cities of the near future will be equipped with vast numbers of IoT devices. Operators of such environments may not even be fully aware of their IoT assets, let alone whether each IoT device is functioning properly safe from cyber-attacks. This paper proposes the use of network traffic analytics to characterize IoT devices, including their typical behaviour mode. We first collect and synthesize traffic traces from a smart-campus environment instrumented with a diversity of IoT devices including cameras, lights, appliances, and health-monitors; our traces, collected over a period of 3 weeks, are released as open data to the public. We then analyze the traffic traces to characterize statistical attributes such as data rates and burstiness, activity cycles, and signalling patterns, for over 20 IoT devices deployed in our environment. Finally, using these attributes, we develop a classification method that can not only distinguish IoT from non-IoT traffic, but also identify specific IoT devices with over 95\% accuracy. Our study empowers operators of smart cities and campuses to discover and monitor their IoT assets based on their network behaviour.},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Communications} {Workshops} ({INFOCOM} {WKSHPS})},
	publisher = {IEEE},
	author = {Sivanathan, Arunan and Sherratt, Daniel and Gharakheili, Hassan Habibi and Radford, Adam and Wijenayake, Chamith and Vishwanath, Arun and Sivaraman, Vijay},
	month = may,
	year = {2017},
	pages = {559--564},
}

@inproceedings{sklyar_enisa_2019,
	title = {{ENISA} {Documents} in {Cybersecurity} {Assurance} for {Industry} 4.0: {IIoT} {Threats} and {Attacks} {Scenarios}},
	volume = {2},
	isbn = {978-1-72814-069-8},
	url = {https://ieeexplore.ieee.org/document/8924452/},
	doi = {10.1109/IDAACS.2019.8924452},
	abstract = {The paper is devoted to analysis of a set of the European Union Agency for Network and Information Security (ENISA) documents in area of IoT security. Industrial IoT (IIoT) characteristics are studied for differences between IIoT and IoT, IIoT asset taxonomy and IIoT security challenges. After that ENISA IoT/IIoT Security Framework has been formed on the base of semantic details of the six studied ENISA documents. Additional attention is paid to IIoT treats taxonomy and attacks scenarios.},
	booktitle = {2019 10th {IEEE} {International} {Conference} on {Intelligent} {Data} {Acquisition} and {Advanced} {Computing} {Systems}: {Technology} and {Applications} ({IDAACS})},
	publisher = {IEEE},
	author = {Sklyar, Vladimir and Kharchenko, Vyacheslav},
	month = sep,
	year = {2019},
	pages = {1046--1049},
}

@inproceedings{sommer_outside_2010,
	title = {Outside the {Closed} {World}: {On} {Using} {Machine} {Learning} for {Network} {Intrusion} {Detection}},
	isbn = {978-1-4244-6894-2},
	url = {http://ieeexplore.ieee.org/document/5504793/},
	doi = {10.1109/SP.2010.25},
	abstract = {In network intrusion detection research, one popular strategy for finding attacks is monitoring a network's activity for anomalies: deviations from profiles of normality previously learned from benign traffic, typically identified using tools borrowed from the machine learning community. However, despite extensive academic research one finds a striking gap in terms of actual deployments of such systems: compared with other intrusion detection approaches, machine learning is rarely employed in operational "real world" settings. We examine the differences between the network intrusion detection problem and other areas where machine learning regularly finds much more success. Our main claim is that the task of finding attacks is fundamentally different from these other applications, making it significantly harder for the intrusion detection community to employ machine learning effectively. We support this claim by identifying challenges particular to network intrusion detection, and provide a set of guidelines meant to strengthen future research on anomaly detection. © 2010 IEEE.},
	booktitle = {2010 {IEEE} {Symposium} on {Security} and {Privacy}},
	publisher = {IEEE},
	author = {Sommer, Robin and Paxson, Vern},
	year = {2010},
	note = {ISSN: 10816011},
	keywords = {\_read\_urgently},
	pages = {305--316},
}

@inproceedings{siniosoglou_neuralpot_2020,
	title = {{NeuralPot}: {An} {Industrial} {Honeypot} {Implementation} {Based} {On} {Deep} {Neural} {Networks}},
	isbn = {978-1-72818-086-1},
	url = {https://ieeexplore.ieee.org/document/9219712/},
	doi = {10.1109/ISCC50000.2020.9219712},
	booktitle = {2020 {IEEE} {Symposium} on {Computers} and {Communications} ({ISCC})},
	publisher = {IEEE},
	author = {Siniosoglou, Ilias and Efstathopoulos, Georgios and Pliatsios, Dimitrios and Moscholios, Ioannis D. and Sarigiannidis, Antonios and Sakellari, Georgia and Loukas, Georgios and Sarigiannidis, Panagiotis},
	month = jul,
	year = {2020},
	pages = {1--7},
}

@inproceedings{sinha_overview_2015,
	address = {Florence Italy},
	title = {An {Overview} of {Microsoft} {Academic} {Service} ({MAS}) and {Applications}},
	isbn = {978-1-4503-3473-0},
	url = {https://dl.acm.org/doi/10.1145/2740908.2742839},
	doi = {10.1145/2740908.2742839},
	abstract = {In this paper we describe a new release of a Web scale entity graph that serves as the backbone of Microsoft Academic Service (MAS), a major production effort with a broadened scope to the namesake vertical search engine that has been publicly available since 2008 as a research prototype. At the core of MAS is a heterogeneous entity graph comprised of six types of entities that model the scholarly activities: ﬁeld of study, author, institution, paper, venue, and event. In addition to obtaining these entities from the publisher feeds as in the previous effort, we in this version include data mining results from the Web index and an in-house knowledge base from Bing, a major commercial search engine. As a result of the Bing integration, the new MAS graph sees signiﬁcant increase in size, with fresh information streaming in automatically following their discoveries by the search engine. In addition, the rich entity relations included in the knowledge base provide additional signals to disambiguate and enrich the entities within and beyond the academic domain. The number of papers indexed by MAS, for instance, has grown from low tens of millions to 83 million while maintaining an above 95\% accuracy based on test data sets derived from academic activities at Microsoft Research. Based on the data set, we demonstrate two scenarios in this work: a knowledge driven, highly interactive dialog that seamlessly combines reactive search and proactive suggestion experience, and a proactive heterogeneous entity recommendation.},
	language = {en},
	urldate = {2021-10-22},
	booktitle = {Proceedings of the 24th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Sinha, Arnab and Shen, Zhihong and Song, Yang and Ma, Hao and Eide, Darrin and Hsu, Bo-June (Paul) and Wang, Kuansan},
	month = may,
	year = {2015},
	pages = {243--246},
}

@inproceedings{sillaber_data_2016,
	address = {New York, New York, USA},
	title = {Data {Quality} {Challenges} and {Future} {Research} {Directions} in {Threat} {Intelligence} {Sharing} {Practice}},
	isbn = {978-1-4503-4565-1},
	url = {http://dl.acm.org/citation.cfm?doid=2994539.2994546},
	doi = {10.1145/2994539.2994546},
	abstract = {In the last couple of years, organizations have demonstrated an increased willingness to participate in threat intelligence sharing platforms. The open exchange of information and knowledge regarding threats, vulnerabilities, incidents and mitigation strategies results from the organizations' growing need to protect against today's sophisticated cyber attacks. To investigate data quality challenges that might arise in threat intelligence sharing, we conducted focus group discussions with ten expert stakeholders from security operations centers of various globally operating organizations. The study addresses several factors affecting shared threat intelligence data quality at multiple levels, including collecting, processing, sharing and storing data. As expected, the study finds that the main factors that affect shared threat intelligence data stem from the limitations and complexities associated with integrating and consolidating shared threat intelligence from different sources while ensuring the data's usefulness for an inhomogeneous group of participants.Data quality is extremely important for shared threat intelligence. As our study has shown, there are no fundamentally new data quality issues in threat intelligence sharing. However, as threat intelligence sharing is an emerging domain and a large number of threat intelligence sharing tools are currently being rushed to market, several data quality issues - particularly related to scalability and data source integration - deserve particular attention.},
	booktitle = {Proceedings of the 2016 {ACM} on {Workshop} on {Information} {Sharing} and {Collaborative} {Security} - {WISCS}'16},
	publisher = {ACM Press},
	author = {Sillaber, Christian and Sauerwein, Clemens and Mussmann, Andrea and Breu, Ruth},
	year = {2016},
	pages = {65--70},
}

@inproceedings{safri_federated_2022,
	title = {A {Federated} {Learning} {Framework} for {IoT}: {Application} to {Industry} 4.0},
	shorttitle = {A {Federated} {Learning} {Framework} for {IoT}},
	doi = {10.1109/CCGrid54584.2022.00066},
	abstract = {Predictive maintenance aims to anticipate indus-trial equipment failures in order to allow early scheduling of corrective actions. Such a maintenance approach is based on a detailed analysis that takes into account the technical and contextual characteristics of the target industrial equipment. However, this analysis requires a significant period of time to collect a representative quantity of data to learn a predictive model. Federated learning (FL in short) is a promising approach that allows several participants to build collaboratively a global predictive model. This approach has been widely explored in generic loT applications and large scale architectures. However, the implementation of FL in actual environments requires to consider several issues to adapt to existing loT architectures, including the management/orchestration of the federated tasks and handling the limitations of computational resources. Indeed, most of the current research focus on the aggregation of heavy deep learning algorithms. In this paper, we propose an architecture for FL in the context of loT based on the classical 3-layer architecture standardized by ETSI 11https://www.etsi.org/. We consider new features for performing federated tasks (training, aggregation and man-agement of each participant). We also propose a stacking-based aggregation method to build the global model in a cost-efficient way. We evaluate finally the performance and effectiveness of this approach on real use-case scenarios. The comparison with other models trained in a centralized way highlights the benefit of our approach.},
	booktitle = {2022 22nd {IEEE} {International} {Symposium} on {Cluster}, {Cloud} and {Internet} {Computing} ({CCGrid})},
	author = {Safri, Hamza and Kandi, Mohamed Mehdi and Miloudi, Youssef and Bortolaso, Christophe and Trystram, Denis and Desprez, Frédéric},
	month = may,
	year = {2022},
	keywords = {Collaborative work, Computer architecture, Federated Learning, Fourth Industrial Revolution, Job shop scheduling, Prediction algorithms, Predictive maintenance, Predictive models, Stacking algorithms, Training, edge, loT},
	pages = {565--574},
}

@inproceedings{saurabh_nfdlm_2022,
	title = {{NFDLM}: {A} {Lightweight} {Network} {Flow} based {Deep} {Learning} {Model} for {DDoS} {Attack} {Detection} in {IoT} {Domains}},
	shorttitle = {{NFDLM}},
	doi = {10.1109/AIIoT54504.2022.9817297},
	abstract = {In the recent years, Distributed Denial of Service (DDoS) attacks on Internet of Things (IoT) devices have become one of the prime concerns to Internet users around the world. One of the sources of the attacks on IoT ecosystems are botnets. Intruders force IoT devices to become unavailable for its legitimate users by sending large number of messages within a short interval. This study proposes NFDLM, a lightweight and optimised Artificial Neural Network (ANN) based Distributed Denial of Services (DDoS) attack detection framework with mutual correlation as feature selection method which produces a superior result when compared with Long Short Term Memory (LSTM) and simple ANN. Overall, the detection performance achieves approximately 99\% accuracy for the detection of attacks from botnets. In this work, we have designed and compared four different models where two are based on ANN and the other two are based on LSTM to detect the attack types of DDoS.},
	booktitle = {2022 {IEEE} {World} {AI} {IoT} {Congress} ({AIIoT})},
	author = {Saurabh, Kumar and Kumar, Tanuj and Singh, Uphar and Vyas, O.P. and Khondoker, Rahamatullah},
	month = jun,
	year = {2022},
	keywords = {ANN, Biological system modeling, Botnet, Botnets, DDoS, Deep learning, Denial-of-service attack, Ecosystems, Feature extraction, Force, IoT, LSTM},
	pages = {736--742},
}

@inproceedings{schneble_optimal_2019,
	address = {Chennai, India},
	title = {Optimal {Feature} {Selection} for {Intrusion} {Detection} in {Medical} {Cyber}-{Physical} {Systems}},
	isbn = {978-1-72815-286-8},
	url = {https://ieeexplore.ieee.org/document/9087284/},
	doi = {10.1109/ICoAC48765.2019.246846},
	abstract = {Medical cyber physical systems (MCPS) integrate the physical, communication and computation components of medical devices to enhance the quality and reliability of healthcare systems. With the remarkable progress of MCPS technologies in recent years, there is a need to advance the security measures to efﬁciently detect attacks in this domain. Research on intrusion detection for medical cyber physical systems is still in its infancy. For an efﬁcient intrusion detection system (IDS), it is important to address the problem of feature selection to remove redundant, irrelevant and noisy features. Feature selection is even more relevant to address in MCPS as the use of entire feature space places unnecessary burden on resource constrained systems in this domain. Also since realtime detection of attacks is critical in healthcare systems, the amount of data processed by IDS must be reduced to achieve low detection latency. In this paper, we investigate the problem of feature selection in medical cyber physical systems. Our initial results demonstrate the laplacian scoring techniques are successful in optimal feature selection with reduced memory consumption.},
	language = {en},
	urldate = {2022-05-28},
	booktitle = {2019 11th {International} {Conference} on {Advanced} {Computing} ({ICoAC})},
	publisher = {IEEE},
	author = {Schneble, William and Thamilarasu, Geethapriya},
	month = dec,
	year = {2019},
	pages = {238--243},
}

@inproceedings{schneider_high-performance_2018,
	address = {New York, NY, USA},
	title = {High-{Performance} {Unsupervised} {Anomaly} {Detection} for {Cyber}-{Physical} {System} {Networks}},
	isbn = {978-1-4503-5992-4},
	url = {https://dl.acm.org/doi/10.1145/3264888.3264890},
	doi = {10.1145/3264888.3264890},
	abstract = {While the ever-increasing connectivity of cyber-physical systems enlarges their attack surface, existing anomaly detection frameworks often do not incorporate the rising heterogeneity of involved systems. Existing frameworks focus on a single fieldbus protocol or require more detailed knowledge of the cyber-physical system itself. Thus, we introduce a uniform method and framework for applying anomaly detection to a variety of fieldbus protocols. We use stacked denoising autoencoders to derive a feature learning and packet classification method in one step. As the approach is based on the raw byte stream of the network traffic, neither specific protocols nor detailed knowledge of the application is needed. Additionally, we pay attention on creating an efficient framework which can also handle the increased amount of communication in cyber-physical systems. Our evaluation on a Secure Water Treatment dataset using EtherNet/IP and a Modbus dataset shows that we can acquire network packets up to 100 times faster than packet parsing based methods. However, we still achieve precision and recall metrics for longer lasting attacks of over 99\%.},
	booktitle = {Proceedings of the 2018 {Workshop} on {Cyber}-{Physical} {Systems} {Security} and {PrivaCy}},
	publisher = {ACM},
	author = {Schneider, Peter and Böttinger, Konstantin},
	month = jan,
	year = {2018},
	note = {ISSN: 15437221},
	pages = {1--12},
}

@inproceedings{ronen_extended_2016,
	title = {Extended {Functionality} {Attacks} on {IoT} {Devices}: {The} {Case} of {Smart} {Lights}},
	isbn = {978-1-5090-1751-5},
	url = {http://ieeexplore.ieee.org/document/7467343/},
	doi = {10.1109/EuroSP.2016.13},
	abstract = {In this paper we consider the security aspects of Internet of Things (IoT) devices, which bridge the physical and virtual worlds. We propose a new taxonomy of attacks, which classifies them into four broad categories. The most interesting category (which we call functionality extension attacks) uses the designed functionality of the IoT device to achieve a totally different effect. To demonstrate this type of attack, we consider the case of smart lights (whose original functionality is just to control the color and intensity of the lights in a particular room) and show how to use them to achieve unrelated effects. In the first attack, we use smart lights as a covert LIFI communication system to exfiltrate data from a highly secure (or even fully airgapped) office building. We implemented the attack and were able to read the leaked data from a distance of over 100 meters using only cheap and readily available equipment. In another attack, we showed that an attacker can strobe the lights at a frequency which may trigger seizures in people suffering from photosensitive epilepsy (in the same way that rapidly flashing video games can cause such seizures). In our experiments, we have tested both high-end and lower-end smart light systems, ranging from an expensive Philips HUE system to a cheap system manufactured by LimitlessLED. In addition, we consider other weaknesses of the systems we tested, and propose feasible remedies for the problems we found.},
	booktitle = {2016 {IEEE} {European} {Symposium} on {Security} and {Privacy} ({EuroS}\&{P})},
	publisher = {IEEE},
	author = {Ronen, Eyal and Shamir, Adi},
	month = mar,
	year = {2016},
	pages = {3--12},
}

@inproceedings{rocha_intrusion_2022,
	title = {Intrusion {Detection} in {Container} {Orchestration} {Clusters} : {A} framework proposal based on real-time system call analysis with machine learning for anomaly detection},
	shorttitle = {Intrusion {Detection} in {Container} {Orchestration} {Clusters}},
	doi = {10.23919/CISTI54924.2022.9820103},
	abstract = {Despite the benefits containerization brings, threats and risks of attacks against containerized technology have grown in equal proportion to its adoption. Intrusion Detection Systems (IDS) have been employed to secure cloud and container environments. However, the inherent characteristics of these environments have presented new challenges to ensuring an adequate level of security. In this paper, a framework is proposed for implementing a Host-based Intrusion Detection System (HIDS) by analyzing system calls with machine learning on a Kubernetes container orchestration cluster. The presented framework prevents the overhead of the cluster nodes from processing focused on intrusion detection through a distributed and scalable architecture. Alerts generated in the occurrence of detected anomalies can be used as a complementary source of information for decision making and action by the Security Operations Center (SOC) team to deal with an eventual security incident. The proposed architecture was implemented in the GNS3 software, emulating a corporate network environment to demonstrate the feasibility of implementing the framework in a real environment.},
	booktitle = {2022 17th {Iberian} {Conference} on {Information} {Systems} and {Technologies} ({CISTI})},
	author = {Rocha, Sávio Levy and Daniel Amvame Nze, Georges and Lopes de Mendonça, Fábio Lucio},
	month = jun,
	year = {2022},
	note = {ISSN: 2166-0727},
	keywords = {Computer architecture, Containers, Decision making, HIDS, Intrusion detection, Machine learning, SOC, Security, Software, containers, intrusion detection, system calls},
	pages = {1--4},
}

@inproceedings{rajasekar_efficient_2022,
	title = {An {Efficient} {Intrusion} {Detection} {Model} {Based} on {Recurrent} {Neural} {Network}},
	doi = {10.1109/ICDCECE53908.2022.9793016},
	abstract = {Intrusion detection has proven to be an efficient strategy of information security since it can identify unknown attacks from network traffic. The existing method to detect network anomalies is often based on classic machine learning models like KNN, SVM, and others. Even though these techniques can provide some impressive results, they have a poor level of accuracy and rely primarily on manual system design is required in feature extraction which is no longer relevant in the big data era. A deep learning-based intrusion detection methodology is suggested in this method to address the issues of low accuracy and feature extraction. The recurrent neural network is used in this approach with three steps in preprocessing such as data numerical conversion, data normalization, and data balancing. It can efficiently represent network traffic flow and enhance the capacity to identify anomalies. The suggested model is put to the test using a publicly available benchmark dataset, and the findings show that it outperforms alternative comparison approaches. The result analysis of the proposed method shows that the average accuracy is 99.56\%, average TPR is 99.55\%, average TNR is 99.32\%.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Distributed} {Computing} and {Electrical} {Circuits} and {Electronics} ({ICDCECE})},
	author = {Rajasekar, Vani and Sarika, Sabavath and S, Velliangiri and Joseph S, Iwin Thanakumar and S, Kalaivani K},
	month = apr,
	year = {2022},
	keywords = {Data Balancing, Deep Learning, Deep learning, Feature extraction, Intrusion detection, Numerical models, Recurrent Neural Network, Recurrent neural networks, Support vector machines, Telecommunication traffic},
	pages = {1--6},
}

@inproceedings{parra_interpretable_2022,
	title = {Interpretable federated transformer log learning for cloud threat forensics},
	author = {Parra, Gonzalo and Selvera, Luis and Khoury, Joseph and Irizarry, Hector and Bou-Harb, Elias and Rad, Paul},
	month = jan,
	year = {2022},
}

@inproceedings{oh_federated_2022,
	address = {Jeju Island, Korea, Republic of},
	title = {A federated binarized neural network model for constrained devices in {IoT} healthcare services},
	isbn = {978-1-66545-818-4},
	url = {https://ieeexplore.ieee.org/document/9722649/},
	doi = {10.1109/ICAIIC54071.2022.9722649},
	abstract = {In IoT healthcare environment, the devices are not sufficiently powerful for operating recent deep learning models, and data collected by the devices are usually decentralized. Moreover, data are unavailable to share between devices because of information security issues. Therefore, a concept of federated learning has emerged to overcome data sharing issues, and a concept of binarized neural network has emerged to generate lightweight deep learning models. This paper proposes a federated binarized neural network model to derive a reliable healthcare system in this circumstance. This paper shows an overview of considered system model with constrained IoT healthcare devices. In addition, this paper shows illustrations of implementing the proposed federated learning model with the proposed binarized MLP networks by utilizing an open-source library. The experiment results show that the binarized MLP network shows comparable performances compared to the fullprecision MLP network while the binarized MLP requires about 10-times less model size for training.},
	language = {en},
	urldate = {2022-03-04},
	booktitle = {2022 {International} {Conference} on {Artificial} {Intelligence} in {Information} and {Communication} ({ICAIIC})},
	publisher = {IEEE},
	author = {Oh, Hyeontaek and Yu, Jongmin and Kim, Nakyoung and Kim, Dongyeong and Lee, Jangwon and Yang, Jinhong},
	month = feb,
	year = {2022},
	pages = {241--245},
}

@inproceedings{otoum_federated_2021,
	address = {Madrid, Spain},
	title = {Federated {Transfer} {Learning}-{Based} {IDS} for the {Internet} of {Medical} {Things} ({IoMT})},
	isbn = {978-1-66542-390-8},
	url = {https://ieeexplore.ieee.org/document/9682118/},
	doi = {10/gpbg4z},
	abstract = {The Internet of Medical Things (IoMT) is a set of medical devices and applications that connect to healthcare systems through the Internet. Those devices are equipped with communication technologies that allow them to communicate with each other and the Internet. Reliance on the IoMT is increasing with the increase in epidemics and chronic diseases such as COVID-19 and diabetes; with the increase in the number of IoMT users and the need for electronic data sharing and virtual services, cyberattacks in the healthcare sector for accessing conﬁdential patient data has been increasing in the recent years. The healthcare applications and their infrastructures have special requirements for handling sensitive users’ data and the need for high availability. Therefore, securing healthcare applications and data has attracted special attention from both industry and researchers. In this paper, we propose a Federated Transfer Learning-based Intrusion Detection System (IDS) to secure the patient’s healthcare-connected devices. The model uses Deep Neural Network (DNN) algorithm for training the network and transferring the knowledge from the connected edge models to build an aggregated global model and customizing it for each one of the connected edge devices without exposing data privacy. CICIDS2017 dataset has been used to evaluate the performance in terms of accuracy, detection rate, and average training time. In addition to preserving data privacy of edge devices and achieving better performance, our comparison indicates that the proposed model can be generalized better and learns incrementally compared to other baseline ML/DL algorithms used in the traditional centralized learning schemes.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2021 {IEEE} {Globecom} {Workshops} ({GC} {Wkshps})},
	publisher = {IEEE},
	author = {Otoum, Yazan and Wan, Yue and Nayak, Amiya},
	month = dec,
	year = {2021},
	pages = {1--6},
}

@inproceedings{park_design_2022,
	title = {Design and {Development} of {Server}-{Client} {Cooperation} {Framework} for {Federated} {Learning}},
	doi = {10.1109/ICUFN55119.2022.9829693},
	abstract = {Federated learning is a machine learning technique that enables distributed training without explicitly data sharing between multiple heterogeneous devices. In this paper, we propose and develop a practical federated learning framework to effectively support model deployment, aggregation, and client device monitoring. The proposed approach is designed as a micro-architecture service using container-related technologies such as Docker, Kubernetes, and Prometheus.},
	booktitle = {2022 {Thirteenth} {International} {Conference} on {Ubiquitous} and {Future} {Networks} ({ICUFN})},
	author = {Park, Jongbin and Woo Kum, Seung},
	month = jul,
	year = {2022},
	note = {ISSN: 2165-8536},
	keywords = {Collaborative work, Computational modeling, Computer architecture, Distributed databases, Edge Computing, Federated Learning Framework, Load management, Machine learning, Micro Service Architecture, Training, \_read\_urgently},
	pages = {271--273},
}

@inproceedings{pahl_distributed_2016,
	title = {Distributed smart space orchestration},
	abstract = {Many networked devices that can interface their physical environments are available off-the-shelf or can be built in 2016. A comprehensive management of those Smart Devices is required to unlock the existing potential. However, the amount and heterogeneity of the devices make their management difficult. A suitable abstraction is missing. This paper identifies requirements on managing Smart Devices from diverse research fields, assesses relevant existing work, proposes a new management middleware design, and evaluates it quantitatively and qualitatively. The presented novel middleware architecture could become an enabler for a software maker culture.},
	booktitle = {Network operations and management symposium 2016 ({NOMS} 2016) - dissertation digest},
	author = {Pahl, Marc-Oliver and Carle, Georg and Klinker, Gudrun},
	month = may,
	year = {2016},
	note = {tex.webpdf: http://www.pahl.de/download/publications/NOMS2016$_{\textrm{D}}$istributed$_{\textrm{S}}$mart$_{\textrm{S}}$pace$_{\textrm{O}}$rchestration$_{\textrm{P}}$ahl.pdf},
}

@inproceedings{panda_distributed_2020,
	title = {Distributed {Ledger} {Technology} for {Securing} {IoT}},
	isbn = {978-1-72816-851-7},
	url = {https://ieeexplore.ieee.org/document/9225333/},
	doi = {10.1109/ICCCNT49239.2020.9225333},
	abstract = {Computing and communication are getting increasingly ubiquitous with the inclusion of sophisticated devices like electric vehicles, smart phones and other house hold appliances. Due to the constant evolution in Internet of Things (IoT), the process of collaboration of these devices at a mass scale in order to provide improved and better services to the society. Traditional mechanisms which are used to sustain privacy and security become incapable from achieving the same for IoT systems having distributed or decentralized topology. Distributed Ledger Technologies (DLT), an emerging digital technology, consists of different kinds of decentralized data structures to ensure immutability by linking blocks using cryptographic measures. DLT has the ability to ensure privacy, security and distributed or decentralized computations with adhering to the constraints of IoT nodes. This study is motivated due to the lack of an in-depth analysis on how the characteristics of DLT can be exploited to secure IoT systems. So, an in depth overview of DLT along with some of the existing solutions to meet security requirements of IoT systems employing DLT have been provided in this paper. With respect to integrating DLT with IoT, this article also highlights the different challenges.},
	booktitle = {2020 11th {International} {Conference} on {Computing}, {Communication} and {Networking} {Technologies} ({ICCCNT})},
	publisher = {IEEE},
	author = {Panda, Soumyashree S. and Mohanta, Bhabendu Kumar and Dey, Meenu Rani and Satapathy, Utkalika and Jena, Debasish},
	month = jul,
	year = {2020},
	pages = {1--6},
}

@inproceedings{panchal_security_2018,
	title = {Security {Issues} in {IIoT}: {A} {Comprehensive} {Survey} of {Attacks} on {IIoT} and {Its} {Countermeasures}},
	isbn = {978-1-5386-5201-5},
	url = {https://ieeexplore.ieee.org/document/8668630/},
	doi = {10.1109/GCWCN.2018.8668630},
	abstract = {Industrial Internet of Things (IIoT) applications connect machines, sensors and actuators in high-stake manufacturing industries. Industrial systems are using the potential of IoT to reduce the unnecessary operational cost and increase the usability and reliability of the industrial assets to achieve more profits. However, such smart Industries need connectivity and interoperability to enhance performance which makes them susceptible to various attacks. Recent attacks on Cyber-physical systems raise a strong security concern as such attacks causes a huge property loss and may also lead to life threatening situations. In this paper we discuss the potential security threats to the Industries adapting to IIoT and study the various attacks that are possible on the components in the layered IIoT architecture and some of the preventive measures. Finally, we propose IIoT attack taxonomy which would help in mitigating the risks of the attacks.},
	booktitle = {2018 {IEEE} {Global} {Conference} on {Wireless} {Computing} and {Networking} ({GCWCN})},
	publisher = {IEEE},
	author = {Panchal, Abhijeet C. and Khadse, Vijay M. and Mahalle, Parikshit N.},
	month = nov,
	year = {2018},
	pages = {124--130},
}

@inproceedings{nuding_data_2022,
	address = {Baltimore MD USA},
	title = {Data {Poisoning} in {Sequential} and {Parallel} {Federated} {Learning}},
	isbn = {978-1-4503-9230-3},
	url = {https://dl.acm.org/doi/10.1145/3510548.3519372},
	doi = {10.1145/3510548.3519372},
	abstract = {Federated Machine Learning has recently become a prominent approach to leverage data that is distributed across different clients, without the need to centralize data. Models are trained locally, and only model parameters are shared and aggregated into a global model. Federated learning can increase privacy of sensitive data, as the data itself is never shared, and benefit from the distributed setting by utilizing computational resources of the clients.},
	language = {en},
	urldate = {2022-07-05},
	booktitle = {Proceedings of the 2022 {ACM} on {International} {Workshop} on {Security} and {Privacy} {Analytics}},
	publisher = {ACM},
	author = {Nuding, Florian and Mayer, Rudolf},
	month = apr,
	year = {2022},
	pages = {24--34},
}

@inproceedings{moustafa_federated_2020,
	title = {Federated {TON}\_IoT {Windows} {Datasets} for {Evaluating} {AI}-{Based} {Security} {Applications}},
	doi = {10.1109/TrustCom50675.2020.00114},
	abstract = {Existing cyber security solutions have been basically developed using knowledge-based models that often cannot trigger new cyber-attack families. With the boom of Artificial Intelligence (AI), especially Deep Learning (DL) algorithms, those security solutions have been plugged-in with AI models to discover, trace, mitigate or respond to incidents of new security events. The algorithms demand a large number of heterogeneous data sources to train and validate new security systems. This paper presents the description of new datasets, the so-called ToN\_IoT, which involve federated data sources collected from Telemetry datasets of IoT services, Operating system datasets of Windows and Linux, and datasets of Network traffic. The paper introduces the testbed and description of TON\_IoT datasets for Windows operating systems. The testbed was implemented in three layers: edge, fog and cloud. The edge layer involves IoT and network devices, the fog layer contains virtual machines and gateways, and the cloud layer involves cloud services, such as data analytics, linked to the other two layers. These layers were dynamically managed using the platforms of software-Defined Network (SDN) and Network-Function Virtualization (NFV) using the VMware NSX and vCloud NFV platform. The Windows datasets were collected from audit traces of memories, processors, networks, processes and hard disks. The datasets would be used to evaluate various AI-based cyber security solutions, including intrusion detection, threat intelligence and hunting, privacy preservation and digital forensics. This is because the datasets have a wide range of recent normal and attack features and observations, as well as authentic ground truth events. The datasets can be publicly accessed from this link [1].},
	booktitle = {2020 {IEEE} 19th {International} {Conference} on {Trust}, {Security} and {Privacy} in {Computing} and {Communications} ({TrustCom})},
	author = {Moustafa, Nour and Keshky, Marwa and Debiez, Essam and Janicke, Helge},
	month = dec,
	year = {2020},
	note = {ISSN: 2324-9013},
	keywords = {Cloud computing, Computer crime, Data privacy, Federated datasets, AI-based security applications, testbed, Windows operating systems, intrusion detection, Internet of Things, Operating systems, Security, Virtual machining},
	pages = {848--855},
}

@inproceedings{mothukuri_cloudfl_2022,
	address = {New York, NY, USA},
	series = {{ARES} '22},
	title = {{CloudFL}: {A} {Zero}-{Touch} {Federated} {Learning} {Framework} for {Privacy}-aware {Sensor} {Cloud}},
	isbn = {978-1-4503-9670-7},
	shorttitle = {{CloudFL}},
	url = {https://doi.org/10.1145/3538969.3543783},
	doi = {10.1145/3538969.3543783},
	abstract = {Intelligent sensing solutions bridge the gap between the physical world and the cyber-physical systems by digitizing the sensor data collected from sensor devices. Sensor cloud networks provide physical and virtual sensing device resources and enable uninterrupted intelligent solutions to end-users. Thanks to advancements in machine learning algorithms and big data, the automation of mundane tasks with artificial intelligence is becoming a reliable smart option. However, existing approaches based on centralized Machine Learning (ML) on sensor cloud networks fail to ensure data privacy. Moreover, centralized ML works with the pre-requisite to transfer the entire training dataset from end devices to a central server. To address this, we propose a Quantized Federated Learning (FL) based approach, called CloudFL, to ensure data privacy on end devices in a sensor cloud network. Our framework enables a personalized version of FL implementation and enhances privacy and security with cryptosystem tools to obfuscate the information of the FL process from unauthorized access. Furthermore, microservices of our approach provide software as a service implementation of FL with instances of cloud servers that require zero-touch on local data for training.},
	urldate = {2022-08-23},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Availability}, {Reliability} and {Security}},
	publisher = {Association for Computing Machinery},
	author = {Mothukuri, Viraaji and Parizi, Reza M. and Pouriyeh, Seyedamin and Mashhadi, Afra},
	year = {2022},
	keywords = {Decentralized machine learning, Federated Learning, Privacy, Quantization, Security., Sensor cloud},
	pages = {1--8},
}

@inproceedings{murdoch_anonymity_2015,
	address = {New York, NY, USA},
	title = {Anonymity vs. {Trust} in {Cyber}-{Security} {Collaboration}},
	isbn = {978-1-4503-3822-6},
	url = {https://dl.acm.org/doi/10.1145/2808128.2808134},
	doi = {10.1145/2808128.2808134},
	abstract = {With the growing threat from overseas and domestic cyber attacks inter-organization cyber-security information sharing is an essential contributor to helping governments and industry to protect and defend their critical network infrastructure from attack. Encouraging collaboration directly impacts the defensive capabilities of all organizations involved in any cyber-information sharing community. A barrier to successful collaboration is the conflicting needs of collaborators to be able to both protect the source of their information for sensitivity, legal, or public relations reasons, but also to validate and trust the information shared with them. This paper uses as an example the UK government's Cyber- Security Information Sharing Partnership (CiSP), an online collaboration environment created by Surevine for sharing and collaborating on cyber-security information across UK industry and government. We discuss the organization and operating principles of the collaboration environment, how the community is structured, and the barriers to participation caused by the conflict between the need for anonymity versus the need to trust the information shared.},
	booktitle = {Proceedings of the 2nd {ACM} {Workshop} on {Information} {Sharing} and {Collaborative} {Security}},
	publisher = {ACM},
	author = {Murdoch, Stuart and Leaver, Nick},
	month = oct,
	year = {2015},
	pages = {27--29},
}

@inproceedings{muros_cooperative_2016,
	title = {Cooperative game theory tools to detect critical nodes in distributed control systems},
	isbn = {978-1-5090-2591-6},
	url = {http://ieeexplore.ieee.org/document/7810285/},
	doi = {10.1109/ECC.2016.7810285},
	abstract = {In this work, we deal with the identification of critical nodes in distributed control systems by means of game theoretical tools. This detection is addressed taking into consideration different factors such as the control performance under different topologies, the communication costs, and the centrality of the nodes in the network under study. In this sense, a generalization of the solution concept known as position value is considered to obtain a payoff for each node. A method that captures relevant information of the nodes using probability density functions of their payoffs is given and tested through an academic example.},
	booktitle = {2016 {European} {Control} {Conference} ({ECC})},
	publisher = {IEEE},
	author = {Muros, F. J. and Algaba, E. and Maestre, J. M. and Camacho, E. F.},
	month = jun,
	year = {2016},
	note = {Issue: 1},
	pages = {190--195},
}

@inproceedings{mcmahan_communication-efficient_2017,
	series = {Proceedings of machine learning research},
	title = {Communication-efficient learning of deep networks from decentralized data},
	volume = {54},
	url = {https://proceedings.mlr.press/v54/mcmahan17a.html},
	abstract = {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent.},
	booktitle = {Proceedings of the 20th international conference on artificial intelligence and statistics},
	publisher = {PMLR},
	author = {McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Aguera y},
	editor = {Singh, Aarti and Zhu, Jerry},
	month = apr,
	year = {2017},
	pages = {1273--1282},
}

@inproceedings{manyadza_fl-finder_2022,
	title = {{FL}-finder: {Detecting} {Unknown} {Network} {Anomaly} in {Federated} {Learning}},
	shorttitle = {{FL}-finder},
	doi = {10.1109/ICAIBD55127.2022.9820480},
	abstract = {The emergence of federated learning has ensured data and privacy security in deep learning models while enabling models to train more efficiently. However, the transmission of network parameters in federated learning may be subject to attacks by unknown anomalies. In this paper, we attempted to detect unknown anomalies in transmitted parameters in federated learning. We designed and implemented F1-finder, an unknown network anomaly detection framework in federated learning, which detects anomalies based on incremental learning. It retains the unknown anomalies to its prior knowledge base using the network updater, and adopts an online mode that reports new anomalies in a real-time. Extensive experimental results show that our model increased the average accuracy of unknown anomaly detection by 10.4\% and the average F1-Score improved to 19\%.},
	booktitle = {2022 5th {International} {Conference} on {Artificial} {Intelligence} and {Big} {Data} ({ICAIBD})},
	author = {Manyadza, Tinashe Justice and Du, Haizhou and Wang, Shiwei and Yang, Wenbin and Chen, Cheng and Tian, Fei},
	month = may,
	year = {2022},
	keywords = {Collaborative work, Data models, Detectors, Energy consumption, Federated Learning, Incremental learning, Knowledge based systems, Learning (artificial intelligence), Prior Knowledge, Real-time systems, Unknown Anomaly Detection},
	pages = {593--597},
}

@inproceedings{mathur_swat_2016,
	address = {Vienna, Austria},
	title = {{SWaT}: a water treatment testbed for research and training on {ICS} security},
	isbn = {978-1-5090-1161-2},
	shorttitle = {{SWaT}},
	url = {http://ieeexplore.ieee.org/document/7469060/},
	doi = {10.1109/CySWater.2016.7469060},
	abstract = {This paper presents the SWaT testbed, a modern industrial control system (ICS) for security research and training. SWaT is currently in use to (a) understand the impact of cyber and physical attacks on a water treatment system, (b) assess the effectiveness of attack detection algorithms, (c) assess the effectiveness of defense mechanisms when the system is under attack, and (d) understand the cascading effects of failures in one ICS on another dependent ICS. SWaT consists of a 6-stage water treatment process, each stage is autonomously controlled by a local PLC. The local ﬁeldbus communications between sensors, actuators, and PLCs is realized through alternative wired and wireless channels. While the experience with the testbed indicates its value in conducting research in an active and realistic environment, it also points to design limitations that make it difﬁcult for system identiﬁcation and attack detection in some experiments.},
	language = {en},
	urldate = {2021-05-19},
	booktitle = {2016 {International} {Workshop} on {Cyber}-physical {Systems} for {Smart} {Water} {Networks} ({CySWater})},
	publisher = {IEEE},
	author = {Mathur, Aditya P. and Tippenhauer, Nils Ole},
	month = apr,
	year = {2016},
	pages = {31--36},
}

@inproceedings{liu_federated_2022,
	title = {Federated {Learning} with {Anomaly} {Client} {Detection} and {Decentralized} {Parameter} {Aggregation}},
	doi = {10.1109/DSN-W54100.2022.00016},
	abstract = {Federated learning is a framework for machine learning that is dedicated to data privacy protection. In federated learning, system cannot fully control the behavior of clients which can be faulty. These behaviors include sharing arbitrary faulty gradients and delaying the process of sharing due to Byzantine attacks or clients’ own software and hardware failures. In federated learning, the parameter server may also be faulty during gradient collection and aggregation, mainly including gradient-based training data inference and model parameter faulty update. The above problems may lead to reduced accuracy of federated learning model training, leakage of client privacy, etc. Existing research enhances the robustness of federated learning by exploiting the decentralization and immutability of Blockchain. For untrusted clients, most research is based on Byzantine fault tolerance to defend against clients indiscriminately, and may cause model accuracy reduction. In addition, most of the research focus on unencrypted gradients, and there is insufficient research on dealing with client anomalies in the case of gradient encryption. For untrusted parameter servers, existing research has problems in energy overhead and scalability. Aiming at the problems above, this paper studies the robustness of federated learning, and proposes a blockchain-based federated learning parameter update architecture PUS-FL. Through experiments simulating distributed machine learning on neural networks, we demonstrate that the anomaly detection algorithm of PUS-FL outperforms conventional gradient filters including geometric median, Multi-Krum and trimmed mean. In addition, our experiments also verify that the scalability-enhanced parameter aggregation consensus algorithm proposed in this paper(SE-PBFT) improves consensus scalability by reducing communication complexity.},
	booktitle = {2022 52nd {Annual} {IEEE}/{IFIP} {International} {Conference} on {Dependable} {Systems} and {Networks} {Workshops} ({DSN}-{W})},
	author = {Liu, Shu and Shang, Yanlei},
	month = jun,
	year = {2022},
	note = {ISSN: 2325-6664},
	keywords = {Blockchain, Byzantine Attack, Collaborative work, Consensus Algorithm, Fault tolerant systems, Federated learning, Inference algorithms, Machine learning, Privacy, Robustness, Scalability, Trusted Computing},
	pages = {37--43},
}

@inproceedings{luo_cost-effective_2021,
	address = {Vancouver, BC, Canada},
	title = {Cost-{Effective} {Federated} {Learning} {Design}},
	isbn = {978-1-66540-325-2},
	url = {https://ieeexplore.ieee.org/document/9488679/},
	doi = {10.1109/INFOCOM42981.2021.9488679},
	abstract = {Federated learning (FL) is a distributed learning paradigm that enables a large number of devices to collaboratively learn a model without sharing their raw data. Despite its practical efﬁciency and effectiveness, the iterative on-device learning process incurs a considerable cost in terms of learning time and energy consumption, which depends crucially on the number of selected clients and the number of local iterations in each training round. In this paper, we analyze how to design adaptive FL that optimally chooses these essential control variables to minimize the total cost while ensuring convergence. Theoretically, we analytically establish the relationship between the total cost and the control variables with the convergence upper bound. To efﬁciently solve the cost minimization problem, we develop a low-cost sampling-based algorithm to learn the convergence related unknown parameters. We derive important solution properties that effectively identify the design principles for different metric preferences. Practically, we evaluate our theoretical results both in a simulated environment and on a hardware prototype. Experimental evidence veriﬁes our derived properties and demonstrates that our proposed solution achieves near-optimal performance for various datasets, different machine learning models, and heterogeneous system settings.},
	language = {en},
	urldate = {2022-05-25},
	booktitle = {{IEEE} {INFOCOM} 2021 - {IEEE} {Conference} on {Computer} {Communications}},
	publisher = {IEEE},
	author = {Luo, Bing and Li, Xiang and Wang, Shiqiang and Huang, Jianwei and Tassiulas, Leandros},
	month = may,
	year = {2021},
	pages = {1--10},
}

@inproceedings{lubben_advances_2021,
	address = {Abu Dhabi, United Arab Emirates},
	title = {Advances in {ML}-{Based} {Anomaly} {Detection} for the {IoT}},
	isbn = {978-1-66540-722-9},
	url = {https://ieeexplore.ieee.org/document/9614280/},
	doi = {10/gpbg2d},
	abstract = {The Internet of Things drives many activities in our modern world. Through its heterogeneity and connectivity to the Internet, it provides an attractive and big attack surface. Anomaly detection is a central tool for making IoT systems more secure. Since 2017, machine learning is successfully used for anomaly detection. This work gives an overview on the evolution of using machine learning for anomaly detection including the most active research groups, and the most attractive venues. In addition, it discusses the advantages and disadvantages of the available methods based on their use in literature.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2021 5th {Cyber} {Security} in {Networking} {Conference} ({CSNet})},
	publisher = {IEEE},
	author = {Lubben, Christian and Pahl, Marc-Oliver},
	month = oct,
	year = {2021},
	pages = {18--22},
}

@inproceedings{magdy_anonymous_2020,
	title = {Anonymous blockchain {Based} {Routing} {For} {Moving}-target {Defense} {Across} {Federated} {Clouds}},
	doi = {10.1109/HPSR48589.2020.9098983},
	abstract = {Cloud federation is the evolution of modern cloud computing. It provides better resource-sharing, perfect resource-utilization, and load-balancing. However, the heterogeneity of security policies and configurations between cloud service providers makes it hard for users to totally trust them. Further, the severe impact of modern cloud attacks such as cross-side channels on federated environments is a major roadblock against such evolution. Securing users' capsules (Virtual Machines and containers) against cross-side channel attacks is considered as a big challenge to cloud service providers. Moving-target Defense (MtD) by live capsule migration was introduced as an effective mechanism to overcome such challenge. However, researchers noted that even with MtD, migrated capsules can still be tracked via routing information. In this paper, we propose a novel Blockchain-based routing mechanism to enable trace-resistant Moving-target Defence (BMtD) to enable anonymous live cross-cloud migrations of running capsules in federated cloud environments. Exploiting the Vulnerable, Exposed, Attacked, Recovered (VEAR) model, simulation results demonstrated the effectiveness of BMtD in minimizing viral attack dispersion.},
	booktitle = {2020 {IEEE} 21st {International} {Conference} on {High} {Performance} {Switching} and {Routing} ({HPSR})},
	author = {Magdy, Yousra and Kashkoush, Mona S. and Azab, Mohamed and Rizk, Mohamed R. M.},
	month = may,
	year = {2020},
	note = {ISSN: 2325-5609},
	keywords = {Blockchain, Cloud Federation, Cloud computing, Containers, IP networks, Light Linux Virtualization, Moving target defense, Public key, Routing},
	pages = {1--7},
}

@inproceedings{majeed_flchain_2019,
	title = {{FLchain}: {Federated} {Learning} via {MEC}-enabled {Blockchain} {Network}},
	isbn = {978-4-88552-320-5},
	url = {https://ieeexplore.ieee.org/document/8892848/},
	doi = {10.23919/APNOMS.2019.8892848},
	abstract = {In this paper, we propose blockchain network based architecture called 'FLchain' for enhancing security of Federated Learning (FL). We leverage the concept of channels for learning multiple global models on FLchain. Local model parameters for each global iteration are stored as a block on the channel-specific ledger. We introduce the notion of 'the global model state trie' which is stored and updated on the blockchain network based on the aggregation of local model updates collected from mobile devices. Qualitative evaluation shows that FLchain is more robust than traditional FL schemes as it ensures provenance and maintains auditable aspects of FL model in an immutable manner.},
	booktitle = {2019 20th {Asia}-{Pacific} {Network} {Operations} and {Management} {Symposium} ({APNOMS})},
	publisher = {IEEE},
	author = {Majeed, Umer and Hong, Choong Seon},
	month = sep,
	year = {2019},
	pages = {1--4},
}

@inproceedings{liu_error_2022,
	title = {Error {Prevalence} in {NIDS} datasets: {A} {Case} {Study} on {CIC}-{IDS}-2017 and {CSE}-{CIC}-{IDS}-2018},
	shorttitle = {Error {Prevalence} in {NIDS} datasets},
	doi = {10.1109/CNS56114.2022.9947235},
	abstract = {Benchmark datasets are heavily depended upon by the research community to validate theoretical findings and track progression in the state-of-the-art. NIDS dataset creation presents numerous challenges on account of the volume, heterogeneity, and complexity of network traffic, making the process labor intensive, and thus, prone to error. This paper provides a critical review of CIC-IDS-2017 and CIC-CSE-IDS-2018, datasets which have seen extensive usage in the NIDS literature, and are currently considered primary benchmarking datasets for NIDS. We report a large number of previously undocumented errors throughout the dataset creation lifecycle, including in attack orchestration, feature generation, documentation, and labeling. The errors destabilize the results and challenge the findings of numerous publications that have relied on it as a benchmark. We demonstrate the implications of these errors through several experiments. We provide comprehensive documentation to summarize the discovery of these issues, as well as a fully-recreated dataset, with labeling logic that has been reverse-engineered, corrected, and made publicly available for the first time. We demonstrate the implications of dataset errors through a series of experiments. The findings serve to remind the research community of common pitfalls with dataset creation processes, and of the need to be vigilant when adopting new datasets. Lastly, we strongly recommend the release of labeling logic for any dataset released, to ensure full transparency.},
	booktitle = {2022 {IEEE} {Conference} on {Communications} and {Network} {Security} ({CNS})},
	author = {Liu, Lisa and Engelen, Gints and Lynar, Timothy and Essam, Daryl and Joosen, Wouter},
	month = oct,
	year = {2022},
	keywords = {Benchmark testing, CIC-IDS-2017, CSE-CIC-IDS-2018, Complexity theory, Documentation, Labeling, Network intrusion, Network security, Telecommunication traffic, datasets, network intrusion detection},
	pages = {254--262},
}

@inproceedings{lightbody_host-based_2022,
	title = {Host-{Based} {Intrusion} {Detection} {System} for {IoT} using {Convolutional} {Neural} {Networks}},
	doi = {10.1109/ISSC55427.2022.9826188},
	abstract = {This paper proposes and analyses a lightweight Convolutional Neural Network (CNN) based anomaly detection framework for Internet of Things (IoT) devices. IoT security has become a massive concern in recent years. IoT devices form the backbone of much of the critical infrastructure we have today. From power stations to biomedical devices, there is the potential of heavy financial damage and loss of human life if they become compromised. As IoT adoption accelerates, the amount of cyberattacks on IoT devices increases substantially. Due to the resource constrained nature of IoT devices, no security solution addresses all concerns in the IoT field. By training models based on normal power consumption behaviour, a wide range of anomalies can be detected in the power time series data of the IoT device. The methodology proposed in this paper is generic in nature, making it applicable to every IoT device on the market. The work in this paper is implemented at the edge, on an ultra-low-power microcontroller.},
	booktitle = {2022 33rd {Irish} {Signals} and {Systems} {Conference} ({ISSC})},
	author = {Lightbody, Dominic and Ngo, Duc-Minh and Temko, Andriy and Murphy, Colin and Popovici, Emanuel},
	month = jun,
	year = {2022},
	note = {ISSN: 2688-1454},
	keywords = {CNN, Convolutional neural networks, HIDS, IDS, Internet of Things, Intrusion detection, IoT, Power demand, Security, Time series analysis, Training, anomaly detection, low-power, machine learning, sustainable security},
	pages = {1--7},
}

@inproceedings{li_local_2021,
	address = {Melbourne, Australia},
	title = {Local {Model} {Update} for {Blockchain} {Enabled} {Federated} {Learning}: {Approach} and {Analysis}},
	isbn = {978-1-66541-760-0},
	shorttitle = {Local {Model} {Update} for {Blockchain} {Enabled} {Federated} {Learning}},
	url = {https://ieeexplore.ieee.org/document/9680546/},
	doi = {10/gpbg4x},
	abstract = {Federated learning (FL) has been considered as a promising distributed learning tool in massive data mining for different local devices. Addressing in the trust risk of centralized model aggregation and the challenge of data heterogeneity in traditional FL, this paper proposes an enhancement FL approach in a blockchain network. By analyzing the shortcakes of the classic FL that is widely used in the blockchain enabled FL networks, we propose a novel local parameter update approach, where the information of the last-round global model is utilized to reduce the local performance drift caused by data heterogeneity. The convergence of the proposed FL approach is then proved and the convergence rate is revealed to be linear to the training time. Finally, extensive experiments are carried out with a public dataset to validate the effectiveness of the proposed approach with comparisons of two classic baseline approaches.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2021 {IEEE} {International} {Conference} on {Blockchain} ({Blockchain})},
	publisher = {IEEE},
	author = {Li, Zhidu and Zhou, Yujie and Wu, Dapeng and Wang, Ruyan},
	month = dec,
	year = {2021},
	pages = {113--121},
}

@inproceedings{li_epps_2019,
	address = {Waikoloa, HI, USA},
	title = {{EPPS}: {Efficient} {Privacy}-{Preserving} {Scheme} in {Distributed} {Deep} {Learning}},
	isbn = {978-1-72810-962-6},
	shorttitle = {{EPPS}},
	url = {https://ieeexplore.ieee.org/document/9013395/},
	doi = {10.1109/GLOBECOM38437.2019.9013395},
	abstract = {As a promising training model with Neural Network, distributed deep learning has been widely applied in various scenarios, where clients and the cloud server work together only by sharing local gradients and global parameters. However, research has shown that the adversary can still reconstruct the users’ private information even if little information is leaked. To address this problem, several approaches of privacy-preserving distributed training have been exploited with existing mature technologies, such as Differential Privacy, Secure Multi-party Computation and Homomorphic Encryption. However, stateof-the-art results are still defective in security, functionality and efﬁciency. In this paper, we propose an Efﬁcient PrivacyPreserving Scheme (EPPS) for distributed deep learning. We claim that our solution achieves the best performance tradeoff between security, efﬁciency and functionality. Speciﬁcally, we adopt the threshold Paillier encryption as the underlying structure to construct our secure training model. Hence, the conﬁdentiality of honest users’ of local gradients can be guaranteed, even the cloud server colluding with multiple users. In addition, since users are often accidentally ofﬂine due to either network environment or equipment damage, our EPPS can also support users exiting at any phases of the entire work process. Further more, we conducted extensive experiments on real-world data to demonstrate the preferable performance of our proposed scheme. Index Terms—Privacy-Preserving, Distributed Deep Learning, Multiple Keys.},
	language = {en},
	urldate = {2021-05-18},
	booktitle = {2019 {IEEE} {Global} {Communications} {Conference} ({GLOBECOM})},
	publisher = {IEEE},
	author = {Li, Yiran and Li, Hongwei and Xu, Guowen and Liu, Sen and Lu, Rongxing},
	month = dec,
	year = {2019},
	pages = {1--6},
}

@inproceedings{leo_federated_2014,
	title = {A federated architecture approach for {Internet} of {Things} security},
	isbn = {978-88-87237-20-7},
	url = {http://ieeexplore.ieee.org/document/6996632/},
	doi = {10.1109/EMTC.2014.6996632},
	abstract = {Internet of Things (IoT) refers to the capability to connect, communicate and remotely manage a large number of networked, automated devices via the Internet. IoT is becoming as part of daily life and aims to extend pervasive communication and networking anytime, anywhere with any device. In this context security requirements and architectures must be properly formulated, implemented in order to enforce the security policies during their life-cycle. This paper provides a survey and analysis of security in the area of IoT introducing an approach addressed to overcome the conventional security solutions and deploy a federated architecture for dynamic prevention, detection, diagnosis, isolation, and countermeasures against cyber attacks. Based on the analysis of the most common web services, the paper defines the security needs proposing a federated model to design an architecture for secure exchange of services in IoT paradigm.},
	booktitle = {2014 {Euro} {Med} {Telco} {Conference} ({EMTC})},
	publisher = {IEEE},
	author = {Leo, Marco and Battisti, Federica and Carli, Marco and Neri, Alessandro},
	month = nov,
	year = {2014},
	pages = {1--5},
}

@inproceedings{lalouani_robust_2021,
	address = {Madrid, Spain},
	title = {Robust {Distributed} {Intrusion} {Detection} {System} for {Edge} of {Things}},
	isbn = {978-1-72818-104-2},
	url = {https://ieeexplore.ieee.org/document/9685361/},
	doi = {10.1109/GLOBECOM46510.2021.9685361},
	abstract = {The edge computing paradigm has been adopted in many Internet-of-Things (IoT) applications to improve responsiveness and conserve communication resources. However, such high agility and efficiency come with increased cyber threats. Intrusion detection systems (IDS) have been the primary means for guarding networked computing assets against hacking attempts. The popular design methodology for IDS relies on the application of machine learning (ML) techniques that use intelligence data to classify malicious activities. However, in the realm of IoT, insufficient data is available to build IDS; hence a distributed intrusion system with continual data collection is primordial to refine the detection model. Such IDS is also subject to privacy constraints and should sustain robustness against data manipulation from internal attackers that degrade the ML model. This paper opts to fulfill these requirements by proposing a novel distributed IDS for IoT. The proposed system employs federated learning to enable privacy preservation and diminish the communication overhead. Our system promotes a reinforcement mechanism to ensure resiliency to data manipulation attacks by single or colluding internal actors. The validation results using recently released datasets demonstrate the effectiveness of our approach.},
	language = {en},
	urldate = {2022-02-15},
	booktitle = {2021 {IEEE} {Global} {Communications} {Conference} ({GLOBECOM})},
	publisher = {IEEE},
	author = {Lalouani, Wassila and Younis, Mohamed},
	month = dec,
	year = {2021},
	pages = {01--06},
}

@inproceedings{lanvin_errors_2022,
	address = {Sousse, Tunisia},
	title = {Errors in the {CICIDS2017} dataset and the significant differences in detection performances it makes},
	url = {https://hal.archives-ouvertes.fr/hal-03775466},
	abstract = {Among the difficulties encountered in building datasets to evaluate intrusion detection tools, a tricky part is the process of labelling the events into malicious and benign classes. The labelling correctness is paramount for the quality of the evaluation of intrusion detection systems but is often considered as the ground truth by practitioners and is rarely verified. Another difficulty lies in the correct capture of the network packets. If it is not the case, the characteristics of the network flows generated from the capture could be modified and lead to false results. In this paper, we present several flaws we identified in the labelling of the CICIDS2017 dataset and in the traffic capture, such as packet misorder, packet duplication and attack that were performed but not correctly labelled. Finally, we assess the impact of these different corrections on the evaluation of supervised intrusion detection approaches.},
	urldate = {2022-09-29},
	booktitle = {{CRiSIS} 2022 - {International} {Conference} on {Risks} and {Security} of {Internet} and {Systems}},
	author = {Lanvin, Maxime and Gimenez, Pierre-François and Han, Yufei and Majorczyk, Frédéric and Mé, Ludovic and Totel, Eric},
	month = dec,
	year = {2022},
	keywords = {\_read\_urgently, dataset labelling, intrusion detection, machine learning},
	pages = {1--16},
}

@inproceedings{lavaur_federated_2021,
	title = {Federated security approaches for {IT} and {OT}},
	copyright = {All rights reserved},
	abstract = {The Internet of Things has begun to spread over a variety of domains, including industry and ﬁnance. It represents an increasing threat for both IT and OT. The lack of collaboration results in the same attacks targeting different organizations one after the other. Often employed as an answer to this problem, cyber threat-intelligence sharing induces its own set of challenges: trust, privacy, and traceability.},
	language = {en},
	author = {Lavaur, Leo and Pahl, Marc-Oliver and Busnel, Yann and Autrel, Fabien},
	year = {2021},
	keywords = {⛔ No DOI found},
	pages = {2},
}

@inproceedings{lautert_fog_2020,
	title = {A fog architecture for privacy-preserving data provenance using blockchains},
	volume = {2020-July},
	isbn = {978-1-72818-086-1},
	url = {https://ieeexplore.ieee.org/document/9219724/},
	doi = {10.1109/ISCC50000.2020.9219724},
	abstract = {Data provenance tracks the origin of information with the goal of improving trust among interested parties. Data provenance is an important requirement for a range of applications such as food safety, supply chains, and tracking of epidemic outbreaks. Many of these applications are inherently distributed and require high levels of privacy and trust.Fog computing and Blockchains are recent technological solutions that were born from advancements in cloud and distributed computing. Fog focuses on bringing the cloud closer to the edge user while Blockchain provides transparency without the need for a trusted centralized entity. Both can be complimentary as Fog spreads the data and computer storage while the Blockchain can keep it consistent and trustworthy. These technologies can be used to improve several aspects in a Data provenance context.In this paper we describe an architecture that allows the tracking of data provenance in a wide-area distributed fog. While we employ blockchains to provide transparency, localized Fogs have control over what is made public on the cloud. The architecture proposed in this paper enables fast and reliable data provenance for clients executing in the Fog using software services that keep the information consistent across all interested parties in the cloud. Any information in the system is associated with a proof of authenticity, but authors have control over the eventual publication of the information.Our proposal was built upon the well established provenance model W3C Prov, which simplifies adoption of the framework.We developed an application consisting of a client and web services that is able to store and share provenance information using open standards in a blockchain. The relate work, architecture and tests for the proposal are presented showing performance improvements when Fog is used when compared to a solution that only runs in the cloud.},
	booktitle = {2020 {IEEE} {Symposium} on {Computers} and {Communications} ({ISCC})},
	publisher = {IEEE},
	author = {Lautert, Filipe and Pigatto, Daniel F. and Gomes, Luiz},
	month = jul,
	year = {2020},
	note = {ISSN: 15301346},
	pages = {1--6},
}

@inproceedings{kurtanovic_automatically_2017,
	title = {Automatically {Classifying} {Functional} and {Non}-functional {Requirements} {Using} {Supervised} {Machine} {Learning}},
	doi = {10.1109/RE.2017.82},
	abstract = {In this paper, we take up the second RE17 data challenge: the identification of requirements types using the "Quality attributes (NFR)" dataset provided. We studied how accurately we can automatically classify requirements as functional (FR) and non-functional (NFR) in the dataset with supervised machine learning. Furthermore, we assessed how accurately we can identify various types of NFRs, in particular usability, security, operational, and performance requirements. We developed and evaluated a supervised machine learning approach employing meta-data, lexical, and syntactical features. We employed under-and over-sampling strategies to handle the imbalanced classes in the dataset and cross-validated the classifiers using precision, recall, and F1 metrics in a series of experiments based on the Support Vector Machine classifier algorithm. We achieve a precision and recall up to 92\% for automatically identifying FRs and NFRs. For the identification of specific NFRs, we achieve the highest precision and recall for security and performance NFRs with 92\% precision and 90\% recall. We discuss the most discriminating features of FRs and NFRs as well as the sampling strategies used with an additional dataset and their impact on the classification accuracy.},
	booktitle = {2017 {IEEE} 25th {International} {Requirements} {Engineering} {Conference} ({RE})},
	author = {Kurtanović, Zijad and Maalej, Walid},
	month = sep,
	year = {2017},
	note = {ISSN: 2332-6441},
	keywords = {Classification, Feature extraction, Imbalanced Data, Machine Learning, Requirements, Security, Support vector machines, Training, Usability, Vegetation},
	pages = {490--495},
}

@inproceedings{kale_hybrid_2022,
	title = {A {Hybrid} {Deep} {Learning} {Anomaly} {Detection} {Framework} for {Intrusion} {Detection}},
	doi = {10.1109/BigDataSecurityHPSCIDS54978.2022.00034},
	abstract = {Cyber intrusion attacks that compromise the users' critical and sensitive data are escalating in volume and intensity, especially with the growing connections between our daily life and the Internet. The large volume and high complexity of such intrusion attacks have impeded the effectiveness of most traditional defence techniques. While at the same time, the remarkable performance of the machine learning methods, especially deep learning, in computer vision, had garnered research interests from the cyber security community to further enhance and automate intrusion detections. However, the expensive data labeling and limitation of anomalous data make it challenging to train an intrusion detector in a fully supervised manner. Therefore, intrusion detection based on unsupervised anomaly detection is an important feature too. In this paper, we propose a three-stage deep learning anomaly detection based network intrusion attack detection framework. The framework comprises an integration of unsupervised (K-means clustering), semi-supervised (GANomaly) and supervised learning (CNN) algorithms. We then evaluated and showed the performance of our implemented framework on three benchmark datasets: NSL-KDD, CIC-IDS2018, and TON IoT.},
	booktitle = {2022 {IEEE} 8th {Intl} {Conference} on {Big} {Data} {Security} on {Cloud} ({BigDataSecurity}), {IEEE} {Intl} {Conference} on {High} {Performance} and {Smart} {Computing}, ({HPSC}) and {IEEE} {Intl} {Conference} on {Intelligent} {Data} and {Security} ({IDS})},
	author = {Kale, Rahul and Lu, Zhi and Fok, Kar Wai and Thing, Vrizlynn L. L.},
	month = may,
	year = {2022},
	keywords = {Anomaly Detection, Conferences, Deep Learning, Deep learning, Feature extraction, Intrusion Detection, Intrusion detection, Machine learning algorithms, Neural Networks, Security, Supervised learning, Unsupervised Learning},
	pages = {137--142},
}

@inproceedings{kokkonen_model_2016,
	title = {Model for sharing the information of cyber security situation awareness between organizations},
	isbn = {978-1-5090-1990-8},
	url = {http://ieeexplore.ieee.org/document/7500406/},
	doi = {10.1109/ICT.2016.7500406},
	abstract = {Exchanging of Situation Awareness information is extremely important for organizations in order to survive as part of the cyber domain. The situation Awareness is required for decision making and for an early warning of upcoming threats. Situation Awareness and the security information in the cyber domain differ from the kinetic domain. Because of that, Situation Awareness has different requirements and use cases, for example when considering time or geographical distances. There is always a risk when sharing security information due to the classified nature of the information. It might contain information of weaknesses or vulnerabilities of the organization, and if used wrongly it jeopardizes the continuity of the business or mission. The model introduced in this paper for creating information sharing topologies enables sharing of classified security related information between multiple organizations with the lowest possible risks levels.},
	booktitle = {2016 23rd {International} {Conference} on {Telecommunications} ({ICT})},
	publisher = {IEEE},
	author = {Kokkonen, Tero and Hautamaki, Jari and Siltanen, Jarmo and Hamalainen, Timo},
	month = may,
	year = {2016},
	pages = {1--5},
}

@inproceedings{jia_contexiot_2017,
	address = {Reston, VA},
	title = {{ContexIoT}: {Towards} {Providing} {Contextual} {Integrity} to {Appified} {IoT} {Platforms}},
	isbn = {1-891562-46-0},
	url = {https://www.ndss-symposium.org/ndss2017/ndss-2017-programme/contexlot-towards-providing-contextual-integrity-appified-iot-platforms/},
	doi = {10.14722/ndss.2017.23051},
	abstract = {The Internet-of-Things (IoT) has quickly evolved to a new appified era where third-party developers can write apps for IoT platforms using programming frameworks. Like other appified platforms, e.g., the smartphone platform, the permission system plays an important role in platform security. However, design flaws in current IoT platform permission models have been reported recently, exposing users to significant harm such as break-ins and theft. To solve these problems, a new access control model is needed for both current and future IoT platforms. In this paper, we propose ContexIoT, a context-based permission system for appified IoT platforms that provides contextual integrity by supporting fine-grained context identification for sensitive actions, and runtime prompts with rich context information to help users perform effective access control. Context definition in ContexIoT is at the inter-procedure control and data flow levels, that we show to be more comprehensive than previous context-based permission systems for the smartphone platform. ContexIoT is designed to be backward compatible and thus can be directly adopted by current IoT platforms. We prototype ContexIoT on the Samsung SmartThings platform, with an automatic app patching mechanism developed to support unmodified commodity SmartThings apps. To evaluate the system’s effectiveness, we perform the first extensive study of possible attacks on appified IoT platforms by reproducing reported IoT attacks and constructing new IoT attacks based on smartphone malware classes. We categorize these attacks based on lifecycle and adversary techniques, and build the first taxonomized IoT attack app dataset. Evaluating ContexIoT on this dataset, we find that it can effectively distinguish the attack context for all the tested apps. The performance evaluation on 283 commodity IoT apps shows that the app patching adds nearly negligible delay to the event triggering latency, and the permission request frequency is far below the threshold that is considered to risk user habituation or annoyance.},
	booktitle = {Proceedings 2017 {Network} and {Distributed} {System} {Security} {Symposium}},
	publisher = {Internet Society},
	author = {Jia, Yunhan Jack and Chen, Qi Alfred and Wang, Shiqi and Rahmati, Amir and Fernandes, Earlence and Mao, Z. Morley and Prakash, Atul},
	year = {2017},
}

@inproceedings{hbaieb_federated_2022,
	address = {New York, NY, USA},
	series = {{ARES} '22},
	title = {Federated learning based {IDS} approach for the {IoV}},
	isbn = {978-1-4503-9670-7},
	url = {https://doi.org/10.1145/3538969.3544422},
	doi = {10.1145/3538969.3544422},
	abstract = {The Internet of Vehicles (IoV) is an Internet of Things (IoT) application that offers several utilities such as traffic analysis, safe driving, road optimization, and travel comfort. Software-Defined Networking (SDN) technology has been shown to provide various benefits to support the IoV. However, the construction of IoV makes it a complex system posing several challenges among which the important ones are security and privacy of data. Intrusion Detection Systems (IDSs) have been proposed in the IoV to identify cyber attacks and protect private data. Recently work has started to implement IDSs based on Federated learning as collaborative IDSs have proved effective security of IoV. In another hand, trust management has revolutionized the IoV filed, providing decision-making support to secure the network. Stating that an SDN-driven IoV architecture in which nodes trustworthiness gets assessed can provide a promising framework for IDS, we propose in this paper a Federated learning-based IDS for the IoV under the SDN structure. We integrate trust metrics to assist in securing the IoV network. Simulation experiments are conducted to validate the proposal.},
	urldate = {2022-08-23},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Availability}, {Reliability} and {Security}},
	publisher = {Association for Computing Machinery},
	author = {Hbaieb, Amal and Ayed, Samiha and Chaari, Lamia},
	year = {2022},
	keywords = {Federated learning, IDS, IoV, SDN, Trust management, VANET, Vehicular networks},
	pages = {1--6},
}

@inproceedings{ji_novel_2022,
	title = {A {Novel} {Method} of {Intrusion} {Detection} {Based} on {Federated} {Transfer} {Learning} and {Convolutional} {Neural} {Network}},
	volume = {10},
	doi = {10.1109/ITAIC54216.2022.9836871},
	abstract = {As a network security defense technology, intrusion detection system can effectively protect network security. At present, machine learning is widely used in intrusion detection and has achieved good application results. The detection methods based on traditional machine learning need enough available intrusion detection data samples, and the samples meet the conditions of independent and identically distributed. However, in reality, the intrusion detection data generated by a single institution is insufficient, and various institutions protect users' privacy and data security in the form of islands, which makes it difficult to maintain the same data distribution. In addition, there is the problem of data imbalance. To solve the above problems, this paper proposes a new intrusion detection method FTLCNN, which integrates federal transfer learning and convolutional neural network. FTLCNN constructs a transfer convolution neural network framework to solve the problems of sample scarcity, imbalance and probability adaptation; under the mechanism of federal learning, FTLCNN use the model to learn without sharing training data, protect data privacy and solve the problem of data island. The experimental on UNSW-NB15 shows that compared with the other four benchmark algorithms, FTLCNN has higher detection rate and lower false positive rate, and has significant advantages in solving the problem of scarcity and imbalance of in intrusion detection.},
	booktitle = {2022 {IEEE} 10th {Joint} {International} {Information} {Technology} and {Artificial} {Intelligence} {Conference} ({ITAIC})},
	author = {Ji, Xiang and Zhang, Hong and Ma, Xulun},
	month = jun,
	year = {2022},
	note = {ISSN: 2693-2865},
	keywords = {Convolutional neural network, Data privacy, Distributed databases, Federal transfer learning, Intrusion detection, Network security, Organizations, Training data, Transfer learning, Unbalanced data},
	pages = {338--343},
}

@inproceedings{harilal_twos_2017,
	address = {New York, NY, USA},
	series = {{MIST} '17},
	title = {{TWOS}: {A} {Dataset} of {Malicious} {Insider} {Threat} {Behavior} {Based} on a {Gamified} {Competition}},
	isbn = {978-1-4503-5177-5},
	shorttitle = {{TWOS}},
	url = {https://doi.org/10.1145/3139923.3139929},
	doi = {10.1145/3139923.3139929},
	abstract = {In this paper we present the design and outcome of a gamified competition that was devised in order to obtain a dataset containing realistic instances of insider threats. The competition simulated user interactions in/among competing companies, where two types of behaviors (normal and malicious) were incentivized. For the case of malicious behavior, we designed sessions for two types of insider threats (masqueraders and traitors). The game involved the participation of 6 teams consisting of 4 students who competed with each other for a period of 5 days, while their activities were monitored considering several heterogeneous sources (mouse, keyboard, process and file-system monitor, network traffic, emails and login/logout). In sum, we obtained 320 hours of active participation that included 18 hours of masquerader data and at least two instances of traitor data. Additionally to malicious behaviors, the students explored various defensive and offensive strategies, such as denial of service attacks and obfuscation techniques, in an effort to get ahead in the competition. The TWOS dataset is publicly accessible for further research purposes.},
	urldate = {2022-08-12},
	booktitle = {Proceedings of the 2017 {International} {Workshop} on {Managing} {Insider} {Security} {Threats}},
	publisher = {Association for Computing Machinery},
	author = {Harilal, Athul and Toffalini, Flavio and Castellanos, John and Guarnizo, Juan and Homoliak, Ivan and Ochoa, Martín},
	month = oct,
	year = {2017},
	keywords = {\_read\_urgently, dataset, malicious insider threat, masquerader, multi player game, traitor, user behavior monitoring},
	pages = {45--56},
}

@inproceedings{jahromi_deep_2021,
	address = {Auckland, New Zealand},
	title = {Deep {Federated} {Learning}-{Based} {Cyber}-{Attack} {Detection} in {Industrial} {Control} {Systems}},
	isbn = {978-1-66540-184-5},
	url = {https://ieeexplore.ieee.org/document/9647838/},
	doi = {10/gpbg3r},
	abstract = {Due to the differences between Information Technology (IT) and Industrial Control System (ICS) networks, current IT security solutions are not working effectively on ICS networks. Moreover, due to security and privacy issues, ICS owners usually do not share their network data with third parties to train specific machine learning-based ICS security solutions. To rectify the mentioned issues, a scalable deep federated learning-based method is presented in this paper. In the proposed method, each client trains an unsupervised deep neural network model using local data and shares its parameters with a server. The server aggregates the clients’ parameters, makes a generalized public model, and shares it with all clients. The proposed model is evaluated using a real-world ICS dataset in a water treatment system and compared with two non-federated learning-based methods. Findings show that the proposed method outperformed the other two methods with the same computational complexity as other deep neural network-based methods in the literature.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2021 18th {International} {Conference} on {Privacy}, {Security} and {Trust} ({PST})},
	publisher = {IEEE},
	author = {Jahromi, Amir Namavar and Schulich, Hadis Karimipour and Dehghantanha, Ali},
	month = dec,
	year = {2021},
	pages = {1--6},
}

@inproceedings{harrison_information_2012,
	title = {Information sharing requirements and framework needed for community cyber incident detection and response},
	isbn = {978-1-4673-2709-1},
	url = {http://ieeexplore.ieee.org/document/6459893/},
	doi = {10.1109/THS.2012.6459893},
	abstract = {Communities, and the critical infrastructure that they rely upon, are becoming ever increasingly integrated into cyberspace. At the same time, communities are experiencing increasing activity and sophistication from a variety of threat agents. The effect of cyber attacks on communities has been observed, and the frequency and devastation of these attacks can only increase in the foreseeable future. Early detection of these attacks is critical for a fast and effective response. We propose detecting community cyber incidents by comparing indicators from community members across space and time. Performing spatiotemporal differentiation on these indicators requires that community members, such as private and governmental organizations, share information about these indicators. However, community members are, for good reasons, reluctant to share sensitive security related information. Additionally, sharing large amounts of information with a trusted, centralized location introduces scalability and reliability problems. In this paper we define the information sharing requirements necessary for fast, effective community cyber incident detection and response, while addressing both privacy and scalability concerns. Furthermore, we introduce a framework to meet these requirements, and analyze a proof of concept implementation. © 2012 IEEE.},
	booktitle = {2012 {IEEE} {Conference} on {Technologies} for {Homeland} {Security} ({HST})},
	publisher = {IEEE},
	author = {Harrison, Keith and White, Gregory},
	month = nov,
	year = {2012},
	pages = {463--469},
}

@inproceedings{guembe_trustworthy_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Trustworthy {Machine} {Learning} {Approaches} for {Cyberattack} {Detection}: {A} {Review}},
	isbn = {978-3-031-10548-7},
	shorttitle = {Trustworthy {Machine} {Learning} {Approaches} for {Cyberattack} {Detection}},
	doi = {10.1007/978-3-031-10548-7_20},
	abstract = {In recent years, machine learning techniques have been utilized in sensitive areas such as health, medical diagnosis, facial recognition, cybersecurity, etc. With this exponential growth comes potential large-scale ethical, safety, and social ramifications. With this enhanced ubiquity and sensitivity, concerns about ethics, trust, transparency, and accountability inevitably arise. Given the threat of sophisticated cyberattacks, it’s critical to establish cybersecurity trustworthy concepts and to develop methodologies and concepts for a wide range of explainable machine cybersecurity models that will assure reliable threat identification and detection, more research is needed. This survey examines a variety of explainable machine learning techniques that can be used to implement a reliable cybersecurity infrastructure in the cybersecurity domain. The main aim of this study is to execute an in-depth review and identification of existing explainable machine learning algorithms for cyberattack detection. This study employed the seven-step survey model to determine the research domain, implement search queries, and compile all retrieved articles from digital databases. This research looks at the literature on trustworthy machine learning algorithms for detecting cyberattacks. An extensive search of electronic databases such as ArXiv, Semantic Scholar, IEEE Xplore, Wiley Library, Scopus, Google Scholar, ACM, and Springer was carried out to find relevant literature in the subject domain. From 2016 to 2022, this study looked at white papers, conference papers, and journals. Only 25 research papers were chosen for this research paper describing trustworthy cybersecurity and explainable AI cybersecurity after we retrieved 800 articles from web databases. The study reveals that the decision tree technique outperforms other state-of-the-art machine learning models in terms of transparency and interpretability. Finally, this research suggests that incorporating explainable into machine learning cybersecurity models will help uncover the root causes of defensive failures, making it easier for cybersecurity experts to enhance both cybersecurity infrastructures and development, rather than just model results, policy, and management.},
	language = {en},
	booktitle = {Computational {Science} and {Its} {Applications} – {ICCSA} 2022 {Workshops}},
	publisher = {Springer International Publishing},
	author = {Guembe, Blessing and Azeta, Ambrose and Misra, Sanjay and Ahuja, Ravin},
	editor = {Gervasi, Osvaldo and Murgante, Beniamino and Misra, Sanjay and Rocha, Ana Maria A. C. and Garau, Chiara},
	year = {2022},
	keywords = {+survey, Machine learning, Trustworthiness, Trustworthy cybersecurity},
	pages = {265--278},
}

@inproceedings{garg_decentralized_2022,
	title = {Decentralized {Machine} {Learning} based {Network} {Data} {Analytics} for {Cognitive} {Management} of {Mobile} {Communication} {Networks}},
	doi = {10.1109/NOMS54207.2022.9789936},
	abstract = {The importance of network data analytics using advanced Machine Learning (ML) algorithms has been very well realized by the Telco industry and has resulted in the introduction of a dedicated Network Data Analytics Function (NWDAF) in the 5G service-based architecture in order to address the issues of integrating analytics into the network. The standardization of NWDAF by the 3rd Generation Partnership Project (3GPP) would enable third-party data analytics service providers to develop and provide AI-driven data analytics services to the Mobile Network Operators. The next-generation Radio Access Networks would require advanced analytics to drive closed-loop self-organizing network functions that are targeted to cognitively enhance network ef ciency and reduce the operational and capital costs of network operators. The existing solutions in this domain rely on conventional ML approaches that require the training data to be accumulated on a single data center. The concerns in this area would be the network overload and the privacy of the network operators that are sharing huge volumes of sensitive network data to the third-party Network Data Analytics Services (NDAS) executing over edge cloud infrastructures, perhaps even operated by some other players. In this paper, we propose and evaluate a Federated Learning based approach to train ML models for cognitive network management of future mobile networks that can enable network operators to get data analytics services by collaboratively building a shared learning model while retaining their critical data locally within their trusted domains.},
	booktitle = {{NOMS} 2022-2022 {IEEE}/{IFIP} {Network} {Operations} and {Management} {Symposium}},
	author = {Garg, Sharva and Bag, Tanmoy and Mitschele-Thiel, Andreas},
	month = apr,
	year = {2022},
	note = {ISSN: 2374-9709},
	keywords = {5G mobile communication, Analytical models, Biological system modeling, Capacity, Costs, Coverage, Data analysis, Federated Learning, Inter-cell Interference, Recommender Systems, Self-Coordination, Self-Organizing networks, Standardization, Training},
	pages = {1--9},
}

@inproceedings{hamouda_intrusion_2021,
	address = {Skikda, Algeria},
	title = {Intrusion {Detection} {Systems} for {Industrial} {Internet} of {Things}: {A} {Survey}},
	isbn = {978-1-66549-655-1},
	shorttitle = {Intrusion {Detection} {Systems} for {Industrial} {Internet} of {Things}},
	url = {https://ieeexplore.ieee.org/document/9715177/},
	doi = {10.1109/ICTAACS53298.2021.9715177},
	abstract = {Industrial Internet of Things (IIoT) applies Internet of Things (IoT) technology in industrial systems, to optimize business processes efficiency, service quality, and reliability. However, with a large of isolated IoT networks deployed in various industries, many vulnerabilities have been exposed to security incidents and posed threats to IIoT security. An intrusion detection system (IDS) is a security monitoring mechanism that promotes cyber security solutions for information systems. The system’s role is to detect abnormal activities of intruders and enable preventive measures to avoid risks. However, applying a traditional IDS-based solution to IIoT is challenging due to its particular characteristics such as resource-constrained, data privacy, and heterogeneity. Researchers are using the new emerging technologies such as Fog/Edge computing, Machine Learning (ML), Deep Learning (DL) to deploy an effective and adaptive IDS for various IIoT operating environments. This study focus is on the development of IDS in particular industrial environments. To this end, we provide a systemic review that addresses IDS deployment strategies, detection approaches, and methodologies and data sources used for evaluation. We also present some suggestions and challenges to be considered when designing IDSbased security for Industrial IoT as future research.},
	language = {en},
	urldate = {2022-02-25},
	booktitle = {2021 {International} {Conference} on {Theoretical} and {Applicative} {Aspects} of {Computer} {Science} ({ICTAACS})},
	publisher = {IEEE},
	author = {Hamouda, Djallel and Ferrag, Mohamed Amine and Benhamida, Nadjette and Seridi, Hamid},
	month = dec,
	year = {2021},
	keywords = {+survey},
	pages = {1--8},
}

@inproceedings{ghimire_data-driven_2021,
	address = {Madrid, Spain},
	title = {Data-{Driven} {Quickest} {Change} {Detection} for {Securing} {Federated} {Learning} for {Internet}-of-{Vehicles}},
	isbn = {978-1-72818-104-2},
	url = {https://ieeexplore.ieee.org/document/9685333/},
	doi = {10.1109/GLOBECOM46510.2021.9685333},
	abstract = {Machine Learning (ML) is on the verge of transitioning from centralized, distributed to federated learning (FL) due to the inherent privacy-preserving framework by FL. FL enables collaborative learning among participants just by exchanging updated model parameters with the FL server while keeping training data local in the end devices which is suitable for vehicular communications. However, this learning framework makes the life of the server difﬁcult to detect the malicious behavior of participants. Malicious model updates from participants may affect the accuracy of the learning model considerably and consequently may cause severe consequences in the Internet of Vehicles (IoV) environment. To address this issue, we propose a novel approach to apply Shiryaev’s quickest change detection (QCD) technique in the FL realm. QCD is applied to detect abnormal changes in statistical properties of model parameters in FL as quickly as possible. We apply QCD on the server-side in two ways. First, QCD is applied to detect a change in the statistical properties over the model parameters sent by the participating devices. Second, QCD is applied to the history of aggregated FL model parameters. The ﬁrst approach facilitates identifying malicious clients which can be eliminated in future learning activities. The other approach assists the server to roll back to an earlier version of the model in case of identifying the anomaly in the aggregated FL parameters. As QCD is applied on the server-side, it does not add any computation overhead on the client-side as well as communication overheard during transmission. These two approaches are evaluated with the help of numerical results.},
	language = {en},
	urldate = {2022-02-15},
	booktitle = {2021 {IEEE} {Global} {Communications} {Conference} ({GLOBECOM})},
	publisher = {IEEE},
	author = {Ghimire, Bimal and Rawat, Danda B. and Rahman, Abdul},
	month = dec,
	year = {2021},
	pages = {1--6},
}

@inproceedings{habibi_lashkari_characterization_2017,
	address = {Porto, Portugal},
	title = {Characterization of {Tor} {Traffic} using {Time} based {Features}:},
	isbn = {978-989-758-209-7},
	shorttitle = {Characterization of {Tor} {Traffic} using {Time} based {Features}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006105602530262},
	doi = {10.5220/0006105602530262},
	abstract = {Tor, Network Trafﬁc Characterization, Network Trafﬁc Analysis, Time-based Features, Machine Learning.},
	language = {en},
	urldate = {2021-10-15},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Information} {Systems} {Security} and {Privacy}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Habibi Lashkari, Arash and Draper Gil, Gerard and Mamun, Mohammad Saiful Islam and Ghorbani, Ali A.},
	year = {2017},
	pages = {253--262},
}

@inproceedings{hamza_detecting_2019,
	address = {New York, NY, USA},
	title = {Detecting {Volumetric} {Attacks} on {loT} {Devices} via {SDN}-{Based} {Monitoring} of {MUD} {Activity}},
	isbn = {978-1-4503-6710-3},
	url = {https://dl.acm.org/doi/10.1145/3314148.3314352},
	doi = {10.1145/3314148.3314352},
	abstract = {Smart environments equipped with IoT devices are increasingly under threat from an escalating number of sophisticated cyber-attacks. Current security approaches are inaccurate, expensive, or unscalable, as they require static signatures of known attacks, specialized hardware, or full packet inspection. The IETF Manufacturer Usage Description (MUD) framework aims to reduce the attack surface on an IoT device by formally defining its expected network behavior. In this paper, we use SDN to monitor compliance with the MUD behavioral profile, and develop machine learning methods to detect volumetric attacks such as DoS, reflective TCP/UDP/ICMP flooding, and ARP spoofing to IoT devices. Our first contribution develops a machine for detecting anomalous patterns of MUD-compliant network activity via coarse-grained (device-level) and fine-grained (flow-level) SDN telemetry for each IoT device, thereby giving visibility into flows that contribute to a volumetric attack. For our second contribution we measure network behavior of IoT devices by collecting benign and volumetric attacks traffic traces in our lab, label our dataset, and make it available to the public. Our last contribution prototypes a full working system (built with an OpenFlow switch, Faucet SDN controller, and a MUD policy engine), demonstrates its application in detecting volumetric attacks on several consumer IoT devices with high accuracy, and provides insights into cost and performance of our system. Our data and solution modules are released as open source to the community.},
	booktitle = {Proceedings of the 2019 {ACM} {Symposium} on {SDN} {Research}},
	publisher = {ACM},
	author = {Hamza, Ayyoob and Gharakheili, Hassan Habibi and Benson, Theophilus A. and Sivaraman, Vijay},
	month = apr,
	year = {2019},
	pages = {36--48},
}

@inproceedings{fu_label_2022,
	title = {Label {Inference} {Attacks} {Against} {Vertical} {Federated} {Learning}},
	isbn = {978-1-939133-31-1},
	url = {https://www.usenix.org/conference/usenixsecurity22/presentation/fu-chong},
	language = {en},
	urldate = {2022-08-12},
	author = {Fu, Chong and Zhang, Xuhong and Ji, Shouling and Chen, Jinyin and Wu, Jingzheng and Guo, Shanqing and Zhou, Jun and Liu, Alex X. and Wang, Ting},
	year = {2022},
	pages = {1397--1414},
}

@inproceedings{gao_fedsec_2022,
	title = {{FedSeC}: a {Robust} {Differential} {Private} {Federated} {Learning} {Framework} in {Heterogeneous} {Networks}},
	shorttitle = {{FedSeC}},
	doi = {10.1109/WCNC51071.2022.9771929},
	abstract = {Federated learning (FL) is considered to be a promising paradigm to solve data privacy disclosure in large-scale machine learning. To further enhance the privacy protection of federated learning, prior works incorporate the differentially private data perturbation into the federated system. But it is not feasible given the impairment of the model from noise, as adding Gaussian noise to achieve differential privacy (DP) deteriorates the accuracy of the model. In particular, the assumption that the sophisticated system is homogeneous is not realistic for real scenarios. Heterogeneous networks exacerbate noise disruptions. In this paper, we present FedSeC, a novel differential private federated learning (DP-FL) framework which operates with robust convergence and high-accuracy while achieving adequate privacy protection. FedSeC improves upon naive combinations of federated learning and differential privacy approaches with an updates-based optimization of relative-staleness and semi-synchronous approach for fast convergence in heterogeneous networks. Moreover, we propose a valid client selection scheme to trade-off fair resource allocation and discriminatory incentives. Through extensive experimental validation of our method in three different heterogeneities, we show that FedSeC outperforms the previous state-of-the-art method.},
	booktitle = {2022 {IEEE} {Wireless} {Communications} and {Networking} {Conference} ({WCNC})},
	author = {Gao, Zhipeng and Duan, Yingwen and Yang, Yang and Rui, Lanlan and Zhao, Chen},
	month = apr,
	year = {2022},
	note = {ISSN: 1558-2612},
	keywords = {Collaborative work, Differential privacy, Distributed machine learning, Federated learning, Gaussian noise, Heterogeneous networks, Machine learning, Perturbation methods, Privacy},
	pages = {1868--1873},
}

@inproceedings{faraj_taxonomy_2020,
	address = {Virtual Event Ireland},
	title = {Taxonomy and challenges in machine learning-based approaches to detect attacks in the internet of things},
	isbn = {978-1-4503-8833-7},
	url = {https://dl.acm.org/doi/10.1145/3407023.3407048},
	doi = {10.1145/3407023.3407048},
	abstract = {The insecure growth of Internet-of-Things (IoT) can threaten its promising benefits to our daily life activities. Weak designs, low computational capabilities, and faulty protocol implementations are just a few examples that explain why IoT devices are nowadays highly prone to cyber-attacks. In this survey paper, we review approaches addressing this problem. We focus on machine learningbased solutions as a representative trend in the related literature. We survey and classify Machine Learning (ML)-based techniques that are suitable for the construction of Intrusion Detection Systems (IDS) for IoT. We contribute with a detailed classification of each approach based on our own taxonomy. Open issues and research challenges are also discussed and provided.},
	language = {en},
	urldate = {2021-06-23},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Availability}, {Reliability} and {Security}},
	publisher = {ACM},
	author = {Faraj, Omair and Megías, David and Ahmad, Abdel-Mehsen and Garcia-Alfaro, Joaquin},
	month = aug,
	year = {2020},
	pages = {1--10},
}

@inproceedings{fung_limitations_2020,
	address = {San Sebastian},
	title = {The {Limitations} of {Federated} {Learning} in {Sybil} {Settings}},
	isbn = {978-1-939133-18-2},
	url = {https://www.usenix.org/conference/raid2020/presentation/fung},
	abstract = {Federated learning over distributed multi-party data is an emerging paradigm that iteratively aggregates updates from a group of devices to train a globally shared model. Relying on a set of devices, however, opens up the door for sybil attacks: malicious devices may be controlled by a single adversary who directs these devices to attack the system. We consider the susceptibility of federated learning to sybil attacks and propose a taxonomy of sybil objectives and strategies in this setting. We describe a new DoS attack that we term training inflation and present several ways to carry out this attack. We then evaluate recent distributed ML fault tolerance proposals and show that these are insufficient to mitigate several sybil-based attacks. Finally, we introduce a defense against targeted sybil-based poisoning called FoolsGold, which identifies sybils based on the diversity of client updates. We show that FoolsGold exceeds state of the art approaches when countering several types of poisoning attacks.},
	booktitle = {23rd {International} {Symposium} on {Research} in {Attacks}, {Intrusions} and {Defenses} (\{{RAID}\} 2020)},
	publisher = {\{USENIX\} Association},
	author = {Fung, Clement and Yoon, Chris J.M. M and Beschastnikh, Ivan},
	month = oct,
	year = {2020},
	pages = {301--316},
}

@inproceedings{fernandez_vazquez_conceptual_2012,
	title = {Conceptual framework for cyber defense information sharing within trust relationships},
	isbn = {978-9949-9040-8-2},
	abstract = {Information and Communication Technologies are increasingly intertwined across the economies and societies of developed countries. Protecting these technologies from cyberthreats requires collaborative relationships for exchanging cyber defense data and an ability to establish trusted relationships. The fact that Communication and Information Systems (CIS) security1 is an international issue increases the complexity of these relationships. Cyber defense collaboration presents specific challenges since most entities would like to share cyber-related data but lack a successful model to do so. We will explore four aspects of cyber defense collaboration to identify approaches for improving cyber defense information sharing. First, incentives and barriers for information sharing, which includes the type of information that may be of interest to share and the motivations that cause social networks to be used or stagnate. Second, collaborative risk management and information value perception. This includes risk management approaches that have built-in mechanisms for sharing and receiving information, increasing transparency, and improving entity peering relationships. Third, we explore procedural models for improving data exchange, with a focus on inter-governmental collaborative challenges. Fourth, we explore automation of sharing mechanisms for commonly shared cyber defense data (e.g., vulnerabilities, threat actors, black/ white lists). In order to reach a common understanding of terminology in this paper, we leverage the NATO CIS Security Capability Breakdown [19], published in November 2011, which is designed to identify and describe (CIS) security and cyber defense terminology and definitions to facilitate NATO, national, and multi-national discussion, coordination, and capability development.},
	booktitle = {2012 4th {International} {Conference} on {Cyber} {Conflict} ({CYCON} 2012)},
	author = {Fernández Vázquez, Diego and Pastor Acosta, Oscar and Spirito, Christopher and Brown, Sarah and Reid, Emily},
	month = jun,
	year = {2012},
	note = {ISSN: 2325-5366},
	pages = {1--17},
}

@inproceedings{el_houda_low-latency_2022,
	address = {Edmonton, AB, Canada},
	title = {A {Low}-{Latency} {Fog}-based {Framework} to secure {IoT} {Applications} using {Collaborative} {Federated} {Learning}},
	isbn = {978-1-66548-001-7},
	url = {https://ieeexplore.ieee.org/document/9843315/},
	doi = {10.1109/LCN53696.2022.9843315},
	abstract = {Attacks against the IoT network are increasing rapidly, leading to an exponential growth in the number of unsecured IoT devices. Existing security mechanisms are facing several issues due to the lack of real-time decisions, high energy consumption, and high time delays. In this context, we propose a novel Low-Latency Fog-based Framework, called FogFed, to secure IoT applications using Fog computing and Federated Learning (FL). The fog brings security mechanisms near IoT devices reducing delays in communication, while FL enables a privacy-aware collaborative learning between IoT while preserving their privacy. FogFed combines two levels of detection, Fog-based IoT attack detection using a binary FL classifier and cloud-based IoT attack detection using a Multiclass FL classifier. The in-depth experiments results with wellknown IoT attack/malware using, the UNSW-NB15 datastet, show the significant accuracy (99\%) and detection rate (99\%), which outperforms centralized ML/DL models, while significantly reducing delays and preserving the privacy.},
	language = {en},
	urldate = {2022-08-31},
	booktitle = {2022 {IEEE} 47th {Conference} on {Local} {Computer} {Networks} ({LCN})},
	publisher = {IEEE},
	author = {El Houda, Zakaria Abou and Khoukhi, Lyes and Brik, Bouziane},
	month = sep,
	year = {2022},
	pages = {343--346},
}

@inproceedings{el_houda_ensemble_2022,
	address = {Edmonton, AB, Canada},
	title = {Ensemble {Learning} for {Intrusion} {Detection} in {SDN}-{Based} {Zero} {Touch} {Smart} {Grid} {Systems}},
	isbn = {978-1-66548-001-7},
	url = {https://ieeexplore.ieee.org/document/9843645/},
	doi = {10.1109/LCN53696.2022.9843645},
	abstract = {Software-defined network (SDN) is widely deployed on Smart Grid (SG) systems. It consists in decoupling control and data planes, to automate the monitoring and management of the communication network, and thus enabling zero touch management of SG systems. However, SDN-based SG is prone to several security threats and varios type of new attacks. To alleviate these issues, various Machine/Deep learning (ML/DL)based intrusion detection systems (IDS) were designed to improve the detection accuracy of conventional IDS. However, they suffer from high variance and/or bias, which may lead to an inaccurate security threat detection. In this context, ensemble learning is an emerging ML technique that aims at combining several ML models; the objective is to generate less data-sensitive (i.e., less variance) and more flexible (i.e., less bias) machine learning models. In this paper, we design a novel framework, called BoostIDS, that leverages ensemble learning to efficiently detect and mitigate security threats in SDN-based SG system. BoostIDS comprises two main modules: (1) A data monitoring and feature selection module that makes use of an efficient Boosting Feature Selection Algorithm to select the best/relevant SG-based features; and (2) An ensemble learning-based threats detection moel that implements a Lightweight Boosting Algorithm (LBA) to timely and effectively detects SG-based attacks in a SDN environment. We conduct extensive experiments to validate BoostIDS on top of multiple real attacks; the obtained results using NSL-KDD and UNSW-NB15 datasets, confirm that BoostIDS can effectively detect/mitigate security threats in SDN-based SG systems, while optimizing training/test time complexity.},
	language = {en},
	urldate = {2022-08-31},
	booktitle = {2022 {IEEE} 47th {Conference} on {Local} {Computer} {Networks} ({LCN})},
	publisher = {IEEE},
	author = {El Houda, Zakaria Abou and Brik, Bouziane and Khoukhi, Lyes},
	month = sep,
	year = {2022},
	pages = {149--156},
}

@inproceedings{elsadig_biological_2010,
	address = {Sanya, Hainan},
	title = {Biological {Intrusion} {Prevention} and {Self}-{Healing} {Model} for {Network} {Security}},
	isbn = {978-1-4244-5666-6 978-0-7695-3940-9},
	url = {https://ieeexplore.ieee.org/document/5431824/},
	doi = {10.1109/ICFN.2010.103},
	language = {en},
	urldate = {2022-03-31},
	booktitle = {2010 {Second} {International} {Conference} on {Future} {Networks}},
	publisher = {IEEE},
	author = {Elsadig, Muna and Abduallah, Azween},
	month = jan,
	year = {2010},
	pages = {337--342},
}

@inproceedings{david_reproducible_2019,
	address = {New York, NY, USA},
	series = {P-{RECS} '19},
	title = {Reproducible {Computer} {Network} {Experiments}: {A} {Case} {Study} {Using} {Popper}},
	isbn = {978-1-4503-6756-1},
	shorttitle = {Reproducible {Computer} {Network} {Experiments}},
	url = {https://doi.org/10.1145/3322790.3330596},
	doi = {10.1145/3322790.3330596},
	abstract = {Computer network research experiments can be broadly grouped in three categories: simulated, controlled, and real-world experiments. Simulation frameworks, experiment testbeds and measurement tools, respectively, are commonly used as the platforms for carrying out network experiments. In many cases, given the nature of computer network experiments, properly configuring these platforms is a complex and time-consuming task, which makes replicating and validating research results quite challenging. This complexity can be reduced by leveraging tools that enable experiment reproducibility. In this paper, we show how a recently proposed reproducibility tool called Popper facilitates the reproduction of networking experiments. In particular, we detail the steps taken to reproduce results in two published articles that rely on simulations. The outcome of this exercise is a generic workflow for carrying out network simulation experiments. In addition, we briefly present two additional Popper workflows for running experiments on controlled testbeds, as well as studies that gather real-world metrics (all code is publicly available on Github). We close by providing a list of lessons we learned throughout this process.},
	urldate = {2022-08-12},
	booktitle = {Proceedings of the 2nd {International} {Workshop} on {Practical} {Reproducible} {Evaluation} of {Computer} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {David, Andrea and Souppe, Mariette and Jimenez, Ivo and Obraczka, Katia and Mansfield, Sam and Veenstra, Kerry and Maltzahn, Carlos},
	year = {2019},
	keywords = {network experiment simulation, popper, reproducible network experiments, software automation},
	pages = {29--34},
}

@inproceedings{draper-gil_characterization_2016,
	address = {Rome, Italy},
	title = {Characterization of {Encrypted} and {VPN} {Traffic} using {Time}-related {Features}:},
	isbn = {978-989-758-167-0},
	shorttitle = {Characterization of {Encrypted} and {VPN} {Traffic} using {Time}-related {Features}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0005740704070414},
	doi = {10.5220/0005740704070414},
	language = {en},
	urldate = {2021-10-15},
	booktitle = {Proceedings of the 2nd {International} {Conference} on {Information} {Systems} {Security} and {Privacy}},
	publisher = {SCITEPRESS - Science and and Technology Publications},
	author = {Draper-Gil, Gerard and Lashkari, Arash Habibi and Mamun, Mohammad Saiful Islam and A. Ghorbani, Ali},
	year = {2016},
	pages = {407--414},
}

@inproceedings{das_holistic_2020,
	address = {Cham},
	series = {Advances in {Intelligent} {Systems} and {Computing}},
	title = {A {Holistic} {Approach} for {Detecting} {DDoS} {Attacks} by {Using} {Ensemble} {Unsupervised} {Machine} {Learning}},
	isbn = {978-3-030-39442-4},
	doi = {10.1007/978-3-030-39442-4_53},
	abstract = {Distributed Denial of Service (DDoS) has been the most prominent attack in cyber-physical system over the last decade. Defending against DDoS attack is not only challenging but also strategic. Tons of new strategies and approaches have been proposed to defend against different types of DDoS attacks. The ongoing battle between the attackers and defenders is full-fledged due to its newest strategies and techniques. Machine learning (ML) has promising outcomes in different research fields including cybersecurity. In this paper, ensemble unsupervised ML approach is used to implement an intrusion detection system which has the noteworthy accuracy to detect DDoS attacks. The goal of this research is to increase the DDoS attack detection accuracy while decreasing the false positive rate. The NSL-KDD dataset and twelve feature sets from existing research are used for experimentation to compare our ensemble results with those of our individual and other existing models.},
	language = {en},
	booktitle = {Advances in {Information} and {Communication}},
	publisher = {Springer International Publishing},
	author = {Das, Saikat and Venugopal, Deepak and Shiva, Sajjan},
	editor = {Arai, Kohei and Kapoor, Supriya and Bhatia, Rahul},
	year = {2020},
	keywords = {Accuracy, DDoS detection, False positive rate, IDS, Novelty and outlier detection, Unsupervised machine learning ensemble, \_read},
	pages = {721--738},
}

@inproceedings{dondio_computing_2014,
	title = {Computing {Trust} as a {Form} of {Presumptive} {Reasoning}},
	volume = {2},
	isbn = {978-1-4799-4143-8},
	url = {http://ieeexplore.ieee.org/document/6927635/},
	doi = {10.1109/WI-IAT.2014.108},
	abstract = {This study describes and evaluates a novel trust model for a range of collaborative applications. The model assumes that humans routinely choose to trust their peers by relying on few recurrent presumptions, which are domain independent and which form a recognisable trust expertise. We refer to these presumptions as trust schemes, a specialised version of Walton's argumentation schemes. Evidence is provided about the efficacy of trust schemes using a detailed experiment on an online community of 80,000 members. Results show how proposed trust schemes are more effective in trust computation when they are combined together and when their plausibility in the selected context is considered.},
	booktitle = {2014 {IEEE}/{WIC}/{ACM} {International} {Joint} {Conferences} on {Web} {Intelligence} ({WI}) and {Intelligent} {Agent} {Technologies} ({IAT})},
	publisher = {IEEE},
	author = {Dondio, Pierpaolo and Longo, Luca},
	month = aug,
	year = {2014},
	pages = {274--281},
}

@inproceedings{bourtoule_machine_2021,
	title = {Machine {Unlearning}},
	doi = {10.1109/SP40001.2021.00019},
	abstract = {Once users have shared their data online, it is generally difficult for them to revoke access and ask for the data to be deleted. Machine learning (ML) exacerbates this problem because any model trained with said data may have memorized it, putting users at risk of a successful privacy attack exposing their information. Yet, having models unlearn is notoriously difficult.We introduce SISA training, a framework that expedites the unlearning process by strategically limiting the influence of a data point in the training procedure. While our framework is applicable to any learning algorithm, it is designed to achieve the largest improvements for stateful algorithms like stochastic gradient descent for deep neural networks. SISA training reduces the computational overhead associated with unlearning, even in the worst-case setting where unlearning requests are made uniformly across the training set. In some cases, the service provider may have a prior on the distribution of unlearning requests that will be issued by users. We may take this prior into account to partition and order data accordingly, and further decrease overhead from unlearning.Our evaluation spans several datasets from different domains, with corresponding motivations for unlearning. Under no distributional assumptions, for simple learning tasks, we observe that SISA training improves time to unlearn points from the Purchase dataset by 4.63×, and 2.45× for the SVHN dataset, over retraining from scratch. SISA training also provides a speed-up of 1.36× in retraining for complex learning tasks such as ImageNet classification; aided by transfer learning, this results in a small degradation in accuracy. Our work contributes to practical data governance in machine unlearning.},
	booktitle = {2021 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	author = {Bourtoule, Lucas and Chandrasekaran, Varun and Choquette-Choo, Christopher A. and Jia, Hengrui and Travers, Adelin and Zhang, Baiwu and Lie, David and Papernot, Nicolas},
	month = may,
	year = {2021},
	note = {ISSN: 2375-1207},
	keywords = {Data privacy, Limiting, Privacy, Stochastic processes, Training, Training data, Transfer learning},
	pages = {141--159},
}

@inproceedings{chaari_fourati_federated_2021,
	address = {Montreal, QC, Canada},
	title = {Federated {Learning} toward {Data} {Preprocessing}: {COVID}-19 {Context}},
	isbn = {978-1-72819-441-7},
	shorttitle = {Federated {Learning} toward {Data} {Preprocessing}},
	url = {https://ieeexplore.ieee.org/document/9473590/},
	doi = {10/gpbg44},
	abstract = {During this last decade, in the digital era, online and real-time data management becomes essential and primordial in several scenarios. In the health domain, and especially for remote healthcare monitoring systems, the management of data in real time becomes a requirement. Indeed, care providers need to access the vital information and sometimes the processed data in order to take timely the adequate decision. However, many issues arise in the data processing regarding real-time aspect, computational complexity and patient mobility. Therefore, Federated Learning (FL) engages promising technologies such as the fog and the cloud computing as well as machine learning (ML) and deep learning (DL) to address the aforementioned issues. Fog computing enables data preprocessing in proximity of medical users, exploiting patients mobile phones or personal digital assistant (PDA) or small-scale distributed servers. In this paper, we pinpoint the important role of the FL-based system within Internet of Medical Things (IoMT) to combat COVID19 pandemic. Speciﬁcally, we ﬁrst introduce the architecture highlighting the fog layer within the smart healthcare system. We then discuss the preprocesing tasks that could be implemented at the fog layer with a particular focus on ML and DL tasks. After that, an investigation related to the FL against several COVID19 contexts is provided. Finally, this paper explores open issues and future directions regarding the FL potentialities in pandemic situation.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2021 {IEEE} {International} {Conference} on {Communications} {Workshops} ({ICC} {Workshops})},
	publisher = {IEEE},
	author = {Chaari Fourati, Lamia and Ayed, Samiha},
	month = jun,
	year = {2021},
	pages = {1--6},
}

@inproceedings{charyyev_iot_2020,
	title = {{IoT} {Traffic} {Flow} {Identification} using {Locality} {Sensitive} {Hashes}},
	volume = {2020-June},
	isbn = {978-1-72815-089-5},
	url = {https://ieeexplore.ieee.org/document/9148743/},
	doi = {10.1109/ICC40277.2020.9148743},
	abstract = {Systems get smarter with computing capabilities, especially in the form of Internet of Things (IoT) devices. IoT devices are often resource-limited as they are optimized for a certain task. Hence, they are prone to be compromised and have become a target of malicious activities. Since IoT devices lack computing power for security software, network administrators need to isolate such devices and limit traffic to the device based on their communication needs. To this end, network administrators need to identify IoT devices when they join a network and detect anomalous traffic when they are compromised. In this paper, we introduce a novel approach to identify the IoT device based on the Nilsimsa hash of its traffic flow. Different from previous studies, the proposed approach does not require feature extraction from the data. In our evaluations, our approach has an average precision and recall of 93\% and 90\%, respectively.},
	booktitle = {{ICC} 2020 - 2020 {IEEE} {International} {Conference} on {Communications} ({ICC})},
	publisher = {IEEE},
	author = {Charyyev, Batyr and Gunes, Mehmet Hadi},
	month = jun,
	year = {2020},
	note = {ISSN: 15503607},
	pages = {1--6},
}

@inproceedings{chantzios_quest_2019,
	title = {The {Quest} for the {Appropriate} {Cyber}-threat {Intelligence} {Sharing} {Platform}},
	isbn = {978-989-758-377-3},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0007978103690376},
	doi = {10.5220/0007978103690376},
	abstract = {Cyber-threat intelligence (CTI) is any information that can help an organization identify, assess, monitor, and respond to cyber-threats. It relates to all cyber components of an organization such as networks, computers, and other types of information technology. In the recent years, due to the major increase of cyber-threats, CTI sharing is becoming increasingly important both as a subject of research and as a concept of providing additional security to organizations. However, selecting the proper tools and platforms for CTI sharing, is a challenging task, that pertains to a variety of aspects. In this paper, we start by overviewing the CTI procedure (threat types, categories, sources and the general CTI life-cycle). Then, we present a set of seven high-level CTI plaftorm recommendations that can be used to evaluate a platform and subsequently we survey six state-of-the-art cyber-threat intelligence platforms. Finally, we compare and evaluate the six aforementioned platforms by means of the earlier proposed recommendations.},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Data} {Science}, {Technology} and {Applications}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Chantzios, Thanasis and Koloveas, Paris and Skiadopoulos, Spiros and Kolokotronis, Nikos and Tryfonopoulos, Christos and Bilali, Vasiliki-Georgia and Kavallieros, Dimitris},
	year = {2019},
	note = {Issue: 786698},
	pages = {369--376},
}

@inproceedings{bhunia_dynamic_2017,
	address = {Melbourne, VIC},
	title = {Dynamic attack detection and mitigation in {IoT} using {SDN}},
	isbn = {978-1-5090-6796-1},
	url = {http://ieeexplore.ieee.org/document/8215418/},
	doi = {10.1109/ATNAC.2017.8215418},
	abstract = {With the advent of smart devices and lowering prices of sensing devices, adoption of Internet of Things (IoT) is gaining momentum. These IoT devices come with greater threat of being attacked or compromised that could lead to Denial of Service (DoS) and Distributed Denial of Service (DDoS). The high volume of IoT devices with high level of heterogeneity, magnify the possibility of security threats. So far, there is no protocol to guarantee the security of IoT devices. But to enable resilience, continuous monitoring is required along with adaptive decision making. These challenges can be addressed with the help of Software Deﬁned Networking (SDN) which can effectively handle the security threats to the IoT devices in dynamic and adaptive manner without any burden on the IoT devices. In this paper, we propose an SDN-based secure IoT framework called SoftThings to detect abnormal behaviors and attacks as early as possible and mitigate as appropriate. Machine Learning is used at the SDN controller to monitor and learn the behavior of IoT devices over time. We have conducted experiments on Mininet emulator. Initial results show that this framework is capable to detect attacks on IoT with around 98\% precision.},
	language = {en},
	urldate = {2022-04-09},
	booktitle = {2017 27th {International} {Telecommunication} {Networks} and {Applications} {Conference} ({ITNAC})},
	publisher = {IEEE},
	author = {Bhunia, Suman Sankar and Gurusamy, Mohan},
	month = nov,
	year = {2017},
	pages = {1--6},
}

@inproceedings{biglar_beigi_towards_2014,
	address = {San Francisco, CA, USA},
	title = {Towards effective feature selection in machine learning-based botnet detection approaches},
	isbn = {978-1-4799-5890-0},
	url = {https://ieeexplore.ieee.org/document/6997492},
	doi = {10.1109/CNS.2014.6997492},
	abstract = {Botnets, as one of the most formidable cyber security threats, are becoming more sophisticated and resistant to detection. In spite of speciﬁc behaviors each botnet has, there exist adequate similarities inside each botnet that separate its behavior from benign trafﬁc. Several botnet detection systems have been proposed based on these similarities. However, offering a solution for differentiating botnet trafﬁc (even those using same protocol, e.g. IRC) from normal trafﬁc is not trivial. Extraction of features in either host or network level to model a botnet has been one of the most popular methods in botnet detection. A subset of features, usually selected based on some intuitive understanding of botnets, is used by the machine learning algorithms to classify/ cluster botnet trafﬁc. These approaches, tested against two or three botnet traces, have mostly showed satisfactory detection results. Even though, their effectiveness in detection of other botnets or real trafﬁc remains in doubt. Additionally, effectiveness of different combination of features in terms of providing more detection coverage has not been fully studied. In this paper we revisit ﬂow-based features employed in the existing botnet detection studies and evaluate their relative effectiveness. To ensure a proper evaluation we create a dataset containing a diverse set of botnet traces and background trafﬁc.},
	language = {en},
	urldate = {2021-10-25},
	booktitle = {2014 {IEEE} {Conference} on {Communications} and {Network} {Security}},
	publisher = {IEEE},
	author = {Biglar Beigi, Elaheh and Hadian Jazi, Hossein and Stakhanova, Natalia and Ghorbani, Ali A.},
	month = oct,
	year = {2014},
	pages = {247--255},
}

@inproceedings{bonawitz_practical_2017,
	address = {New York, NY, USA},
	title = {Practical {Secure} {Aggregation} for {Privacy}-{Preserving} {Machine} {Learning}},
	isbn = {978-1-4503-4946-8},
	url = {https://dl.acm.org/doi/10.1145/3133956.3133982},
	doi = {10.1145/3133956.3133982},
	abstract = {We design a novel, communication-efficient, failure-robust protocol for secure aggregation of high-dimensional data. Our protocol allows a server to compute the sum of large, user-held data vectors from mobile devices in a secure manner (i.e. without learning each user's individual contribution), and can be used, for example, in a federated learning setting, to aggregate user-provided model updates for a deep neural network. We prove the security of our protocol in the honest-but-curious and active adversary settings, and show that security is maintained even if an arbitrarily chosen subset of users drop out at any time. We evaluate the efficiency of our protocol and show, by complexity analysis and a concrete implementation, that its runtime and communication overhead remain low even on large data sets and client pools. For 16-bit input values, our protocol offers 1.73× communication expansion for 210 users and 220-dimensional vectors, and 1.98× expansion for 214 users and 224-dimensional vectors over sending data in the clear.},
	booktitle = {Proceedings of the 2017 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H. Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn},
	month = oct,
	year = {2017},
	note = {ISSN: 15437221},
	pages = {1175--1191},
}

@inproceedings{bhatia_privacy_2016,
	title = {Privacy {Risk} in {Cybersecurity} {Data} {Sharing}},
	doi = {10.1145/2994539.2994541},
	abstract = {As information systems become increasingly interdependent, there is an increased need to share cybersecurity data across government agencies and companies, and within and across industrial sectors. This sharing includes threat, vulnerability and incident reporting data, among other data. For cyberattacks that include socio-technical vectors, such as phishing or watering hole attacks, this increased sharing could expose customer and employee personal data to increased privacy risk. In the US, privacy risk arises when the government voluntarily receives data from companies without meaningful consent from individuals, or without a lawful procedure that protects an individual's right to due process. In this paper, we describe a study to examine the trade-off between the need for potentially sensitive data, which we call incident data usage, and the perceived privacy risk of sharing that data with the government. The study is comprised of two parts: a data usage estimate built from a survey of 76 security professionals with mean eight years' experience; and a privacy risk estimate that measures privacy risk using an ordinal likelihood scale and nominal data types in factorial vignettes. The privacy risk estimate also factors in data purposes with different levels of societal benefit, including terrorism, imminent threat of death, economic harm, and loss of intellectual property. The results show which data types are high-usage, low-risk versus those that are low-usage, high-risk. We discuss the implications of these results and recommend future work to improve privacy when data must be shared despite the increased risk to privacy.},
	booktitle = {Proceedings of the 2016 {ACM} on {Workshop} on {Information} {Sharing} and {Collaborative} {Security} - {WISCS}'16},
	publisher = {ACM Press},
	author = {Bhatia, Jaspreet and Breaux, Travis D. and Friedberg, Liora and Hibshi, Hanan and Smullen, Daniel},
	year = {2016},
	pages = {57--64},
}

@inproceedings{bajpai_challenges_2017,
	address = {Los Angeles CA USA},
	title = {Challenges with {Reproducibility}},
	isbn = {978-1-4503-5060-0},
	url = {https://dl.acm.org/doi/10.1145/3097766.3097767},
	doi = {10.1145/3097766.3097767},
	abstract = {The Computer Science (CS) culture is gentle to accepting papers that are non-reproducible as long as they appear plausible. In this paper, we discuss some of the challenges with reproducibility and a set of recommendations that we as a community can undertake to initiate a cultural change.},
	language = {en},
	urldate = {2022-08-12},
	booktitle = {Proceedings of the {Reproducibility} {Workshop}},
	publisher = {ACM},
	author = {Bajpai, Vaibhav and Kühlewind, Mirja and Ott, Jörg and Schönwälder, Jürgen and Sperotto, Anna and Trammell, Brian},
	month = aug,
	year = {2017},
	pages = {1--4},
}

@inproceedings{bernstein_signsgd_2018,
	series = {Proceedings of machine learning research},
	title = {{signSGD}: {Compressed} optimisation for non-convex problems},
	volume = {80},
	url = {https://proceedings.mlr.press/v80/bernstein18a.html},
	abstract = {Training large neural networks requires distributing learning across multiple workers, where the cost of communicating gradients can be a significant bottleneck. signSGD alleviates this problem by transmitting just the sign of each minibatch stochastic gradient. We prove that it can get the best of both worlds: compressed gradients and SGD-level convergence rate. The relative ₁/₂ geometry of gradients, noise and curvature informs whether signSGD or SGD is theoretically better suited to a particular problem. On the practical side we find that the momentum counterpart of signSGD is able to match the accuracy and convergence speed of Adam on deep Imagenet models. We extend our theory to the distributed setting, where the parameter server uses majority vote to aggregate gradient signs from each worker enabling 1-bit compression of worker-server communication in both directions. Using a theorem by Gauss we prove that majority vote can achieve the same reduction in variance as full precision distributed SGD. Thus, there is great promise for sign-based optimisation schemes to achieve fast communication and fast convergence. Code to reproduce experiments is to be found at https://github.com/jxbz/signSGD.},
	booktitle = {Proceedings of the 35th international conference on machine learning},
	publisher = {PMLR},
	author = {Bernstein, Jeremy and Wang, Yu-Xiang and Azizzadenesheli, Kamyar and Anandkumar, Animashree},
	editor = {Dy, Jennifer and Krause, Andreas},
	month = jul,
	year = {2018},
	pages = {560--569},
}

@inproceedings{bethencourt_ciphertext-policy_2007,
	title = {Ciphertext-{Policy} {Attribute}-{Based} {Encryption}},
	isbn = {0-7695-2848-1},
	url = {http://ieeexplore.ieee.org/document/4223236/},
	doi = {10.1109/SP.2007.11},
	abstract = {In several distributed systems a user should only be able to access data if a user posses a certain set of credentials or attributes. Currently, the only method for enforcing such policies is to employ a trusted server to store the data and mediate access control. However, if any server storing the data is compromised, then the confidentiality of the data will be compromised. In this paper we present a system for realizing complex access control on encrypted data that we call Ciphertext-Policy Attribute-Based Encryption. By using our techniques encrypted data can be kept confidential even if the storage server is untrusted; moreover, our methods are secure against collusion attacks. Previous Attribute-Based Encryption systems used attributes to describe the encrypted data and built policies into user's keys; while in our system attributes are used to describe a user's credentials, and a party encrypting data determines a policy for who can decrypt. Thus, our methods are conceptually closer to traditional access control methods such as Role-Based Access Control (RBAC). In addition, we provide an implementation of our system and give performance measurements. ©2007 IEEE.},
	booktitle = {2007 {IEEE} {Symposium} on {Security} and {Privacy} ({SP} '07)},
	publisher = {IEEE},
	author = {Bethencourt, John and Sahai, Amit and Waters, Brent},
	month = may,
	year = {2007},
	note = {ISSN: 10816011},
	pages = {321--334},
}

@inproceedings{badsha_blocynfo-share_2020,
	title = {{BloCyNfo}-{Share}: {Blockchain} based {Cybersecurity} {Information} {Sharing} with {Fine} {Grained} {Access} {Control}},
	isbn = {978-1-72813-783-4},
	url = {https://ieeexplore.ieee.org/document/9031164/},
	doi = {10.1109/CCWC47524.2020.9031164},
	abstract = {To build a proactive cyber defense system, sharing the cybersecurity information has been very popular by which any organization can get more information about unknown and new threats. Cybersecurity Information Exchange (CYBEX) is one of the important platforms which has been playing an important role in implementing proactive cyber defense system by allowing organizations sharing their cybersecurity information. However, they are centralized and therefore they may suffer from complete failure in case of any damage or accident. Moreover, while sharing private information it lacks the mechanism of providing rights to query organizations i.e., enabling the access control over the shared sensitive information. Finally, nonrepudiation of the system does not exist i.e., there is no way to track or keep the record what any organization is sharing and it is necessary to keep the record in case anyone denies after sharing false information. To address these issues, in this paper we propose blockchain based privacy preserving cybersecurity information sharing using proxy re-encryption and attribute-based encryption (BloCyNfo-Share) where the organization can achieve fine-grain access control by delegating which organization can have the access to its cybersecurity information leveraging the benefits of blockchain technology. We conduct privacy and experimental analysis of the proposed system and the findings show that the model is private as well as efficient.},
	booktitle = {2020 10th {Annual} {Computing} and {Communication} {Workshop} and {Conference} ({CCWC})},
	publisher = {IEEE},
	author = {Badsha, Shahriar and Vakilinia, Iman and Sengupta, Shamik},
	month = jan,
	year = {2020},
	pages = {0317--0323},
}

@inproceedings{badsha_privacy_2019,
	title = {Privacy {Preserving} {Cyber} {Threat} {Information} {Sharing} and {Learning} for {Cyber} {Defense}},
	isbn = {978-1-72810-554-3},
	url = {https://ieeexplore.ieee.org/document/8666477/},
	doi = {10.1109/CCWC.2019.8666477},
	abstract = {To secure cyber infrastructure against intentional and potentially malicious threats, a growing collaborative effort between cybersecurity professionals and researchers from institutions, private industries, academia, and government agencies has engaged in exploiting and designing a variety of cyber defense systems. Cybersecurity researchers and designers aim to maintain the confidentiality, integrity, and availability of information and information management systems through various cyber defense systems that protect computers and networks from hackers who may want to steal financial, medical, or other identity-based information. The Cooperative Cyber-defense has been recognized as an essential strategy to fight against cyberattacks. Cyber-security information sharing among various organizations and leveraging the aggregated cyber information to build proactive cyber defense system is nontrivial for organizations. However, building such cyber defense system is challenged by two issues: (1) organizations are reluctant to share their private information to others (2) even when they agree on a solution where information can be shared in privacy preserving manner, the obfuscated cyber threat information has to be processed to build the trained model for future prediction of any new or unknown cyber incident. To address these issues, in this paper, we propose a privacy preserving protocol where organizations can share their private information as an encrypted form with others and they can learn the information for future prediction without disclosing any private information. More specifically we propose a privacy preserving decision tree algorithm, where each organization can build and learn the decision tree based on overall organizations' training spam/ham email data without disclosing any private information of any party. Once the building of a decision tree is done, the organizations can predict if any new email is spam or ham locally.},
	booktitle = {2019 {IEEE} 9th {Annual} {Computing} and {Communication} {Workshop} and {Conference} ({CCWC})},
	publisher = {IEEE},
	author = {Badsha, Shahriar and Vakilinia, Iman and Sengupta, Shamik},
	month = jan,
	year = {2019},
	pages = {0708--0714},
}

@inproceedings{ayed_federated_2021,
	address = {Dubai, United Arab Emirates},
	title = {Federated {Learning} for {Anomaly}-{Based} {Intrusion} {Detection}},
	isbn = {978-1-66540-304-7},
	url = {https://ieeexplore.ieee.org/document/9615816/},
	doi = {10/gpbg2j},
	abstract = {We are attending a severe zero-day cyber attacks. Machine learning based anomaly detection is deﬁnitely the most efﬁcient defence in depth approach. It consists to analyzing the network trafﬁc in order to distinguish the normal behaviour from the abnormal one. This approach is usually implemented in a central server where all the network trafﬁc is analyzed which can rise privacy issues. In fact, with the increasing adoption of Cloud infrastructures, it is important to reduce as much as possible the outsourcing of such sensitive information to the several network nodes. A better approach is to ask each node to analyze its own data and then to exchange its learning ﬁnding (model) with a coordinator. In this paper, we investigate the application of federated learning for networkbased intrusion detection. Our experiment was conducted based on the CICIDS2017 dataset. We present a f ederated learning on a deep learning algorithm CNN based on model averaging. It is a self-learning system for detecting anomalies caused by malicious adversaries without human intervention and can cope with new and unknown attacks without decreasing performance. These experimentation demonstrate that this approach is effective in detecting intrusion.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2021 {International} {Symposium} on {Networks}, {Computers} and {Communications} ({ISNCC})},
	publisher = {IEEE},
	author = {Ayed, Mohamed Ali and Talhi, Chamseddine},
	month = oct,
	year = {2021},
	keywords = {\_read},
	pages = {1--8},
}

@inproceedings{arp_dos_2022,
	address = {Boston, MA},
	title = {Dos and don’ts of machine learning in computer security},
	isbn = {978-1-939133-31-1},
	url = {https://www.usenix.org/conference/usenixsecurity22/presentation/arp},
	booktitle = {31st {USENIX} security symposium ({USENIX} security 22)},
	publisher = {USENIX Association},
	author = {Arp, Daniel and Quiring, Erwin and Pendlebury, Feargus and Warnecke, Alexander and Pierazzi, Fabio and Wressnegger, Christian and Cavallaro, Lorenzo and Rieck, Konrad},
	month = aug,
	year = {2022},
	keywords = {\_read\_urgently},
	pages = {3971--3988},
}

@inproceedings{anton_putting_2019,
	title = {Putting {Together} the {Pieces}: {A} {Concept} for {Holistic} {Industrial} {Intrusion} {Detection}},
	language = {en},
	booktitle = {Proceedings of the 2019 {European} {Conference} on {Cyber} {Warfare} and {Security} ({ECCWS})},
	author = {Antón, Simon Duque and Schotten, Hans Dieter},
	year = {2019},
	keywords = {⛔ No DOI found},
	pages = {11},
}

@inproceedings{androulaki_hyperledger_2018,
	address = {New York, NY, USA},
	title = {Hyperledger {Fabric}: {A} {Distributed} {Operating} {System} for {Permissioned} {Blockchains}},
	isbn = {978-1-4503-5584-1},
	url = {https://dl.acm.org/doi/10.1145/3190508.3190538},
	doi = {10.1145/3190508.3190538},
	abstract = {Fabric is a modular and extensible open-source system for deploying and operating permissioned blockchains and one of the Hyperledger projects hosted by the Linux Foundation (www.hyperledger.org). Fabric is the first truly extensible blockchain system for running distributed applications. It supports modular consensus protocols, which allows the system to be tailored to particular use cases and trust models. Fabric is also the first blockchain system that runs distributed applications written in standard, general-purpose programming languages, without systemic dependency on a native cryptocurrency. This stands in sharp contrast to existing block-chain platforms that require "smart-contracts" to be written in domain-specific languages or rely on a cryptocurrency. Fabric realizes the permissioned model using a portable notion of membership, which may be integrated with industry-standard identity management. To support such flexibility, Fabric introduces an entirely novel blockchain design and revamps the way blockchains cope with non-determinism, resource exhaustion, and performance attacks. This paper describes Fabric, its architecture, the rationale behind various design decisions, its most prominent implementation aspects, as well as its distributed application programming model. We further evaluate Fabric by implementing and benchmarking a Bitcoin-inspired digital currency. We show that Fabric achieves end-to-end throughput of more than 3500 transactions per second in certain popular deployment configurations, with sub-second latency, scaling well to over 100 peers.},
	booktitle = {Proceedings of the {Thirteenth} {EuroSys} {Conference}},
	publisher = {ACM},
	author = {Androulaki, Elli and Barger, Artem and Bortnikov, Vita and Cachin, Christian and Christidis, Konstantinos and De Caro, Angelo and Enyeart, David and Ferris, Christopher and Laventman, Gennady and Manevich, Yacov and Muralidharan, Srinivasan and Murthy, Chet and Nguyen, Binh and Sethi, Manish and Singh, Gari and Smith, Keith and Sorniotti, Alessandro and Stathakopoulou, Chrysoula and Vukolić, Marko and Cocco, Sharon Weed and Yellick, Jason},
	month = apr,
	year = {2018},
	pages = {1--15},
}

@inproceedings{alsaheel_atlas_2021,
	title = {{ATLAS}: {A} {Sequence}-based {Learning} {Approach} for {Attack} {Investigation}},
	isbn = {978-1-939133-24-3},
	shorttitle = {{ATLAS}},
	url = {https://www.usenix.org/conference/usenixsecurity21/presentation/alsaheel},
	language = {en},
	urldate = {2022-08-30},
	author = {Alsaheel, Abdulellah and Nan, Yuhong and Ma, Shiqing and Yu, Le and Walkup, Gregory and Celik, Z. Berkay and Zhang, Xiangyu and Xu, Dongyan},
	year = {2021},
	pages = {3005--3022},
}

@inproceedings{ali-tolppa_self-healing_2018,
	address = {Santa Fe},
	title = {{SELF}-{HEALING} {AND} {RESILIENCE} {IN} {FUTURE} {5G} {COGNITIVE} {AUTONOMOUS} {NETWORKS}},
	isbn = {978-92-61-26921-0},
	url = {https://ieeexplore.ieee.org/document/8598115/},
	doi = {10.23919/ITU-WT.2018.8598115},
	abstract = {In the Self-Organizing Networks (SON) concept, self-healing functions are used to detect, diagnose and correct degraded states in the managed network functions or other resources. Such methods are increasingly important in future network deployments, since ultra-high reliability is one of the key requirements for the future 5G mobile networks, e.g. in critical machine-type communication. In this paper, we discuss the considerations for improving the resiliency of future cognitive autonomous mobile networks. In particular, we present an automated anomaly detection and diagnosis function for SON self-healing based on multi-dimensional statistical methods, case-based reasoning and active learning techniques. Insights from both the human expert and sophisticated machine learning methods are combined in an iterative way. Additionally, we present how a more holistic view on mobile network self-healing can improve its performance.},
	language = {en},
	urldate = {2022-03-31},
	booktitle = {2018 {ITU} {Kaleidoscope}: {Machine} {Learning} for a {5G} {Future} ({ITU} {K})},
	publisher = {IEEE},
	author = {Ali-Tolppa, Janne and Kocsis, Szilard and Schultz, Benedek and Bodrog, Levente and Kajo, Marton},
	month = nov,
	year = {2018},
	pages = {1--8},
}

@inproceedings{althubiti_applying_2018,
	address = {St. Petersburg, FL},
	title = {Applying {Long} {Short}-{Term} {Memory} {Recurrent} {Neural} {Network} for {Intrusion} {Detection}},
	isbn = {978-1-5386-6133-8},
	url = {https://ieeexplore.ieee.org/document/8478898/},
	doi = {10.1109/SECON.2018.8478898},
	abstract = {These days, web applications are used extensively. While organizations benefit from the new abilities they provide, the chance of being targeted is increased, which may cause massive system damage. It is thus important to detect web application attacks. Web intrusion detection systems (IDSs) are important for protecting systems from external users or internal attacks. There are however, many challenges that arise while developing a powerful IDS for unexpected and irregular attacks. Deep Learning approaches provide several methods, and they can detect known and unknown attacks. Long Short-Term Memory (LSTM) is a type of Recurrent Neural Network (RNN) and has the ability to remember values over arbitrary intervals. LSTM is a suitable method to classify and predict known and unknown intrusions. In this work, we propose a deep learning approach to construct an IDS. We apply LSTM RNNs and train the model using the CSIC 2010 HTTP dataset. An LSTM model using the Adam optimizer can construct an efficient IDS binary classifier with an accuracy rate of 0.9997.},
	language = {en},
	urldate = {2021-10-13},
	booktitle = {{SoutheastCon} 2018},
	publisher = {IEEE},
	author = {Althubiti, Sara and Nick, William and Mason, Janelle and Yuan, Xiaohong and Esterline, Albert},
	month = apr,
	year = {2018},
	pages = {1--5},
}

@inproceedings{anceaume_ankle_2012,
	title = {{AnKLe}: {Detecting} {Attacks} in {Large} {Scale} {Systems} via {Information} {Divergence}},
	isbn = {978-1-4673-0938-7},
	url = {http://ieeexplore.ieee.org/document/6214766/},
	doi = {10.1109/EDCC.2012.9},
	abstract = {In this paper, we consider the setting of large scale distributed systems, in which each node needs to quickly process a huge amount of data received in the form of a stream that may have been tampered with by an adversary. In this situation, a fundamental problem is how to detect and quantify the amount of work performed by the adversary. To address this issue, we propose AnKLe (for Attack-tolerant enhanced Kullback-Leibler divergence Estimator), a novel algorithm for estimating the KL divergence of an observed stream compared to the expected one. AnKLe combines sampling techniques and information-theoretic methods. It is very efficient, both in terms of space and time complexities, and requires only a single pass over the data stream. Experimental results show that the estimation provided by AnKLe remains accurate even for different adversarial settings for which the quality of other methods dramatically decreases. © 2012 IEEE.},
	booktitle = {2012 {Ninth} {European} {Dependable} {Computing} {Conference}},
	publisher = {IEEE},
	author = {Anceaume, Emmanuelle and Busnel, Yann and Gambs, Sébastien},
	month = may,
	year = {2012},
	pages = {114--125},
}

@inproceedings{anceaume_anomaly_2014,
	title = {Anomaly {Characterization} in {Large} {Scale} {Networks}},
	isbn = {978-1-4799-2233-8},
	url = {https://ieeexplore.ieee.org/document/6903568},
	doi = {10.1109/DSN.2014.23},
	abstract = {The context of this work is the online characterization of errors in large scale systems. In particular, we address the following question: Given two successive configurations of the system, can we distinguish massive errors from isolated ones, the former ones impacting a large number of nodes while the second ones affect solely a small number of them, or even a single one? The rationale of this question is twofold. First, from a theoretical point of view, we characterize errors with respect to their neighbourhood, and we show that there are error scenarios for which isolated and massive errors are indistinguishable from an omniscient observer point of view. We then relax the definition of this problem by introducing unresolved configurations, and exhibit necessary and sufficient conditions that allow any node to determine the type of errors it has been impacted by. These conditions only depend on the close neighbourhood of each node and thus are locally computable. We present algorithms that implement these conditions, and show through extensive simulations, their performances. Now from a practical point of view, distinguishing isolated errors from massive ones is of utmost importance for networks providers. For instance, for Internet service providers that operate millions of home gateways, it would be very interesting to have procedures that allow gateways to self distinguish whether their dysfunction is caused by network-level errors or by their own hardware or software, and to notify the service provider only in the latter case.},
	booktitle = {2014 44th {Annual} {IEEE}/{IFIP} {International} {Conference} on {Dependable} {Systems} and {Networks}},
	publisher = {IEEE},
	author = {Anceaume, Emmanuelle and Busnel, Yann and Merrer, Erwan Le and Ludinard, Romaric and Marchand, Jean Louis and Sericola, Bruno},
	month = jun,
	year = {2014},
	pages = {68--79},
}

@inproceedings{abouzahra_effect_2014,
	title = {The {Effect} of {Community} {Type} on {Knowledge} {Sharing} {Incentives} in {Online} {Communities}: {A} {Meta}-analysis},
	isbn = {978-1-4799-2504-9},
	url = {http://ieeexplore.ieee.org/document/6758821/},
	doi = {10.1109/HICSS.2014.224},
	abstract = {Online communities are computer mediated, self-organizing, open networks where people voluntarily communicate and share knowledge. Knowledge sharing in online communities requires exerting time and effort and hence community members need motivation to contribute in these communities. Prior research identified numerous incentives that can motivate knowledge sharing in online communities such as self-efficacy and trust. However, research did not consider the effects of community types on the effectiveness of these incentives. In this paper we use meta-analysis to examine the effects of community type on knowledge sharing incentives in communities of interest and communities of practice. We examined 24 papers focusing on knowledge sharing incentives and we found that the type of online community moderates the effects of trust, commitment, task enjoyment and reciprocity on knowledge sharing. The outcome of this research demonstrates that future research should consider community types in knowledge sharing models. © 2014 IEEE.},
	booktitle = {2014 47th {Hawaii} {International} {Conference} on {System} {Sciences}},
	publisher = {IEEE},
	author = {Abouzahra, Mohamed and Tan, Joseph},
	month = jan,
	year = {2014},
	note = {ISSN: 15301605},
	pages = {1765--1773},
}

@inproceedings{abbasi_flitc_2022,
	title = {{FLITC}: {A} {Novel} {Federated} {Learning}-{Based} {Method} for {IoT} {Traffic} {Classification}},
	shorttitle = {{FLITC}},
	doi = {10.1109/SMARTCOMP55677.2022.00055},
	abstract = {Internet of Things (IoT) systems are rightly receiving considerable interest for many real-world applications, from in-body networks to satellite networks. Such a massive-scale system generates a considerable amount of traffic data, making IoT systems a distributed data source generator. For many reasons, such as the functionality of IoT applications and Quality of Service (QoS) provisioning, classifying these traffic data is of high importance. In the last few years, widespread interest has been expressed in applying Machine Learning (ML)-based techniques for Network Traffic Classification (NTC) tasks. However, the traditional centralized learning-based traffic classifiers pose serious challenges, especially in IoT networks. The centralized ML techniques call for collecting a large amount of data from various IoT devices, which in turn introduces data governance and privacy challenges. Furthermore, in the centralized ML, training data need to be transferred to the Cloud, which increases communication cost and latency. To address these problems, we propose Federated Learning (FL) Internet of Things (IoT) Traffic Classifier (FLITC)-a Federated Learning (FL)-based IoT traffic classification method which is based on the Multi-Layer Perception (MLP) neural network and holds the local data unimpaired on IoT devices by sending only the learned parameters to the aggregation server. Our experimental results show that the FLITC beats centralized learning in preserving the privacy of sensitive data and offers a better degree of accuracy at the cost of a longer training time.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Smart} {Computing} ({SMARTCOMP})},
	author = {Abbasi, Mahmoud and Taherkordi, Amir and Shahraki, Amin},
	month = jun,
	year = {2022},
	note = {ISSN: 2693-8340},
	keywords = {Costs, Data privacy, Federated Learning, Internet of Things, Network Traffic Analysis, Privacy, Quality of service, Soft sensors, Telecommunication traffic, Traffic Classification, Training, Training data},
	pages = {206--212},
}

@incollection{wang_dapt_2020,
	address = {Cham},
	title = {{DAPT} 2020 - {Constructing} a {Benchmark} {Dataset} for {Advanced} {Persistent} {Threats}},
	volume = {1271},
	isbn = {978-3-030-59620-0 978-3-030-59621-7},
	url = {https://link.springer.com/10.1007/978-3-030-59621-7_8},
	abstract = {Machine learning is being embraced by information security researchers and organizations alike for its potential in detecting attacks that an organization faces, speciﬁcally attacks that go undetected by traditional signature-based intrusion detection systems. Along with the ability to process large amounts of data, machine learning brings the potential to detect contextual and collective anomalies, an essential attribute of an ideal threat detection system. Datasets play a vital role in developing machine learning models that are capable of detecting complex and sophisticated threats like Advanced Persistent Threats (APT). However, there is currently no APT-dataset that can be used for modeling and detecting APT attacks. Characterized by the sophistication involved and the determined nature of the APT attackers, these threats are not only diﬃcult to detect but also to model. Generic intrusion datasets have three key limitations - (1) They capture attack traﬃc at the external endpoints, limiting their usefulness in the context of APTs which comprise of attack vectors within the internal network as well (2) The diﬀerence between normal and anomalous behavior is quiet distinguishable in these datasets and thus fails to represent the sophisticated attackers’ of APT attacks (3) The data imbalance in existing datasets do not reﬂect the real-world settings rendering themselves as a benchmark for supervised models and falling short of semi-supervised learning. To address these concerns, in this paper, we propose a dataset DAPT 2020 which consists of attacks that are part of Advanced Persistent Threats (APT). These attacks (1) are hard to distinguish from normal traﬃc ﬂows but investigate the raw feature space and (2) comprise of traﬃc on both public-to-private interface and the internal (private) network. Due to the existence of severe class imbalance, we benchmark DAPT 2020 dataset on semi-supervised models and show that they perform poorly trying to detect attack traﬃc in the various stages of an APT.},
	language = {en},
	urldate = {2022-06-24},
	booktitle = {Deployable {Machine} {Learning} for {Security} {Defense}},
	publisher = {Springer International Publishing},
	author = {Myneni, Sowmya and Chowdhary, Ankur and Sabur, Abdulhakim and Sengupta, Sailik and Agrawal, Garima and Huang, Dijiang and Kang, Myong},
	editor = {Wang, Gang and Ciptadi, Arridhana and Ahmadzadeh, Ali},
	year = {2020},
	doi = {10.1007/978-3-030-59621-7_8},
	note = {Series Title: Communications in Computer and Information Science},
	pages = {138--163},
}

@incollection{stern_public-key_1999,
	address = {Berlin, Heidelberg},
	title = {Public-{Key} {Cryptosystems} {Based} on {Composite} {Degree} {Residuosity} {Classes}},
	volume = {1592},
	isbn = {978-3-540-65889-4},
	url = {http://link.springer.com/10.1007/3-540-48910-X_16},
	abstract = {This paper investigates a novel computational problem, namely the Composite Residuosity Class Problem, and its applications to public-key cryptography. We propose a new trapdoor mechanism and derive from this technique three encryption schemes : a trapdoor permutation and two homomorphic probabilistic encryption schemes computationally comparable to RSA. Our cryptosystems, based on usual modular arithmetics, are provably secure under appropriate assumptions in the standard model.},
	language = {en},
	urldate = {2021-07-05},
	booktitle = {Advances in {Cryptology} — {EUROCRYPT} ’99},
	publisher = {Springer Berlin Heidelberg},
	author = {Paillier, Pascal},
	editor = {Stern, Jacques},
	year = {1999},
	doi = {10.1007/3-540-48910-X_16},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {223--238},
}

@incollection{parker_toward_2015,
	address = {Hoboken, NJ, USA},
	title = {Toward a {New} {Framework} for {Information} {Security}?},
	url = {http://doi.wiley.com/10.1002/9781118851678.ch3},
	booktitle = {Computer {Security} {Handbook}},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Parker, Donn B.},
	month = sep,
	year = {2015},
	doi = {10.1002/9781118851678.ch3},
	pages = {3.1--3.23},
}

@incollection{yadav_technical_2015,
	title = {Technical {Aspects} of {Cyber} {Kill} {Chain}},
	volume = {536},
	url = {http://link.springer.com/10.1007/978-3-319-22915-7_40},
	abstract = {Recent trends in targeted cyber-attacks has increased the interest of research in the field of cyber security. Such attacks have massive disruptive effects on organizations, enterprises and governments. Cyber kill chain is a model to describe cyber-attacks so as to develop incident response and analysis capabilities. Cyber kill chain in simple terms is an attack chain, the path that an intruder takes to penetrate information systems over time to execute an attack on the target. This paper broadly categories the methodologies, techniques and tools involved in cyber-attacks. This paper intends to help a cyber security researcher to realize the options available to an attacker at every stage of a cyberattack.},
	booktitle = {Communications in {Computer} and {Information} {Science}},
	author = {Yadav, Tarun and Rao, Arvind Mallari},
	year = {2015},
	doi = {10.1007/978-3-319-22915-7_40},
	note = {ISSN: 18650929},
	pages = {438--452},
}

@incollection{kolodziej_nad_2022,
	address = {Cham},
	title = {{NAD}: {Machine} {Learning} {Based} {Component} for {Unknown} {Attack} {Detection} in {Network} {Traffic}},
	volume = {13300},
	isbn = {978-3-031-04035-1 978-3-031-04036-8},
	shorttitle = {{NAD}},
	url = {https://link.springer.com/10.1007/978-3-031-04036-8_4},
	abstract = {Detection of unknown attacks is challenging due to the lack of exemplary attack vectors. However, previously unknown attacks are a signiﬁcant danger for systems due to a lack of tools for protecting systems against them, especially in fast-evolving Internet of Things (IoT) technology. The most widely used approach for malicious behaviour of the monitored system is detecting anomalies. The vicious behaviour might result from an attack (both known and unknown) or accidental breakdown. We present a Net Anomaly Detector (NAD) system that uses one-class classiﬁcation Machine Learning techniques to detect anomalies in the network traﬃc. The highly modular architecture allows the system to be expanded with adapters for various types of networks. We propose and discuss multiple approaches for increasing detection quality and easing the component deployment in unknown networks by known attacks emulation, exhaustive feature extraction, hyperparameter tuning, detection threshold adaptation and ensemble models strategies. Furthermore, we present both centralized and decentralized deployment schemes and present preliminary results of experiments for the TCP/IP network trafﬁc conducted on the CIC-IDS2017 dataset.},
	language = {en},
	urldate = {2022-07-05},
	booktitle = {Cybersecurity of {Digital} {Service} {Chains}},
	publisher = {Springer International Publishing},
	author = {Krzysztoń, Mateusz and Lew, Marcin and Marks, Michał},
	editor = {Kołodziej, Joanna and Repetto, Matteo and Duzha, Armend},
	year = {2022},
	doi = {10.1007/978-3-031-04036-8_4},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {\_read},
	pages = {83--102},
}

@incollection{maurice_sec2graph_2020,
	address = {Cham},
	title = {Sec2graph: {Network} {Attack} {Detection} {Based} on {Novelty} {Detection} on {Graph} {Structured} {Data}},
	volume = {12223},
	isbn = {978-3-030-52682-5 978-3-030-52683-2},
	shorttitle = {Sec2graph},
	url = {http://link.springer.com/10.1007/978-3-030-52683-2_12},
	abstract = {Being able to timely detect new kinds of attacks in highly distributed, heterogeneous and evolving networks without generating too many false alarms is especially challenging. Many researchers proposed various anomaly detection techniques to identify events that are inconsistent with past observations. While supervised learning is often used to that end, security experts generally do not have labeled datasets and labeling their data would be excessively expensive. Unsupervised learning, that does not require labeled data should then be used preferably, even if these approaches have led to less relevant results. We introduce in this paper a uniﬁed and unique graph representation called security objects’ graphs. This representation mixes and links events of diﬀerent kinds and allows a rich description of the activities to be analyzed. To detect anomalies in these graphs, we propose an unsupervised learning approach based on auto-encoder. Our hypothesis is that as security objects’ graphs bring a rich vision of the normal situation, an auto-encoder is able to build a relevant model of this situation. To validate this hypothesis, we apply our approach to the CICIDS2017 dataset and show that although our approach is unsupervised, its detection results are as good, and even better than those obtained by many supervised approaches.},
	language = {en},
	urldate = {2022-06-10},
	booktitle = {Detection of {Intrusions} and {Malware}, and {Vulnerability} {Assessment}},
	publisher = {Springer International Publishing},
	author = {Leichtnam, Laetitia and Totel, Eric and Prigent, Nicolas and Mé, Ludovic},
	editor = {Maurice, Clémentine and Bilge, Leyla and Stringhini, Gianluca and Neves, Nuno},
	year = {2020},
	doi = {10.1007/978-3-030-52683-2_12},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {\_read\_urgently},
	pages = {238--258},
}

@incollection{pereira_gossip_2019,
	address = {Cham},
	title = {Gossip {Learning} as a {Decentralized} {Alternative} to {Federated} {Learning}},
	volume = {11534},
	isbn = {978-3-030-22495-0 978-3-030-22496-7},
	url = {http://link.springer.com/10.1007/978-3-030-22496-7_5},
	abstract = {Federated learning is a distributed machine learning approach for computing models over data collected by edge devices. Most importantly, the data itself is not collected centrally, but a master-worker architecture is applied where a master node performs aggregation and the edge devices are the workers, not unlike the parameter server approach. Gossip learning also assumes that the data remains at the edge devices, but it requires no aggregation server or any central component. In this empirical study, we present a thorough comparison of the two approaches. We examine the aggregated cost of machine learning in both cases, considering also a compression technique applicable in both approaches. We apply a real churn trace as well collected over mobile phones, and we also experiment with diﬀerent distributions of the training data over the devices. Surprisingly, gossip learning actually outperforms federated learning in all the scenarios where the training data are distributed uniformly over the nodes, and it performs comparably to federated learning overall.},
	language = {en},
	urldate = {2022-02-04},
	booktitle = {Distributed {Applications} and {Interoperable} {Systems}},
	publisher = {Springer International Publishing},
	author = {Hegedűs, István and Danner, Gábor and Jelasity, Márk},
	editor = {Pereira, José and Ricci, Laura},
	year = {2019},
	doi = {10.1007/978-3-030-22496-7_5},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {\_read},
	pages = {74--90},
}

@incollection{gangemi_semantic_2018,
	address = {Cham},
	title = {Semantic {Query} {Federation} for {Scalable} {Security} {Log} {Analysis}},
	volume = {11155},
	isbn = {978-3-319-98191-8 978-3-319-98192-5},
	url = {http://link.springer.com/10.1007/978-3-319-98192-5_48},
	abstract = {The digitalization of business processes increasingly exposes organizations to sophisticated cyber-security threats. To contain attacks and minimize their impact, it is essential to detect them early. To this end, it is necessary to analyze a wide range of log ﬁles that potentially provide clues about malicious activity. However, these logs are typically voluminous, heterogeneous, diﬃcult to interpret, and stored in disparate locations, which makes it diﬃcult to analyze them. Current approaches to analyze security logs mainly focus on regular expressions and statistical indicators and do not directly provide actionable insight to security analysts. To address these limitations, we propose a distributed approach that enables semantic querying of dispersed log sources in large-scale infrastructures. To automatically integrate and reason about security log information, we will leverage linked data technologies and state-ofthe-art federated query processing systems. In this proposal, we discuss the research problem, methodology, approach and evaluation plan for scalable federated semantic security log analysis.},
	language = {en},
	urldate = {2021-10-12},
	booktitle = {The {Semantic} {Web}: {ESWC} 2018 {Satellite} {Events}},
	publisher = {Springer International Publishing},
	author = {Kurniawan, Kabul},
	editor = {Gangemi, Aldo and Gentile, Anna Lisa and Nuzzolese, Andrea Giovanni and Rudolph, Sebastian and Maleshkova, Maria and Paulheim, Heiko and Pan, Jeff Z and Alam, Mehwish},
	year = {2018},
	doi = {10.1007/978-3-319-98192-5_48},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {294--303},
}

@incollection{kruegel_using_2003,
	title = {Using {Decision} {Trees} to {Improve} {Signature}-{Based} {Intrusion} {Detection}},
	abstract = {Most deployed intrusion detection systems (IDSs) follow a signature-based approach where attacks are identiﬁed by matching each input event against predeﬁned signatures that model malicious activity. This matching process accounts for the most resource intensive task of an IDS. Many systems perform the matching by comparing each input event to all rules sequentially. This is far from being optimal. Although sometimes ad-hoc optimizations are utilized, no general solution to this problem has been proposed so far.},
	language = {en},
	booktitle = {Recent {Advances} in {Intrusion} {Detection}},
	author = {Kruegel, Christopher and Toth, Thomas},
	year = {2003},
	pages = {173--191},
}

@incollection{jiang_machine_2020,
	address = {Singapore},
	title = {Machine {Learning} in {Industrial} {Control} {System} {Security}: {A} {Survey}},
	isbn = {978-981-329-698-5},
	url = {http://link.springer.com/10.1007/978-981-32-9698-5_35},
	abstract = {Industrial control system (ICS) is becoming more and more open to the outside world for the advancement of Industrial Internet, which means people can have access to the industrial control system with traditional internet-based methods. However, the connections with outside world make ICS exposed to numerous unpredictable dangers. In addition, artificial intelligence (AI) has made great progress and applying AI to other fields is the trend in both academia and industry. This paper will introduce the basic information of ICS and review related works in anomaly detection based on AI. Based on the analysis of previous researches and the features of ICS, the prospect of anomaly detection of ICS is forecasted.},
	booktitle = {Proceedings of 2019 {Chinese} {Intelligent} {Systems} {Conference}},
	publisher = {Springer Singapore},
	author = {Jiang, Dianbin and Zhao, Jingling},
	editor = {Jia, Yingmin and Du, Junping and Zhang, Weicun},
	year = {2020},
	doi = {10.1007/978-981-32-9698-5_35},
	pages = {310--317},
}

@incollection{paiva_critique_2021,
	address = {Cham},
	title = {A {Critique} on the {Use} of {Machine} {Learning} on {Public} {Datasets} for {Intrusion} {Detection}},
	volume = {1439},
	isbn = {978-3-030-85346-4 978-3-030-85347-1},
	url = {https://link.springer.com/10.1007/978-3-030-85347-1_19},
	abstract = {Intrusion detection has become an open challenge in any modern ICT system due to the ever-growing urge towards assuring security of present day networks. Various machine learning methods have been proposed for ﬁnding an eﬀective solution to detect and prevent network intrusions. Many approaches, tuned and tested by means of public datasets, capitalize on well-known classiﬁers, which often reach detection accuracy close to 1. However, these results strongly depend on the training data, which may not be representative of real production environments and ever-evolving attacks. This paper is an initial exploration around this problem. After having learned a detector on the top of a public intrusion detection dataset, we test it against held-out data not used for learning and additional data gathered by attack emulation in a controlled network. The experiments presented are focused on Denial of Service attacks and based on the CICIDS2017 dataset. Overall, the ﬁgures gathered conﬁrm that results obtained in the context of synthetic datasets may not generalize in practice.},
	language = {en},
	urldate = {2022-05-23},
	booktitle = {Quality of {Information} and {Communications} {Technology}},
	publisher = {Springer International Publishing},
	author = {Catillo, Marta and Del Vecchio, Andrea and Pecchia, Antonio and Villano, Umberto},
	editor = {Paiva, Ana C. R. and Cavalli, Ana Rosa and Ventura Martins, Paula and Pérez-Castillo, Ricardo},
	year = {2021},
	doi = {10.1007/978-3-030-85347-1_19},
	note = {Series Title: Communications in Computer and Information Science},
	pages = {253--266},
}

@incollection{shyamasundar_wids_2017,
	address = {Cham},
	title = {{wIDS}: {A} {Multilayer} {IDS} for {Wireless}-{Based} {SCADA} {Systems}},
	volume = {10717},
	isbn = {978-3-319-72597-0 978-3-319-72598-7},
	shorttitle = {{wIDS}},
	url = {http://link.springer.com/10.1007/978-3-319-72598-7_24},
	abstract = {The increasing use of wireless sensors networks in Supervisory Control and Data Acquisition systems (SCADA) raises the need of enforcing the security of this promising technology. Indeed, SCADA systems are used to manage critical installations that have hard security, reliability and real-time requirements. Consequently, in order to ensure Wireless Industrial Sensor Networks (WISN) security, Intrusion Detection Systems should be used as a second line of defense, in addition to sensor’s embedded security mechanisms. In this paper, we present wIDS a multilayer speciﬁcation-based Intrusion Detection System specially tailored for WISN. It has a two-level detection architecture and is based on a formal description of node’s normal behavior.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {Information {Systems} {Security}},
	publisher = {Springer International Publishing},
	author = {Bayou, Lyes and Espes, David and Cuppens-Boulahia, Nora and Cuppens, Frédéric},
	editor = {Shyamasundar, Rudrapatna K. and Singh, Virendra and Vaidya, Jaideep},
	year = {2017},
	doi = {10.1007/978-3-319-72598-7_24},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {387--404},
}

@incollection{clark_hardware_2005,
	title = {A hardware platform for network intrusion detection and prevention},
	isbn = {978-0-12-088476-6},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780120884766500071},
	abstract = {The current generation of centralized network intrusion detection systems (NIDS) have various limitations on their performance and effectiveness. In this paper, we argue that intrusion detection analysis should be distributed to network node IDS (NNIDS) running in hardware on the end hosts. An NNIDS can unambiguously inspect traffic to and from the host, and when implemented on the network interface hardware, can function independently of the host operating system to provide better protection with less overhead than software implementations. We discuss the computation and communication characteristics of typical software intrusion detection analysis tasks. Then, we describe our efforts in mapping these tasks to a hardware platform using COTS components including Intel IXP network processors and Xilinx Virtex FPGAs. We report the performance of our prototype NNIDS implementation and provide analysis on how the network processor architecture affects the performance. Our results show that the NNIDS can achieve high performance with a pipeline of processing stages and careful allocation of tasks to the most appropriate hardware resources.},
	language = {en},
	urldate = {2022-01-12},
	booktitle = {Network {Processor} {Design}},
	publisher = {Elsevier},
	author = {Clark, Chris and Lee, Wenke and Schimmel, David and Contis, Didier and Koné, Mohamed and Thomas, Ashley},
	year = {2005},
	doi = {10.1016/B978-012088476-6/50007-1},
	keywords = {\_read\_urgently},
	pages = {99--118},
}

@incollection{chaki_network_2011,
	address = {Berlin, Heidelberg},
	title = {Network {Event} {Correlation} and {Semantic} {Reasoning} for {Federated} {Networks} {Protection} {System}},
	volume = {245},
	isbn = {978-3-642-27244-8 978-3-642-27245-5},
	url = {http://link.springer.com/10.1007/978-3-642-27245-5_8},
	abstract = {In this paper we present semantic approach to network event correlation for large-scale federated intrusion detection system. The major contributions of this paper are: network event correlation mechanism and semantic reasoning based on the ontology. Our propositions and deployments are used in Federated Networks Protection System as a part of the Decision Module.},
	language = {en},
	urldate = {2021-10-12},
	booktitle = {Computer {Information} {Systems} – {Analysis} and {Technologies}},
	publisher = {Springer Berlin Heidelberg},
	author = {Choraś, Michał and Kozik, Rafał},
	editor = {Chaki, Nabendu and Cortesi, Agostino},
	year = {2011},
	doi = {10.1007/978-3-642-27245-5_8},
	note = {Series Title: Communications in Computer and Information Science},
	pages = {48--54},
}

@incollection{tian_network_2015,
	address = {Cham},
	title = {Network {Traffic} {Pattern} {Analysis} {Using} {Improved} {Information} {Theoretic} {Co}-clustering {Based} {Collective} {Anomaly} {Detection}},
	volume = {153},
	isbn = {978-3-319-23801-2 978-3-319-23802-9},
	url = {http://link.springer.com/10.1007/978-3-319-23802-9_17},
	abstract = {Collective anomaly is a pattern in the data when a group of similar data instances behave anomalously with respect to the entire dataset. Clustering is a useful unsupervised technique to identify the underlying pattern in the data as well as anomaly detection. However, existing clustering based techniques have high false alarm rates and consider individual data instance behaviour for anomaly detection. In this paper, we formulate the problem of detecting DoS (Denial of Service) attacks as collective anomaly detection and propose a mathematically logical criteria for selecting the important traﬃc attributes for detecting collective anomaly. Information theoretic co-clustering algorithm is advantageous over regular clustering for creating more ﬁne-grained representation of the data, however lacks the ability to handle mixed attribute data. We extend the co-clustering algorithm by incorporating the ability to handle categorical attributes which augments the detection accuracy of DoS attacks in benchmark KDD cup 1999 network traﬃc dataset than the existing techniques.},
	language = {en},
	urldate = {2022-08-12},
	booktitle = {International {Conference} on {Security} and {Privacy} in {Communication} {Networks}},
	publisher = {Springer International Publishing},
	author = {Ahmed, Mohiuddin and Mahmood, Abdun Naser},
	editor = {Tian, Jin and Jing, Jiwu and Srivatsa, Mudhakar},
	year = {2015},
	doi = {10.1007/978-3-319-23802-9_17},
	note = {Series Title: Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
	pages = {204--219},
}

@book{ludwig_federated_2022,
	title = {Federated {Learning}},
	url = {https://link.springer.com/book/10.1007/978-3-030-96896-0},
	abstract = {This book presents an in-depth summary of the most important issues and approaches to Federated Learning (FL) for researchers and practitioners.},
	language = {en},
	urldate = {2022-08-11},
	author = {Ludwig, Heiko and Baracaldo, Nathalie},
	year = {2022},
}

@incollection{kouvatsos_implementation_2011,
	address = {Berlin, Heidelberg},
	title = {Implementation and {Evaluation} of {Network} {Intrusion} {Detection} {Systems}},
	volume = {5233},
	isbn = {978-3-642-02741-3 978-3-642-02742-0},
	url = {http://link.springer.com/10.1007/978-3-642-02742-0_42},
	abstract = {Performance evaluation of Network Intrusion Detection Systems (NIDS) has been carried out to identify its limitations in high speed environment. This has been done by employing evasive and avoidance strategies simulating real-life normal and attack traffic flows on a sophisticated Test-Bench. Snort, an open source Intrusion Detection System, has been selected as an evaluation platform. In this paper, Snort has been evaluated on host and virtual configurations using different operating systems and hardware implementations. Evaluation methodology is based on the concept of stressing the system by injecting various traffic loads (packet sizes, bandwidth and attack signatures) and analyzing its packet handling and detection capacity. We have observed few performance issues with Snort which has resulted into packet drop and low detection rate. Finally, we have analyzed the factors responsible for it and have recommended techniques to improve systems packet handling and detection capability.},
	language = {en},
	urldate = {2022-01-12},
	booktitle = {Network {Performance} {Engineering}},
	publisher = {Springer Berlin Heidelberg},
	author = {Akhlaq, Monis and Alserhani, Faeiz and Awan, Irfan and Mellor, John and Cullen, Andrea J. and Al-Dhelaan, Abdullah},
	editor = {Kouvatsos, Demetres D.},
	year = {2011},
	doi = {10.1007/978-3-642-02742-0_42},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {988--1016},
}

@book{goodfellow_deep_2016,
	address = {Cambridge, Massachusetts},
	series = {Adaptive computation and machine learning},
	title = {Deep learning},
	isbn = {978-0-262-03561-3},
	publisher = {The MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
	keywords = {Machine learning},
}

@book{gough_introduction_2017,
	title = {An introduction to systematic reviews},
	publisher = {Sage},
	author = {Gough, David and Oliver, Sandy and Thomas, James},
	year = {2017},
}

@book{bishop_pattern_2006,
	address = {New York},
	series = {Information science and statistics},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	year = {2006},
	keywords = {Machine learning, Pattern perception},
}

@article{attota_ensemble_2021,
	title = {An {Ensemble} {Multi}-{View} {Federated} {Learning} {Intrusion} {Detection} for {IoT}},
	volume = {9},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9521524/},
	doi = {10.1109/ACCESS.2021.3107337},
	abstract = {The rise in popularity of Internet of Things (IoT) devices has attracted hackers to develop IoT-speciﬁc attacks. The microservice architecture of IoT devices relies on the Internet to provide their intended services. An unguarded IoT network makes inter-connected devices vulnerable to attacks. It will be a tedious and ineffective process to manually detect the attacks in the network, as the attackers frequently upgrade their attack strategies. Machine learning (ML)-assisted approaches have been proposed to build intrusion detection for cybersecurity automation in IoT networks. However, most such approaches focus on training an ML model using a single view of the dataset, which often fails to build insightful knowledge and understand each feature’s impact on the ML model’s decision-making ability. As such, the model training with a single view may result in an incomplete understanding of patterns in large feature-set datasets. Moreover, the current approaches are mainly designed in a centralized manner in which the raw data is transferred from the edge devices to the central server for training. This, in turn, may expose the data to all kinds of attacks without adhering to the privacy-preserving of data security. Multi-view learning has gained popularity for its ability to learn from different data views and deliver efﬁcient performance with more distinguished predictions. This paper proposes a federated learning-based intrusion detection approach, called MV-FLID, that trains on multiple views of IoT network data in a decentralized format to detect, classify, and defend against attacks. The multi-view ensemble learning aspect helps in maximizing the learning efﬁciency of different classes of attacks. The Federated Learning (FL) aspect, wherein the device’s data is not shared to the server, performs proﬁle aggregation efﬁciently with the beneﬁt of peer learning. Our evaluation results show that our proposed approach has higher accuracy compared to the traditional non-FL centralized approach.},
	language = {en},
	urldate = {2023-10-19},
	journal = {IEEE Access},
	author = {Attota, Dinesh Chowdary and Mothukuri, Viraaji and Parizi, Reza M. and Pouriyeh, Seyedamin},
	year = {2021},
	pages = {117734--117745},
}

@article{lingzi_zhu_ticps_nodate,
	title = {{TICPS}: {A} {Trustworthy} {Collaborative} {Intrusion} {Detection} {Framework} for {Industrial} {Cyber}–{Physical} {Systems}},
	abstract = {The networking of industrial cyber-physical systems (CPSs) brings more security threats, which highlights the significance of intrusion detection frameworks. However, the data of industrial CPSs have the problem of islanding and high sensitivity. As a distributed machine learning technique, the federate learning (FL) framework alleviates this situation by allowing detection models to be constructed collaboratively with multiple agents while protecting data privacy. However, existing FL-based intrusion detection methods perform ineffectively on the poisoning attacks launched by malicious agents. The poisoning attacks can manipulate the local data set to send malicious updates to the server, thus corrupting the intrusion detection model. To address these issues, we design TICPS, a collaborative intrusion detection framework based on a trustworthy model update strategy to detect cyber threats from industrial CPSs. The framework utilizes FL to allow multiple industrial CPSs to jointly construct a comprehensive intrusion detection model. In addition, we evaluate the trustworthiness of each industrial agent by similarity tests between local model updates and a trustworthy root model update. By implementing secure model aggregation updates, the models can perform effective intrusion detection even under poisoning attacks. Extensive experiments on real industrial CPSs datasets demonstrate the effectiveness of our framework in detecting various types of cyber threats to industrial CPSs. In particular, when the proportion of malicious agents reaches 90\% under three typical poisoning attacks, it can still achieve 94\% accuracy of intrusion detection.},
	author = {{Lingzi Zhu} and {Bo Zhao} and {Weidong Li} and {Yixuan Wang} and {Yang An}},
	keywords = {\_done, \_unpublished},
}

@inproceedings{chilukuri_achieving_2020,
	title = {Achieving {Optimal} {Cache} {Utility} in {Constrained} {Wireless} {Networks} through {Federated} {Learning}},
	doi = {10.1109/WoWMoM49955.2020.00053},
	abstract = {Edge computing allows constrained end devices in wireless networks to offioad heavy computing tasks or data storage when local resources are insufficient. Edge nodes can provide resources such as the bandwidth, storage and innetwork compute power. For example, edge nodes can provide data caches to which constrained end devices can off-load their data and from where user can access data more effectively. However, fair allocation of these resources to competing end devices and data classes while providing good Quality of Service is a challenging task, due to frequently changing network topology and/or traffic conditions. In this paper, we present Federated learning-based dynamic Cache allocation (FedCache) for edge caches in dynamic, constrained networks. FedCache uses federated learning to learn the benefit of a particular cache allocation with low communication overhead. Edge nodes learn locally to adapt to different network conditions and collaboratively share this knowledge so as to avoid having to transmit all data to a single location. Through this federated learning approach, nodes can find resource allocations that result in maximum fairness or efficiency in terms of the cache hit ratio for a given network state. Simulation results show that cache resource allocation using FedCache results in optimal fairness or efficiency of utility for different classes of data when compared to proportional allocation, while incurring low communication overhead.},
	booktitle = {2020 {IEEE} 21st {International} {Symposium} on "{A} {World} of {Wireless}, {Mobile} and {Multimedia} {Networks}" ({WoWMoM})},
	author = {Chilukuri, Shanti and Pesch, Dirk},
	month = aug,
	year = {2020},
	keywords = {Bandwidth, Data models, Dynamic scheduling, Quality of experience, Quality of service, Resource management, Silicon, edge computing, fairness, federated learning, resource allocation},
	pages = {254--263},
}

@misc{samarakoon_5g-nidd_2022,
	title = {{5G}-{NIDD}: {A} {Comprehensive} {Network} {Intrusion} {Detection} {Dataset} {Generated} over {5G} {Wireless} {Network}},
	shorttitle = {{5G}-{NIDD}},
	url = {http://arxiv.org/abs/2212.01298},
	abstract = {With a plethora of new connections, features, and services introduced, the 5th generation (5G) wireless technology reﬂects the development of mobile communication networks and is here to stay for the next decade. The multitude of services and technologies that 5G incorporates have made modern communication networks very complex and sophisticated in nature. This complexity along with the incorporation of Machine Learning (ML) and Artiﬁcial Intelligence (AI) provides the opportunity for the attackers to launch intelligent attacks against the network and network devices. These attacks often traverse undetected due to the lack of intelligent security mechanisms to counter these threats. Therefore, the implementation of real-time, proactive, and self-adaptive security mechanisms throughout the network would be an integral part of 5G as well as future communication systems. Therefore, large amounts of data collected from real networks will play an important role in the training of AI/ML models to identify and detect malicious content in network trafﬁc. This work presents 5G-NIDD, a fully labeled dataset built on a functional 5G test network that can be used by those who develop and test AI/ML solutions. The work further analyses the collected data using common ML models and shows the achieved accuracy levels.},
	language = {en},
	urldate = {2022-12-14},
	publisher = {arXiv},
	author = {Samarakoon, Sehan and Siriwardhana, Yushan and Porambage, Pawani and Liyanage, Madhusanka and Chang, Sang-Yoon and Kim, Jinoh and Kim, Jonghyun and Ylianttila, Mika},
	month = dec,
	year = {2022},
	note = {arXiv:2212.01298 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Networking and Internet Architecture},
}

@inproceedings{gopalan_balancing_2021,
	title = {Balancing {Approaches} towards {ML} for {IDS}: {A} {Survey} for the {CSE}-{CIC} {IDS} {Dataset}},
	shorttitle = {Balancing {Approaches} towards {ML} for {IDS}},
	doi = {10.1109/ICCSPA49915.2021.9385742},
	abstract = {Balanced datasets play a key role in the bias observed in machine learning algorithms towards classification and prediction. The CSE-CIC IDS datasets published in 2017 and 2018 have both attracted considerable scholarly attention towards research in intrusion detection systems. Recent work published using this dataset indicates little attention paid to the imbalance of the dataset. The study presented in this paper sets out to explore the degree to which imbalance has been treated and provide a taxonomy of the machine learning approaches developed using these datasets. A survey of published works related to these datasets was done to deliver a combined qualitative and quantitative methodological approach for our analysis towards deriving a taxonomy. The research presented here confirms that the impact of bias due to the imbalance datasets is rarely addressed. This data supports further research and development of supervised machine learning techniques which reduce the impact of bias in classification or prediction due to these imbalance datasets.},
	booktitle = {2020 {International} {Conference} on {Communications}, {Signal} {Processing}, and their {Applications} ({ICCSPA})},
	author = {Gopalan, Subiksha Srinivasa and Ravikumar, Dharshini and Linekar, Dino and Raza, Ali and Hasib, Maheen},
	month = mar,
	year = {2021},
	keywords = {Machine learning, Machine learning algorithms, Measurement, Predictive models, Research and development, Signal processing, Taxonomy, balance, dataset, intrusion detection system, machine learning},
	pages = {1--6},
}

@article{rodriguez-barroso_survey_2023,
	title = {Survey on federated learning threats: {Concepts}, taxonomy on attacks and defences, experimental study and challenges},
	volume = {90},
	issn = {1566-2535},
	shorttitle = {Survey on federated learning threats},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253522001439},
	doi = {10.1016/j.inffus.2022.09.011},
	abstract = {Federated learning is a machine learning paradigm that emerges as a solution to the privacy-preservation demands in artificial intelligence. As machine learning, federated learning is threatened by adversarial attacks against the integrity of the learning model and the privacy of data via a distributed approach to tackle local and global learning. This weak point is exacerbated by the inaccessibility of data in federated learning, which makes the protection against adversarial attacks harder and evidences the need to furtherance the research on defence methods to make federated learning a real solution for safeguarding data privacy. In this paper, we present an extensive review of the threats of federated learning, as well as as their corresponding countermeasures, attacks versus defences. This survey provides a taxonomy of adversarial attacks and a taxonomy of defence methods that depict a general picture of this vulnerability of federated learning and how to overcome it. Likewise, we expound guidelines for selecting the most adequate defence method according to the category of the adversarial attack. Besides, we carry out an extensive experimental study from which we draw further conclusions about the behaviour of attacks and defences and the guidelines for selecting the most adequate defence method according to the category of the adversarial attack. Finally, we present our learned lessons and challenges.},
	urldate = {2023-09-29},
	journal = {Information Fusion},
	author = {Rodríguez-Barroso, Nuria and Jiménez-López, Daniel and Luzón, M. Victoria and Herrera, Francisco and Martínez-Cámara, Eugenio},
	month = feb,
	year = {2023},
	keywords = {+survey, Adversarial attacks, Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Defences, Federated learning, Privacy attacks, ⛔ No DOI found},
	pages = {148--173},
}

@inproceedings{moustafa_unsw-nb15_2015,
	title = {{UNSW}-{NB15}: a comprehensive data set for network intrusion detection systems ({UNSW}-{NB15} network data set)},
	shorttitle = {{UNSW}-{NB15}},
	url = {https://ieeexplore.ieee.org/abstract/document/7348942},
	doi = {10.1109/MilCIS.2015.7348942},
	abstract = {One of the major research challenges in this field is the unavailability of a comprehensive network based data set which can reflect modern network traffic scenarios, vast varieties of low footprint intrusions and depth structured information about the network traffic. Evaluating network intrusion detection systems research efforts, KDD98, KDDCUP99 and NSLKDD benchmark data sets were generated a decade ago. However, numerous current studies showed that for the current network threat environment, these data sets do not inclusively reflect network traffic and modern low footprint attacks. Countering the unavailability of network benchmark data set challenges, this paper examines a UNSW-NB15 data set creation. This data set has a hybrid of the real modern normal and the contemporary synthesized attack activities of the network traffic. Existing and novel methods are utilised to generate the features of the UNSWNB15 data set. This data set is available for research purposes and can be accessed from the link.},
	urldate = {2023-10-09},
	booktitle = {2015 {Military} {Communications} and {Information} {Systems} {Conference} ({MilCIS})},
	author = {Moustafa, Nour and Slay, Jill},
	month = nov,
	year = {2015},
	pages = {1--6},
}

@inproceedings{duraz_cyber_2023,
	address = {New York, NY, USA},
	series = {{EICC} '23},
	title = {Cyber {Informedness}: {A} {New} {Metric} using {CVSS} to {Increase} {Trust} in {Intrusion} {Detection} {Systems}},
	isbn = {978-1-4503-9829-9},
	shorttitle = {Cyber {Informedness}},
	url = {https://dl.acm.org/doi/10.1145/3590777.3590786},
	doi = {10.1145/3590777.3590786},
	abstract = {Intrusion Detection Systems (IDSs) are essential cybersecurity components. Previous cyberattack detection methods relied more on signatures and rules to detect cyberattacks, although there has been a change in paradigm in the last decade, with Machine Learning (ML) enabling more efficient and flexible statistical methods. However, ML is currently unable to integrate cybersecurity information into its inner workings. This paper introduces Cyber Informedness, a new metric taking into account cybersecurity information to give a more informed representation of performance, influenced by the severity of the attacks encountered. This metric uses a de facto standard in cybersecurity: the Common Vulnerability Scoring System (CVSS). Results on two public datasets show that this new metric validates results obtained with generic metrics. Furthermore, this new metric highlights ML-based IDSs that prioritize high performance on severe attacks, which is not visible with generic metrics. Consequently, this new metric nicely completes generic metrics by bridging the gap between ML and cybersecurity.},
	urldate = {2023-10-10},
	booktitle = {Proceedings of the 2023 {European} {Interdisciplinary} {Cybersecurity} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Duraz, Robin and Espes, David and Francq, Julien and Vaton, Sandrine},
	year = {2023},
	keywords = {Cybersecurity metrics, Intrusion Detection Systems, Machine Learning},
	pages = {53--58},
}

@inproceedings{lubben_distributed_2023,
	address = {Miami, FL, USA},
	title = {Distributed {Device}-{Specific} {Anomaly} {Detection} for {Resource}-{Constrained} {Devices}},
	isbn = {978-1-66547-716-1},
	url = {https://ieeexplore.ieee.org/document/10154372/},
	doi = {10.1109/NOMS56928.2023.10154372},
	abstract = {The Internet of Things (IoT) requires security mechanisms that account for heterogeneous devices and resource constraints. Current Anomaly Detection (AD) approaches typically apply centralized data processing. This lacks scalability as well as privacy, bandwidth consumption, latency, and availability. The combination of device-specific AD models and distributed edge computing provides a solution to these challenges. It allows the creation of simplified, lightweight AD models that run on constrained hardware. The hands-on environment described allows interactive exploration of the impact of model simplification. This includes live evaluation of performance metrics and processing latency on a constrained device.},
	language = {en},
	urldate = {2023-10-09},
	booktitle = {{NOMS} 2023-2023 {IEEE}/{IFIP} {Network} {Operations} and {Management} {Symposium}},
	publisher = {IEEE},
	author = {Lübben, Christian and Pahl, Marc-Oliver},
	month = may,
	year = {2023},
	pages = {1--3},
}

@article{roy_braintorrent_2019,
	title = {{BrainTorrent}: {A} {Peer}-to-{Peer} {Environment} for {Decentralized} {Federated} {Learning}},
	shorttitle = {{BrainTorrent}},
	url = {https://www.semanticscholar.org/paper/BrainTorrent%3A-A-Peer-to-Peer-Environment-for-Roy-Siddiqui/aad543a5b7f231f085764ce0258fe8914a15006f},
	abstract = {Access to sufficient annotated data is a common challenge in training deep neural networks on medical images. As annotating data is expensive and time-consuming, it is difficult for an individual medical center to reach large enough sample sizes to build their own, personalized models. As an alternative, data from all centers could be pooled to train a centralized model that everyone can use. However, such a strategy is often infeasible due to the privacy-sensitive nature of medical data. Recently, federated learning (FL) has been introduced to collaboratively learn a shared prediction model across centers without the need for sharing data. In FL, clients are locally training models on site-specific datasets for a few epochs and then sharing their model weights with a central server, which orchestrates the overall training process. Importantly, the sharing of models does not compromise patient privacy. A disadvantage of FL is the dependence on a central server, which requires all clients to agree on one trusted central body, and whose failure would disrupt the training process of all clients. In this paper, we introduce BrainTorrent, a new FL framework without a central server, particularly targeted towards medical applications. BrainTorrent presents a highly dynamic peer-to-peer environment, where all centers directly interact with each other without depending on a central body. We demonstrate the overall effectiveness of FL for the challenging task of whole brain segmentation and observe that the proposed server-less BrainTorrent approach does not only outperform the traditional server-based one but reaches a similar performance to a model trained on pooled data.},
	urldate = {2023-09-11},
	journal = {ArXiv},
	author = {Roy, Abhijit Guha and Siddiqui, Shayan and Pölsterl, Sebastian and Navab, Nassir and Wachinger, C.},
	month = may,
	year = {2019},
	keywords = {⛔ No DOI found},
}

@misc{li_federated_2021,
	title = {Federated {Learning} on {Non}-{IID} {Data} {Silos}: {An} {Experimental} {Study}},
	shorttitle = {Federated {Learning} on {Non}-{IID} {Data} {Silos}},
	url = {http://arxiv.org/abs/2102.02079},
	abstract = {Due to the increasing privacy concerns and data regulations, training data have been increasingly fragmented, forming distributed databases of multiple “data silos” (e.g., within different organizations and countries). To develop effective machine learning services, there is a must to exploit data from such distributed databases without exchanging the raw data. Recently, federated learning (FL) has been a solution with growing interests, which enables multiple parties to collaboratively train a machine learning model without exchanging their local data. A key and common challenge on distributed databases is the heterogeneity of the data distribution among the parties. The data of different parties are usually non-independently and identically distributed (i.e., non-IID). There have been many FL algorithms to address the learning effectiveness under non-IID data settings. However, there lacks an experimental study on systematically understanding their advantages and disadvantages, as previous studies have very rigid data partitioning strategies among parties, which are hardly representative and thorough. In this paper, to help researchers better understand and study the non-IID data setting in federated learning, we propose comprehensive data partitioning strategies to cover the typical non-IID data cases. Moreover, we conduct extensive experiments to evaluate state-ofthe-art FL algorithms. We ﬁnd that non-IID does bring signiﬁcant challenges in learning accuracy of FL algorithms, and none of the existing state-of-the-art FL algorithms outperforms others in all cases. Our experiments provide insights for future studies of addressing the challenges in “data silos”.},
	language = {en},
	urldate = {2023-09-12},
	publisher = {arXiv},
	author = {Li, Qinbin and Diao, Yiqun and Chen, Quan and He, Bingsheng},
	month = oct,
	year = {2021},
	note = {arXiv:2102.02079 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
}

@article{beltran_decentralized_2022,
	title = {Decentralized {Federated} {Learning}: {Fundamentals}, {State} of the {Art}, {Frameworks}, {Trends}, and {Challenges}},
	copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
	shorttitle = {Decentralized {Federated} {Learning}},
	url = {https://arxiv.org/abs/2211.08413},
	doi = {10.48550/ARXIV.2211.08413},
	abstract = {In recent years, Federated Learning (FL) has gained relevance in training collaborative models without sharing sensitive data. Since its birth, Centralized FL (CFL) has been the most common approach in the literature, where a central entity creates a global model. However, a centralized approach leads to increased latency due to bottlenecks, heightened vulnerability to system failures, and trustworthiness concerns affecting the entity responsible for the global model creation. Decentralized Federated Learning (DFL) emerged to address these concerns by promoting decentralized model aggregation and minimizing reliance on centralized architectures. However, despite the work done in DFL, the literature has not (i) studied the main aspects differentiating DFL and CFL; (ii) analyzed DFL frameworks to create and evaluate new solutions; and (iii) reviewed application scenarios using DFL. Thus, this article identifies and analyzes the main fundamentals of DFL in terms of federation architectures, topologies, communication mechanisms, security approaches, and key performance indicators. Additionally, the paper at hand explores existing mechanisms to optimize critical DFL fundamentals. Then, the most relevant features of the current DFL frameworks are reviewed and compared. After that, it analyzes the most used DFL application scenarios, identifying solutions based on the fundamentals and frameworks previously defined. Finally, the evolution of existing DFL solutions is studied to provide a list of trends, lessons learned, and open challenges.},
	urldate = {2023-09-11},
	author = {Beltrán, Enrique Tomás Martínez and Pérez, Mario Quiles and Sánchez, Pedro Miguel Sánchez and Bernal, Sergio López and Bovet, Gérôme and Pérez, Manuel Gil and Pérez, Gregorio Martínez and Celdrán, Alberto Huertas},
	year = {2022},
	note = {Publisher: arXiv
Version Number: 4},
	keywords = {Cryptography and Security (cs.CR), Distributed, Parallel, and Cluster Computing (cs.DC), FOS: Computer and information sciences, Machine Learning (cs.LG), Networking and Internet Architecture (cs.NI)},
}

@article{pappas_ipls_2021,
	title = {{IPLS}: {A} {Framework} for {Decentralized} {Federated} {Learning}},
	shorttitle = {{IPLS}},
	url = {https://ieeexplore.ieee.org/document/9472790/},
	doi = {10.23919/IFIPNetworking52078.2021.9472790},
	abstract = {The proliferation of resourceful mobile devices that store rich, multidimensional and privacy-sensitive user data motivate federated learning, a paradigm that enables mobile devices to produce a machine-learning model without sharing their data. However, the majority of the existing federated frameworks follow a centralized approach. In this work, we introduce IPLS, a fully decentralized federated learning framework that is partially based on the interplanetary file system (IPFS). By using IPLS and connecting into the corresponding private IPFS network, any party can initiate the training process of a machine-learning model or join an ongoing training process that has been started by another party. IPLS scales with the number of participants, is robust against intermittent connectivity and dynamic participant departures/arrivals, requires minimal resources and guarantees that the accuracy of the trained model quickly converges to that of a centralized federated learning framework with a negligible accuracy drop of less than 1‰.},
	urldate = {2023-09-11},
	journal = {2021 IFIP Networking Conference (IFIP Networking)},
	author = {Pappas, Christodoulos and Chatzopoulos, Dimitris and Lalis, Spyros and Vavalis, Manolis},
	month = jun,
	year = {2021},
	note = {Conference Name: 2021 IFIP Networking Conference (IFIP Networking)
ISBN: 9783903176393
Place: Espoo and Helsinki, Finland
Publisher: IEEE},
	pages = {1--6},
}

@article{li_blockchain-based_2021,
	title = {A {Blockchain}-{Based} {Decentralized} {Federated} {Learning} {Framework} with {Committee} {Consensus}},
	volume = {35},
	issn = {0890-8044, 1558-156X},
	url = {https://ieeexplore.ieee.org/document/9293091/},
	doi = {10.1109/MNET.011.2000263},
	abstract = {Federated learning has been widely studied and applied to various scenarios, such as financial credit, medical identification, and so on. Under these settings, federated learning protects users from exposing their private data, while cooperatively training a shared machine learning algorithm model (i.e., the global model) for a variety of realworld applications. The only data exchanged is the gradient of the model or the updated model (i.e., the local model update). However, the security of federated learning is increasingly being questioned, due to the malicious clients or central servers' constant attack on the global model or user privacy data. To address these security issues, we propose a decentralized federated learning framework based on blockchain, that is, a Block-chain-based Federated Learning framework with Committee consensus (BFLC). Without a centralized server, the framework uses blockchain for the global model storage and the local model update exchange. To enable the proposed BFLC, we also devise an innovative committee consensus mechanism, which can effectively reduce the amount of consensus computing and reduce malicious attacks. We then discuss the scalability of BFLC, including theoretical security, storage optimization, and incentives. Finally, based on a FISCO blockchain system, we perform experiments using an AlexNet model on several frameworks with a real-world dataset FEMNIST. The experimental results demonstrate the effectiveness and security of the BFLC framework.},
	number = {1},
	urldate = {2023-09-11},
	journal = {IEEE Network},
	author = {Li, Yuzheng and Chen, Chuan and Liu, Nan and Huang, Huawei and Zheng, Zibin and Yan, Qiang},
	month = jan,
	year = {2021},
	pages = {234--241},
}

@article{bellet_d-cliques_2021,
	title = {D-{Cliques}: {Compensating} {NonIIDness} in {Decentralized} {Federated} {Learning} with {Topology}},
	shorttitle = {D-{Cliques}},
	url = {https://www.semanticscholar.org/paper/D-Cliques%3A-Compensating-NonIIDness-in-Decentralized-Bellet-Kermarrec/163f98375fdc9bc3faff00dee6b8143cbe25f880},
	abstract = {The convergence speed of machine learning models trained with Federated Learning is significantly affected by non-independent and identically distributed (non-IID) data partitions, even more so in a fully decentralized setting without a central server. In this paper, we show that the impact of local class bias, an important type of data non-IIDness, can be significantly reduced by carefully designing the underlying communication topology. We present D-Cliques, a novel topology that reduces gradient bias by grouping nodes in interconnected cliques such that the local joint distribution in a clique is representative of the global class distribution. We also show how to adapt the updates of decentralized SGD to obtain unbiased gradients and implement an effective momentum with D-Cliques. Our empirical evaluation on MNIST and CIFAR10 demonstrates that our approach provides similar convergence speed as a fully-connected topology with a significant reduction in the number of edges and messages. In a 1000-node topology, D-Cliques requires 98\% less edges and 96\% less total messages, with further possible gains using a small-world topology across cliques.},
	urldate = {2023-09-11},
	journal = {ArXiv},
	author = {Bellet, A. and Kermarrec, Anne-Marie and Lavoie, Erick},
	year = {2021},
	keywords = {⛔ No DOI found},
}

@inproceedings{lalitha_fully_2018,
	title = {Fully {Decentralized} {Federated} {Learning}},
	url = {https://www.semanticscholar.org/paper/Fully-Decentralized-Federated-Learning-Lalitha/2ecc7707aa49b7baa2f4bbc5d8491d0d464bdb9c},
	abstract = {We consider the problem of training a machine learning model over a network of users in a fully decentralized framework. The users take a Bayesian-like approach via the introduction of a belief over the model parameter space. We propose a distributed learning algorithm in which users update their belief by aggregate information from their one-hop neighbors to learn a model that best fits the observations over the entire network. In addition, we also obtain sufficient conditions to ensure that the probability of error is small for every user in the network. Finally, we discuss approximations required for applying this algorithm for training Neural Networks.},
	urldate = {2023-09-11},
	author = {Lalitha, Anusha},
	year = {2018},
	keywords = {⛔ No DOI found},
}

@article{hu_decentralized_2019,
	title = {Decentralized {Federated} {Learning}: {A} {Segmented} {Gossip} {Approach}},
	shorttitle = {Decentralized {Federated} {Learning}},
	url = {https://www.semanticscholar.org/paper/Decentralized-Federated-Learning%3A-A-Segmented-Hu-Jiang/df4fa94897ce02d2f394d8ae7304da639d3e7b5c},
	abstract = {The emerging concern about data privacy and security has motivated the proposal of federated learning, which allows nodes to only synchronize the locally-trained models instead their own original data. Conventional federated learning architecture, inherited from the parameter server design, relies on highly centralized topologies and the assumption of large nodes-to-server bandwidths. However, in real-world federated learning scenarios the network capacities between nodes are highly uniformly distributed and smaller than that in a datacenter. It is of great challenges for conventional federated learning approaches to efficiently utilize network capacities between nodes. In this paper, we propose a model segment level decentralized federated learning to tackle this problem. In particular, we propose a segmented gossip approach, which not only makes full utilization of node-to-node bandwidth, but also has good training convergence. The experimental results show that even the training time can be highly reduced as compared to centralized federated learning.},
	urldate = {2023-09-11},
	journal = {ArXiv},
	author = {Hu, Chenghao and Jiang, Jingyan and Wang, Zhi},
	month = aug,
	year = {2019},
	keywords = {⛔ No DOI found},
}

@article{lavaur_metrics_nodate,
	title = {Metrics and {Strategies} for {Adversarial} {Mitigation} in {Federated} {Learning}-based {Intrusion} {Detection}},
	abstract = {Since its introduction in 2016, federated learning (FL) has been used in multiple domains, such as intrusion detection. However, FL literature shows that the heterogeneity of most realworld FL applications makes it difficult for clients to converge in a suitable global model. Furthermore, as a collaborative system, FL is vulnerable to attacks, such as model poisoning. While strategies have been identified in the literature, they often rely on the assumption that the data distribution among participants is homogeneous. In this paper, we review the current challenges in clustering and adversarial mitigation in heterogeneous FL, and propose different strategies to address them. Namely, we present a cross-evaluation framework for exhaustive gathering, and a set of algorithmic countermeasures based on principal component analysis. We show preliminary results of our clustering mechanism, which validates the effectiveness of the cross-evaluation framework.},
	language = {en},
	author = {Lavaur, Léo and Busnel, Yann and Lechevalier, Pierre-Marie and Pahl, Marc-Oliver and Autrel, Fabien},
	keywords = {⛔ No DOI found},
}

@article{schoen_towards_nodate,
	title = {Towards generic quality assessment of synthetic traffic for evaluating intrusion detection systems},
	abstract = {Network Intrusion Detection Systems (NIDSes) evaluation requires background trafﬁc. However, real background trafﬁc is hard to collect. We hence rely on synthetic trafﬁc generated especially for this task. The quality of the generated trafﬁc has to be evaluated according to some clearly deﬁned criteria. In this paper, we show how to adapt the quality assessment solutions proposed for different ﬁelds of data generation such as image or text generation to network trafﬁc. We summarize our study by discussing the criteria that evaluate the quality of a generated network trafﬁc and by proposing functions to evaluate these criteria. This is the ﬁrst contribution in the context of the Ph.D. thesis of Adrien Schoen.},
	language = {en},
	author = {Schoen, Adrien and Blanc, Gregory and Gimenez, Pierre-François and Han, Yufei and Majorczyk, Frédéric and Mé, Ludovic},
	keywords = {⛔ No DOI found},
}

@incollection{koprinska_evaluation_2023,
	address = {Cham},
	title = {Evaluation of the {Limit} of {Detection} in {Network} {Dataset} {Quality} {Assessment} with {PerQoDA}},
	volume = {1753},
	isbn = {978-3-031-23632-7 978-3-031-23633-4},
	url = {https://link.springer.com/10.1007/978-3-031-23633-4_13},
	abstract = {Machine learning is recognised as a relevant approach to detect attacks and other anomalies in network traffic. However, there are still no suitable network datasets that would enable effective detection. On the other hand, the preparation of a network dataset is not easy due to privacy reasons but also due to the lack of tools for assessing their quality. In a previous paper, we proposed a new method for data quality assessment based on permutation testing. This paper presents a parallel study on the limits of detection of such an approach. We focus on the problem of network flow classification and use well-known machine learning techniques. The experiments were performed using publicly available network datasets.},
	language = {en},
	urldate = {2023-08-03},
	booktitle = {Machine {Learning} and {Principles} and {Practice} of {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer Nature Switzerland},
	author = {Wasielewska, Katarzyna and Soukup, Dominik and Čejka, Tomáš and Camacho, José},
	editor = {Koprinska, Irena and Mignone, Paolo and Guidotti, Riccardo and Jaroszewicz, Szymon and Fröning, Holger and Gullo, Francesco and Ferreira, Pedro M. and Roqueiro, Damian and Ceddia, Gaia and Nowaczyk, Slawomir and Gama, João and Ribeiro, Rita and Gavaldà, Ricard and Masciari, Elio and Ras, Zbigniew and Ritacco, Ettore and Naretto, Francesca and Theissler, Andreas and Biecek, Przemyslaw and Verbeke, Wouter and Schiele, Gregor and Pernkopf, Franz and Blott, Michaela and Bordino, Ilaria and Danesi, Ivan Luciano and Ponti, Giovanni and Severini, Lorenzo and Appice, Annalisa and Andresini, Giuseppina and Medeiros, Ibéria and Graça, Guilherme and Cooper, Lee and Ghazaleh, Naghmeh and Richiardi, Jonas and Saldana, Diego and Sechidis, Konstantinos and Canakoglu, Arif and Pido, Sara and Pinoli, Pietro and Bifet, Albert and Pashami, Sepideh},
	year = {2023},
	doi = {10.1007/978-3-031-23633-4_13},
	note = {Series Title: Communications in Computer and Information Science},
	pages = {170--185},
}

@article{magnani_enhancing_nodate,
	title = {Enhancing {Network} {Intrusion} {Detection}: {An} {Online} {Methodology} for {Performance} {Analysis}},
	abstract = {Machine learning models have been extensively proposed for classifying network ﬂows as benign or malicious, either in-network or at the endpoints of the infrastructure. Typically, the performance of such models is assessed by evaluating the trained model against a portion of the available dataset. However, in a production scenario, these models are fed by a monitoring stage that collects information from ﬂows and provides inputs to a ﬁltering stage that eventually blocks malicious trafﬁc. To the best of our knowledge, no work has analysed the entire pipeline, focusing on its performance in terms of both inputs (i.e., the information collected from each ﬂow) and outputs (i.e., the system’s ability to prevent an attack from reaching the application layer).},
	language = {en},
	author = {Magnani, Simone and Doriguzzi-Corin, Roberto and Siracusa, Domenico},
	keywords = {\_read\_urgently, ⛔ No DOI found},
}

@article{catillo_successful_2023,
	title = {Successful intrusion detection with a single deep autoencoder: theory and practice},
	issn = {1573-1367},
	shorttitle = {Successful intrusion detection with a single deep autoencoder},
	url = {https://doi.org/10.1007/s11219-023-09636-2},
	doi = {10.1007/s11219-023-09636-2},
	abstract = {Intrusion detection is a key topic in computer security. Due to the ever-increasing number of network attacks, several accurate anomaly-based techniques have been proposed for intrusion detection, wherein pattern recognition through machine learning techniques is typically used. Many proposals rely on the use of autoencoders, due to their capability to analyze complex, high-dimensional, and large-scale data. They capitalize on composite architectures and accurate learning approaches, possibly in combination with sophisticated feature selection techniques. However, due to their high complexity and lack of transferability of the impressive intrusion detection results, they are hardly ever used in production environments. This paper is developed around the intuition that complexity is not necessarily justified because a single autoencoder is enough to obtain similar, if not better, intrusion detection results compared to related proposals. The wide study presented here addresses the effect of the seed, a deep investigation on the training loss, and feature selection across the use of different hardware platforms. The best practices presented, regarding set-up and training, threshold setting, and possible use of feature selection techniques for performance improvement, can be valuable for any future work on the use of autoencoders for successful intrusion detection purposes.},
	language = {en},
	urldate = {2023-06-08},
	journal = {Software Quality Journal},
	author = {Catillo, Marta and Pecchia, Antonio and Villano, Umberto},
	month = may,
	year = {2023},
	keywords = {Autoencoders, Deep learning, Denial of service, Intrusion detection},
}

@misc{kundu_robustness_2022,
	title = {Robustness and {Personalization} in {Federated} {Learning}: {A} {Unified} {Approach} via {Regularization}},
	shorttitle = {Robustness and {Personalization} in {Federated} {Learning}},
	url = {http://arxiv.org/abs/2009.06303},
	doi = {10.48550/arXiv.2009.06303},
	abstract = {We present a class of methods for robust, personalized federated learning, called Fed+, that unifies many federated learning algorithms. The principal advantage of this class of methods is to better accommodate the real-world characteristics found in federated training, such as the lack of IID data across parties, the need for robustness to outliers or stragglers, and the requirement to perform well on party-specific datasets. We achieve this through a problem formulation that allows the central server to employ robust ways of aggregating the local models while keeping the structure of local computation intact. Without making any statistical assumption on the degree of heterogeneity of local data across parties, we provide convergence guarantees for Fed+ for convex and non-convex loss functions under different (robust) aggregation methods. The Fed+ theory is also equipped to handle heterogeneous computing environments including stragglers without additional assumptions; specifically, the convergence results cover the general setting where the number of local update steps across parties can vary. We demonstrate the benefits of Fed+ through extensive experiments across standard benchmark datasets.},
	urldate = {2023-05-16},
	publisher = {arXiv},
	author = {Kundu, Achintya and Yu, Pengqian and Wynter, Laura and Lim, Shiau Hong},
	month = jul,
	year = {2022},
	note = {arXiv:2009.06303 [cs, math, stat]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
}

@inproceedings{camacho_dataset_2022,
	title = {Dataset {Quality} {Assessment} in {Autonomous} {Networks} with {Permutation} {Testing}},
	doi = {10.1109/NOMS54207.2022.9789767},
	abstract = {The development of autonomous or self-driving networks is one of the main challenges faced by the telecommunication industry. Future networks are expected to realise a number of tasks, including network optimization and failure recovery, with minimal human supervision. In this context, the network community (manufacturers, operators, researchers, etc.) is looking at Machine Learning (ML) methods with high expectations. However, ML models can only be as good as the data they are trained on, which means that autonomous networks also require a sound autonomous procedure to assess, and if possible improve, data quality. Although the application of ML techniques in communication networks is ample in the literature, analyzing the quality of the network data seems an ignored problem. This paper presents work in progress on the application of permutation testing to assess the quality of network datasets. We illustrate our approach on a number of simple synthetic datasets with pre-established quality and then we demonstrate its application in a publicly available network dataset.},
	booktitle = {{NOMS} 2022-2022 {IEEE}/{IFIP} {Network} {Operations} and {Management} {Symposium}},
	author = {Camacho, José and Wasielewska, Katarzyna},
	month = apr,
	year = {2022},
	note = {ISSN: 2374-9709},
	keywords = {Communication networks, Communications technology, Data integrity, Data models, Industries, Machine learning, Quality assessment, anomaly detection, autonomous networks, classification, data quality assessment, network data, permutation testing, self-driving networks},
	pages = {1--4},
}

@article{wasielewska_evaluation_2022,
	title = {Evaluation of the {Limit} of {Detection} in {Network} {Dataset} {Quality} {Assessment} with {PerQoDA}},
	copyright = {Creative Commons Attribution-NonCommercial-NoDerivs 3.0 License},
	url = {https://digibug.ugr.es/handle/10481/81204},
	abstract = {Machine learning is recognised as a relevant approach to detect 
attacks and other anomalies in network traffic. However, there are 
still no suitable network datasets that would enable effective detection. 
On the other hand, the preparation of a network dataset is not easy due 
to privacy reasons but also due to the lack of tools for assessing their 
quality. In a previous paper, we proposed a new method for data quality 
assessment based on permutation testing. This paper presents a parallel 
study on the limits of detection of such an approach. We focus on the 
problem of network flow classification and use well-known machine learning 
techniques. The experiments were performed using publicly available 
network datasets.},
	language = {eng},
	urldate = {2023-05-15},
	author = {Wasielewska, Katarzyna and Soukup, Dominik and Cejka, Tomas and Camacho Páez, José},
	year = {2022},
	note = {Accepted: 2023-04-24T07:50:11Z
Publisher: European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML-PKDD 2022, 4th Workshop on Machine Learning for Cybersecurity (MLCS)},
	keywords = {⛔ No DOI found},
}

@incollection{jourdan_data-driven_2023,
	address = {Cham},
	title = {Data-{Driven} {Evaluation} of {Intrusion} {Detectors}: {A} {Methodological} {Framework}},
	volume = {13877},
	isbn = {978-3-031-30121-6 978-3-031-30122-3},
	shorttitle = {Data-{Driven} {Evaluation} of {Intrusion} {Detectors}},
	url = {https://link.springer.com/10.1007/978-3-031-30122-3_9},
	abstract = {Intrusion detection systems are an important domain in cybersecurity research. Countless solutions have been proposed, continuously improving upon one another. Yet, and despite the introduction of distinct approaches, including machine-learning methods, the evaluation methodology has barely evolved.},
	language = {en},
	urldate = {2023-05-12},
	booktitle = {Foundations and {Practice} of {Security}},
	publisher = {Springer Nature Switzerland},
	author = {Ayoubi, Solayman and Blanc, Gregory and Jmila, Houda and Silverston, Thomas and Tixeuil, Sébastien},
	editor = {Jourdan, Guy-Vincent and Mounier, Laurent and Adams, Carlisle and Sèdes, Florence and Garcia-Alfaro, Joaquin},
	year = {2023},
	doi = {10.1007/978-3-031-30122-3_9},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {\_read\_urgently},
	pages = {142--157},
}

@article{maseer_benchmarking_2021,
	title = {Benchmarking of {Machine} {Learning} for {Anomaly} {Based} {Intrusion} {Detection} {Systems} in the {CICIDS2017} {Dataset}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3056614},
	abstract = {An intrusion detection system (IDS) is an important protection instrument for detecting complex network attacks. Various machine learning (ML) or deep learning (DL) algorithms have been proposed for implementing anomaly-based IDS (AIDS). Our review of the AIDS literature identifies some issues in related work, including the randomness of the selected algorithms, parameters, and testing criteria, the application of old datasets, or shallow analyses and validation of the results. This paper comprehensively reviews previous studies on AIDS by using a set of criteria with different datasets and types of attacks to set benchmarking outcomes that can reveal the suitable AIDS algorithms, parameters, and testing criteria. Specifically, this paper applies 10 popular supervised and unsupervised ML algorithms for identifying effective and efficient ML-AIDS of networks and computers. These supervised ML algorithms include the artificial neural network (ANN), decision tree (DT), k-nearest neighbor (k-NN), naive Bayes (NB), random forest (RF), support vector machine (SVM), and convolutional neural network (CNN) algorithms, whereas the unsupervised ML algorithms include the expectation-maximization (EM), k-means, and self-organizing maps (SOM) algorithms. Several models of these algorithms are introduced, and the turning and training parameters of each algorithm are examined to achieve an optimal classifier evaluation. Unlike previous studies, this study evaluates the performance of AIDS by measuring the true positive and negative rates, accuracy, precision, recall, and F-Score of 31 ML-AIDS models. The training and testing time for ML-AIDS models are also considered in measuring their performance efficiency given that time complexity is an important factor in AIDSs. The ML-AIDS models are tested by using a recent and highly unbalanced multiclass CICIDS2017 dataset that involves real-world network attacks. In general, the k-NN-AIDS, DT-AIDS, and NB-AIDS models obtain the best results and show a greater capability in detecting web attacks compared with other models that demonstrate irregular and inferior results.},
	journal = {IEEE Access},
	author = {Maseer, Ziadoon Kamil and Yusof, Robiah and Bahaman, Nazrulazhar and Mostafa, Salama A. and Foozy, Cik Feresa Mohd},
	year = {2021},
	note = {Conference Name: IEEE Access},
	keywords = {Benchmark testing, Classification algorithms, Cyberattacks, Feature extraction, Radio frequency, Self-organizing feature maps, Support vector machines, Training, intrusion detection system, machine learning, supervised and unsupervised learning},
	pages = {22351--22370},
}

@article{hidayat_machine_2022,
	title = {Machine {Learning}-{Based} {Intrusion} {Detection} {System}: {An} {Experimental} {Comparison}},
	copyright = {Copyright (c) 2022 Authors},
	issn = {2810-9503},
	shorttitle = {Machine {Learning}-{Based} {Intrusion} {Detection} {System}},
	url = {https://ojs.bonviewpress.com/index.php/JCCE/article/view/270},
	doi = {10.47852/bonviewJCCE2202270},
	abstract = {Recently, networks are moving toward automation and getting more and more intelligent. With the advent of big data and cloud computing technologies, lots and lots of data are being produced on the internet. Every day, petabytes of data are produced from websites, social media sites, or the internet. As more and more data are produced, a continuous threat of network attacks is also growing. An intrusion detection system (IDS) is used to detect such types of attacks in the network. IDS inspects packet headers and data and decides whether the traffic is anomalous or normal based on the contents of the packet. In this research, ML techniques are being used for intrusion detection purposes. Feature selection is also used for efficient and optimal feature selection. The research proposes a hybrid feature selection technique composed of the Pearson correlation coefficient and random forest model. For the machine learning (ML) model, decision tree, AdaBoost, and K-nearest neighbor are trained and tested on the TON\_IoT dataset. The dataset is new and contains new and recent attack types and features. For deep learning (DL), multilayer perceptron (MLP) and long short-term memory are trained and tested. Evaluation is done on the basis of accuracy, precision, and recall. It is concluded from the results that the decision tree for ML and MLP for DL provides optimal accuracy with fewer false-positive and false-negative rates. It is also concluded from the results that the ML techniques are effective for detecting intrusion in the networks.},
	language = {en},
	urldate = {2023-05-11},
	journal = {Journal of Computational and Cognitive Engineering},
	author = {Hidayat, Imran and Ali, Muhammad Zulfiqar and Arshad, Arshad},
	month = jul,
	year = {2022},
	keywords = {machine learning},
}

@inproceedings{falcao_quantitative_2019,
	address = {New York, NY, USA},
	series = {{SAC} '19},
	title = {Quantitative comparison of unsupervised anomaly detection algorithms for intrusion detection},
	isbn = {978-1-4503-5933-7},
	url = {https://doi.org/10.1145/3297280.3297314},
	doi = {10.1145/3297280.3297314},
	abstract = {Anomaly detection algorithms aim at identifying unexpected fluctuations in the expected behavior of target indicators, and, when applied to intrusion detection, suspect attacks whenever the above deviations are observed. Through years, several of such algorithms have been proposed, evaluated experimentally, and analyzed in qualitative and quantitative surveys. However, the experimental comparison of a comprehensive set of algorithms for anomaly-based intrusion detection against a comprehensive set of attacks datasets and attack types was not investigated yet. To fill such gap, in this paper we experimentally evaluate a pool of twelve unsupervised anomaly detection algorithms on five attacks datasets. Results allow elaborating on a wide range of arguments, from the behavior of the individual algorithm to the suitability of the datasets to anomaly detection. We identify the families of algorithms that are more effective for intrusion detection, and the families that are more robust to the choice of configuration parameters. Further, we confirm experimentally that attacks with unstable and non-repeatable behavior are more difficult to detect, and that datasets where anomalies are rare events usually result in better detection scores.},
	urldate = {2023-05-11},
	booktitle = {Proceedings of the 34th {ACM}/{SIGAPP} {Symposium} on {Applied} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Falcão, Filipe and Zoppi, Tommaso and Silva, Caio Barbosa Viera and Santos, Anderson and Fonseca, Baldoino and Ceccarelli, Andrea and Bondavalli, Andrea},
	year = {2019},
	keywords = {anomaly detection, attack model, attacks datasets, comparison, intrusion detection, unsupervised algorithms},
	pages = {318--327},
}

@article{vu_network_nodate,
	title = {Network attacks detection across infrastructures using an auto-labeling method and network-based {Deep} {Inductive} {Transfer} {Learning} approach},
	url = {https://www.researchsquare.com/article/rs-2554201/v1},
	doi = {10.21203/rs.3.rs-2554201/v1},
	abstract = {An alarming number of cyber attacks have been witnessed in recent years, especially during COVID-19 epidemic. Many prevention measures have been proposed as a defense line for a network infrastructure, including Intrusion Detection System (IDS). A variance of IDS using Machine Learning and Deep Learning to detect network anomalies is gaining promising results. However, this approach also poses limitations regarding the indigenous dataset acquisition or the ability to apply a model learned from a benchmark dataset to different network infrastructures. Therefore, this paper proposes a reliable automatic labeling method for a new network dataset, and a Deep Transfer Learning model to detect both known and unknown attacks across different network infrastructures, then compares with other approaches.},
	language = {en},
	urldate = {2023-04-17},
	author = {Vu, Dinh-Minh and Nguyen, Gia Bach and Tran, Hoang Hai},
	keywords = {\_done, \_unpublished},
}

@article{belenguer_gowfed_2023,
	title = {G{öwFed}: {A} novel federated network intrusion detection system},
	issn = {1084-8045},
	shorttitle = {G{öwFed}},
	url = {https://www.sciencedirect.com/science/article/pii/S1084804523000723},
	doi = {10.1016/j.jnca.2023.103653},
	abstract = {Network intrusion detection systems are evolving into intelligent systems that perform data analysis while searching for anomalies in their environment. Indeed, the development of deep learning techniques paved the way to build more complex and effective threat detection models. However, training those models may be computationally infeasible in most Edge or IoT devices. Current approaches rely on powerful centralized servers that receive data from all their parties — violating basic privacy constraints and substantially affecting response times and operational costs due to the huge communication overheads. To mitigate these issues, Federated Learning emerged as a promising approach, where different agents collaboratively train a shared model, without exposing training data to others or requiring a compute-intensive centralized infrastructure. This work presents GöwFed, a novel network threat detection system that combines the usage of Gower Dissimilarity matrices and Federated averaging. Different approaches of GöwFed have been developed based on state-of the-art knowledge: (1) a vanilla version — achieving a median point of [0.888, 0.960] in the PR space and a median accuracy of 0.930; and (2) a version instrumented with an attention mechanism — achieving comparable results when 0.8 of the best performing nodes contribute to the model. Furthermore, each variant has been tested using simulation oriented tools provided by TensorFlow Federated framework. In the same way, a centralized analogous development of the Federated systems is carried out to explore their differences in terms of scalability and performance — the median point of the experiments is [0.987, 0.987]) and the median accuracy is 0.989. Overall, GöwFed intends to be the first stepping stone towards the combined usage of Federated Learning and Gower Dissimilarity matrices to detect network threats in industrial-level networks.},
	language = {en},
	urldate = {2023-05-02},
	journal = {Journal of Network and Computer Applications},
	author = {Belenguer, Aitor and Pascual, Jose A. and Navaridas, Javier},
	month = apr,
	year = {2023},
	keywords = {Federated Learning, Gower distance, Internet of Things, Intrusion Detection Systems},
	pages = {103653},
}

@inproceedings{popoola_federated_2021,
	title = {Federated {Deep} {Learning} for {Collaborative} {Intrusion} {Detection} in {Heterogeneous} {Networks}},
	doi = {10.1109/VTC2021-Fall52928.2021.9625505},
	abstract = {In this paper, we propose Federated Deep Learning (FDL) for intrusion detection in heterogeneous networks. Local Deep Neural Network (DNN) models are used to learn the hierarchical representations of the private network traffic data in multiple edge nodes. A dedicated central server receives the parameters of the local DNN models from the edge nodes, and it aggregates them to produce an FDL model using the Fed+ fusion algorithm. Simulation results show that the FDL model achieved an accuracy of 99.27 ± 0.79\%, a precision of 97.03 ± 4.22\%, a recall of 98.06 ± 1.72\%, an F1 score of 97.50 ± 2.55\%, and a False Positive Rate (FPR) of 2.40 ± 2.47\%. The classification performance and the generalisation ability of the FDL model are better than those of the local DNN models. The Fed+ algorithm outperformed two state-of-the-art fusion algorithms, namely federated averaging (FedAvg) and Coordinate Median (CM). Therefore, the DNN-Fed+ model is preferable for intrusion detection in heterogeneous wireless networks.},
	booktitle = {2021 {IEEE} 94th {Vehicular} {Technology} {Conference} ({VTC2021}-{Fall})},
	author = {Popoola, Segun I. and Gui, Guan and Adebisi, Bamidele and Hammoudeh, Mohammad and Gacanin, Haris},
	month = sep,
	year = {2021},
	note = {ISSN: 2577-2465},
	keywords = {Deep learning, Heterogeneous networks, Image edge detection, Intrusion detection, Simulation, Telecommunication traffic, Wireless networks, deep learning, federated learning, heterogeneous wireless networks, intrusion detection, smart city},
	pages = {1--6},
}

@article{de_carvalho_bertoli_generalizing_2023,
	title = {Generalizing intrusion detection for heterogeneous networks: {A} stacked-unsupervised federated learning approach},
	volume = {127},
	issn = {0167-4048},
	shorttitle = {Generalizing intrusion detection for heterogeneous networks},
	url = {https://www.sciencedirect.com/science/article/pii/S0167404823000160},
	doi = {10.1016/j.cose.2023.103106},
	abstract = {The constantly evolving digital transformation imposes new requirements on our society. Aspects relating to reliance on the networking domain and the difficulty of achieving security by design pose a challenge today. As a result, data-centric and machine-learning approaches arose as feasible solutions for securing large networks. Although, in the network security domain, ML-based solutions face a challenge regarding the capability to generalize between different contexts. In other words, solutions based on specific network data usually do not perform satisfactorily on other networks. This paper describes the stacked-unsupervised federated learning (FL) approach to generalize on a cross-silo configuration for a flow-based network intrusion detection system (NIDS). The proposed approach we have examined comprises a deep autoencoder in conjunction with an energy flow classifier in an ensemble learning task. Our approach performs better than traditional local learning and naive cross-evaluation (training in one context and testing on another network data). Remarkably, the proposed approach demonstrates a sound performance in the case of non-IID data silos. In conjunction with an informative feature in an ensemble architecture for unsupervised learning, we advise that the proposed FL-based NIDS results in a feasible approach for generalization between heterogeneous networks.},
	language = {en},
	urldate = {2023-03-14},
	journal = {Computers \& Security},
	author = {de Carvalho Bertoli, Gustavo and Alves Pereira Junior, Lourenço and Saotome, Osamu and dos Santos, Aldri Luiz},
	month = apr,
	year = {2023},
	keywords = {Federated learning, Generalization, Network flows, Network intrusion detection, Unsupervised learning},
	pages = {103106},
}

@misc{mo_ppfl_2021,
	title = {{PPFL}: {Privacy}-preserving {Federated} {Learning} with {Trusted} {Execution} {Environments}},
	shorttitle = {{PPFL}},
	url = {http://arxiv.org/abs/2104.14380},
	abstract = {We propose and implement a Privacy-preserving Federated Learning (𝑃𝑃𝐹 𝐿) framework for mobile systems to limit privacy leakages in federated learning. Leveraging the widespread presence of Trusted Execution Environments (TEEs) in high-end and mobile devices, we utilize TEEs on clients for local training, and on servers for secure aggregation, so that model/gradient updates are hidden from adversaries. Challenged by the limited memory size of current TEEs, we leverage greedy layer-wise training to train each model’s layer inside the trusted area until its convergence. The performance evaluation of our implementation shows that 𝑃𝑃𝐹 𝐿 can significantly improve privacy while incurring small system overheads at the client-side. In particular, 𝑃𝑃𝐹 𝐿 can successfully defend the trained model against data reconstruction, property inference, and membership inference attacks. Furthermore, it can achieve comparable model utility with fewer communication rounds (0.54×) and a similar amount of network traffic (1.002×) compared to the standard federated learning of a complete model. This is achieved while only introducing up to ∼15\% CPU time, ∼18\% memory usage, and ∼21\% energy consumption overhead in 𝑃𝑃𝐹 𝐿’s client-side.},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Mo, Fan and Haddadi, Hamed and Katevas, Kleomenis and Marin, Eduard and Perino, Diego and Kourtellis, Nicolas},
	month = jun,
	year = {2021},
	note = {arXiv:2104.14380 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
}

@article{chen_training-integrity_2020,
	title = {A training-integrity privacy-preserving federated learning scheme with trusted execution environment},
	volume = {522},
	issn = {00200255},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025520301201},
	doi = {10.1016/j.ins.2020.02.037},
	language = {en},
	urldate = {2023-04-03},
	journal = {Information Sciences},
	author = {Chen, Yu and Luo, Fang and Li, Tong and Xiang, Tao and Liu, Zheli and Li, Jin},
	month = jun,
	year = {2020},
	pages = {69--79},
}

@inproceedings{zhang_shufflefl_2021,
	address = {Virtual Event Italy},
	title = {{ShuffleFL}: gradient-preserving federated learning using trusted execution environment},
	isbn = {978-1-4503-8404-9},
	shorttitle = {{ShuffleFL}},
	url = {https://dl.acm.org/doi/10.1145/3457388.3458665},
	doi = {10.1145/3457388.3458665},
	abstract = {Federated Learning (FL) is a promising approach to privacy-preserving machine learning. However, recent works reveal that gradients can leak private data. Using trusted SGX-processors for this task yields gradient-preserving but requires to prevent exploitation of any side-channel attacks.},
	language = {en},
	urldate = {2023-04-03},
	booktitle = {Proceedings of the 18th {ACM} {International} {Conference} on {Computing} {Frontiers}},
	publisher = {ACM},
	author = {Zhang, Yuhui and Wang, Zhiwei and Cao, Jiangfeng and Hou, Rui and Meng, Dan},
	month = may,
	year = {2021},
	pages = {161--168},
}

@misc{mondal_flatee_2021,
	title = {Flatee: {Federated} {Learning} {Across} {Trusted} {Execution} {Environments}},
	shorttitle = {Flatee},
	url = {http://arxiv.org/abs/2111.06867},
	abstract = {Federated learning allows us to distributively train a machine learning model where multiple parties share local model parameters without sharing private data. However, parameter exchange may still leak information. Several approaches have been proposed to overcome this, based on multi-party computation, fully homomorphic encryption, etc.; many of these protocols are slow and impractical for real-world use as they involve a large number of cryptographic operations. In this paper, we propose the use of Trusted Execution Environments (TEE), which provide a platform for isolated execution of code and handling of data, for this purpose. We describe Flatee, an eﬃcient privacy-preserving federated learning framework across TEEs, which considerably reduces training and communication time. Our framework can handle malicious parties (we do not natively solve adversarial data poisoning, though we describe a preliminary approach to handle this).},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Mondal, Arup and More, Yash and Rooparaghunath, Ruthu Hulikal and Gupta, Debayan},
	month = nov,
	year = {2021},
	note = {arXiv:2111.06867 [cs]},
	keywords = {Computer Science - Cryptography and Security},
}

@misc{layeghy_generalisability_2022,
	title = {On {Generalisability} of {Machine} {Learning}-based {Network} {Intrusion} {Detection} {Systems}},
	url = {http://arxiv.org/abs/2205.04112},
	abstract = {Many of the proposed machine learning (ML) based network intrusion detection systems (NIDSs) achieve near perfect detection performance when evaluated on synthetic benchmark datasets. Though, there is no record of if and how these results generalise to other network scenarios, in particular to real-world networks. In this paper, we investigate the generalisability property of ML-based NIDSs by extensively evaluating seven supervised and unsupervised learning models on four recently published benchmark NIDS datasets. Our investigation indicates that none of the considered models is able to generalise over all studied datasets. Interestingly, our results also indicate that the generalisability has a high degree of asymmetry, i.e., swapping the source and target domains can signiﬁcantly change the classiﬁcation performance. Our investigation also indicates that overall, unsupervised learning methods generalise better than supervised learning models in our considered scenarios. Using SHAP values to explain these results indicates that the lack of generalisability is mainly due to the presence of strong correspondence between the values of one or more features and Attack/Benign classes in one datasetmodel combination and its absence in other datasets that have different feature distributions.},
	language = {en},
	urldate = {2023-03-23},
	publisher = {arXiv},
	author = {Layeghy, Siamak and Portmann, Marius},
	month = may,
	year = {2022},
	note = {arXiv:2205.04112 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Networking and Internet Architecture},
}

@article{almanifi_communication_2023,
	title = {Communication and computation efficiency in {Federated} {Learning}: {A} survey},
	issn = {2542-6605},
	shorttitle = {Communication and computation efficiency in {Federated} {Learning}},
	url = {https://www.sciencedirect.com/science/article/pii/S2542660523000653},
	doi = {10.1016/j.iot.2023.100742},
	abstract = {Federated Learning is a much-needed technology in this golden era of big data and Artificial Intelligence, due to its vital role in preserving data privacy, and eliminating the need to transfer and process huge amounts of data, while maintaining the numerous benefits of Machine Learning. As opposed to the typical central training process, Federated Learning involves the collaborative training of statistical models by exchanging learned parameter updates. However, wide adoption of the technology is hindered by the communication and computation overhead forming due to the demanding computational cost of training, and the large-sized parameter updates exchanged. In popular applications such as those involving Internet of Things, the effects of the overhead are exacerbated due to the low computational prowess of edge and fog devices, limited bandwidth, and data capacity of internet connections. Over the years, many research activities that target this particular issue were conducted but a comprehensive review of the fragmented literature is still missing. This paper aims at filling this gap by providing a systematic review of recent work conducted to improve the communication and/or computation efficiency in Federated Learning. We begin by introducing the essentials of Federated Learning and its variations, followed by the literature review placed according to an encompassing, easy-to-follow taxonomy. Lastly, the work sheds light on the current challenges faced by the technology and possible directions for future work.},
	language = {en},
	urldate = {2023-03-09},
	journal = {Internet of Things},
	author = {Almanifi, Omair Rashed Abdulwareth and Chow, Chee-Onn and Tham, Mau-Luen and Chuah, Joon Huang and Kanesan, Jeevan},
	month = mar,
	year = {2023},
	keywords = {Communication efficiency, Computation efficiency, Federated Learning, Internet of Things, Machine learning},
	pages = {100742},
}

@article{aissaoui_surveying_nodate,
	title = {Surveying cryptographic methods for {UAV} communications},
	volume = {7},
	abstract = {This article presents our survey work on Unmanned Aerial Vehicle (UAV) communication security for UAV Traffic Management (UTM) safety [1]. A majority of UAV missions require flying through public airspace. Airspace management is a sector with very high safety standards, as can be seen with commercial civil aviation. Reliable communication links between aircraft, their pilots and UTM systems are necessary to safely carry out these missions. Several security properties have to be provided in order to ensure a safe traffic. Current cryptographic standards used over the internet are not suitable to Unmanned Aerial System (UAS), mainly due to their computational complexity. The survey discusses every communication link and assesses the security needs in order to enable a safe traffic management. We then present and discuss several research works providing the required properties using cryptographic primitives. In particular, authenticated key exchange protocols specifically developed for constrained systems are compared and evaluated as solutions for UAS security. We also discuss symmetric encryption alternatives to the AES algorithm as well as works to secure current UTM protocols such as ADS-B and RemoteID. The analysis reveals a lack of signature solutions, the need for the development of a complete secure architecture able to provide authentication and integrity and a need for post-quantum lightweight solutions. We then present our current work which focuses on implementing a post-quantum signature standard to evaluate its pertinence for UAS.},
	language = {en},
	number = {7},
	author = {Aissaoui, Ridwane},
	keywords = {\_done, \_unpublished},
	pages = {85},
}

@article{milenkoski_evaluating_2015,
	title = {Evaluating {Computer} {Intrusion} {Detection} {Systems}: {A} {Survey} of {Common} {Practices}},
	volume = {48},
	issn = {0360-0300},
	shorttitle = {Evaluating {Computer} {Intrusion} {Detection} {Systems}},
	url = {https://doi.org/10.1145/2808691},
	doi = {10.1145/2808691},
	abstract = {The evaluation of computer intrusion detection systems (which we refer to as intrusion detection systems) is an active research area. In this article, we survey and systematize common practices in the area of evaluation of such systems. For this purpose, we define a design space structured into three parts: workload, metrics, and measurement methodology. We then provide an overview of the common practices in evaluation of intrusion detection systems by surveying evaluation approaches and methods related to each part of the design space. Finally, we discuss open issues and challenges focusing on evaluation methodologies for novel intrusion detection systems.},
	number = {1},
	urldate = {2023-03-04},
	journal = {ACM Computing Surveys},
	author = {Milenkoski, Aleksandar and Vieira, Marco and Kounev, Samuel and Avritzer, Alberto and Payne, Bryan D.},
	month = sep,
	year = {2015},
	keywords = {Computer intrusion detection systems, measurement methodology, metrics, workload generation},
	pages = {12:1--12:41},
}

@article{durbet_observations_nodate,
	title = {Some {Observations} on {Fuzzy} {Vault} {Based} {Biometric} {Protocols}},
	volume = {86},
	language = {en},
	number = {11},
	author = {DURBET, Axel},
	keywords = {\_done, \_unpublished},
}

@article{he_reinforcement_nodate,
	title = {Reinforcement learning meets network intrusion detection: a transferable and adaptable framework for anomaly behavior identification},
	abstract = {Anomaly detection plays an important role in network security and traffic classification. Many works have focused on anomaly detection to improve network security, including traditional machine learning (ML) methods and deep learning (DL) methods. In the process of training models, these methods often require a large number of samples and need to get the results by classifying the whole dataset, which lead to their inflexibility. Meanwhile, the model trained on one dataset cannot be transferable to another dataset. These problems limit the application of previous methods in the network security management. To address these challenges, we consider using deep reinforcement learning (DRL) for anomaly detection, and propose a transferable and adaptable network intrusion detection system (TA-NIDS) based on DRL. The interaction process between the agent and the environment is different every time. A small scale dataset can also produce a large number of interactive processes. Therefore, few-shot learning is feasible. Then, a reasonable reward function can let the agent learn to choose outliers first without classifying the whole dataset. The real-time changing environment in reinforcement learning (RL) is also closer to the real environment. These make TA-NIDS more adaptable for the actual scene. More importantly, the original feature is transformed into many state, so there is no requirement for the feature dimension. And the general rather than specific state of one dataset makes the model transferable to other datasets. Experiments on IDS2017, IDS2018, NSL-KDD and UNSW-NB15 show that the framework which gives priority to selecting outliers can realize few-shot learning, has high accuracy, good transferability, and it is adaptable to the actual scene.},
	journal = {IEEE Transactions on Network and Service Management},
	author = {He, Mingshu and Wang, Xiaojuan and Wei, Peng and Jin, Lei and Yang, Liu and Li, Ziyang},
	keywords = {\_done, \_unpublished},
}

@article{ayoubi_evaluation_nodate,
	title = {Evaluation {Framework} for {ML}-based {IDS}},
	abstract = {Intrusion detection is an important topic in cybersecurity research, but the evaluation methodology has remained stagnant despite advancements including the use of machine learning. In this paper, we design a comprehensive evaluation framework for Machine Learning (ML)-based IDS and take into account the unique aspects of ML algorithms, their strengths, and weaknesses. The framework design is inspired by both i) traditional IDS evaluation methods and ii) recommendations for evaluating ML algorithms in diverse application areas. Data quality being the key to machine learning, we focus on datadriven evaluation by exploring data-related issues.},
	language = {en},
	author = {Ayoubi, Solayman and Blanc, Gregory and Jmila, Houda and Silverston, Thomas and Tixeuil, Sebastien},
	keywords = {\_done, \_unpublished, ⛔ No DOI found},
}

@article{michel_metrics_nodate,
	title = {Metrics for community dynamics applied to unsupervised attacks detection},
	abstract = {Attack detection in big networks has become a necessity. Yet, with the ever changing threat landscape and massive amount of data to handle, network intrusion detection systems (NIDS) end up being obsolete. Different machine-learning-based solutions have been developed to answer the detection problem for data with evolving statistical distributions. However, no approach has proved to be both scalable and robust to passing time. In this paper, we propose a scalable and unsupervised approach to detect behavioral patterns without prior knowledge on the nature of attacks. For this purpose, we define novel metrics for graph community dynamics and use them as feature with unsupervised detection algorithm on the UGR’16 dataset. The proposed approach improves existing detection algorithms by 285,56\% in precision and 222,82\% in recall when compared to usual feature extraction (FE) using isolation forest.},
	language = {en},
	author = {Michel, Julien and Parrend, Pierre},
	keywords = {\_done, \_unpublished, ⛔ No DOI found},
}

@article{minh_explainable-by-design_nodate,
	title = {An explainable-by-design ensemble learning system to detect unknown network attacks},
	abstract = {Machine learning is a promising technology for network intrusion detection systems. There is a wide variety of machine learning algorithms whose results seem complementary, but determining which result is true is difficult because models lack explainability. Our system intends to reconstruct attack patterns from a set of unsupervised learning models’ outputs, and show them to security analysts. Therefore, we introduce an explainable-by-design system to detect network attacks, and evaluated its accuracy on the CSE-CIC-IDS2018 dataset [1].},
	language = {en},
	author = {Minh, Celine and Vermeulen, Kevin and Lefebvre, Cedric and Owezarski, Philippe and Ritchie, William},
	keywords = {\_done, \_unpublished, ⛔ No DOI found},
}

@article{soule_lorganisation_nodate,
	title = {De l’{Organisation} des {Systèmes} {Multi}-{Agents} de {Cyber}-defense},
	language = {fr},
	author = {Soulé, Julien and Théron, Paul and Jamont, Jean-Paul and Occello, Michel and Traonouez, Louis-Marie},
	keywords = {\_done, \_unpublished, ⛔ No DOI found},
}

@inproceedings{roy_chowdhury_eiffel_2022,
	address = {New York, NY, USA},
	series = {{CCS} '22},
	title = {{EIFFeL}: {Ensuring} {Integrity} for {Federated} {Learning}},
	isbn = {978-1-4503-9450-5},
	shorttitle = {{EIFFeL}},
	url = {https://doi.org/10.1145/3548606.3560611},
	doi = {10.1145/3548606.3560611},
	abstract = {Federated learning (FL) enables clients to collaborate with a server to train a machine learning model. To ensure privacy, the server performs secure aggregation of updates from the clients. Unfortunately, this prevents verification of the well-formedness (integrity) of the updates as the updates are masked. Consequently, malformed updates designed to poison the model can be injected without detection. In this paper, we formalize the problem of ensuring both update privacy and integrity in FL and present a new system, EIFFeL, that enables secure aggregation of verified updates. EIFFeL is a general framework that can enforce arbitrary integrity checks and remove malformed updates from the aggregate, without violating privacy. Our empirical evaluation demonstrates the practicality of EIFFeL. For instance, with 100 clients and 10\% poisoning, EIFFeL can train an MNIST classification model to the same accuracy as that of a non-poisoned federated learner in just 2.4s per iteration.},
	urldate = {2023-02-08},
	booktitle = {Proceedings of the 2022 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {Association for Computing Machinery},
	author = {Roy Chowdhury, Amrita and Guo, Chuan and Jha, Somesh and van der Maaten, Laurens},
	month = nov,
	year = {2022},
	keywords = {input integrity, poisoning attacks, secure aggregation},
	pages = {2535--2549},
}

@inproceedings{medina_brite_2001,
	title = {{BRITE}: an approach to universal topology generation},
	shorttitle = {{BRITE}},
	doi = {10.1109/MASCOT.2001.948886},
	abstract = {Effective engineering of the Internet is predicated upon a detailed understanding of issues such as the large-scale structure of its underlying physical topology, the manner in which it evolves over time, and the way in which its constituent components contribute to its overall function. Unfortunately, developing a deep understanding of these issues has proven to be a challenging task, since it in turn involves solving difficult problems such as mapping the actual topology, characterizing it, and developing models that capture its emergent behavior. Consequently, even though there are a number of topology models, it is an open question as to how representative the generated topologies they generate are of the actual Internet. Our goal is to produce a topology generation framework which improves the state of the art and is based on the design principles of representativeness, inclusiveness, and interoperability. Representativeness leads to synthetic topologies that accurately reflect many aspects of the actual Internet topology (e.g. hierarchical structure, node degree distribution, etc.). Inclusiveness combines the strengths of as many generation models as possible in a single generation tool. Interoperability provides interfaces to widely-used simulation applications such as ns and SSF and visualization tools like otter. We call such a tool a universal topology generator.},
	booktitle = {{MASCOTS} 2001, {Proceedings} {Ninth} {International} {Symposium} on {Modeling}, {Analysis} and {Simulation} of {Computer} and {Telecommunication} {Systems}},
	author = {Medina, A. and Lakhina, A. and Matta, I. and Byers, J.},
	month = aug,
	year = {2001},
	note = {ISSN: 1526-7639},
	keywords = {Bandwidth, Character generation, Computer science, Engineering profession, IP networks, Internet, Large-scale systems, Network topology, Protocols, Visualization},
	pages = {346--353},
}

@article{medina_origin_2000,
	title = {On the origin of power laws in {Internet} topologies},
	volume = {30},
	issn = {0146-4833},
	url = {https://doi.org/10.1145/505680.505683},
	doi = {10.1145/505680.505683},
	abstract = {Recent empirical studies [6] have shown that Internet topologies exhibit power laws of the form y = x α for the following relationships: (P1) outdegree of node (domain or router) versus rank; (P2) number of nodes versus outdegree; (P3) number of node pairs within a neighborhood versus neighborhood size (in hops); and (P4) eigenvalues of the adjacency matrix versus rank. However, causes for the appearance of such power laws have not been convincingly given. In this paper, we examine four factors in the formation of Internet topologies. These factors are (F1) preferential connectivity of a new node to existing nodes; (F2) incremental growth of the network; (F3) distribution of nodes in space; and (F4) locality of edge connections. In synthetically generated network topologies, we study the relevance of each factor in causing the aforementioned power laws as well as other properties, namely diameter, average path length and clustering coefficient. Different kinds of network topologies are generated: (T1) topologies generated using our parametrized generator, we call BRITE; (T2) random topologies generated using the well-known Waxman model [12]; (T3) Transit-Stub topologies generated using GT-ITM tool [3]; and (T4) regular grid topologies. We observe that some generated topologies may not obey power laws P1 and P2. Thus, the existence of these power laws can be used to validate the accuracy of a given tool in generating representative Internet topologies. Power laws P3 and P4 were observed in nearly all considered topologies, but different topologies showed different values of the power exponent α. Thus, while the presence of power laws P3 and P4 do not give strong evidence for the representativeness of a generated topology, the value of α in P3 and P4 can be used as a litmus test for the representativeness of a generated topology. We also find that factors F1 and F2 are the key contributors in our study which provide the resemblance of our generated topologies to that of the Internet.},
	number = {2},
	urldate = {2023-02-08},
	journal = {ACM SIGCOMM Computer Communication Review},
	author = {Medina, Alberto and Matta, Ibrahim and Byers, John},
	year = {2000},
	pages = {18--28},
}

@inproceedings{guilloteau_painless_2022,
	title = {Painless {Transposition} of {Reproducible} {Distributed} {Environments} with {NixOS} {Compose}},
	volume = {CLUSTER 2022 - IEEE International Conference on Cluster Computing},
	url = {https://hal.science/hal-03723771},
	abstract = {Development of environments for distributed systems is a tedious and time-consuming iterative process. The reproducibility of such environments is a crucial factor for rigorous scientific contributions. We think that being able to smoothly test environments both locally and on a target distributed platform makes development cycles faster and reduces the friction to adopt better experimental practices. To address this issue, this paper introduces the notion of environment transposition and implements it in NixOS Compose, a tool that generates reproducible distributed environments. It enables users to deploy their environments on virtualized (docker, QEMU) or physical (Grid'5000) platforms with the same unique description of the environment. We show that NixOS Compose enables to build reproducible environments without overhead by comparing it to state-of-the-art solutions for the generation of distributed environments (EnOSlib and Kameleon). NixOS Compose actually enables substantial performance improvements on image building time over Kameleon (up to 11x faster for initial builds and up to 19x faster when building a variation of an existing environment).},
	language = {en},
	urldate = {2023-01-17},
	author = {Guilloteau, Quentin and Bleuzen, Jonathan and Poquet, Millian and Richard, Olivier},
	month = sep,
	year = {2022},
	keywords = {\_read\_urgently},
	pages = {1},
}

@article{rashme_international_nodate,
	title = {International {Journal} of {Image}, {Graphics} and {Signal} {Processing}({IJIGSP})},
	volume = {10},
	url = {https://www.mecs-press.org/ijigsp/ijigsp-v10-n10/v10n10-7.html},
	language = {en},
	number = {10},
	urldate = {2023-01-25},
	journal = {International Journal of Image, Graphics and Signal Processing(IJIGSP)},
	author = {Rashme, Tamanna Yesmin and Uddin, Mohammed Nasir},
	keywords = {⛔ No DOI found},
	pages = {63},
}

@article{xiao_time-sensitive_2023,
	title = {Time-sensitive {Learning} for {Heterogeneous} {Federated} {Edge} {Intelligence}},
	issn = {1558-0660},
	doi = {10.1109/TMC.2023.3237374},
	abstract = {Real-time machine learning (ML) has recently attracted significant interest due to its potential to support instantaneous learning, adaptation, and decision making in a wide range of application domains, including self-driving vehicles, intelligent transportation, and industry automation. In this paper, we investigate real-time ML in a federated edge intelligence (FEI) system, an edge computing system that implements federated learning (FL) solutions based on data samples collected and uploaded from decentralized data networks, e.g., Internet-of-Things (IoT) and/or wireless sensor networks. FEI systems often exhibit heterogenous communication and computational resource distribution, as well as non-i.i.d. data samples arrived at different edge servers, resulting in long model training time and inefficient resource utilization. Motivated by this fact, we propose a time-sensitive federated learning (TS-FL) framework to minimize the overall run-time for collaboratively training a shared ML model with desirable accuracy. Training acceleration solutions for both TS-FL with synchronous coordination (TS-FL-SC) and asynchronous coordination (TS-FL-ASC) are investigated. To address the straggler effect in TS-FL-SC, we develop an analytical solution to characterize the impact of selecting different subsets of edge servers on the overall model training time. A server dropping-based solution is proposed to allow some slow-performance edge servers to be removed from participating in the model training if their impact on the resulting model accuracy is limited. A joint optimization algorithm is proposed to minimize the overall time consumption of model training by selecting participating edge servers, the local epoch number (the number of model training iterations per coordination), and the data batch size (the number of data samples for each model training iteration). Motivated by the fact that data samples at the slowest edge server may exhibit special characteristics that cannot be removed from model training, we develop an analytical expression to characterize the impact of both staleness effect of asynchronous coordination and straggler effect of FL on the time consumption of TS-FL-ASC. We propose a load forwarding-based solution that allows a slow edge server to offload part of its training samples to trusted edge servers with higher processing capability. We develop a hardware prototype to evaluate the model training time of a heterogeneous FEI system. Experimental results show that our proposed TS-FL-SC and TS-FL-ASC can provide up to 63\% and 28\% of reduction, in the overall model training time, respectively, compared with traditional FL solutions.},
	journal = {IEEE Transactions on Mobile Computing},
	author = {Xiao, Yong and Zhang, Xiaohan and Li, Yingyu and Shi, Guangming and Krunz, Marwan and Nguyen, Diep N. and Hoang, Dinh Thai},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Mobile Computing},
	keywords = {Analytical models, Computational modeling, Data models, Predictive models, Runtime, Servers, Time-sensitive machine learning, Training, asynchronous coordination, edge intelligence, federated learning},
	pages = {1--18},
}

@inproceedings{thai_adversarial_2022,
	title = {Adversarial {AutoEncoder} and {Generative} {Adversarial} {Networks} for {Semi}-{Supervised} {Learning} {Intrusion} {Detection} {System}},
	doi = {10.1109/RIVF55975.2022.10013926},
	abstract = {As one of the defensive solutions against cyberattacks, an Intrusion Detection System (IDS) plays an important role in observing the network state and alerting suspicious actions that can break down the system. There are many attempts of adopting Machine Learning (ML) in IDS to achieve high performance in intrusion detection. However, all of them necessitate a large amount of labeled data. In addition, labeling attack data is a time-consuming and expensive human-labor operation, it makes existing ML methods difficult to deploy in a new system or yields lower results due to a lack of labels on pre-trained data. To address these issues, we propose a semi-supervised IDS model that leverages Generative Adversarial Networks (GANs) and Adversarial AutoEncoder (AAE), called a semi-supervised adversarial autoencoder (SAAE). Our SAAE experimental results on two public datasets for benchmarking ML-based IDS, including NF-CSE-CIC-IDS2018 and NF-UNSW-NB15, demonstrate the effectiveness of AAE and GAN in case of using only a small number of labeled data. In particular, our approach outperforms other ML methods with the highest detection rates in spite of the scarcity of labeled data for model training, even with only 1\% labeled data.},
	booktitle = {2022 {RIVF} {International} {Conference} on {Computing} and {Communication} {Technologies} ({RIVF})},
	author = {Thai, Ho Huy and Hieu, Nguyen Duc and Van Tho, Nguyen and Hoang, Hien Do and Duy, Phan The and Pham, Van-Hau},
	month = dec,
	year = {2022},
	note = {ISSN: 2162-786X},
	keywords = {Adversarial Auto Encoder, Benchmark testing, Data models, Generative Adversarial Networks, Generative adversarial networks, Intrusion Detection, Intrusion detection, Network architecture, Semi-supervised Learning, Semisupervised learning, Training},
	pages = {584--589},
}

@article{singh_fair_2023,
	title = {Fair detection of poisoning attacks in federated learning on non-i.i.d. data},
	issn = {1573-756X},
	url = {https://doi.org/10.1007/s10618-022-00912-6},
	doi = {10.1007/s10618-022-00912-6},
	abstract = {Reconciling machine learning with individual privacy is one of the main motivations behind federated learning (FL), a decentralized machine learning technique that aggregates partial models trained by clients on their own private data to obtain a global deep learning model. Even if FL provides stronger privacy guarantees to the participating clients than centralized learning collecting the clients’ data in a central server, FL is vulnerable to some attacks whereby malicious clients submit bad updates in order to prevent the model from converging or, more subtly, to introduce artificial bias in the classification (poisoning). Poisoning detection techniques compute statistics on the updates to identify malicious clients. A downside of anti-poisoning techniques is that they might lead to discriminate minority groups whose data are significantly and legitimately different from those of the majority of clients. This would not only be unfair, but would yield poorer models that would fail to capture the knowledge in the training data, especially when data are not independent and identically distributed (non-i.i.d.). In this work, we strive to strike a balance between fighting poisoning and accommodating diversity to help learning fairer and less discriminatory federated learning models. In this way, we forestall the exclusion of diverse clients while still ensuring detection of poisoning attacks. Empirical work on three data sets shows that employing our approach to tell legitimate from malicious updates produces models that are more accurate than those obtained with state-of-the-art poisoning detection techniques. Additionally, we explore the impact of our proposal on the performance of models on non-i.i.d local training data.},
	language = {en},
	urldate = {2023-01-25},
	journal = {Data Mining and Knowledge Discovery},
	author = {Singh, Ashneet Khandpur and Blanco-Justicia, Alberto and Domingo-Ferrer, Josep},
	month = jan,
	year = {2023},
	keywords = {Fairness, Federated learning, Minorities., Privacy, Security},
}

@inproceedings{peregrina_towards_2022,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Towards a {Metadata} {Management} {System} for {Provenance}, {Reproducibility} and {Accountability} in {Federated} {Machine} {Learning}},
	isbn = {978-3-031-23298-5},
	doi = {10.1007/978-3-031-23298-5_1},
	abstract = {The application of Data Governance (DG) to Federated Machine Learning (FML) could provide a way to produce better Machine Learning models. Nevertheless, such an application is still almost nonexistent in literature. Within a proposal for applying DG to FML, we first present an approach of metadata for FML, to provide accountability and assist with the continuous improvement of models in the federation. Our proposal includes a metadata model for tracing the operations of participants and collecting all information regarding the definition of goals and configuration of FML training processes. Additionally, we present the outline of a metadata management system as part of a broader DG architecture. Finally, we show some use cases of metadata management.},
	language = {en},
	booktitle = {Advances in {Service}-{Oriented} and {Cloud} {Computing}},
	publisher = {Springer Nature Switzerland},
	author = {Peregrina, José A. and Ortiz, Guadalupe and Zirpins, Christian},
	editor = {Zirpins, Christian and Ortiz, Guadalupe and Nochta, Zoltan and Waldhorst, Oliver and Soldani, Jacopo and Villari, Massimo and Tamburri, Damian},
	year = {2022},
	keywords = {Data Governance, Federated Machine Learning, Metadata},
	pages = {5--18},
}

@inproceedings{li_hbmd-fl_2022,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {{HBMD}-{FL}: {Heterogeneous} {Federated} {Learning} {Algorithm} {Based} on {Blockchain} and {Model} {Distillation}},
	isbn = {978-3-031-23098-1},
	shorttitle = {{HBMD}-{FL}},
	doi = {10.1007/978-3-031-23098-1_9},
	abstract = {Federated learning is a distributed machine learning framework that allows participants to keep their privacy data locally. Traditional federated learning coordinates participants collaboratively train a powerful global model. However, this process has several problems: it cannot meet the heterogeneous model’s requirements, and it cannot resist poisoning attacks and single-point-of-failure. In order to resolve these issues, we proposed a heterogeneous federated learning algorithm based on blockchain and model distillation. The problem of fully heterogeneous models that are hard to aggregate in the central server can be solved by leveraging model distillation technology. Moreover, blockchain replaces the central server in federated learning to solve the single-point-of-failure problem. The validation algorithm is combined with cross-validation, which helps federated learning to resist poison attacks. The extensive experimental results demonstrate that HBMD-FL can resist poisoning attacks while losing less than 3\$\${\textbackslash}\%\$\$of model accuracy, and the communication consumption significantly outperformed the comparison algorithm.},
	language = {en},
	booktitle = {Emerging {Information} {Security} and {Applications}},
	publisher = {Springer Nature Switzerland},
	author = {Li, Ye and Zhang, Jiale and Zhu, Junwu and Li, Wenjuan},
	editor = {Chen, Jiageng and He, Debiao and Lu, Rongxing},
	year = {2022},
	keywords = {Blockchain, Federated learning, Heterogeneous, Model distillation},
	pages = {145--159},
}

@inproceedings{cai_cluster-based_2022,
	title = {Cluster-based {Federated} {Learning} {Framework} for {Intrusion} {Detection}},
	doi = {10.1109/PAAP56126.2022.10010553},
	abstract = {With the rapid development of Industrial Internet, the network intrusion detection has become particularly important. In the Industrial Internet, large-scale data is distributed in the edge nodes caused the joint analysis of network intrusion detection at each edge node has become necessary. Federated learning structure can avoid data out of local nodes to protect user privacy data. However, the data distribution is different for each edge nodes, which limits the effectiveness of federated learning models. We focus on the non-IID data features and propose a new cluster-based federated learning framework for network intrusion detection. In this method, we cluster clients into different communities by data labels, which the clients contain the similar proportion of data labels in the same community. Based on the clustering results, we decompose federated learning model aggregation into cluster aggregation and global aggregation by leveraging similarities both within and between clusters. We conduct extensive experiments based on UNSW\_NB15 dataset. The results show that our method has better performance than FedAvg and FedProx. It can work well in scenarios with different distributions of data samples while ensuring data security and privacy protection.},
	booktitle = {2022 {IEEE} 13th {International} {Symposium} on {Parallel} {Architectures}, {Algorithms} and {Programming} ({PAAP})},
	author = {Cai, Luxin and Chen, Naiyue and Wei, Yuanmeng and Chen, Huaping and Li, Yidong},
	month = nov,
	year = {2022},
	keywords = {Data privacy, Data security, Distributed databases, Federated learning, Image edge detection, Intrusion detection, Network intrusion detection, Programming, \_read\_urgently, cluster, federated learning, non-IID, similarity},
	pages = {1--6},
}

@article{chu_securing_nodate,
	title = {Securing {Federated} {Sensitive} {Topic} {Classification} against {Poisoning} {Attacks}},
	abstract = {We present a Federated Learning (FL) based solution for building a distributed classifier capable of detecting URLs containing sensitive content, i.e., content related to categories such as health, political beliefs, sexual orientation, etc. Although such a classifier addresses the limitations of previous offline/centralised classifiers, it is still vulnerable to poisoning attacks from malicious users that may attempt to reduce the accuracy for benign users by disseminating faulty model updates. To guard against this, we develop a robust aggregation scheme based on subjective logic and residual-based attack detection. Employing a combination of theoretical analysis, trace-driven simulation, as well as experimental validation with a prototype and real users, we show that our classifier can detect sensitive content with high accuracy, learn new labels fast, and remain robust in view of poisoning attacks from malicious users, as well as imperfect input from non-malicious ones.},
	language = {en},
	author = {Chu, Tianyue and Garcia-Recuero, Alvaro and Iordanou, Costas and Smaragdakis, Georgios and Delft, TU and Laoutaris, Nikolaos},
	keywords = {⛔ No DOI found},
}

@inproceedings{shi_data_2021,
	title = {Data {Privacy} {Security} {Guaranteed} {Network} {Intrusion} {Detection} {System} {Based} on {Federated} {Learning}},
	doi = {10.1109/INFOCOMWKSHPS51825.2021.9484545},
	abstract = {With the development of computer software, the amount of network data has increased geometrically. Therefore, how to quickly identify attacks from a large amount of network information is a meaningful research direction. The intrusion detection system (IDS) is the core contributor to protecting the host from attack. It can distinguish the characteristics of intrusion behavior and the intrusion action from the data of the host. However, with the huge increase in the amount of data now, the efficiency of identifying data characteristics is getting lower and lower. In addition, smart terminal equipment such as notebooks, smart phones and wearable devices are also emerging, and these devices are connected to the internet through wireless or wired means. The physical data generated by terminal equipment involves huge amount of personal sensitive data, which poses a challenge to data privacy and security. Federated learning, as a new type of distributed learning framework, allows training data to be shared among multiple participants without revealing their data privacy. In order to solve the problem of privacy data in intrusion detection,, this paper proposes a network intrusion detection method based on federated learning and conducting experiments on the UNSW-NB15 dataset and CICIDS2018 dataset. The simulation results show that the method proposed in this paper can protect data privacy under the premise of achieving acceptable accuracy of intrusion traffic identification.},
	booktitle = {{IEEE} {INFOCOM} 2021 - {IEEE} {Conference} on {Computer} {Communications} {Workshops} ({INFOCOM} {WKSHPS})},
	author = {Shi, Jibo and Ge, Bin and Liu, Yang and Yan, Yu and Li, Shuang},
	month = may,
	year = {2021},
	keywords = {CICIDS2018, Conferences, Data privacy, IDS, Network intrusion detection, Privacy security, Training data, UNSW-NB15, Wearable computers, Wireless communication, Wireless sensor networks, federated learning},
	pages = {1--6},
}

@incollection{dimitrova_time_2020,
	address = {Cham},
	title = {Time {Series} {Anomaly} {Detection} with {Variational} {Autoencoder} {Using} {Mahalanobis} {Distance}},
	volume = {1316},
	isbn = {978-3-030-62097-4 978-3-030-62098-1},
	url = {https://link.springer.com/10.1007/978-3-030-62098-1_4},
	abstract = {Two themes have dominated the research on anomaly detection in time series data, one related to explorations of deep architectures for the task, and the other, equally important, the creation of large benchmark datasets. In line with the current trends, we have proposed several deep learning architectures based on Variational Autoencoders that have been evaluated for detecting cyber-attacks on water distribution system on the BATADAL challenge task and dataset. The second research aim of this study was to examine the impact of using Mahalanobis distance as a reconstruction error on the performance of the proposed models.},
	language = {en},
	urldate = {2023-01-13},
	booktitle = {{ICT} {Innovations} 2020. {Machine} {Learning} and {Applications}},
	publisher = {Springer International Publishing},
	author = {Gjorgiev, Laze and Gievska, Sonja},
	editor = {Dimitrova, Vesna and Dimitrovski, Ivica},
	year = {2020},
	doi = {10.1007/978-3-030-62098-1_4},
	note = {Series Title: Communications in Computer and Information Science},
	pages = {42--55},
}

@article{chhikara_adaptive_2023,
	title = {Adaptive federated learning scheme for recognition of malicious attacks in an {IoT} network},
	issn = {1436-5057},
	url = {https://doi.org/10.1007/s00607-022-01146-6},
	doi = {10.1007/s00607-022-01146-6},
	abstract = {The Internet of Things (IoT) is crucial for deploying a novel Artificial Intelligence (AI) model for both network and application management. However, using classical centralized learning algorithms in the IoT environment is challenging, given massively distributed private datasets. Advancements in AI have helped us solve various use cases, but it operates under two significant challenges. Firstly, the data exists in separate clusters, and secondly, the current AI has limited data privacy and security. Federated learning (FL) aims to preserve data privacy through distributed learning methods that keep the data in storage silos. Likewise, differential privacy improves data privacy by measuring the privacy loss in communication among the elements of FL. The paper proposes two adaptive approaches for making model training differentially private in a vertical federated environment. The first one uses random feature selection to train different machine learning models, and performance improvement is also proposed. The second approach uses a tree structure, i.e., Classification and Regression Trees, using some defined constraints. Further, we created a scheme to help identify malicious users/devices in a federated network cluster using parity checks for every FL iteration.},
	language = {en},
	urldate = {2023-01-12},
	journal = {Computing},
	author = {Chhikara, Prateek and Tekchandani, Rajkumar and Kumar, Neeraj},
	month = jan,
	year = {2023},
	keywords = {68, Differential privacy, Federated learning, Internet of Things, Machine learning},
}

@misc{gill_feddebug_2023,
	title = {{FedDebug}: {Systematic} {Debugging} for {Federated} {Learning} {Applications}},
	shorttitle = {{FedDebug}},
	url = {http://arxiv.org/abs/2301.03553},
	abstract = {In Federated Learning (FL), clients train a model locally and share it with a central aggregator to build a global model. Impermissibility to access client’s data and collaborative training makes FL appealing for applications with data-privacy concerns such as medical imaging. However, these FL characteristics pose unprecedented challenges for debugging. When a global model’s performance deteriorates, ﬁnding the round and the clients responsible is a major pain point. Developers resort to trial-and-error debugging with subsets of clients, hoping to increase the accuracy or let future FL rounds retune the model, which are time-consuming and costly.},
	language = {en},
	urldate = {2023-01-12},
	publisher = {arXiv},
	author = {Gill, Waris and Anwar, Ali and Gulzar, Muhammad Ali},
	month = jan,
	year = {2023},
	note = {arXiv:2301.03553 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Computer Science - Software Engineering},
}

@article{asgharzadeh_anomaly-based_2023,
	title = {Anomaly-based {Intrusion} {Detection} {System} in the {Internet} of {Things} using a {Convolutional} {Neural} {Network} and {Multi}-{Objective} {Enhanced} {Capuchin} {Search} {Algorithm}},
	issn = {0743-7315},
	url = {https://www.sciencedirect.com/science/article/pii/S0743731522002611},
	doi = {10.1016/j.jpdc.2022.12.009},
	abstract = {Nowadays, the growth and pervasiveness of Internet of Things (IoT) devices have led to increased attacks by hackers and attackers. On the other hand, using IoT infrastructure in various fields has increased the number of node security breaches, attacks, and anomalies. Therefore, detecting anomalies in IoT devices is vital to reduce attacks and strengthen security. Over the past few years, various research has been conducted in anomaly-based intrusion detection using machine learning and deep learning methods. The biggest challenge in machine learning methods is the inability to extract new features. To do this, researchers use deep learning methods to extract new features that lead to increased accuracy in intrusion detection. There are important unsolved challenges in research, including determining important features in detecting malicious attacks, extracting features from raw network traffic data using deep networks, and insufficient accuracy in detecting attacks against IoT devices. Convolutional neural networks are considered a powerful and reliable method in this field due to the ability to automatically extract features from data and perform faster calculations. This study has designed and implemented the IoT features extraction convolutional neural network called IoTFECNN with hybrid layers for better anomaly detection in the IoT. Moreover, a binary multi-objective enhanced Capuchin Search Algorithm (CSA) called BMECapSA is developed for efficient feature selection. The combination of the IoTFECNN and BMECapSA methods has led to the introduction of a new hybrid method called CNN-BMECapSA-RF. Finally, the proposed method is implemented and tested on two data sets, NSL-KDD and TON-IoT. The results of various experiments exhibit that the proposed method has better results regarding classification criteria compared to existing deep learning and machine learning-based anomaly detection systems. The proposed method has reached 99.99\% and 99.85\% accuracy by identifying 27\% and 44\% of the effective features on the TON-IoT and NSL-KDD datasets, respectively.},
	language = {en},
	urldate = {2023-01-12},
	journal = {Journal of Parallel and Distributed Computing},
	author = {Asgharzadeh, Hossein and Ghaffari, Ali and Masdari, Mohammad and Soleimanian Gharehchopogh, Farhad},
	month = jan,
	year = {2023},
	keywords = {Convolutional neural network, Internet of Things, Intrusion detection system, Multi-objective CSA},
}

@article{chen_feddual_2023,
	title = {{FedDual}: {Pair}-{Wise} {Gossip} {Helps} {Federated} {Learning} in {Large} {Decentralized} {Networks}},
	volume = {18},
	issn = {1556-6021},
	shorttitle = {{FedDual}},
	doi = {10.1109/TIFS.2022.3222935},
	abstract = {There is a significant recent interest in collaboratively training a machine learning (ML) model without collecting data to a central server. Federated learning (FL) emerges as an efficient solution mitigating systemic privacy risks and communication costs. However, conventional FL inherited from parameter server designs relies too much on a central server, which may lead to privacy risks, communication bottlenecks, or a single point of failure. In this paper, we propose an asynchronous and hierarchical local gradient aggregation and global model update algorithm, FedDual, under three different security considerations for FL in large decentralized networks. Particularly, FedDual preserves privacy by introducing local differential privacy (LDP) and aggregates local gradients asynchronously and hierarchically via a pair-wise gossip algorithm, which is more competitive than previous gossip-based decentralized FL methods in terms of privacy preservation and communication efficiency, and offers more computational efficiency compared to existing blockchain-assisted decentralized FL methods. Further, we devise a noise cutting trick based on Private Set Intersection (PSI) to mitigate the prediction performance loss of the global model caused by the leveraged LDP. Rigorous analyses show that FedDual helps decentralized FL achieve the same convergence rate of \${\textbackslash}mathcal O{\textbackslash}left({\textbackslash}frac 1T{\textbackslash}right) \$ as centralized ML theoretically. Ingenious experiments on MNIST, CIFAR-10, and FEMNIST confirm that the model prediction performance gained from FedDual is close to centralized ML. More importantly, the proposed noise cutting trick helps FedDual to train better global models than LDP-based FL methods in terms of prediction performance and convergence rate.},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Chen, Qian and Wang, Zilong and Wang, Hongbo and Lin, Xiaodong},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Computational modeling, Convergence, Data models, Federated learning, Privacy, Security, Servers, Training, decentralized networks, efficiency, privacy-preserving, security},
	pages = {335--350},
}

@article{sun_fedsea_2022,
	title = {{FedSEA}: {A} {Semi}-{Asynchronous} {Federated} {Learning} {Framework} for {Extremely} {Heterogeneous} {Devices}},
	abstract = {Federated learning (FL) has attracted increasing attention as a promising technique to drive a vast number of edge devices with artificial intelligence. However, it is very challenging to guarantee the efficiency of a FL system in practice due to the heterogeneous computation resources on different devices. To improve the efficiency of FL systems in the real world, asynchronous FL (AFL) and semiasynchronous FL (SAFL) methods are proposed such that the server does not need to wait for stragglers. However, existing AFL and SAFL systems suffer from poor accuracy and low efficiency in realistic settings where the data is non-IID distributed across devices and the on-device resources are extremely heterogeneous. In this work, we propose FedSEA – a semi-asynchronous FL framework for extremely heterogeneous devices. We theoretically disclose that the unbalanced aggregation frequency is a root cause of accuracy drop in SAFL. Based on this analysis, we design a training configuration scheduler to balance the aggregation frequency of devices such that the accuracy can be improved. To improve the efficiency of the system in realistic settings where the devices have dynamic on-device resource availability, we design a scheduler that can efficiently predict the arriving time of local updates from devices and adjust the synchronization time point according to the devices’ predicted arriving time. We also consider the extremely heterogeneous settings where there exist extremely lagging devices that take hundreds of times as long as the training time of the other devices. In the real world, there might be even some extreme stragglers which are not capable of training the global model. To enable these devices to join in training without impairing the systematic efficiency, FedSEA enables these extreme stragglers to conduct local training on much smaller models. Our experiments show that compared with status quo approaches, FedSEA improves the inference accuracy by 44.34\% and reduces the systematic time cost and local training time cost by 87.02× and 792.9×. FedSEA also reduces the energy consumption of the devices with extremely limited resources by 752.9×.},
	language = {en},
	author = {Sun, Jingwei and Li, Ang and Duan, Lin and Alam, Samiul and Deng, Xuliang and Guo, Xin and Wang, Haiming and Gorlatova, Maria and Zhang, Mi and Li, Hai and Chen, Yiran},
	year = {2022},
	keywords = {⛔ No DOI found},
}

@inproceedings{mbow_advances_2022,
	address = {Singapore},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Advances in {Adversarial} {Attacks} and {Defenses} in {Intrusion} {Detection} {System}: {A} {Survey}},
	isbn = {978-981-19776-9-5},
	shorttitle = {Advances in {Adversarial} {Attacks} and {Defenses} in {Intrusion} {Detection} {System}},
	doi = {10.1007/978-981-19-7769-5_15},
	abstract = {Machine learning is one of the predominant methods used in computer science and has been widely and successfully applied in many areas such as computer vision, pattern recognition, natural language processing, cyber security etc. In cyber security, the application of machine learning algorithms for network intrusion detection system (NIDS) has seen promising results for anomaly detection mostly with the adoption of deep learning and is still growing. However, machine learning algorithms are vulnerable to adversarial attacks resulting in significant performance degradation. Adversarial attacks are security threats that aim to deceive the learning algorithm by manipulating its predictions, and Adversarial machine learning is a research area that studies both the generation and defense of such attacks. Researchers have extensively worked on the adversarial machine learning in computer vision but not many works in Intrusion detection system. However, failure in this critical Intrusion detection area could compromise the security of an entire system, and need much attention. This paper provides a review of the advancement in adversarial machine learning based intrusion detection and explores the various defense techniques applied against. Finally discuss their limitations for future research direction in this emerging area.},
	language = {en},
	booktitle = {Science of {Cyber} {Security} - {SciSec} 2022 {Workshops}},
	publisher = {Springer Nature},
	author = {Mbow, Mariama and Sakurai, Kouichi and Koide, Hiroshi},
	editor = {Su, Chunhua and Sakurai, Kouichi},
	year = {2022},
	keywords = {Adversarial attack, Cyber security, Deep learning, Evasion attack, Intrusion detection, Machine learning, Poisoning attack},
	pages = {196--212},
}

@article{costa_turning_2022,
	title = {Turning {Federated} {Learning} {Systems} {Into} {Covert} {Channels}},
	volume = {10},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2022.3229124},
	abstract = {Federated learning (FL) goes beyond traditional, centralized machine learning by distributing model training among a large collection of edge clients. These clients cooperatively train a global, e.g., cloud-hosted, model without disclosing their local, private training data. The global model is then shared among all the participants which use it for local predictions. This paper proves that FL systems can be turned into covert channels to implement a stealth communication infrastructure. The main intuition is that, during federated training, a malicious sender can poison the global model by submitting purposely crafted examples. Although the effect of the model poisoning is negligible to other participants and does not alter the overall model performance, it can be observed by a malicious receiver and used to transmit a sequence of bits. We mounted our attack on an FL system to verify its feasibility. Experimental evidence shows that this covert channel is reliable, efficient, and extremely hard to counter. These results highlight that our new attacker model threatens FL infrastructures.},
	journal = {IEEE Access},
	author = {Costa, Gabriele and Pinelli, Fabio and Soderi, Simone and Tolomei, Gabriele},
	year = {2022},
	note = {Conference Name: IEEE Access},
	keywords = {Data models, Federated learning, Predictive models, Security, Servers, Task analysis, Training, adversarial attacks, covert channel, machine learning security},
	pages = {130642--130656},
}

@article{abosata_customised_2023,
	title = {Customised {Intrusion} {Detection} for an {Industrial} {IoT} {Heterogeneous} {Network} {Based} on {Machine} {Learning} {Algorithms} {Called} {FTL}-{CID}},
	volume = {23},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/23/1/321},
	doi = {10.3390/s23010321},
	abstract = {Technological breakthroughs in the Internet of Things (IoT) easily promote smart lives for humans by connecting everything through the Internet. The de facto standardised IoT routing strategy is the routing protocol for low-power and lossy networks (RPL), which is applied in various heterogeneous IoT applications. Hence, the increase in reliance on the IoT requires focus on the security of the RPL protocol. The top defence layer is an intrusion detection system (IDS), and the heterogeneous characteristics of the IoT and variety of novel intrusions make the design of the RPL IDS significantly complex. Most existing IDS solutions are unified models and cannot detect novel RPL intrusions. Therefore, the RPL requires a customised global attack knowledge-based IDS model to identify both existing and novel intrusions in order to enhance its security. Federated transfer learning (FTL) is a trending topic that paves the way to designing a customised RPL-IoT IDS security model in a heterogeneous IoT environment. In this paper, we propose a federated-transfer-learning-assisted customised distributed IDS (FT-CID) model to detect RPL intrusion in a heterogeneous IoT. The design process of FT-CID includes three steps: dataset collection, FTL-assisted edge IDS learning, and intrusion detection. Initially, the central server initialises the FT-CID with a predefined learning model and observes the unique features of different RPL-IoTs to construct a local model. The experimental model generates an RPL-IIoT dataset with normal and abnormal traffic through simulation on the Contiki-NG OS. Secondly, the edge IDSs are trained using the local parameters and the globally shared parameters generated by the central server through federation and aggregation of different local parameters of various edges. Hence, transfer learning is exploited to update the server’s and edges’ local and global parameters based on relational knowledge. It also builds and customised IDS model with partial retraining through local learning based on globally shared server knowledge. Finally, the customised IDS in the FT-CID model enforces the detection of intrusions in heterogeneous IoT networks. Moreover, the FT-CID model accomplishes high RPL security by implicitly utilising the local and global parameters of different IoTs with the assistance of FTL. The FT-CID detects RPL intrusions with an accuracy of 85.52\% in tests on a heterogeneous IoT network.},
	language = {en},
	number = {1},
	urldate = {2023-01-09},
	journal = {Sensors},
	author = {Abosata, Nasr and Al-Rubaye, Saba and Inalhan, Gokhan},
	month = jan,
	year = {2023},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {AMI, Internet of Things (IoT), application, attacks, distributed sensors, intrusion detection, machine learning, security},
	pages = {321},
}

@article{song_intrusion_2023,
	title = {Intrusion detection model using gene expression programming to optimize parameters of convolutional neural network for energy internet},
	volume = {134},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494622010092},
	doi = {10.1016/j.asoc.2022.109960},
	abstract = {The open, interconnected, and shared operational characteristics of the energy Internet introduce more sophisticated cybersecurity attacks. How to accurately detect these cyber attacks is crucial for energy Internet security protection. Existing machine learning-based intrusion detection algorithms cannot cope with the continuous increase of network traffic and features in the energy Internet. And convolutional neural networks (CNN) can be a good solution for the descending and optimal selection of high-dimensional intrusion features. Unfortunately, traditional convolutional neural networks have complex structures with many parameters and are prone to fall into local optimality. To fill the gap of CNN, in this paper, we use a gene expression programming (GEP) to optimize the parameters of CNN and propose an intrusion detection algorithm based on GEP-CNN (GCNN-IDS). Our key idea is to avoid the convolutional neural network from falling into local optimum by designing a new code on GEP and fitness function to optimize the parameters of the CNN using the global search capability of GEP. The experimental results on two benchmark datasets and a real dataset substantiate that the detection accuracy of the optimized CNN-based intrusion detection algorithm (ICNN-IDS) reaches up to 0.9143 under different parameter combinations; meanwhile, compared with other algorithms, the detection accuracy, precision, recall, F1 and false detection rate of the intrusion detection model proposed in this paper reach 0.9897, 0.99, 0.98, 0.97 and 0.0126, respectively.},
	language = {en},
	urldate = {2023-01-09},
	journal = {Applied Soft Computing},
	author = {Song, Deng and Yuan, Xinya and Li, Qianliang and Zhang, Jie and Sun, Mengfei and Fu, Xiong and Yang, Lechan},
	month = feb,
	year = {2023},
	keywords = {Convolutional neural network, Gene expression programming, Intrusion detection, Parameter optimization},
	pages = {109960},
}

@inproceedings{kumari_baybfed_2022,
	title = {{BayBFed}: {Bayesian} {Backdoor} {Defense} for {Federated} {Learning}},
	isbn = {978-1-66549-336-9},
	shorttitle = {{BayBFed}},
	url = {https://www.computer.org/csdl/proceedings-article/sp/2023/933600b747/1Js0Ej4gSME},
	doi = {10.1109/SP46215.2023.00100},
	abstract = {Federated learning (FL) is an emerging technology that allows participants to jointly train a machine learning model without sharing their private data with others. However, FL is vulnerable to poisoning attacks such as backdoor attacks. Consequently, a variety of defenses have recently been proposed, which have primarily utilized intermediary states of the global model (i.e., logits) or distance of the local models (i.e., L2\&\#x2212;norm) with respect to the global model to detect malicious backdoors in FL. However, as these approaches directly operate on client updates (or weights), their effectiveness depends on factors such as clients\&\#x2019; data distribution or the adversary\&\#x2019;s attack strategies. In this paper, we introduce a novel and more generic backdoor defense framework, called BayBFed, which proposes to utilize probability distributions over client updates to detect malicious updates in FL: BayBFed computes a probabilistic measure over the clients\&\#x2019; updates to keep track of any adjustments made in the updates, and uses a novel detection algorithm that can leverage this probabilistic measure to efficiently detect and filter out malicious updates. Thus, it overcomes the shortcomings of previous approaches that arise due to the direct usage of client updates; nevertheless, our probabilistic measure will include all aspects of the local client training strategies. BayBFed utilizes two Bayesian Non-Parametric (BNP) extensions: (i) a Hierarchical Beta-Bernoulli process to draw a probabilistic measure given the clients\&\#x2019; updates, and (ii) an adaptation of the Chinese Restaurant Process (CRP), referred by us as CRP-Jensen, which leverages this probabilistic measure to detect and filter out malicious updates. We extensively evaluate our defense approach on five benchmark datasets: CIFAR10, Reddit, IoT intrusion detection, MNIST, and FMNIST, and show that it can effectively detect and eliminate malicious updates in FL without deteriorating the benign performance of the global model.},
	language = {English},
	urldate = {2023-01-09},
	publisher = {IEEE Computer Society},
	author = {Kumari, Kavita and Rieger, Phillip and Fereidooni, Hossein and Jadliwala, Murtuza and Sadeghi, Ahmad-Reza},
	month = dec,
	year = {2022},
	keywords = {⚠️ Invalid DOI},
	pages = {1747--1764},
}

@article{rajan_blockchain-based_nodate,
	title = {Blockchain-based multi-layered federated extreme learning networks in connected vehicles},
	volume = {n/a},
	issn = {1468-0394},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13222},
	doi = {10.1111/exsy.13222},
	abstract = {Intelligent and networked vehicles help build an efficient vehicular network's infrastructure. The widespread use of electronic software exposes these networks to cyber-attacks. Intrusion detection systems (IDS) are useful for preventing vehicle network assaults. IDS have been customized using machine and deep learning networks for greater real-time performance. Current learning-based intrusion detection systems demand substantial processing capabilities to train and update intricate training models in vehicular devices, resulting in decreased efficiency and ability to defend against assaults. This study presents Blockchain-based Multi-Layer Federated Extreme Learning Machines (MLFEM) enabled IDS (BEF-IDS) for safe data transfers. The proposed IDS leverages federated learning to generate Multi-Layered Extreme Learning Machines, which are offloaded to dispersed vehicular edge devices such as Road-Side Units (RSU) and connected vehicles. This federated strategy decreases resource use without sacrificing security. Blockchain technology records and shares training models, assuring network security. Using real-time data sets, the suggested algorithm's performance under different attack scenarios were extensively tested. The suggested method obtained 98\% accuracy and Recall, 97.9\% Precision, and 97.9\% F1 Score performance, which suggests it's incredibly secure and costs very little to transmit.},
	language = {en},
	number = {n/a},
	urldate = {2023-01-09},
	journal = {Expert Systems},
	author = {Rajan, Durga and Eswaran, Poovammal and Srivastava, Gautam and Ramana, Kadiyala and Iwendi, Celestine},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/exsy.13222},
	keywords = {blockchain, federated learning, intrusion detection systems, privacy, security},
	pages = {e13222},
}

@article{bao_federated_2022,
	title = {Federated learning in cloud-edge collaborative architecture: key technologies, applications and challenges},
	volume = {11},
	issn = {2192-113X},
	shorttitle = {Federated learning in cloud-edge collaborative architecture},
	url = {https://doi.org/10.1186/s13677-022-00377-4},
	doi = {10.1186/s13677-022-00377-4},
	abstract = {In recent years, with the rapid growth of edge data, the novel cloud-edge collaborative architecture has been proposed to compensate for the lack of data processing power of traditional cloud computing. On the other hand, on account of the increasing demand of the public for data privacy, federated learning has been proposed to compensate for the lack of security of traditional centralized machine learning. Deploying federated learning in cloud-edge collaborative architecture is widely considered to be a promising cyber infrastructure in the future. Although each cloud-edge collaboration and federated learning is hot research topic respectively at present, the discussion of deploying federated learning in cloud-edge collaborative architecture is still in its infancy and little research has been conducted. This article aims to fill the gap by providing a detailed description of the critical technologies, challenges, and applications of deploying federated learning in cloud-edge collaborative architecture, and providing guidance on future research directions.},
	number = {1},
	urldate = {2023-01-09},
	journal = {Journal of Cloud Computing},
	author = {Bao, Guanming and Guo, Ping},
	month = dec,
	year = {2022},
	keywords = {Cloud-edge collaborative computing, Federated learning},
	pages = {94},
}

@article{selamnia_edge_nodate,
	title = {Edge {Computing}-enabled {Intrusion} {Detection} for {C}-{V2X} {Networks} using {Federated} {Learning}},
	abstract = {Intrusion detection systems (IDS) have already demonstrated their effectiveness in detecting various attacks in cellular vehicle-to-everything (C-V2X) networks, especially when using machine learning (ML) techniques. However, it has been shown that generating ML-based models in a centralized way consumes a massive quantity of network resources, such as CPU/memory and bandwidth, which may represent a critical issue in such networks. To avoid this problem, the new concept of Federated Learning (FL) emerged to build ML-based models in a distributed and collaborative way. In such an approach, the set of nodes, e.g., vehicles or gNodeB, collaborate to create a global ML model trained across these multiple decentralized nodes, each one with its respective data samples that are not shared with any other nodes. In this way, FL enables, on the one hand, data privacy since sharing data with a central location is not always feasible and, on the other hand, network overhead reduction. This paper designs a new IDS for C-V2X networks based on FL. It leverages edge computing to not only build a prediction model in a distributed way but also to enable lowlatency intrusion detection. Moreover, we build our FL-based IDS on top of the well-known CIC-IDS2018 dataset, which includes the main network attacks. Noting that, we first perform feature engineering on the dataset using the ANOVA method to consider only the most informative features. Simulation results show the efficiency of our system compared to the existing solutions in terms of attack detection accuracy while reducing network resource consumption.},
	language = {en},
	author = {Selamnia, Aymene and Brik, Bouziane and Senouci, Sidi Mohammed and Boualouache, Abdelwahab and Hossain, Shajjad},
	keywords = {⛔ No DOI found},
}

@inproceedings{zaabar_intrusion_2022,
	title = {Intrusion {Detection} {System} for {IoMT} through {Blockchain}-based {Federated} {Learning}},
	doi = {10.1109/SIN56466.2022.9970536},
	abstract = {Federated Learning (FL) is a feasible technology to collaboratively train a model without sharing private data. This approach differs from traditional machine learning techniques, which aggregate local datasets in a single server. Thus, FL is adopted in the Healthcare sector to preserve the privacy of collected sensitive medical data from heterogenous and resource-constrained Internet of Medical Things (IoMT). However, FL requires aggregating all trained local models in a central server that presents a single point of failure. To address this issue, we propose a novel Blockchain-based Federated Learning architecture, which is applied to detect malicious network traffic in IoMT environments. In this paper, the proposed architecture takes advantage of a Hyperledger Fabric channel coupled with FL to manage efficiently and securely the learning process of an Intrusion Detection System (IDS). The Blockchain channel replaces the commonly used central server with the traditional FL approach. Moreover, the proposed approach benefits from the inherent features of Blockchain and FL. Besides, it secures patient data collection from the IoMT by examining the network traffic for unauthorised behaviour or policy breaches.},
	booktitle = {2022 15th {International} {Conference} on {Security} of {Information} and {Networks} ({SIN})},
	author = {Zaabar, Bessem and Cheikhrouhou, Omar and Abid, Mohamed},
	month = nov,
	year = {2022},
	keywords = {Blockchain, Data privacy, Distributed ledger, Fabrics, Fed-erated Learning (FL), Federated learning, Internet of Medical Things, Internet of Medical Things (IoMT), Intrusion Detection System (IDS), Intrusion detection, Security and Privacy, Telecommunication traffic},
	pages = {01--08},
}

@inproceedings{singh_enhancing_2022,
	title = {Enhancing {Collaborative} {Intrusion} detection networks against insider attack using supervised learning technique},
	doi = {10.1109/MysuruCon55714.2022.9972599},
	abstract = {As network are being used, intrusion occurs from a variety of sources. According to their actions to damage network functioning, cyberattack is a significant issue in communication systems. The privacy, authenticity, or accessibility of a resource may be compromised by unauthorized activity or attacks, which intrusion detection systems (IDS) can help identify. Researchers explore the findings of research articles on the past, present, and potential of intrusion detection systems on wireless networks. Statistical modelling and deep learning are used to analyses the findings of journals. Isolation forest are one of the strategies that can acquire accurate network measures and produce appropriate choices by raising the detection rate and accuracy. In this paper, we propose a decision tree-based method for detection of network intrusions with improved data quality. In order to improve the data quality and provide appropriate training, networking data pre-processing and attributes selection based on entropy are specifically carried out. A isolation forest classifier is then constructed for accurate intrusion detection. Experimental analysis of two datasets demonstrates the proposed model's ability to produce reliable results. Actually, using the CICIDS2017 and NSL-KDD datasets, our model's accuracy is 99.98\% and 99.82\%, respectively. When compared to existing models, the new approach has many benefits in terms of false alarm rate (FAR), detection rate (DR), and accuracy (ACC).},
	booktitle = {2022 {IEEE} 2nd {Mysore} {Sub} {Section} {International} {Conference} ({MysuruCon})},
	author = {Singh, Rajesh and Deorari, Rajesh},
	month = oct,
	year = {2022},
	keywords = {Analytical models, Collaboration, Data integrity, Intrusion detection, Supervised learning, Training, Wireless networks, collaborative intrusion detection, insider attacks and intrusion datasets, supervised learning},
	pages = {1--6},
}

@inproceedings{zakariyya_resource_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Resource {Efficient} {Federated} {Deep} {Learning} for {IoT} {Security} {Monitoring}},
	isbn = {978-3-031-21311-3},
	doi = {10.1007/978-3-031-21311-3_6},
	abstract = {Federated Learning (FL) uses a distributed Machine Learning (ML) concept to build a global model using multiple local models trained on distributed edge devices. A disadvantage of the FL paradigm is the requirement of many communication rounds before model convergence. As a result, there is a challenge for running on-device FL with resource-hungry algorithms such as Deep Neural Network (DNN), especially in the resource-constrained Internet of Things (IoT) environments for security monitoring. To address this issue, this paper proposes Resource Efficient Federated Deep Learning (REFDL) method. Our method exploits and optimizes Federated Averaging (Fed-Avg) DNN based technique to reduce computational resources consumption for IoT security monitoring. It utilizes pruning and simulated micro-batching in optimizing the Fed-Avg DNN for effective and efficient IoT attacks detection at distributed edge nodes. The performance was evaluated using various realistic IoT and non-IoT benchmark datasets on virtual and testbed environments build with GB-BXBT-2807 edge-computing-like devices. The experimental results show that the proposed method can reduce memory usage by 81\% in the simulated environment of virtual workers compared to its benchmark counterpart. In the realistic testbed scenario, it saves 6\% memory while reducing execution time by 15\% without degrading accuracy.},
	language = {en},
	booktitle = {Attacks and {Defenses} for the {Internet}-of-{Things}},
	publisher = {Springer Nature Switzerland},
	author = {Zakariyya, Idris and Kalutarage, Harsha and Al-Kadri, M. Omar},
	editor = {Li, Wenjuan and Furnell, Steven and Meng, Weizhi},
	year = {2022},
	keywords = {Deep Neural Network (DNN), Distributed machine learning, Edge devices, Federated learning (FL), Internet of Things (IoT), Security monitoring},
	pages = {122--142},
}

@article{petrakopoulos_ddos_nodate,
	title = {{DDoS} {Detection} using {Trust}-{Aware} {Federated} {Learning} for {Heterogeneous} {Collaborators}},
	language = {en},
	author = {Petrakopoulos, Vasilis},
	keywords = {⛔ No DOI found},
}

@article{abdelbasset_efficient_2022,
	title = {Efficient and {Lightweight} {Convolutional} {Networks} for {IoT} {Malware} {Detection}: {A} {Federated} {Learning} {Approach}},
	issn = {2327-4662},
	shorttitle = {Efficient and {Lightweight} {Convolutional} {Networks} for {IoT} {Malware} {Detection}},
	doi = {10.1109/JIOT.2022.3229005},
	abstract = {Over the past few years, billions of unsecured Internet of Things (IoT) devices have been produced and released, and that number will only grow as wireless technology advances. As a result of their susceptibility to malware, effective methods have become necessary for identifying IoT malware. However, the low generalizability and the non-independently and identically distributed data (non-IID) still pose a major challenge to achieving this goal. In this work, a new federated malware detection paradigm, termed FED-MAL, is introduced to collaboratively train multiple distributed edge devices to detect malware. In FED-MAL, the malware binaries are transformed into image format to lessen the impact on non-IID, and then a compact convolutional model, named AM-NET, is proposed to learn the malware patterns as an image recognition task. The compact nature of AM-NET makes it an appropriate choice for deployment on resource-constrained IoT devices. Following, a refined edge-based adversarial training is given in FED-MAL to empower generalizability and resistibility by generating adversarial samples from various participating clients. Experimental evaluation on publicly available malware datasets shows that the FED-MAL is efficacious, reliable, expandable, generalizable, and communication efficient.},
	journal = {IEEE Internet of Things Journal},
	author = {Abdelbasset, Mohamed and Hawash, Hossam and Sallam, Karam M. and Elgendi, Ibrahim and Munasinghe, Kumudu and Jamalipour, Abbas},
	year = {2022},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Deep Learning, Detectors, Edge/Fog Computing, Feature extraction, Federated Learning, Image edge detection, Internet of Things, Malware, Malware Detection, Security, Training, adversarial attacks},
	pages = {1--1},
}

@inproceedings{ring_ip2vec_2017,
	title = {{IP2Vec}: {Learning} {Similarities} {Between} {IP} {Addresses}},
	shorttitle = {{IP2Vec}},
	doi = {10.1109/ICDMW.2017.93},
	abstract = {IP Addresses are a central part of packet- and flow-based network data. However, visualization and similarity computation of IP Addresses are challenging to due the missing natural order. This paper presents a novel similarity measure IP2Vec for IP Addresses that builds on ideas from Word2Vec, a popular approach in text mining. The key idea is to learn similarities by extracting available context information from network data. IP Addresses are similar if they appear in similar contexts. Thus, IP2Vec is automatically derived from the given network data set. The proposed approach is evaluated experimentally on two public flow-based data sets. In particular, we demonstrate the effectiveness of clustering IP Addresses within a botnet data set. In addition, we use visualization methods to analyse the learned similarities in more detail. These experiments indicate that IP2Vec is well suited to capture the similarity of IP Addresses based on their network communications.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Data} {Mining} {Workshops} ({ICDMW})},
	author = {Ring, Markus and Dallmann, Alexander and Landes, Dieter and Hotho, Andreas},
	month = nov,
	year = {2017},
	note = {ISSN: 2375-9259},
	keywords = {Biological neural networks, Data mining, Feature extraction, IP Addresses, IP networks, Intrusion Detection, Neurons, Similarity Measure, Training, Vocabulary, Word2Vec},
	pages = {657--666},
}

@article{bahaa_novel_2022,
	title = {A novel hybrid optimization enabled robust {CNN} algorithm for an {IoT} network intrusion detection approach},
	volume = {17},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0278493},
	doi = {10.1371/journal.pone.0278493},
	abstract = {Due to the huge number of connected Internet of Things (IoT) devices within a network, denial of service and flooding attacks on networks are on the rise. IoT devices are disrupted and denied service because of these attacks. In this study, we proposed a novel hybrid meta-heuristic adaptive particle swarm optimization–whale optimizer algorithm (APSOWOA) for optimization of the hyperparameters of a convolutional neural network (APSOWOA-CNN). The APSO–WOA optimization algorithm’s fitness value is defined as the validation set’s cross-entropy loss function during CNN model training. In this study, we compare our optimization algorithm with other optimization algorithms, such as the APSO algorithm, for optimization of the hyperparameters of CNN. In model training, the APSO–WOA–CNN algorithm achieved the best performance compared to the FNN algorithm, which used manual parameter settings. We evaluated the APSO–WOA–CNN algorithm against APSO–CNN, SVM, and FNN. The simulation results suggest that APSO–WOA–CNf[N is effective and can reliably detect multi-type IoT network attacks. The results show that the APSO–WOA–CNN algorithm improves accuracy by 1.25\%, average precision by 1\%, the kappa coefficient by 11\%, Hamming loss by 1.2\%, and the Jaccard similarity coefficient by 2\%, as compared to the APSO–CNN algorithm, and the APSO–CNN algorithm achieves the best performance, as compared to other algorithms.},
	language = {en},
	number = {12},
	urldate = {2022-12-14},
	journal = {PLOS ONE},
	author = {Bahaa, Ahmed and Sayed, Abdalla and Elfangary, Laila and Fahmy, Hanan},
	editor = {V. E., Sathishkumar},
	month = dec,
	year = {2022},
	pages = {e0278493},
}

@inproceedings{zainudin_fedddos_2022,
	title = {{FedDDoS}: {An} {Efficient} {Federated} {Learning}-based {DDoS} {Attacks} {Classification} in {SDN}-{Enabled} {IIoT} {Networks}},
	shorttitle = {{FedDDoS}},
	doi = {10.1109/ICTC55196.2022.9952610},
	abstract = {Independent distribution systems are made possible by Industry 4.0, and these systems produce heterogeneous data that is vulnerable to cyberattacks. The Distributed Denial of Service (DDoS) attack is a typical contemporary cyber threat that disables a target server by flooding it with malicious traffic. In this research, a deep-federated learning-based decentralized DDoS classification method enables independent clients to train local data while maintaining each industrial agent's data privacy. This framework applies a filter-based Pearson correlation coefficient (PCC) feature selection technique for selecting potential features to reduce complexity and improve the model performance. The proposed model has been evaluated with the recent DDoS attacks dataset, CICDDoS2019, and achieves great accuracy of 98.37\% with a computational time of 3.917 ms.},
	booktitle = {2022 13th {International} {Conference} on {Information} and {Communication} {Technology} {Convergence} ({ICTC})},
	author = {Zainudin, Ahmad and Akter, Rubina and Kim, Dong-Seong and Lee, Jae-Min},
	month = oct,
	year = {2022},
	note = {ISSN: 2162-1241},
	keywords = {Computational modeling, DDoS classification, Data privacy, Denial-of-service attack, Feature extraction, Fourth Industrial Revolution, IIoT, Information and communication technology, SDN, Servers, federated learning},
	pages = {1279--1283},
}

@inproceedings{he_lightweight_2022,
	title = {Lightweight network intrusion detection method based on improved federated learning},
	volume = {12288},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12288/122881M/Lightweight-network-intrusion-detection-method-based-on-improved-federated-learning/10.1117/12.2641086.full},
	doi = {10.1117/12.2641086},
	abstract = {Computer network has been widely used in all walks of life, network security has also received unprecedented attention, network intrusion detection technology is one of the key technologies to maintain network security. Traditional intrusion detection methods based on rules have some disadvantages, such as dependence on manual intervention, difficulty in updating rules database, and difficulty in detecting unknown intrusion. Therefore, a lightweight network intrusion detection method is designed based on improved federated learning. Firstly a network intrusion detection model is constructed based on improved federated learning to realize lightweight network intrusion detection. The experimental results show that the designed network intrusion detection method has good detection effect and has certain application value, which can be used as a reference for subsequent network intrusion detection.},
	urldate = {2022-12-14},
	booktitle = {International {Conference} on {Computer}, {Artificial} {Intelligence}, and {Control} {Engineering} ({CAICE} 2022)},
	publisher = {SPIE},
	author = {He, Yang and Jia, Yongliang and Tao, Peng},
	month = dec,
	year = {2022},
	pages = {394--399},
}

@article{pourahmadi_spotting_2022,
	title = {Spotting {Anomalies} at the {Edge}: {Outlier} {Exposure}-based {Cross}-silo {Federated} {Learning} for {DDoS} {Detection}},
	issn = {1941-0018},
	shorttitle = {Spotting {Anomalies} at the {Edge}},
	doi = {10.1109/TDSC.2022.3224896},
	abstract = {Distributed Denial-of-Service (DDoS) attacks are expected to continue plaguing service availability in emerging networks which rely on distributed edge clouds to offer critical, latency-sensitive applications. However, edge servers increase the network attack surface, which is exacerbated with the massive number of connected Internet of Things (IoT) devices that can be weaponized to launch DDoS attacks. Therefore, it is crucial to detect DDoS attacks early, i.e., at the network edge. In this paper, we empower the network edge with intelligent DDoS detection by learning from similarities between different data and DDoS attacks available across the edge servers. To this end, we develop a novel Outlier Exposure (OE)-enabled cross-silo Federated Learning framework, namely FedOE. FedOE enables distributed training of OE-based ML models using a limited number of labeled outliers (i.e., attack flows) experienced at edge servers. We propose a novel OE-based Autoencoder (oAE) that can better discriminate anomalies in comparison to the widely adopted traditional Autoencoder, using a tailored, OE-based loss function. We evaluate oAE in FedOE and demonstrate its ability to generalize to zero-day attacks, with just 50 labeled attack flows per edge server. The results show that oAE achieves a high F1-score for most DDoS attacks, outclassing its non-OE counterpart.},
	journal = {IEEE Transactions on Dependable and Secure Computing},
	author = {Pourahmadi, Vahid and Alameddine, Hyame Assem and Salahuddin, Mohammad A. and Boutaba, Raouf},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Dependable and Secure Computing},
	keywords = {Anomaly detection, Computer crime, DDoS detection, Data models, Denial-of-service attack, Edge intelligence, Image edge detection, Servers, Training, anomaly detection, federated learning, outlier exposure},
	pages = {1--14},
}

@misc{hendrycks_deep_2019,
	title = {Deep {Anomaly} {Detection} with {Outlier} {Exposure}},
	url = {http://arxiv.org/abs/1812.04606},
	doi = {10.48550/arXiv.1812.04606},
	abstract = {It is important to detect anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). This enables anomaly detectors to generalize and detect unseen anomalies. In extensive experiments on natural language processing and small- and large-scale vision tasks, we find that Outlier Exposure significantly improves detection performance. We also observe that cutting-edge generative models trained on CIFAR-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; we use OE to mitigate this issue. We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance.},
	urldate = {2022-12-14},
	publisher = {arXiv},
	author = {Hendrycks, Dan and Mazeika, Mantas and Dietterich, Thomas},
	month = jan,
	year = {2019},
	note = {arXiv:1812.04606 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{fang_aflguard_2022,
	address = {New York, NY, USA},
	series = {{ACSAC} '22},
	title = {{AFLGuard}: {Byzantine}-robust {Asynchronous} {Federated} {Learning}},
	isbn = {978-1-4503-9759-9},
	shorttitle = {{AFLGuard}},
	url = {https://doi.org/10.1145/3564625.3567991},
	doi = {10.1145/3564625.3567991},
	abstract = {Federated learning (FL) is an emerging machine learning paradigm, in which clients jointly learn a model with the help of a cloud server. A fundamental challenge of FL is that the clients are often heterogeneous, e.g., they have different computing powers, and thus the clients may send model updates to the server with substantially different delays. Asynchronous FL aims to address this challenge by enabling the server to update the model once any client’s model update reaches it without waiting for other clients’ model updates. However, like synchronous FL, asynchronous FL is also vulnerable to poisoning attacks, in which malicious clients manipulate the model via poisoning their local data and/or model updates sent to the server. Byzantine-robust FL aims to defend against poisoning attacks. In particular, Byzantine-robust FL can learn an accurate model even if some clients are malicious and have Byzantine behaviors. However, most existing studies on Byzantine-robust FL focused on synchronous FL, leaving asynchronous FL largely unexplored. In this work, we bridge this gap by proposing AFLGuard, a Byzantine-robust asynchronous FL method. We show that, both theoretically and empirically, AFLGuard is robust against various existing and adaptive poisoning attacks (both untargeted and targeted). Moreover, AFLGuard outperforms existing Byzantine-robust asynchronous FL methods.},
	urldate = {2022-12-14},
	booktitle = {Proceedings of the 38th {Annual} {Computer} {Security} {Applications} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Fang, Minghong and Liu, Jia and Gong, Neil Zhenqiang and Bentley, Elizabeth S.},
	year = {2022},
	keywords = {Byzantine Robustness, Federated Learning, Poisoning Attacks},
	pages = {632--646},
}

@inproceedings{wang_enidrift_2022,
	address = {New York, NY, USA},
	series = {{ACSAC} '22},
	title = {{ENIDrift}: {A} {Fast} and {Adaptive} {Ensemble} {System} for {Network} {Intrusion} {Detection} under {Real}-world {Drift}},
	isbn = {978-1-4503-9759-9},
	shorttitle = {{ENIDrift}},
	url = {https://doi.org/10.1145/3564625.3567992},
	doi = {10.1145/3564625.3567992},
	abstract = {Machine Learning (ML) techniques have been widely applied for network intrusion detection. However, existing ML-based network intrusion detection systems (NIDSs) suffer from fundamental limitations that hinder them from being deployed in the real world. They consider a narrow scope rather than real-world drift that involves dynamically distributed network packets and well-crafted ML attacks. Besides, they pose high runtime overhead and have low processing speed. In this paper, we solve the limitations and design ENIDrift, a fast and adaptive ensemble system for real-world network intrusion detection. ENIDrift employs iP2V, a novel incremental feature extraction method based on network packet fields, which adopts a simple three-layer neural network with relatively lightweight computation and achieves high efficiency. ENIDrift uses a stable sub-classifier generation module that constructs new sub-classifiers based on the stability and accuracy of incoming data chunks, and its training time is reduced from to . We extend the threat model and place experiments in real-world settings. We make the first real-world drift dataset, RWDIDS, which contains intense and different drifts for NIDS. Our extensive evaluation under real-world drift demonstrates that ENIDrift significantly outperforms the state-of-the-art solutions by up to 69.78\% of F1 and reduces running time by 87.6\%. ENIDrift achieves a 100\% F1 against our adversarial attack and is adaptive to various real-world drifts. Our field test also shows ENIDrift functions well even with delayed, inadequate training data, which is practical for real-world usage.},
	urldate = {2022-12-14},
	booktitle = {Proceedings of the 38th {Annual} {Computer} {Security} {Applications} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Xian},
	year = {2022},
	keywords = {Anomaly Detection, Concept Drift, Ensemble Learning, Network Intrusion Detection, Network Security},
	pages = {785--798},
}

@article{gao_sverifl_2023,
	title = {{SVeriFL}: {Successive} verifiable federated learning with privacy-preserving},
	volume = {622},
	issn = {0020-0255},
	shorttitle = {{SVeriFL}},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025522014359},
	doi = {10.1016/j.ins.2022.11.124},
	abstract = {With federated learning, one of the most notable features is that it can update global model parameter without using the users’ local data. However, various security and privacy problems still exist in the process of federated learning. The problem of devising a secure and verifiable federated learning framework, so as to obtain high performance federated learning model and protect right and interests of participants has not been sufficiently studied, the malicious server may conduct dishonest data aggregation and return incorrect aggregated gradients to all the participants. What is more, the server with ulterior motives may return correct aggregated results to some participants, but return wrong results to the specific participant. To solve the above problems, we propose the SVeriFL, a successive verifiable federated learning with privacy-preserving in this work. In specific, an elaborately designed protocol based on BLS signature and multi-party security is introduced, such that the integrity of parameter uploaded by participant and correctness of aggregated results of server can be verified; the consistency of aggregation results received from server between any multiple participants can also be testified. Moreover, the CKKS approximate homomorphic encryption is used to protect data privacy of the participant. Experimental results and analyses validate the practical performance and computation efficiency of the presented SVeriFL.},
	language = {en},
	urldate = {2022-12-14},
	journal = {Information Sciences},
	author = {Gao, Hang and He, Ningxin and Gao, Tiegang},
	month = apr,
	year = {2023},
	keywords = {Approximate homomorphic encryption, Privacy-preserving, Successive verifiable federated learning},
	pages = {98--114},
}

@article{qi_fedbkd_2022,
	title = {{FedBKD}: {Heterogenous} {Federated} {Learning} {Via} {Bidirectional} {Knowledge} {Distillation} for {Modulation} {Classification} in {IoT}-{Edge} {System}},
	issn = {1941-0484},
	shorttitle = {{FedBKD}},
	doi = {10.1109/JSTSP.2022.3224597},
	abstract = {Benefit from the rapid evolution of artificial intelligence and wireless communication technology, diverse Internet of Things (IoT) devices with edge computing ability have widely penetrated every aspect of daily human life. However, the deviations of private datasets and the heterogeneity of local models caused by the difference in device composition and application scenarios have hampering the aggregation of global recognition model in modulation classification task, thus constraining the classification performance of intelligent IoT-edge devices severely. To address this problem, we propose a heterogenous Federated learning framework based on Bidirectional Knowledge Distillation (FedBKD) for IoT system, which integrates knowledge distillation into the local model upload (client-to-cloud) and global model download (cloud-to-client) steps of federated learning. The client-to-cloud distillation is regarded as a process of multi-teacher knowledge distillation and the global network is regarded as a student network that unifies the heterogeneous knowledge from multiple local teacher networks. A public dataset is generated by conditional variational autoencoder (CVAE) and stored in the cloud server for supporting the obtaining of heterogeneous knowledge without sharing the private data of IoT devices. The cloud-to-client distillation is single-teacher-multiple-students process, which distills the knowledge from the single global model back to multiple heterogeneous local networks and partial knowledge distillation is used in this process. We implement our FedBKD method in the modulation classification task and the simulation results have proven the effectiveness of our proposed method.},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Qi, Peihan and Zhou, Xiaoyu and Ding, Yuanlei and Zhang, Zhengyu and Zheng, Shilian and Li, Zan},
	year = {2022},
	note = {Conference Name: IEEE Journal of Selected Topics in Signal Processing},
	keywords = {Adaptation models, Data models, Federated learning, Internet of Things, IoT, Knowledge engineering, Modulation, Training, conditional variational autoencoder, federated learning, knowledge distillation, model heterogeneity},
	pages = {1--16},
}

@article{putra_trust_nodate,
	title = {Trust and {Reputation} {Management} for {Blockchain}-enabled {IoT}},
	abstract = {In recent years, there has been an increasing interest in incorporating blockchain for the Internet of Things (IoT) to address the inherent issues of IoT, such as single point of failure and data silos. However, blockchain alone cannot ascertain the authenticity and veracity of the data coming from IoT devices. The append-only nature of blockchain exacerbates this issue, as it would not be possible to alter the data once recorded onchain. Trust and Reputation Management (TRM) is an effective approach to overcome the aforementioned trust issues. However, designing TRM frameworks for blockchain-enabled IoT applications is a non-trivial task, as each application has its unique trust challenges with their unique features and requirements. In this paper, we present our experiences in designing TRM framework for various blockchain-enabled IoT applications to provide insights and highlight open research challenges for future opportunities.},
	language = {en},
	author = {Putra, Guntur Dharma and Malik, Sidra and Dedeoglu, Volkan and Kanhere, Salil S and Jurdak, Raja},
	keywords = {⛔ No DOI found},
}

@inproceedings{patel_detection_2022,
	title = {Detection of {Intrusions} using {Support} {Vector} {Machines} and {Deep} {Neural} {Networks}},
	doi = {10.1109/ICRITO56286.2022.9964756},
	abstract = {An Intrusion detection system (IDS) plays a role in network intrusion detection through network data analysis, and high detection accuracy, precision, and recall are required to detect intrusions. Also, various techniques such as expert systems, data mining, and state transition analysis are used for network data analysis. The paper compares the detection effects of the two IDS methods using data mining. The first technique is a support vector machine (SVM), a machine learning algorithm; the second is a deep neural network (DNN), one of the artificial neural network models. The accuracy, precision, and recall were calculated and compared using NSL-KDD training and validation data, which is widely used in intrusion detection to compare the detection effects of the two techniques. DNN shows slightly higher accuracy than the SVM model. The risk of recognizing an actual intrusion as normal data is much greater than the risk of considering normal data as an intrusion, so DNN proves to be much more effective in intrusion detection than SVM.},
	booktitle = {2022 10th {International} {Conference} on {Reliability}, {Infocom} {Technologies} and {Optimization} ({Trends} and {Future} {Directions}) ({ICRITO})},
	author = {Patel, N D and Mehtre, B M and Wankar, Rajeev},
	month = oct,
	year = {2022},
	keywords = {Advanced Persistent Threat (APT), Data analysis, Deep Neural Network (DNN), Deep learning, Intrusion Detection System (IDS), Intrusion detection, Machine Learning, Market research, NSL-KDD, Network intrusion detection, Support Vector Machine (SVM), Support vector machines, Training},
	pages = {1--5},
}

@article{cui_wasserstein_nodate,
	title = {A {WASSERSTEIN} {GAN} {BASED} {FRAMEWORK} {FOR} {ADVERSARIAL} {ATTACKS} {AGAINST} {INTRUSION} {DETECTION} {SYSTEMS}},
	language = {en},
	author = {Cui, Fangda},
	keywords = {⛔ No DOI found},
}

@article{guo_seeing_2023,
	title = {Seeing is believing: {Towards} interactive visual exploration of data privacy in federated learning},
	volume = {60},
	issn = {0306-4573},
	shorttitle = {Seeing is believing},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457322002631},
	doi = {10.1016/j.ipm.2022.103162},
	abstract = {Federated learning (FL), as a popular distributed machine learning paradigm, has driven the integration of knowledge in ubiquitous data owners under one roof. Although designed for privacy-preservation by nature, the supposed well-sanitized parameters still convey sensitive information (e.g., reconstruction attack), while existing technical countermeasures provide weak explainability for privacy understanding and protection practices of general users. This work investigates these privacy concerns with an exploratory study and elaborates on data owners’ expectations in FL. Based on the analysis, we design the first interactive visualization system for FL privacy that supports intelligible privacy inspection and adjustment for data owners. Specifically, our proposal facilitates sample recommendation for joint privacy–performance training at cold start. Then it provides visual interpretation and attention rendering of privacy risks in view of multiple attacking channels and a holistic view. Further it supports interactive privacy enhancement involving both user initiative and differential privacy technique, and iterative trade-off with real-time inference accuracy estimation. We evaluate the effectiveness of the system and collect qualitative feedbacks from users. The results demonstrate that 96.7\% of users acknowledge the benefits to privacy inspection and adjustment and 90.3\% are willing to use our system. More importantly, 87.1\% increase the willingness of contributing data for FL.},
	language = {en},
	number = {2},
	urldate = {2022-12-14},
	journal = {Information Processing \& Management},
	author = {Guo, Yeting and Liu, Fang and Zhou, Tongqing and Cai, Zhiping and Xiao, Nong},
	month = mar,
	year = {2023},
	keywords = {Federated learning, Privacy protection, Visualization},
	pages = {103162},
}

@article{verma_fldid_2022,
	title = {{FLDID}: {Federated} {Learning} {Enabled} {Deep} {Intrusion} {Detection} in {Smart} {Manufacturing} {Industries}},
	volume = {22},
	issn = {1424-8220},
	shorttitle = {{FLDID}},
	url = {https://www.mdpi.com/1424-8220/22/22/8974},
	doi = {10.3390/s22228974},
	abstract = {The rapid development in manufacturing industries due to the introduction of IIoT devices has led to the emergence of Industry 4.0 which results in an industry with intelligence, increased efﬁciency and reduction in the cost of manufacturing. However, the introduction of IIoT devices opens up the door for a variety of cyber threats in smart industries. The detection of cyber threats against such extensive, complex, and heterogeneous smart manufacturing industries is very challenging due to the lack of sufﬁcient attack traces. Therefore, in this work, a Federated Learning enabled Deep Intrusion Detection framework is proposed to detect cyber threats in smart manufacturing industries. The proposed FLDID framework allows multiple smart manufacturing industries to build a collaborative model to detect threats and overcome the limited attack example problem with individual industries. Moreover, to ensure the privacy of model gradients, Paillier-based encryption is used in communication between edge devices (representative of smart industries) and the server. The deep learning-based hybrid model, which consists of a Convolutional Neural Network, Long Short Term Memory, and Multi-Layer Perceptron is used in the intrusion detection model. An exhaustive set of experiments on the publically available dataset proves the effectiveness of the proposed framework for detecting cyber threats in smart industries over the state-of-the-art approaches.},
	language = {en},
	number = {22},
	urldate = {2022-12-14},
	journal = {Sensors},
	author = {Verma, Priyanka and Breslin, John G. and O’Shea, Donna},
	month = nov,
	year = {2022},
	pages = {8974},
}

@article{zangrandi_stepping_2020,
	title = {Stepping out of the {MUD}: {Contextual} threat information for {IoT} devices with manufacturer-provided behaviour profiles},
	abstract = {Besides coming with unprecedented benefits, the Internet of Things (IoT) suffers deficits in security measures, leading to attacks increasing every year. In particular, network environments such as smart homes lack managed security capabilities to detect IoT-related attacks; IoT devices hosted therein are thus more easily infiltrated by threats. As such, context awareness on IoT infections is hard to achieve, preventing prompt response. In this work, we propose MUDscope, an approach to monitor malicious network activities affecting IoT in real-world consumer environments. We leverage the recent Manufacturer Usage Description (MUD) specification, which defines networking whitelists for IoT devices in MUD profiles, to reflect consistent and necessarily-anomalous activities from smart things. Our approach characterizes this traffic and extracts signatures for given attacks. By analyzing attack signatures for multiple devices, we gather insights into emerging attack patterns. We evaluate our approach on both an existing dataset, and a new openly available dataset created for this research. We show that MUDscope detects several attacks targeting IoT devices with an F1-score of 95.77\% and correctly identifies signatures for specific attacks with an F1-score of 87.72\%.},
	language = {en},
	author = {Zangrandi, Luca Morgese and van Ede, Thijs and Booij, Tim and Sciancalepore, Savio and Allodi, Luca and Continella, Andrea},
	year = {2020},
	keywords = {\_read\_urgently, ⛔ No DOI found},
	pages = {15},
}

@misc{sarhan_cyber_2021,
	title = {A {Cyber} {Threat} {Intelligence} {Sharing} {Scheme} based on {Federated} {Learning} for {Network} {Intrusion} {Detection}},
	url = {http://arxiv.org/abs/2111.02791},
	doi = {10.48550/arXiv.2111.02791},
	abstract = {The uses of Machine Learning (ML) in detection of network attacks have been effective when designed and evaluated in a single organisation. However, it has been very challenging to design an ML-based detection system by utilising heterogeneous network data samples originating from several sources. This is mainly due to privacy concerns and the lack of a universal format of datasets. In this paper, we propose a collaborative federated learning scheme to address these issues. The proposed framework allows multiple organisations to join forces in the design, training, and evaluation of a robust ML-based network intrusion detection system. The threat intelligence scheme utilises two critical aspects for its application; the availability of network data traffic in a common format to allow for the extraction of meaningful patterns across data sources. Secondly, the adoption of a federated learning mechanism to avoid the necessity of sharing sensitive users' information between organisations. As a result, each organisation benefits from other organisations cyber threat intelligence while maintaining the privacy of its data internally. The model is trained locally and only the updated weights are shared with the remaining participants in the federated averaging process. The framework has been designed and evaluated in this paper by using two key datasets in a NetFlow format known as NF-UNSW-NB15-v2 and NF-BoT-IoT-v2. Two other common scenarios are considered in the evaluation process; a centralised training method where the local data samples are shared with other organisations and a localised training method where no threat intelligence is shared. The results demonstrate the efficiency and effectiveness of the proposed framework by designing a universal ML model effectively classifying benign and intrusive traffic originating from multiple organisations without the need for local data exchange.},
	urldate = {2022-12-09},
	publisher = {arXiv},
	author = {Sarhan, Mohanad and Layeghy, Siamak and Moustafa, Nour and Portmann, Marius},
	month = nov,
	year = {2021},
	note = {arXiv:2111.02791 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Networking and Internet Architecture},
}

@book{oppliger_ssl_2016,
	address = {Boston},
	edition = {Second edition},
	series = {Artech {House} information security and privacy series},
	title = {{SSL} and {TLS}: theory and practice},
	isbn = {978-1-60807-998-8},
	shorttitle = {{SSL} and {TLS}},
	language = {en},
	publisher = {Artech House},
	author = {Oppliger, Rolf},
	year = {2016},
	note = {OCLC: ocn951909923},
	keywords = {Computer networks, Security measures},
}

@misc{zhang_dim-krum_2022,
	title = {Dim-{Krum}: {Backdoor}-{Resistant} {Federated} {Learning} for {NLP} with {Dimension}-wise {Krum}-{Based} {Aggregation}},
	shorttitle = {Dim-{Krum}},
	url = {http://arxiv.org/abs/2210.06894},
	abstract = {Despite the potential of federated learning, it is known to be vulnerable to backdoor attacks. Many robust federated aggregation methods are proposed to reduce the potential backdoor risk. However, they are mainly validated in the CV ﬁeld. In this paper, we ﬁnd that NLP backdoors are hard to defend against than CV, and we provide a theoretical analysis that the malicious update detection error probabilities are determined by the relative backdoor strengths. NLP attacks tend to have small relative backdoor strengths, which may result in the failure of robust federated aggregation methods for NLP attacks. Inspired by the theoretical results, we can choose some dimensions with higher backdoor strengths to settle this issue. We propose a novel federated aggregation algorithm, Dim-Krum, for NLP tasks, and experimental results validate its effectiveness.},
	language = {en},
	urldate = {2022-10-18},
	publisher = {arXiv},
	author = {Zhang, Zhiyuan and Su, Qi and Sun, Xu},
	month = oct,
	year = {2022},
	note = {arXiv:2210.06894 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@article{lin_privacy-enhanced_2022,
	title = {Privacy-{Enhanced} {Intrusion} {Detection} and {Defense} for {Cyber}-{Physical} {Systems}: {A} {Deep} {Reinforcement} {Learning} {Approach}},
	volume = {2022},
	issn = {1939-0122, 1939-0114},
	shorttitle = {Privacy-{Enhanced} {Intrusion} {Detection} and {Defense} for {Cyber}-{Physical} {Systems}},
	url = {https://www.hindawi.com/journals/scn/2022/4996427/},
	doi = {10.1155/2022/4996427},
	abstract = {Cyber-physical systems (CPSs) will play an important role in future real-world applications through the deep integration of computing, communication, and control technologies. CPSs are increasingly deployed in critical infrastructure, industry, and homes to achieve a smart grid, smart transportation, and smart healthcare and to bring many benefits to citizens, businesses, and governments. However, the openness and complexity brought by network and wireless communication technology, as well as the intelligence and dynamic of network intrusions make CPS more vulnerable to network intrusions and bring more serious threats to human life, enterprise productivity, and national security. Therefore, intrusion detection and defense in CPS have attracted considerable attention and have become a fundamental aspect of CPS security. However, a new challenging problem arises: how to improve the efficiency and accuracy of intrusion detection while protecting user privacy during the intrusion detection process. To address this challenge, we propose a deep reinforcement learning-based privacy-enhanced intrusion detection and defense mechanism (PIDD) for CPS. The PIDD is composed of three modules: privacy-enhanced topology graphs generation module, graph convolutional networks-based user evaluation module, and the deep reinforcement learning-based intruder identification and handling module. The experimental results show that the proposed PIDD achieves excellent performance in intrusion detection accuracy, intrusion defense percentage, and privacy protection.},
	language = {en},
	urldate = {2022-10-18},
	journal = {Security and Communication Networks},
	author = {Lin, Qingyuan and Ming, Rui and Zhang, Kailing and Luo, Haibo},
	editor = {Wu, Yulei},
	month = oct,
	year = {2022},
	pages = {1--9},
}

@article{huang_eefed_2022,
	title = {{EEFED}: {Personalized} federated learning of {Execution}\&{Evaluation} dual network for {CPS} intrusion detection},
	issn = {1556-6021},
	shorttitle = {{EEFED}},
	doi = {10.1109/TIFS.2022.3214723},
	abstract = {In the modern interconnected world, intelligent networks and computing technologies are increasingly being incorporated in industrial systems. However, this adoption of advanced technology has resulted in increased cyber threats to cyber-physical systems. Existing intrusion detection systems are continually challenged by constantly evolving cyber threats. Machine learning algorithms have been applied for intrusion detection. In these techniques, a classification model is trained by learning cyber behavior patterns. However, these models typically require considerable high-quality datasets. Limited attack samples are available because of the unpredictability and constant evolution of cyber threats. To address these problems, we propose a novel federated Execution\&Evaluation dual network framework (EEFED), which allows multiple federal participants to personalize their local detection models undermining the original purpose of Federated Learning. Thus, a general global detection model was developed for collaboratively improving the performance of a single local model against cyberattacks. The proposed personalized update algorithm and the optimizing backtracking parameters replacement policy effectively reduced the negative influence of federated learning in imbalanced and non-i.i.d distribution of data. The proposed method improved model stability. Furthermore, extensive experiments conducted on a network dataset in various cyber scenarios revealed that the proposed method outperformed single model and state-of-the-art methods.},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Huang, Xianting and Liu, Jing and Lai, Yingxu and Mao, Beifeng and Lyu, Hongshuo},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Computational modeling, Computer crime, Data models, Federated learning, Intrusion detection, Security, Training, \_read, cyber security, cyber-physical system (CPS), intrusion detection, personalized model},
	pages = {1--1},
}

@misc{vucovich_anomaly_2022,
	title = {Anomaly {Detection} via {Federated} {Learning}},
	url = {http://arxiv.org/abs/2210.06614},
	abstract = {Machine learning has helped advance the ﬁeld of anomaly detection by incorporating classiﬁers and autoencoders to decipher between normal and anomalous behavior. Additionally, federated learning has provided a way for a global model to be trained with multiple clients’ data without requiring the client to directly share their data. This paper proposes a novel anomaly detector via federated learning to detect malicious network activity on a client’s server. In our experiments, we use an autoencoder with a classiﬁer in a federated learning framework to determine if the network activity is benign or malicious. By using our novel min-max scalar and sampling technique, called FedSam, we determined federated learning allows the global model to learn from each client’s data and, in turn, provide a means for each client to improve their intrusion detection system’s defense against cyber-attacks.},
	language = {en},
	urldate = {2022-10-18},
	publisher = {arXiv},
	author = {Vucovich, Marc and Tarcar, Amogh and Rebelo, Penjo and Gade, Narendra and Porwal, Ruchi and Rahman, Abdul and Redino, Christopher and Choi, Kevin and Nandakumar, Dhruv and Schiller, Robert and Bowen, Edward and West, Alex and Bhattacharya, Sanmitra and Veeramani, Balaji},
	month = oct,
	year = {2022},
	note = {arXiv:2210.06614 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Machine Learning, \_read},
}

@article{rahman_icn-iot_2023,
	title = {On the {ICN}-{IoT} with federated learning integration of communication: {Concepts}, security-privacy issues, applications, and future perspectives},
	volume = {138},
	issn = {0167-739X},
	shorttitle = {On the {ICN}-{IoT} with federated learning integration of communication},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X22002667},
	doi = {10.1016/j.future.2022.08.004},
	abstract = {The individual and integration use of the Internet of Things (IoT), Information-Centric Networking (ICN), and Federated Learning (FL) have recently been used in several network-related scenarios and have consequently experienced a growing interest in the research community. Federated learning addresses the privacy and security issues of the IoT data in a decentralized manner. Also, it can be capable of training the multiple learning algorithms through local content except for exchanging data through intelligent Artificial Intelligence (AI)-based algorithms. Moreover, in ICN, the content is retrieved and stored based on the content name rather than the content location address. On the other hand, it is challenging to support the massive IoT devices by the fifth generation (5G) mobile-cellular networks. Therefore, the cellular 6G networks are expected to increase the connection capabilities by 10–100 times over 5G, which necessitates a convergence of Communication, Computing, and Caching (3C). At the same time, the in-network caching capabilities of ICN can be attractive features for IoT networks. IoT aspires to link anybody and/or everything at any time and location. However, integrating IoT with different areas is a new academic topic and is still in its infancy. As a result, this research highlights the potential of ICN for IoTs by conducting an exhaustive literature review. This work provides a comprehensive survey regarding these three recent research trends (i.e., FL, IoT, and ICN) and reviews the related state-of-the-art literature. We first describe the main features of each technology and discuss their most common and used variants. Furthermore, we envision the integration of such technologies to take advantage efficiently. Indeed, we consider their group-wise (FL-ICN-IoT) utilization based on the need for more robust security and privacy. Additionally, we cover the application fields of these technologies both individually and combinedly. Finally, we discuss the open issues of the reviewed research and describe potential directions for future avenues regarding integrating IoT, ICN, and FL technologies.},
	language = {en},
	urldate = {2022-09-28},
	journal = {Future Generation Computer Systems},
	author = {Rahman, Anichur and Hasan, Kamrul and Kundu, Dipanjali and Islam, Md. Jahidul and Debnath, Tanoy and Band, Shahab S. and Kumar, Neeraj},
	month = jan,
	year = {2023},
	keywords = {Artificial Intelligence, Communication, Computing, Confidentiality, Federated Learning, Information-Centric Networking, Internet of Things, Machine Learning, Privacy, Security, \_done},
	pages = {61--88},
}

@misc{nardi_anomaly_2022,
	title = {Anomaly {Detection} through {Unsupervised} {Federated} {Learning}},
	url = {http://arxiv.org/abs/2209.04184},
	abstract = {Federated learning (FL) is proving to be one of the most promising paradigms for leveraging distributed resources, enabling a set of clients to collaboratively train a machine learning model while keeping the data decentralized. The explosive growth of interest in the topic has led to rapid advancements in several core aspects like communication efficiency, handling non-IID data, privacy, and security capabilities. However, the majority of FL works only deal with supervised tasks, assuming that clients' training sets are labeled. To leverage the enormous unlabeled data on distributed edge devices, in this paper, we aim to extend the FL paradigm to unsupervised tasks by addressing the problem of anomaly detection in decentralized settings. In particular, we propose a novel method in which, through a preprocessing phase, clients are grouped into communities, each having similar majority (i.e., inlier) patterns. Subsequently, each community of clients trains the same anomaly detection model (i.e., autoencoders) in a federated fashion. The resulting model is then shared and used to detect anomalies within the clients of the same community that joined the corresponding federated process. Experiments show that our method is robust, and it can detect communities consistent with the ideal partitioning in which groups of clients having the same inlier patterns are known. Furthermore, the performance is significantly better than those in which clients train models exclusively on local data and comparable with federated models of ideal communities' partition.},
	language = {en},
	urldate = {2022-09-29},
	publisher = {arXiv},
	author = {Nardi, Mirko and Valerio, Lorenzo and Passarella, Andrea},
	month = sep,
	year = {2022},
	note = {arXiv:2209.04184 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@incollection{grieco_towards_2020,
	address = {Cham},
	title = {Towards {Named} {AI} {Networking}: {Unveiling} the {Potential} of {NDN} for {Edge} {AI}},
	volume = {12338},
	isbn = {978-3-030-61745-5 978-3-030-61746-2},
	shorttitle = {Towards {Named} {AI} {Networking}},
	url = {https://link.springer.com/10.1007/978-3-030-61746-2_2},
	abstract = {Thanks to recent advancements in edge computing, the traditional centralized cloud-based approach to deploy Artiﬁcial Intelligence (AI) techniques will be soon replaced or complemented by the so-called edge AI approach. By pushing AI at the network edge, close to the large amount of raw input data, the traﬃc traversing the core network as well as the inference latency can be reduced. Despite such neat beneﬁts, the actual deployment of edge AI across distributed nodes raises novel challenges to be addressed, such as the need to enforce proper addressing and discovery procedures, to identify AI components, and to chain them in an interoperable manner. Named Data Networking (NDN) has been recently argued as one of the main enablers of network and computing convergence, which edge AI should build upon. However, the peculiarities of such a new paradigm entails to go a step further. In this paper we disclose the potential of NDN to support the orchestration of edge AI. Several motivations are discussed, as well as the challenges which serve as guidelines for progress beyond the state of the art in this topic.},
	language = {en},
	urldate = {2022-09-29},
	booktitle = {Ad-{Hoc}, {Mobile}, and {Wireless} {Networks}},
	publisher = {Springer International Publishing},
	author = {Campolo, Claudia and Lia, Gianmarco and Amadeo, Marica and Ruggeri, Giuseppe and Iera, Antonio and Molinaro, Antonella},
	editor = {Grieco, Luigi Alfredo and Boggia, Gennaro and Piro, Giuseppe and Jararweh, Yaser and Campolo, Claudia},
	year = {2020},
	doi = {10.1007/978-3-030-61746-2_2},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {16--22},
}

@article{amadeo_ndne_2016,
	title = {{NDNe}: {Enhancing} {Named} {Data} {Networking} to {Support} {Cloudification} at the {Edge}},
	volume = {20},
	issn = {1558-2558},
	shorttitle = {{NDNe}},
	doi = {10.1109/LCOMM.2016.2597850},
	abstract = {The technological advances in mobile devices are pushing cloud computing to the network edge, where services such as data storage and processing can be offered by mobile devices locally with improved quality. In this letter, we identify named data networking (NDN) as a key enabler to support “by design” the peculiarities of decentralized edge clouds at the network layer. We extend NDN beyond its original scope of content retrieval facilitator, by letting names to address, not only “contents” but also “cloud services,” and enhancing the semantics of NDN primitives to efficiently and reliably support both the provider discovery and the service provisioning phases. An early evaluation is performed to showcase the benefits of the proposal, and also when compared with a traditional TCP/IP-based approach.},
	number = {11},
	journal = {IEEE Communications Letters},
	author = {Amadeo, Marica and Campolo, Claudia and Molinaro, Antonella},
	month = nov,
	year = {2016},
	note = {Conference Name: IEEE Communications Letters},
	keywords = {Cloud computing, Delays, Memory, Mobile communication, Mobile handsets, Named data networking, Semantics, Wireless communication, mobile cloud computing, mobile edge computing},
	pages = {2264--2267},
}

@inproceedings{sifalakis_information_2014,
	address = {New York, NY, USA},
	series = {{ACM}-{ICN} '14},
	title = {An information centric network for computing the distribution of computations},
	isbn = {978-1-4503-3206-4},
	url = {https://doi.org/10.1145/2660129.2660150},
	doi = {10.1145/2660129.2660150},
	abstract = {Named Function Networking (NFN) extends classic Information Centric Networking (ICN), such that in addition to resolving data access by name, it also supports the concept of function definition and application to data (or other functions) in the same resolution-by-name process. This empowers the network to select internally (optimal) places for fulfilling a potentially complex user expression. Forwarding optimization and routing policies become thereafter a basis of dynamic decisions for (re)-distributing computations, and retrieving results. In this paper we describe the intrinsic operations and mechanisms of an instantiation of NFN based on untyped Lambda expressions and Scala procedures. Then, we demonstrate through a series of proof-of-concept experiments how they extend the capabilities of an information centric network (CCN), for orchestrating and distributing data computations, and re-using cached results from previous computations. In the end we report and discuss the main observations stemming from these experiments and highlight important insights that can impact the architecting of ICN protocols that focus on named-data.},
	urldate = {2022-09-29},
	booktitle = {Proceedings of the 1st {ACM} {Conference} on {Information}-{Centric} {Networking}},
	publisher = {Association for Computing Machinery},
	author = {Sifalakis, Manolis and Kohler, Basil and Scherb, Christopher and Tschudin, Christian},
	month = sep,
	year = {2014},
	keywords = {information centric networking, named data networking, named-function networking, network architectures},
	pages = {137--146},
}

@inproceedings{mtibaa_compute-centric_2020,
	title = {Compute-{Centric} {Networking} {At} {The} {Edge}: {An} {Autonomous} {Driving} {Use}-{Case}},
	shorttitle = {Compute-{Centric} {Networking} {At} {The} {Edge}},
	doi = {10.1109/GIIS50753.2020.9248493},
	abstract = {This paper highlights the benefits of information-centric networking (ICN) and its named data networking (NDN) architecture for future edge computing applications in a multi-tenant multi-stakeholder ecosystem. We consider an exemplary scenario of autonomous driving to discuss open issues for efficient and timely distributed compute-centric networking. We discuss what NDN has to offer for efficient and resilient edge computing, and what needs to be done to augment NDN to move from an information-centric architecture to a compute-centric architecture. Based on the autonomous driving scenario, we identify security, naming, networking challenges, and discuss the different options to tackle these challenges and propose potential solutions.},
	booktitle = {2020 {Global} {Information} {Infrastructure} and {Networking} {Symposium} ({GIIS})},
	author = {Mtibaa, Abderrahmen},
	month = oct,
	year = {2020},
	note = {ISSN: 2150-329X},
	keywords = {Autonomous vehicles, Computer architecture, Edge computing, Information-centric networking, Resilience, Security, Synchronization},
	pages = {1--6},
}

@inproceedings{amadeo_client_2022,
	title = {Client {Discovery} and {Data} {Exchange} in {Edge}-based {Federated} {Learning} via {Named} {Data} {Networking}},
	doi = {10.1109/ICC45855.2022.9839172},
	abstract = {Federated learning (FL) is gaining momentum as a prominent solution to perform training procedures without the need to move sensitive end-user data to a centralized third party server. In FL, models are locally trained at distributed end-devices, acting as clients, and only model updates are transferred from the clients to the aggregator, which is in charge of global model aggregation. Although FL can ensure better privacy preservation than centralized machine learning (ML), it exhibits still some concerns. First, clients need to be properly discovered and selected to ensure that highly accurate models are built. Second, huge models may still require to be exchanged from the aggregator to all the selected clients, incurring a not negligible network footprint. To tackle such issues, in this paper, we propose a framework built upon in-network caching, multicast and name based data delivery, natively provided by the Named Data Networking (NDN) paradigm, in order to support client discovery and aggregator-clients data exchange. Benefits of the proposal are showcased when compared to a conventional application-layer solution.},
	booktitle = {{ICC} 2022 - {IEEE} {International} {Conference} on {Communications}},
	author = {Amadeo, Marica and Campolo, Claudia and Iera, Antonio and Molinaro, Antonella and Ruggeri, Giuseppe},
	month = may,
	year = {2022},
	note = {ISSN: 1938-1883},
	keywords = {Collaborative work, Edge Artificial Intelligence, Federated Learning, In-network caching, Information Centric Networking, Machine learning, Multicast communication, Named Data Networking, Packet loss, Privacy, Proposals, Training},
	pages = {2990--2995},
}

@inproceedings{bano_kafkafed_2022,
	title = {{KafkaFed}: {Two}-{Tier} {Federated} {Learning} {Communication} {Architecture} for {Internet} of {Vehicles}},
	shorttitle = {{KafkaFed}},
	doi = {10.1109/PerComWorkshops53856.2022.9767510},
	abstract = {In the current era of the Internet of Vehicles (IoV), vehicle to vehicle data sharing can provide customized applications for Connected and Autonomous Vehicles (CAVs). The advancement of Deep Learning (DL) methodologies is one of the key driving forces for CAVs, allowing elaborating a massive amount of data by the resource-constrained onboard devices. In a traditional centralized DL approach, vehicle data are transmitted to the cloud for the training of models. This approach leads to significant communication overhead, high delays, and data privacy concerns. Conversely, Federated Learning (FL) performs the training using the local models in a distributed fashion and mitigates the data privacy risks by sharing only the model parameters with the server, optimizing the FL to be used with resources-constrained devices. In this paper, we propose the design of a scalable communication infrastructure to support the FL procedure based on Information-Centric Networking (ICN) using Apache Kafka, called KafkaFed. The ICN-based infrastructure allows to overcome the shortcomings of current client-server architectures for FL, in which routing is content-based or name-based to achieve efficient data retrieval for mobile nodes. In ICN, data are stored at intermediate nodes to provide efficient and reliable data delivery. A proof of concept of the KafkaFed communication architecture is developed and tested in an emulated environment. The performance of the proposed framework compared to the client server-based FL architecture, i.e., FLOWER showed a boost of almost 40\% with just 32 clients in addition to several other advantages of scalability, reliability, and security},
	booktitle = {2022 {IEEE} {International} {Conference} on {Pervasive} {Computing} and {Communications} {Workshops} and other {Affiliated} {Events} ({PerCom} {Workshops})},
	author = {Bano, Saira and Tonellotto, Nicola and Cassarà, Pietro and Gotta, Alberto},
	month = mar,
	year = {2022},
	keywords = {Apache Kafka, Collaborative work, Computer architecture, Conferences, Connected and autonomous vehicles, Data models, Data privacy, Federated Learning, Publish/Subscribe model, Scalability, Training},
	pages = {515--520},
}

@article{chen_zero_2021,
	title = {Zero {Knowledge} {Clustering} {Based} {Adversarial} {Mitigation} in {Heterogeneous} {Federated} {Learning}},
	volume = {8},
	issn = {2327-4697},
	doi = {10.1109/TNSE.2020.3002796},
	abstract = {The simultaneous development of deep learning techniques and Internet of Things (IoT)/Cyber-physical Systems (CPS) technologies has afforded untold possibilities for improving distributed computing, sensing, and data analysis. Among these technologies, federated learning has received increased attention as a privacy-preserving collaborative learning paradigm, and has shown significant potential in IoT/CPS-driven large-scale smart-world systems. At the same time, the vulnerabilities of deep neural networks, especially to adversarial attacks, cannot be overstated and should not be minimized. Moreover, the distributed nature of federated learning makes defense against such adversarial attacks a more challenging problem due to the unavailability of local data and resource heterogeneity. To tackle these challenges, in this paper, we propose ZeKoC, a Zero Knowledge Clustering approach to mitigating adversarial attacks. Particularly, we first formulate the problem of resource-constrained adversarial mitigation. Specifically, noting that a global server has no access to training samples, we reformulate the unsupervised weight clustering problem. Our proposed ZeKoC approach allows the server to automatically split and merge weight clusters for weight selection and aggregation. Theoretical analysis demonstrates that convergence is guaranteed. Further, our experimental results illustrate that, in a non-i.i.d. (i.e., independent and identically distributed) data setting, the proposed ZeKoC approach successfully mitigates general attacks while outperforming state-of-art schemes.},
	number = {2},
	journal = {IEEE Transactions on Network Science and Engineering},
	author = {Chen, Zheyi and Tian, Pu and Liao, Weixian and Yu, Wei},
	month = apr,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Network Science and Engineering},
	keywords = {Data models, Distributed databases, Machine learning, Non-i.i.d. data, Peer-to-peer computing, Security, Servers, Training, adversarial mitigation, federated learning},
	pages = {1070--1083},
}

@misc{trocoso-pastoriza_orchestrating_2022,
	title = {Orchestrating {Collaborative} {Cybersecurity}: {A} {Secure} {Framework} for {Distributed} {Privacy}-{Preserving} {Threat} {Intelligence} {Sharing}},
	shorttitle = {Orchestrating {Collaborative} {Cybersecurity}},
	url = {http://arxiv.org/abs/2209.02676},
	abstract = {Cyber Threat Intelligence (CTI) sharing is an important activity to reduce information asymmetries between attackers and defenders. However, this activity presents challenges due to the tension between data sharing and conﬁdentiality, that result in information retention often leading to a free-rider problem. Therefore, the information that is shared represents only the tip of the iceberg. Current literature assumes access to centralized databases containing all the information, but this is not always feasible, due to the aforementioned tension. This results in unbalanced or incomplete datasets, requiring the use of techniques to expand them; we show how these techniques lead to biased results and misleading performance expectations. We propose a novel framework for extracting CTI from distributed data on incidents, vulnerabilities and indicators of compromise, and demonstrate its use in several practical scenarios, in conjunction with the Malware Information Sharing Platforms (MISP). Policy implications for CTI sharing are presented and discussed. The proposed system relies on an eﬃcient combination of privacy enhancing technologies and federated processing. This lets organizations stay in control of their CTI and minimize the risks of exposure or leakage, while enabling the beneﬁts of sharing, more accurate and representative results, and more eﬀective predictive and preventive defenses.},
	language = {en},
	urldate = {2022-09-12},
	publisher = {arXiv},
	author = {Trocoso-Pastoriza, Juan R. and Mermoud, Alain and Bouyé, Romain and Marino, Francesco and Bossuat, Jean-Philippe and Lenders, Vincent and Hubaux, Jean-Pierre},
	month = sep,
	year = {2022},
	note = {arXiv:2209.02676 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Databases},
}

@article{fotiadou_incidents_2020,
	title = {Incidents {Information} {Sharing} {Platform} for {Distributed} {Attack} {Detection}},
	volume = {1},
	issn = {2644-125X},
	doi = {10.1109/OJCOMS.2020.2989925},
	abstract = {Intrusion detection plays a critical role in cyber-security domain since malicious attacks cause irreparable damages to cyber-systems. In this work, we propose the I2SP prototype, which is a novel Information Sharing Platform, able to gather, pre-process, model, and distribute network-traffic information. Within the I2SP prototype we build several challenging deep feature learning models for network-traffic intrusion detection. The learnt representations will be utilized for classifying each new network measurement into its corresponding threat level. We evaluate our prototype's performance by conducting case studies using cyber-security data extracted from the Malware Information Sharing Platform (MISP)-API. To the best of our knowledge, we are the first that combine the MISP-API in order to construct an information sharing mechanism that supports multiple novel deep feature learning architectures for intrusion detection. Experimental results justify that the proposed deep feature learning techniques are able to predict accurately MISP threat-levels.},
	journal = {IEEE Open Journal of the Communications Society},
	author = {Fotiadou, Konstantina and Velivassaki, Terpsichori-Helen and Voulkidis, Artemis and Railis, Konstantinos and Trakadas, Panagiotis and Zahariadis, Theodore},
	year = {2020},
	note = {Conference Name: IEEE Open Journal of the Communications Society},
	keywords = {Anomaly detection, Computer architecture, Feature extraction, Intrusion detection, Malware, Malware information sharing platform, Prototypes, convolutional neural networks, deep feature learning, long-short memory neural networks, network intrusion detection, anomaly detection, stacked-sparse autoencoders},
	pages = {593--605},
}

@misc{bertoli_generalizing_2022,
	title = {Generalizing intrusion detection for heterogeneous networks: {A} stacked-unsupervised federated learning approach},
	shorttitle = {Generalizing intrusion detection for heterogeneous networks},
	url = {http://arxiv.org/abs/2209.00721},
	abstract = {The constantly evolving digital transformation imposes new requirements on our society. Aspects relating to reliance on the networking domain and the difficulty of achieving security by design pose a challenge today. As a result, data-centric and machine-learning approaches arose as feasible solutions for securing large networks. Although, in the network security domain, ML-based solutions face a challenge regarding the capability to generalize between different contexts. In other words, solutions based on specific network data usually do not perform satisfactorily on other networks. This paper describes the stacked-unsupervised federated learning (FL) approach to generalize on a cross-silo configuration for a flow-based network intrusion detection system (NIDS). The proposed approach we have examined comprises a deep autoencoder in conjunction with an energy flow classifier in an ensemble learning task. Our approach performs better than traditional local learning and naive cross-evaluation (training in one context and testing on another network data). Remarkably, the proposed approach demonstrates a sound performance in the case of non-iid data silos. In conjunction with an informative feature in an ensemble architecture for unsupervised learning, we advise that the proposed FL-based NIDS results in a feasible approach for generalization between heterogeneous networks. To the best of our knowledge, our proposal is the first successful approach to applying unsupervised FL on the problem of network intrusion detection generalization using flow-based data.},
	language = {en},
	urldate = {2022-09-12},
	publisher = {arXiv},
	author = {Bertoli, Gustavo de Carvalho and Junior, Lourenço Alves Pereira and Santos, Aldri Luiz dos and Saotome, Osamu},
	month = sep,
	year = {2022},
	note = {arXiv:2209.00721 [cs]},
	keywords = {Computer Science - Cryptography and Security, \_read\_urgently},
}

@misc{wang_federated_2022,
	title = {Federated {Multi}-{Discriminator} {BiWGAN}-{GP} based {Collaborative} {Anomaly} {Detection} for {Virtualized} {Network} {Slicing}},
	url = {http://arxiv.org/abs/2208.07985},
	abstract = {Virtualized network slicing allows a multitude of logical networks to be created on a common substrate infrastructure to support diverse services. A virtualized network slice is a logical combination of multiple virtual network functions, which run on virtual machines (VMs) as software applications by virtualization techniques. As the performance of network slices hinges on the normal running of VMs, detecting and analyzing anomalies in VMs are critical. Based on the three-tier management framework of virtualized network slicing, we ﬁrst develop a federated learning (FL) based three-tier distributed VM anomaly detection framework, which enables distributed network slice managers to collaboratively train a global VM anomaly detection model while keeping metrics data locally. The high-dimensional, imbalanced, and distributed data features in virtualized network slicing scenarios invalidate the existing anomaly detection models. Considering the powerful ability of generative adversarial network (GAN) in capturing the distribution from complex data, we design a new multi-discriminator Bidirectional Wasserstein GAN with Gradient Penalty (BiWGAN-GP) model to learn the normal data distribution from high-dimensional resource metrics datasets that are spread on multiple VM monitors. The multi-discriminator BiWGAN-GP model can be trained over distributed data sources, which avoids high communication and computation overhead caused by the centralized collection and processing of local data. We deﬁne an anomaly score as the discriminant criterion to quantify the deviation of new metrics data from the learned normal distribution to detect abnormal behaviors arising in VMs. The efﬁciency and effectiveness of the proposed collaborative anomaly detection algorithm are validated through extensive experimental evaluation on a real-world dataset.},
	language = {en},
	urldate = {2022-09-09},
	publisher = {arXiv},
	author = {Wang, Weili and Liang, Chengchao and Tang, Lun and Yanikomeroglu, Halim and Chen, Qianbin},
	month = aug,
	year = {2022},
	note = {arXiv:2208.07985 [cs]},
	keywords = {Computer Science - Networking and Internet Architecture},
}

@article{khan_federated-srus_2022,
	title = {Federated-{SRUs}: {A} {Federated} {Simple} {Recurrent} {Units}-based {IDS} for {Accurate} {Detection} of {Cyber} {Attacks} {Against} {IoT}-augmented {Industrial} {Control} {Systems}},
	issn = {2327-4662},
	shorttitle = {Federated-{SRUs}},
	doi = {10.1109/JIOT.2022.3200048},
	abstract = {The security of Industrial Control Systems (ICS) against cyber-attacks is essential in modern era since ICSs are vital constituent of modern societies and smart cities. However, the augmentation of legacy ICS networks with smart computing and networking technologies (such as, IoT) have intensely enlarged the surface of attacks against these critical infrastructures. This augmentation makes these networks more vulnerable to cyber-attacks and despite the current security solutions, attackers still find ways to proliferate these networks. Intrusion Detection System (IDS) is one of the key security aspect to prevent these networks from contemporary cyber-attacks. Therefore, this paper proposes a new IDS model named Federated-SRUs (simple recurrent units) for the security of IoT-based ICSs. Specifically, the Federated-SRUs IDS model uses an improved simple recurrent units architecture to reduce computational cost and alleviate the gradient vanishing issue in recurrent networks. Then, it performs data aggregation through several communication rounds in federated architecture which allows multiple ICS networks and stakeholders to build a comprehensive IDS model in a privacy-preserving manner. The performance of Federated-SRUs IDS model is validated through experiments using real-world gas pipeline-based ICS network data, which indicates that it is able to accurately detect intrusions in real-time without compromising privacy and security. Experiments also verify that the Federated-SRUs model outperforms existing state-of-the-art approaches and thus can serve as a viable IDS method in IoT-based ICS networks.},
	journal = {IEEE Internet of Things Journal},
	author = {Khan, Izhar Ahmed and Pi, Dechang and Abbas, Muhammad Zahid and Zia, Umar and Hussain, Yasir and Soliman, Hatem},
	year = {2022},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Computational modeling, Computer architecture, Data models, Industrial Internet of Things, Integrated circuits, Intrusion detection, IoT, Security, cyber-attacks, industrial control systems, industrial networks, intrusion detection},
	pages = {1--1},
}

@article{he_cgan-based_2022,
	title = {{CGAN}-{Based} {Collaborative} {Intrusion} {Detection} for {UAV} {Networks}: {A} {Blockchain} {Empowered} {Distributed} {Federated} {Learning} {Approach}},
	issn = {2327-4662},
	shorttitle = {{CGAN}-{Based} {Collaborative} {Intrusion} {Detection} for {UAV} {Networks}},
	doi = {10.1109/JIOT.2022.3200121},
	abstract = {Numerous resource-constrained IoT devices make the edge IoT consisting of UAVs vulnerable to network intrusion. Therefore, it’s critical to design an effective intrusion detection system (IDS). However, the differences in local data sets among UAVs show small samples and uneven distribution, further reducing the detection accuracy of network intrusion. This paper proposes a conditional generative adversarial nets (CGAN)-based collaborative intrusion detection algorithm with blockchain empowered distributed federated learning to solve the above problems. This study introduces long short-term memory (LSTM) into the CGAN training to improve the effect of generative networks. Based on the feature extraction ability of LSTM networks, the generated data with CGAN are used as augmented data and applied in the detection and classification of intrusion data. Distributed federated learning with differential privacy ensures data security and privacy and allows collaborative training of CGAN models using multiple distributed datasets. Blockchain stores and shares the training models to ensure security when the global model’s aggregation and updating. The proposed method has good generalization ability, which can greatly improve the detection of intrusion data.},
	journal = {IEEE Internet of Things Journal},
	author = {He, Xiaoqiang and Chen, Qianbin and Tang, Lun and Wang, Weili and Liu, Tong},
	year = {2022},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Blockchains, Collaborative work, Data models, Data privacy, Internet of Things, Intrusion detection, Training, UAV network, blockchain, conditional generative adversarial network, distributed federated learning, intrusion detection system, long short-term memory},
	pages = {1--1},
}

@misc{sun_dpauc_2022,
	title = {{DPAUC}: {Differentially} {Private} {AUC} {Computation} in {Federated} {Learning}},
	shorttitle = {{DPAUC}},
	url = {http://arxiv.org/abs/2208.12294},
	abstract = {Federated learning (FL) has gained signiﬁcant attention recently as a privacyenhancing tool to jointly train a machine learning model by multiple participants. The prior work on FL has mostly studied how to protect label privacy during model training. However, model evaluation in FL might also lead to potential leakage of private label information. In this work, we propose an evaluation algorithm that can accurately compute the widely used AUC (area under the curve) metric when using the label differential privacy (DP) in FL. Through extensive experiments, we show our algorithms can compute accurate AUCs compared to the ground truth.},
	language = {en},
	urldate = {2022-09-05},
	publisher = {arXiv},
	author = {Sun, Jiankai and Yang, Xin and Yao, Yuanshun and Xie, Junyuan and Wu, Di and Wang, Chong},
	month = aug,
	year = {2022},
	note = {arXiv:2208.12294 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@misc{severi_network-level_2022,
	title = {Network-{Level} {Adversaries} in {Federated} {Learning}},
	url = {http://arxiv.org/abs/2208.12911},
	abstract = {Federated learning is a popular strategy for training models on distributed, sensitive data, while preserving data privacy. Prior work identiﬁed a range of security threats on federated learning protocols that poison the data or the model. However, federated learning is a networked system where the communication between clients and server plays a critical role for the learning task performance. We highlight how communication introduces another vulnerability surface in federated learning and study the impact of network-level adversaries on training federated learning models. We show that attackers dropping the network trafﬁc from carefully selected clients can signiﬁcantly decrease model accuracy on a target population. Moreover, we show that a coordinated poisoning campaign from a few clients can amplify the dropping attacks. Finally, we develop a server-side defense which mitigates the impact of our attacks by identifying and up-sampling clients likely to positively contribute towards target accuracy. We comprehensively evaluate our attacks and defenses on three datasets, assuming encrypted communication channels and attackers with partial visibility of the network.},
	language = {en},
	urldate = {2022-09-05},
	publisher = {arXiv},
	author = {Severi, Giorgio and Jagielski, Matthew and Yar, Gökberk and Wang, Yuxuan and Oprea, Alina and Nita-Rotaru, Cristina},
	month = aug,
	year = {2022},
	note = {arXiv:2208.12911 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Networking and Internet Architecture},
}

@article{yang_dynamic_2022,
	title = {A dynamic global backbone updating for communication-efficient personalised federated learning},
	volume = {34},
	issn = {0954-0091, 1360-0494},
	url = {https://www.tandfonline.com/doi/full/10.1080/09540091.2022.2114428},
	doi = {10.1080/09540091.2022.2114428},
	abstract = {Federated learning (FL) is an emerging distributed machine learning technique. However, when dealing with heterogeneous data, a shared global model cannot generalise all devices’ local data. Furthermore, the FL training process necessitates frequent parameter communication, which interferes with the limited bandwidth and unstable connections of participating devices. These two issues have a significant impact on FL’s effectiveness and efficiency. In this paper, an enhanced communication-efficient personalised FL technique, FedGB, is proposed. Different from existing approaches, FedGB believes that only interacting common information from training results on different devices can improve local personalised training results more effectively. FedGB dynamically selects the backbone structures in the local models to represent the dynamically determined backbone information (common features) in the global model for aggregation. Only interacting common features between different nodes reduce the impact of heterogeneous data to a certain extent. The dynamic adaptive sub-model selection avoids the impact of manually setting the scale of sub-model. FedGB can thus reduce communication overheads while maintaining inference accuracy. The results obtained in a variety of experimental settings show that FedGB can effectively improve communication efficiency and inference accuracy.},
	language = {en},
	number = {1},
	urldate = {2022-09-01},
	journal = {Connection Science},
	author = {Yang, Zhao and Sun, Qingshuang},
	month = dec,
	year = {2022},
	pages = {2240--2264},
}

@misc{Xu2022a,
	title = {An {Efficient} and {Reliable} {Asynchronous} {Federated} {Learning} {Scheme} for {Smart} {Public} {Transportation}},
	url = {http://arxiv.org/abs/2208.07194},
	abstract = {Machine Learning (ML) is a distributed approach for training predictive models on the Internet of Vehicles (IoV) to enable smart public transportation. Since the trafﬁc conditions change over time, the ML model that predicts trafﬁc ﬂows and the time passengers wait at stops must be updated continuously and efﬁciently. Federated learning (FL) is a distributed machine learning scheme that allows vehicles to receive continuous model updates without having to upload raw data to the cloud and wait for models to be trained. However, FL in smart public transportation is vulnerable to poisoning or DDoS attacks since vehicles travel in public. Besides, due to device heterogeneity and imbalanced data distributions, the synchronized aggregation strategy that collects local models from speciﬁc vehicles before aggregation is inefﬁcient. Although Asynchronous Federated Learning (AFL) schemes are developed to improve efﬁciency by aggregating local models as soon as they are received, the stale local models remain unreasonably weighted, resulting in poor learning performance. To enable smarter public transportation, this paper offers a blockchainbased asynchronous federated learning scheme with a dynamic scaling factor (DBAFL). Speciﬁcally, the novel committee-based consensus algorithm for blockchain improves reliability at the lowest possible cost of time. Meanwhile, the devised dynamic scaling factor allows AFL to assign reasonable weight to stale local models. Extensive experiments conducted on heterogeneous devices validate outperformed learning performance, efﬁciency, and reliability of DBAFL.},
	language = {en},
	urldate = {2022-08-23},
	publisher = {arXiv},
	author = {Xu, Chenhao and Qu, Youyang and Luan, Tom H. and Eklund, Peter W. and Xiang, Yong and Gao, Longxiang},
	month = aug,
	year = {2022},
	note = {arXiv:2208.07194 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
}

@misc{Zheng2018,
	title = {Research {Datasets}: {Taxonomy} and {Empirical} {Analysis}},
	shorttitle = {Replication {Data} for},
	url = {https://dataverse.harvard.edu/citation?persistentId=doi:10.7910/DVN/4EPUIA},
	doi = {10.7910/DVN/4EPUIA},
	abstract = {We inspect 965 cybersecurity research papers published between 2012 and 2016 in order to understand better how datasets are used, produced and shared. We construct a taxonomy of the types of data created and shared, informed and validated by the examined papers. We then analyze the gathered data on datasets. Three quarters of existing datasets used as input to research are publicly available, but less than one ﬁfth of datasets created by researchers are publicly shared. Using a series of linear regressions, we demonstrate that those researchers who do make public the datasets they create are rewarded with more citations to the associated papers. Hence, we conclude that an under-appreciated incentive exists for researchers to share their created datasets with the broader research community.},
	language = {en},
	urldate = {2022-08-08},
	author = {Zheng, Muwei and Robbins, Hannah and Chai, Zimo and Thapa, Prakash and Moore, Tyler},
	year = {2018},
}

@misc{Zhao2022a,
	title = {Multi-{Agent} {Learning} for {Resilient} {Distributed} {Control} {Systems}},
	url = {http://arxiv.org/abs/2208.05060},
	abstract = {Resilience describes a system’s ability to function under disturbances and threats. Many critical infrastructures, including smart grids and transportation networks, are large-scale complex systems consisting of many interdependent subsystems. Decentralized architecture becomes a key resilience design paradigm for large-scale systems. In this book chapter, we present a multi-agent system (MAS) framework for distributed large-scale control systems and discuss the role of MAS learning in resiliency. This chapter introduces the creation of an artiﬁcial intelligence (AI) stack in the MAS to provide computational intelligence for subsystems to detect, respond, and recover. We discuss the application of learning methods at the cyber and physical layers of the system. The discussions focus on distributed learning algorithms for subsystems to respond to each other, and game-theoretic learning for them to respond to disturbances and adversarial behaviors. The book chapter presents a case study of distributed renewable energy systems to elaborate on the MAS architecture and its interface with the AI stack.},
	language = {en},
	urldate = {2022-08-16},
	publisher = {arXiv},
	author = {Zhao, Yuhan and Rieger, Craig and Zhu, Quanyan},
	month = aug,
	year = {2022},
	note = {arXiv:2208.05060 [cs, eess]},
	keywords = {Electrical Engineering and Systems Science - Systems and Control},
}

@misc{Zhang2022c,
	title = {{FLDetector}: {Defending} {Federated} {Learning} {Against} {Model} {Poisoning} {Attacks} via {Detecting} {Malicious} {Clients}},
	shorttitle = {{FLDetector}},
	url = {http://arxiv.org/abs/2207.09209},
	abstract = {Federated learning (FL) is vulnerable to model poisoning attacks, in which malicious clients corrupt the global model via sending manipulated model updates to the server. Existing defenses mainly rely on Byzantine-robust or provably robust FL methods, which aim to learn an accurate global model even if some clients are malicious. However, they can only resist a small number of malicious clients. It is still an open challenge how to defend against model poisoning attacks with a large number of malicious clients. Our FLDetector addresses this challenge via detecting malicious clients. FLDetector aims to detect and remove majority of the malicious clients such that a Byzantine-robust or provably robust FL method can learn an accurate global model using the remaining clients. Our key observation is that, in model poisoning attacks, the model updates from a client in multiple iterations are inconsistent. Therefore, FLDetector detects malicious clients via checking their model-updates consistency. Roughly speaking, the server predicts a client’s model update in each iteration based on historical model updates, and flags a client as malicious if the received model update from the client and the predicted model update are inconsistent in multiple iterations. Our extensive experiments on three benchmark datasets show that FLDetector can accurately detect malicious clients in multiple stateof-the-art model poisoning attacks and adaptive attacks tailored to FLDetector. After removing the detected malicious clients, existing Byzantine-robust FL methods can learn accurate global models. Our code is available at https://github.com/zaixizhang/FLDetector.},
	language = {en},
	urldate = {2022-08-12},
	publisher = {arXiv},
	author = {Zhang, Zaixi and Cao, Xiaoyu and Jia, Jinyuan and Gong, Neil Zhenqiang},
	month = jul,
	year = {2022},
	note = {arXiv:2207.09209 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
}

@misc{Xiong2022,
	title = {{FedDM}: {Iterative} {Distribution} {Matching} for {Communication}-{Efficient} {Federated} {Learning}},
	shorttitle = {{FedDM}},
	url = {http://arxiv.org/abs/2207.09653},
	abstract = {Federated learning (FL) has recently attracted increasing attention from academia and industry, with the ultimate goal of achieving collaborative training under privacy and communication constraints. Existing iterative model averaging based FL algorithms require a large number of communication rounds to obtain a wellperformed model due to extremely unbalanced and non-i.i.d data partitioning among different clients. Thus, we propose FedDM to build the global training objective from multiple local surrogate functions, which enables the server to gain a more global view of the loss landscape. In detail, we construct synthetic sets of data on each client to locally match the loss landscape from original data through distribution matching. FedDM reduces communication rounds and improves model quality by transmitting more informative and smaller synthesized data compared with unwieldy model weights. We conduct extensive experiments on three image classiﬁcation datasets, and results show that our method can outperform other FL counterparts in terms of efﬁciency and model performance. Moreover, we demonstrate that FedDM can be adapted to preserve differential privacy with Gaussian mechanism and train a better model under the same privacy budget.},
	language = {en},
	urldate = {2022-08-12},
	publisher = {arXiv},
	author = {Xiong, Yuanhao and Wang, Ruochen and Cheng, Minhao and Yu, Felix and Hsieh, Cho-Jui},
	month = jul,
	year = {2022},
	note = {arXiv:2207.09653 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@misc{Prasad2022,
	title = {Reconciling {Security} and {Communication} {Efficiency} in {Federated} {Learning}},
	url = {http://arxiv.org/abs/2207.12779},
	abstract = {Cross-device Federated Learning is an increasingly popular machine learning setting to train a model by leveraging a large population of client devices with high privacy and security guarantees. However, communication efﬁciency remains a major bottleneck when scaling federated learning to production environments, particularly due to bandwidth constraints during uplink communication. In this paper, we formalize and address the problem of compressing client-to-server model updates under the Secure Aggregation primitive, a core component of Federated Learning pipelines that allows the server to aggregate the client updates without accessing them individually. In particular, we adapt standard scalar quantization and pruning methods to Secure Aggregation and propose Secure Indexing, a variant of Secure Aggregation that supports quantization for extreme compression. We establish state-of-the-art results on LEAF benchmarks in a secure Federated Learning setup with up to 40× compression in uplink communication with no meaningful loss in utility compared to uncompressed baselines.},
	language = {en},
	urldate = {2022-08-18},
	publisher = {arXiv},
	author = {Prasad, Karthik and Ghosh, Sayan and Cormode, Graham and Mironov, Ilya and Yousefpour, Ashkan and Stock, Pierre},
	month = jul,
	year = {2022},
	note = {arXiv:2207.12779 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
}

@misc{Li2022c,
	title = {Differentially {Private} {Vertical} {Federated} {Clustering}},
	url = {http://arxiv.org/abs/2208.01700},
	abstract = {In many applications, multiple parties have private data regarding the same set of users but on disjoint sets of attributes, and a server wants to leverage the data to train a model. To enable model learning while protecting the privacy of the data subjects, we need vertical federated learning (VFL) techniques, where the data parties share only information for training the model, instead of the private data. However, it is challenging to ensure that the shared information maintains privacy while learning accurate models. To the best of our knowledge, the algorithm proposed in this paper is the first practical solution for differentially private vertical federated 𝑘-means clustering, where the server can obtain a set of global centers with a provable differential privacy guarantee. Our algorithm assumes an untrusted central server that aggregates differentially private local centers and membership encodings from local data parties. It builds a weighted grid as the synopsis of the global dataset based on the received information. Final centers are generated by running any 𝑘-means algorithm on the weighted grid. Our approach for grid weight estimation uses a novel, light-weight, and differentially private set intersection cardinality estimation algorithm based on the Flajolet-Martin sketch. To improve the estimation accuracy in the setting with more than two data parties, we further propose a refined version of the weights estimation algorithm and a parameter tuning strategy to reduce the final 𝑘-means utility to be close to that in the central private setting. We provide theoretical utility analysis and experimental evaluation results for the cluster centers computed by our algorithm and show that our approach performs better both theoretically and empirically than the two baselines based on existing techniques.},
	language = {en},
	urldate = {2022-08-16},
	publisher = {arXiv},
	author = {Li, Zitao and Wang, Tianhao and Li, Ninghui},
	month = aug,
	year = {2022},
	note = {arXiv:2208.01700 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}
